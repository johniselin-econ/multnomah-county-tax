-------------------------------------------------------------
      name:  <unnamed>
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county
> -tax/code/logs/00_log_multnomah_2025-12-16.log
  log type:  text
 opened on:  16 Dec 2025, 15:39:49

. 
. ** Set Seed 
. set seed 56403

. 
. ** Set scheme
. set scheme plotplainblind

. 
. ** Set parameters 
. local overwrite_csv = 0

. global start_year_acs = 2015

. global end_year_acs = 2023

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000002.tmp"

. /**********************************************************
> *********************
> File Name:              02_indiv_analysis.do
> Creator:                John Iselin
> Date Update:    November 29, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform individual-level migration analysis. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> ***********************************************************
> ********************/
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text 
> name(log_02)
-------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county
> -tax/code/logs/02_log_individual_2025-12-16.log
  log type:  text
 opened on:  16 Dec 2025, 15:39:51

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , //
> /
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ====================================================
> ========
.     // Configuration: project root for relative paths
.     // ====================================================
> ========
.     local __project_root "C:/Users/ji252/Documents/GitHub/m
> ultnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "-------------------------------------
> -----------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp'
>  wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'
> "
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `re
> place'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "-------------------------------------
> -----------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ss
> c install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sampl
> e..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlis
> t', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc
>  r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after app
> lying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights
> )
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided we
> ights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' 
> not found. Either create it or pass weights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `
> wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR typ
> es..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `c
> atv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `
> catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year'
> ) force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and cou
> ld not be cleanly converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'
> "
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> 
> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in
>  absorb(): `absorb'. Remove it from absorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datas
> ets)
.     if `__dbg' di as txt "[Step 5] Collecting year and cate
> gory levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in
>  estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyea
> r()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found 
> in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yea
> rv' if `touse' `wgt', absorb(`absorb') vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse'
>  `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients.
> .."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r mi
> ssing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9
> .4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coeffic
> ients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se 
> ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.
> `yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(
> __se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched th
> e expected naming pattern. Plot cannot be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coe
> fficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label 
> to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-categ
> ory)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing t
> o baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(yea
> r==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no obs
> ervations in baseyear(`baseyear'). Cannot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseye
> ar:"
180.                     bysort cat_level: gen __hasbase = !m
> issing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building pl
> ot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c
> '
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels i
> f available
.                         local serieslab "`c'"
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab'
>  `c'
202.                                 if `"`tmp'"' != `""' loc
> al serieslab `"`tmp'"'
203.                         }
204.                         else {
205.                                 local serieslab `"cat=`c
> '"'
206.                         }
207. 
.                         // CI bars (do not appear in legend
> )
.                         if "`noci'" == "" {
208.                                 local ++pnum
209.                                 local plots `plots' ///
>                                         (rcap ll ul year if
>  cat_level==`c', sort legend(off))
210.                         }
211. 
.                         // Connected series (this is what a
> ppears in legend)
.                         local ++pnum
212.                         local plots `plots' ///
>                                 (connected b year if cat_le
> vel==`c', sort)
213. 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
214.                         local leg_labels `leg_labels' la
> bel(`pnum' `"`serieslab'"')
215.                 }
216. 
.                 if `"`plots'"' == `""' {
217.                         di as error "No series were buil
> t for plotting (plotspec empty)."
218.                         exit 2000
219.                 }
220. 
.                 if `__dbgdetail' {
221.                         di as txt "  twoway plot spec (t
> runcated to 200 chars):"
222.                         local tmp = substr("`plots'", 1,
>  200)
223.                         di as txt "    `tmp'..."
224.                         di as txt "  legend order: `leg_
> order'"
225.                         di as txt "  legend labels: `leg
> _labels'"
226.                 }
227. 
.                 // X axis labels: use actual year values pr
> esent in coef dataset
.                 levelsof year, local(xyrs)
228.                 if `__dbg' di as txt "  X-axis years use
> d: `xyrs'"
229. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
230.                 local ytitle_input ""
231.                 local title_input  ""
232. 
.                 // xtitle: default Year unless user explici
> tly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
233.                         local xtitle_input "xtitle(Year)
> "
234.                 }
235.                 else {
236.                         local xtitle_input `"xtitle(`"`x
> title'"')"'
237.                 }
238. 
.                 // ytitle: default depends on baseyear, unl
> ess user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
239.                         if `baseyear' != 0 local ytitle_
> input `"ytitle(`"`varlist' (relative to `baseyear')"')"'
240.                         else              local ytitle_i
> nput `"ytitle(`"`varlist' (adjusted mean)"')"'
241.                 }
242.                 else {
243.                         local ytitle_input `"ytitle(`"`y
> title'"')"'
244.                 }
245. 
.                 // title: allow blank/off if title not supp
> lied
.                 if `"`title'"' != `""' {
246.                         local title_input `"title(`"`tit
> le'"')"'
247.                 }
248. 
.                 if `__dbg' {
249.                         di as txt "  xtitle_input: `xtit
> le_input'"
250.                         di as txt "  ytitle_input: `ytit
> le_input'"
251.                         di as txt "  title_input : `titl
> e_input'"
252.                 }
253. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labe
> ls' position(6) cols(1)) ///
>                         yline(0)
254. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
255. 
.             // Start from saving() value
.             local outpath `"`saving'"'
256. 
.             // Strip embedded double-quotes
.             local outpath : subinstr local outpath `"""' ""
> , all
257. 
.             // Normalize slashes
.             local outpath : subinstr local outpath "\" "/" 
> , all
258. 
.             // If relative path, prepend project root
.             // absolute if it begins with "X:/" or "/"
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr
> ("`outpath'",1,1) != "/" {
259.                 local outpath "`__project_root'`outpath'
> "
260.             }
261. 
.             // Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath
>  "`outpath'.pdf"
262. 
.             // Ensure output directory exists (create it if
>  possible)
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p
> '-1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating out
> put directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory do
> es not exist and could not be created: `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 11] Exporting graph
>  to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", 
> as(pdf) replace
276.             else                graph export "`outpath'"
> , as(pdf)
277.         }
278. 
.     restore
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "-------------------------------------
> -----------------------"
282.     }
283. end

. 
. 
. 
. ** Load ACS Data 
. use "${data}working/acs_migration_file", replace 

. 
. ** Define sample 
. drop if qmigplc1 == 4                                   // 
> FAILED EDIT OF MIGPLACE 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // ALASKA AND HAWAI
> I 
(136,571 observations deleted)

. 
. ** Define indicator for being in Multnomah County in origin
> /destination year
. gen multnomah_o = state_fips_o == 41 & county_fips_o == 51

. gen multnomah_d = state_fips_d == 41 & county_fips_d == 51

. 
. ** Define samples 
. gen sample_1 = multnomah_o == 1                            
>      // Multnomah in origin-year 

. gen sample_2 = multnomah_o != 1                                 // Not in Multnomah

. label var sample_1 "Out-migration Sample"

. label var sample_1 "In-migration Sample"

. 
. ** Define moving indicator 
. gen out_1 = same_county == 0 

. label var out_1 "Moved out of Multnomah"

. gen out_2 = multnomah_d == 1 

. label var out_2 "Moved to Multnomah"

. 
. ** Define variables of interest
. 
. ** Age 
. recode age      (18/24 = 1 "18-24")     ///
>                         (25/44 = 2 "25-44")             ///
>                         (45/64 = 3 "45-64")     ///
>                         (65/max = 4 "65+"),     ///
>         gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex  
. gen cat_sex = sex == 2 

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female"

. label values cat_sex lb_cat_sex 

. 
. ** Marital Status               
. recode marst    (1 = 1 "Married")                               ///
>                                 (2/3 = 2 "Seperated")                   ///
>                                 (4/5 = 3 "Divourced / Widowed") ///
>                                 (6 = 4 "Single"),                               ///
>         gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home 
. recode nchild   (0 = 0 "0 Children")                                    ///
>                                 (1 = 1 "1 Child")                                               
> ///
>                                 (2 = 2 "2 Children")                                    ///
>                                 (3/max = 3 "3+ Children"),                              ///
>         gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education 
. recode educd    (min/61 = 1 "Less than HS")     ///
>                                 (62/71 = 2 "HS Diploma")                ///
>                                 (80/100 = 3 "Some College")     ///
>                                 (101/max = 4 "College Degree"), ///
>         gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. ** Earnings / Income 
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi =  cpi99 / tmp2 

. drop tmp1 tmp2 

. 
. ** Loop over income variables 
. foreach var of varlist inctot incwage incearn ftotinc {
  2.         
.         ** Update CPI 
.         gen real_`var' = round(`var' * cpi) 
  3.         
.         ** Categorical variables 
.         recode real_`var'       (min/-1 = 1 "Negative income")          ///
>                                                 (0 = 2 "$0")                                    
>         ///
>                                                 (1/24999 = 3 "$1-$25K")                         
> ///
>                                                 (25000/49999 = 4 "$25K-$50K")           ///
>                                                 (50000/99999 = 5 "$50K-$100K")          ///
>                                                 (100000/199999 = 6 "$100K-$200K")       ///
>                                                 (200000/max = 7 "$200K+") ,             ///
>                         gen(cat_`var')
  4.                         
.         ** Tab
.         tab cat_`var', m 
  5.         
. }
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. ** Label variable 
. label var cat_inctot "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(`Out not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000003.tmp"

. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab "`c'"
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 if `"`tmp'"' != `""' local serieslab `"`tmp'"'
203.                         }
204.                         else {
205.                                 local serieslab `"cat=`c'"'
206.                         }
207. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
208.                                 local ++pnum
209.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort legend(off))
210.                         }
211. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
212.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
213. 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
214.                         local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
215.                 }
216. 
.                 if `"`plots'"' == `""' {
217.                         di as error "No series were built for plotting (plotspec empty)."
218.                         exit 2000
219.                 }
220. 
.                 if `__dbgdetail' {
221.                         di as txt "  twoway plot spec (truncated to 200 chars):"
222.                         local tmp = substr("`plots'", 1, 200)
223.                         di as txt "    `tmp'..."
224.                         di as txt "  legend order: `leg_order'"
225.                         di as txt "  legend labels: `leg_labels'"
226.                 }
227. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
228.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
229. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
230.                 local ytitle_input ""
231.                 local title_input  ""
232. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
233.                         local xtitle_input "xtitle(Year)"
234.                 }
235.                 else {
236.                         local xtitle_input `"xtitle(`xtitle')"'
237.                 }
238. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
239.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
240.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
241.                 }
242.                 else {
243.                         local ytitle_input `"ytitle(`ytitle')"'
244.                 }
245. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
246.                         local title_input `"title(`title')"'
247.                 }
248. 
.                 if `__dbg' {
249.                         di as txt "  xtitle_input: `xtitle_input'"
250.                         di as txt "  ytitle_input: `ytitle_input'"
251.                         di as txt "  title_input : `title_input'"
252.                 }
253. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) cols(1)) ///
>                         yline(0)
254. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
255. 
.             // Start from saving() value
.             local outpath `saving'
256. 
.             // Strip embedded double-quotes
.             local outpath : subinstr local outpath `"""' "", all
257. 
.             // Normalize slashes
.             local outpath : subinstr local outpath "\" "/" , all
258. 
.             // If relative path, prepend project root
.             // absolute if it begins with "X:/" or "/"
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'",1,1) != "/" {
259.                 local outpath "`__project_root'`outpath'"
260.             }
261. 
.             // Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
262. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p'-1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
276.             else                graph export "`outpath'", as(pdf)
277.         }
278. 
.     restore
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "------------------------------------------------------------"
282.     }
283. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000004.tmp"

. }
} is not a valid command name
r(199);

end of do-file

r(199);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000005.tmp"

. ** Label variable 
. label var cat_inctot "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
Users not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000006.tmp"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug detail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
option detail not allowed
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000007.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort legend(off)) (connected b year if cat_level==0, sort) (
> rcap ll ul year if cat_level==1, sort legend(off)) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 `unknown function 0"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000008.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab "`c'"
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 if `"`tmp'"' != `""' local serieslab `tmp'
203.                         }
204.                         else {
205.                                 local serieslab `"cat=`c'"'
206.                         }
207. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
208.                                 local ++pnum
209.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort legend(off))
210.                         }
211. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
212.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
213. 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
214.                         local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
215.                 }
216. 
.                 if `"`plots'"' == `""' {
217.                         di as error "No series were built for plotting (plotspec empty)."
218.                         exit 2000
219.                 }
220. 
.                 if `__dbgdetail' {
221.                         di as txt "  twoway plot spec (truncated to 200 chars):"
222.                         local tmp = substr("`plots'", 1, 200)
223.                         di as txt "    `tmp'..."
224.                         di as txt "  legend order: `leg_order'"
225.                         di as txt "  legend labels: `leg_labels'"
226.                 }
227. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
228.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
229. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
230.                 local ytitle_input ""
231.                 local title_input  ""
232. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
233.                         local xtitle_input "xtitle(Year)"
234.                 }
235.                 else {
236.                         local xtitle_input `"xtitle(`xtitle')"'
237.                 }
238. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
239.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
240.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
241.                 }
242.                 else {
243.                         local ytitle_input `"ytitle(`ytitle')"'
244.                 }
245. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
246.                         local title_input `"title(`title')"'
247.                 }
248. 
.                 if `__dbg' {
249.                         di as txt "  xtitle_input: `xtitle_input'"
250.                         di as txt "  ytitle_input: `ytitle_input'"
251.                         di as txt "  title_input : `title_input'"
252.                 }
253. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) cols(1)) ///
>                         yline(0)
254. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
255. 
.             // Start from saving() value
.             local outpath `saving'
256. 
.             // Strip embedded double-quotes
.             local outpath : subinstr local outpath `"""' "", all
257. 
.             // Normalize slashes
.             local outpath : subinstr local outpath "\" "/" , all
258. 
.             // If relative path, prepend project root
.             // absolute if it begins with "X:/" or "/"
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'",1,1) != "/" {
259.                 local outpath "`__project_root'`outpath'"
260.             }
261. 
.             // Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
262. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p'-1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
276.             else                graph export "`outpath'", as(pdf)
277.         }
278. 
.     restore
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "------------------------------------------------------------"
282.     }
283. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000009.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort legend(off)) (connected b year if cat_level==0, sort) (
> rcap ll ul year if cat_level==1, sort legend(off)) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 `unknown function 0"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000a.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab "`c'"
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 if `"`tmp'"' != `""' local serieslab "`tmp'"
203.                         }
204.                         else {
205.                                 local serieslab "cat=`c'"
206.                         }
207. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
208.                                 local ++pnum
209.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort legend(off))
210.                         }
211. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
212.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
213. 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
214.                         local leg_labels `leg_labels' label(`pnum' `serieslab')
215.                 }
216. 
.                 if `"`plots'"' == `""' {
217.                         di as error "No series were built for plotting (plotspec empty)."
218.                         exit 2000
219.                 }
220. 
.                 if `__dbgdetail' {
221.                         di as txt "  twoway plot spec (truncated to 200 chars):"
222.                         local tmp = substr("`plots'", 1, 200)
223.                         di as txt "    `tmp'..."
224.                         di as txt "  legend order: `leg_order'"
225.                         di as txt "  legend labels: `leg_labels'"
226.                 }
227. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
228.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
229. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
230.                 local ytitle_input ""
231.                 local title_input  ""
232. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
233.                         local xtitle_input "xtitle(Year)"
234.                 }
235.                 else {
236.                         local xtitle_input `"xtitle(`xtitle')"'
237.                 }
238. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
239.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
240.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
241.                 }
242.                 else {
243.                         local ytitle_input `"ytitle(`ytitle')"'
244.                 }
245. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
246.                         local title_input `"title(`title')"'
247.                 }
248. 
.                 if `__dbg' {
249.                         di as txt "  xtitle_input: `xtitle_input'"
250.                         di as txt "  ytitle_input: `ytitle_input'"
251.                         di as txt "  title_input : `title_input'"
252.                 }
253. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) cols(1)) ///
>                         yline(0)
254. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
255. 
.             // Start from saving() value
.             local outpath `saving'
256. 
.             // Strip embedded double-quotes
.             local outpath : subinstr local outpath `"""' "", all
257. 
.             // Normalize slashes
.             local outpath : subinstr local outpath "\" "/" , all
258. 
.             // If relative path, prepend project root
.             // absolute if it begins with "X:/" or "/"
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'",1,1) != "/" {
259.                 local outpath "`__project_root'`outpath'"
260.             }
261. 
.             // Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
262. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p'-1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
276.             else                graph export "`outpath'", as(pdf)
277.         }
278. 
.     restore
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "------------------------------------------------------------"
282.     }
283. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000b.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort legend(off)) (connected b year if cat_level==0, sort) (
> rcap ll ul year if cat_level==1, sort legend(off)) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 0) label(4 1)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
Users not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000c.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab "`c'"
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 if `"`tmp'"' != `""' local serieslab "`tmp'"
203.                         }
204.                         else {
205.                                 local serieslab `"cat=`c'"'
206.                         }
207. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
208.                                 local ++pnum
209.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort)
210.                         }
211. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
212.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
213. 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
214.                         local leg_labels `leg_labels' label(`pnum' `serieslab'")
215.                 }
216. 
.                 if `"`plots'"' == `""' {
217.                         di as error "No series were built for plotting (plotspec empty)."
218.                         exit 2000
219.                 }
220. 
.                 if `__dbgdetail' {
221.                         di as txt "  twoway plot spec (truncated to 200 chars):"
222.                         local tmp = substr("`plots'", 1, 200)
223.                         di as txt "    `tmp'..."
224.                         di as txt "  legend order: `leg_order'"
225.                         di as txt "  legend labels: `leg_labels'"
226.                 }
227. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
228.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
229. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
230.                 local ytitle_input ""
231.                 local title_input  ""
232. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
233.                         local xtitle_input "xtitle(Year)"
234.                 }
235.                 else {
236.                         local xtitle_input `"xtitle(`xtitle')"'
237.                 }
238. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
239.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
240.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
241.                 }
242.                 else {
243.                         local ytitle_input `"ytitle(`ytitle')"'
244.                 }
245. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
246.                         local title_input `"title(`title')"'
247.                 }
248. 
.                 if `__dbg' {
249.                         di as txt "  xtitle_input: `xtitle_input'"
250.                         di as txt "  ytitle_input: `ytitle_input'"
251.                         di as txt "  title_input : `title_input'"
252.                 }
253. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) cols(1)) ///
>                         yline(0)
254. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
255. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`saving'", "/")
256.             if `p' > 0 {
257.                 local outdir = substr("`saving'", 1, `p'-1)
258.                 if !direxists("`saving'") {
259.                     if `__dbg' di as txt "  Creating output directory: `saving'"
260.                     capture mkdir "`saving'"
261.                     if _rc & !direxists("`saving'") {
262.                         di as error "Output directory does not exist and could not be created
> : `saving'"
263.                         exit 601
264.                     }
265.                 }
266.             }
267. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `saving'"
268. 
.             if "`replace'" != "" graph export "`saving'", as(pdf) replace
269.             else                graph export "`saving'", as(pdf)
270.         }
271. 
.     restore
272. 
.     if `__dbg' {
273.         di as txt "hdfe_catyear_plot DEBUG END"
274.         di as txt "------------------------------------------------------------"
275.     }
276. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000d.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort) (connected b year if cat_level==0, sort) (rcap ll ul y
> ear if cat_level==1, sort) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 0too many ')' or ']'
r(132);

end of do-file

r(132);

. des cat_sex

Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------
cat_sex         float   %9.0g      lb_cat_sex
                                              Female indicator

. local temp: label lb_cat_sex 1

. dis "`temp'"
Female

. local serieslab "1"

. if `"`temp'"' != `""' local serieslab "`temp'"

. des "`serieslab'"
"Female invalid name
r(198);

. des `serieslab'
variable Female not found
r(111);

. dis "`serieslab'"
Female

. if "`temp'" != `""' local serieslab "`temp'"

. dis "`serieslab'"
Female

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000e.tmp"

. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab ""
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 if "`tmp'" != `""' local serieslab "`tmp'"
203.                         }
204.                         else {
205.                                 local serieslab "cat=`c'"
206.                         }
207. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
208.                                 local ++pnum
209.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort)
210.                         }
211. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
212.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
213. 
.                         local tmp "label(`pnum' `serieslab')"
214.                                 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
215.                         local leg_labels `leg_labels' `tmp'
216.                 }
217. 
.                 if `"`plots'"' == `""' {
218.                         di as error "No series were built for plotting (plotspec empty)."
219.                         exit 2000
220.                 }
221. 
.                 if `__dbgdetail' {
222.                         di as txt "  twoway plot spec (truncated to 200 chars):"
223.                         local tmp = substr("`plots'", 1, 200)
224.                         di as txt "    `tmp'..."
225.                         di as txt "  legend order: `leg_order'"
226.                         di as txt "  legend labels: `leg_labels'"
227.                 }
228. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
229.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
230. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
231.                 local ytitle_input ""
232.                 local title_input  ""
233. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
234.                         local xtitle_input "xtitle(Year)"
235.                 }
236.                 else {
237.                         local xtitle_input `"xtitle(`xtitle')"'
238.                 }
239. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
240.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
241.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
242.                 }
243.                 else {
244.                         local ytitle_input `"ytitle(`ytitle')"'
245.                 }
246. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
247.                         local title_input `"title(`title')"'
248.                 }
249. 
.                 if `__dbg' {
250.                         di as txt "  xtitle_input: `xtitle_input'"
251.                         di as txt "  ytitle_input: `ytitle_input'"
252.                         di as txt "  title_input : `title_input'"
253.                 }
254. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) cols(1)) ///
>                         yline(0)
255. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
256. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`saving'", "/")
257.             if `p' > 0 {
258.                 local outdir = substr("`saving'", 1, `p'-1)
259.                 if !direxists("`saving'") {
260.                     if `__dbg' di as txt "  Creating output directory: `saving'"
261.                     capture mkdir "`saving'"
262.                     if _rc & !direxists("`saving'") {
263.                         di as error "Output directory does not exist and could not be created
> : `saving'"
264.                         exit 601
265.                     }
266.                 }
267.             }
268. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `saving'"
269. 
.             if "`replace'" != "" graph export "`saving'", as(pdf) replace
270.             else                graph export "`saving'", as(pdf)
271.         }
272. 
.     restore
273. 
.     if `__dbg' {
274.         di as txt "hdfe_catyear_plot DEBUG END"
275.         di as txt "------------------------------------------------------------"
276.     }
277. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000f.tmp"

. 
. ** Label variable 
. label var cat_inctot "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort) (connected b year if cat_level==0, sort) (rcap ll ul y
> ear if cat_level==1, sort) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 0) label(4 1)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
Users not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000g.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
.         if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
169.             label values cat_level `vlab'
170.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
171.         }
172. 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab ""
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 dis "`tmp'"
203.                                 if "`tmp'" != "" local serieslab "`tmp'"
204.                         }
205.                         else {
206.                                 local serieslab "cat=`c'"
207.                         }
208. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
209.                                 local ++pnum
210.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort)
211.                         }
212. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
213.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
214. 
.                         local tmp "label(`pnum' `serieslab')"
215.                                 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
216.                         local leg_labels `leg_labels' `tmp'
217.                 }
218. 
.                 if `"`plots'"' == `""' {
219.                         di as error "No series were built for plotting (plotspec empty)."
220.                         exit 2000
221.                 }
222. 
.                 if `__dbgdetail' {
223.                         di as txt "  twoway plot spec (truncated to 200 chars):"
224.                         local tmp = substr("`plots'", 1, 200)
225.                         di as txt "    `tmp'..."
226.                         di as txt "  legend order: `leg_order'"
227.                         di as txt "  legend labels: `leg_labels'"
228.                 }
229. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
230.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
231. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
232.                 local ytitle_input ""
233.                 local title_input  ""
234. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
235.                         local xtitle_input "xtitle(Year)"
236.                 }
237.                 else {
238.                         local xtitle_input `"xtitle(`xtitle')"'
239.                 }
240. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
241.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
242.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
243.                 }
244.                 else {
245.                         local ytitle_input `"ytitle(`ytitle')"'
246.                 }
247. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
248.                         local title_input `"title(`title')"'
249.                 }
250. 
.                 if `__dbg' {
251.                         di as txt "  xtitle_input: `xtitle_input'"
252.                         di as txt "  ytitle_input: `ytitle_input'"
253.                         di as txt "  title_input : `title_input'"
254.                 }
255. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) rows(1)) ///
>                         yline(0)
256. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
257. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`saving'", "/")
258.             if `p' > 0 {
259.                 local outdir = substr("`saving'", 1, `p'-1)
260.                 if !direxists("`saving'") {
261.                     if `__dbg' di as txt "  Creating output directory: `saving'"
262.                     capture mkdir "`saving'"
263.                     if _rc & !direxists("`saving'") {
264.                         di as error "Output directory does not exist and could not be created
> : `saving'"
265.                         exit 601
266.                     }
267.                 }
268.             }
269. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `saving'"
270. 
.             if "`replace'" != "" graph export "`saving'", as(pdf) replace
271.             else                graph export "`saving'", as(pdf)
272.         }
273. 
.     restore
274. 
.     if `__dbg' {
275.         di as txt "hdfe_catyear_plot DEBUG END"
276.         di as txt "------------------------------------------------------------"
277.     }
278. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000h.tmp"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
  Applied value label to cat_level: lb_cat_sex
[Step 10] Building plot command...
0
1
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort) (connected b year if cat_level==0, sort) (rcap ll ul y
> ear if cat_level==1, sort) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 0) label(4 1)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
Users not found
r(111);

end of do-file

r(111);

. local vlab "lb_cat_sex"

. local c = 0

. local tmp : label `vlab' `c'

. dis `tmp'
Male not found
r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000i.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
. 
. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
165.             label values cat_level `vlab'
166.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
167.         }
168. 
.                 if `__dbgdetail' {
169.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
170.             list in 1/8, abbrev(24)
171.         }
172.                 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 foreach c of local cats {
197.                         quietly count if cat_level == `c'
198.                         if r(N) == 0 continue
199. 
.                         // Legend label: use value labels if available
.                         local serieslab ""
200.                         if "`vlab'" != "" {
201.                                 local tmp : label `vlab' `c'
202.                                 dis "`tmp'"
203.                                 if "`tmp'" != "" local serieslab "`tmp'"
204.                         }
205.                         else {
206.                                 local serieslab "cat=`c'"
207.                         }
208. 
.                         // CI bars (do not appear in legend)
.                         if "`noci'" == "" {
209.                                 local ++pnum
210.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort)
211.                         }
212. 
.                         // Connected series (this is what appears in legend)
.                         local ++pnum
213.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort)
214. 
.                         local tmp "label(`pnum' `serieslab')"
215.                                 
.                         // Legend: only connected plots
.                         local leg_order  `leg_order' `pnum'
216.                         local leg_labels `leg_labels' `tmp'
217.                 }
218. 
.                 if `"`plots'"' == `""' {
219.                         di as error "No series were built for plotting (plotspec empty)."
220.                         exit 2000
221.                 }
222. 
.                 if `__dbgdetail' {
223.                         di as txt "  twoway plot spec (truncated to 200 chars):"
224.                         local tmp = substr("`plots'", 1, 200)
225.                         di as txt "    `tmp'..."
226.                         di as txt "  legend order: `leg_order'"
227.                         di as txt "  legend labels: `leg_labels'"
228.                 }
229. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
230.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
231. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
232.                 local ytitle_input ""
233.                 local title_input  ""
234. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
235.                         local xtitle_input "xtitle(Year)"
236.                 }
237.                 else {
238.                         local xtitle_input `"xtitle(`xtitle')"'
239.                 }
240. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
241.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
242.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
243.                 }
244.                 else {
245.                         local ytitle_input `"ytitle(`ytitle')"'
246.                 }
247. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
248.                         local title_input `"title(`title')"'
249.                 }
250. 
.                 if `__dbg' {
251.                         di as txt "  xtitle_input: `xtitle_input'"
252.                         di as txt "  ytitle_input: `ytitle_input'"
253.                         di as txt "  title_input : `title_input'"
254.                 }
255. 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' position(6) rows(1)) ///
>                         yline(0)
256. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
257. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`saving'", "/")
258.             if `p' > 0 {
259.                 local outdir = substr("`saving'", 1, `p'-1)
260.                 if !direxists("`saving'") {
261.                     if `__dbg' di as txt "  Creating output directory: `saving'"
262.                     capture mkdir "`saving'"
263.                     if _rc & !direxists("`saving'") {
264.                         di as error "Output directory does not exist and could not be created
> : `saving'"
265.                         exit 601
266.                     }
267.                 }
268.             }
269. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `saving'"
270. 
.             if "`replace'" != "" graph export "`saving'", as(pdf) replace
271.             else                graph export "`saving'", as(pdf)
272.         }
273. 
.     restore
274. 
.     if `__dbg' {
275.         di as txt "hdfe_catyear_plot DEBUG END"
276.         di as txt "------------------------------------------------------------"
277.     }
278. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000j.tmp"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
0
1
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort) (connected b year if cat_level==0, sort) (rcap ll ul y
> ear if cat_level==1, sort) (connected b year if cat_level==1, sort)...
  legend order: 2 4
  legend labels: label(2 0) label(4 1)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
Users not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000k.tmp"

. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  16 Dec 2025, 16:14:23

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
. 
. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
165.             label values cat_level `vlab'
166.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
167.         }
168. 
.                 if `__dbgdetail' {
169.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
170.             list in 1/8, abbrev(24)
171.         }
172.                 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        /// Build twoway spec + legend mapping + consistent colors
>                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 // Legend rows: 1 by default, 2 if more than 4 categories
.                 local ncat : word count `cats'
197.                 local legrows 1
198.                 if `ncat' > 4 local legrows 2
199. 
.                 // Use Stata's default color cycle but ensure each CI matches its line color
.                 // We manually advance the same color index for each category.
.                 local col_i 0
200. 
.                 foreach c of local cats {
201.                         quietly count if cat_level == `c'
202.                         if r(N) == 0 continue
203. 
.                         // ---------------------------------------
.                         // Legend label: use value labels if avail
.                         // ---------------------------------------
.                         local serieslab ""
204.                         if "`vlab'" != "" {
205.                                 local tmp : label `vlab' `c'
206.                                 if `"`tmp'"' != `""' local serieslab `"`tmp'"'
207.                                 else                 local serieslab `"`c'"'
208.                         }
209.                         else {
210.                                 local serieslab `"cat=`c'"'
211.                         }
212. 
.                         // ---------------------------------------
.                         // Pick a color index for this category
.                         // (leverages Stata's default pstyle cycle)
.                         // ---------------------------------------
.                         local ++col_i
213.                         
.                         // color comes from pstyle(p#); CI uses same pstyle but 50% opacity
.                         local pstyle "p`col_i'"
214. 
.                         // ---------------------------------------
.                         // CI bars (not in legend), same color @ 50% opacity
.                         // ---------------------------------------
.                         if "`noci'" == "" {
215.                                 local ++pnum
216.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort ///
>                                                 pstyle(`pstyle') lcolor(%50))
217.                         }
218. 
.                         // ---------------------------------------
.                         // Connected series (IN legend)
.                         // ---------------------------------------
.                         local ++pnum
219.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort ///
>                                         pstyle(`pstyle'))
220. 
.                         // Legend: only connected plots, label safely quoted
.                         local leg_order  `leg_order' `pnum'
221.                         local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
222.                 }
223. 
.                 if `"`plots'"' == `""' {
224.                         di as error "No series were built for plotting (plotspec empty)."
225.                         exit 2000
226.                 }
227. 
.                 if `__dbgdetail' {
228.                         di as txt "  twoway plot spec (truncated to 200 chars):"
229.                         local tmp = substr("`plots'", 1, 200)
230.                         di as txt "    `tmp'..."
231.                         di as txt "  legend order: `leg_order'"
232.                         di as txt "  legend labels: `leg_labels'"
233.                         di as txt "  legend rows: `legrows'"
234.                 }
235. 
. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
236.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
237. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
238.                 local ytitle_input ""
239.                 local title_input  ""
240. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
241.                         local xtitle_input "xtitle(Year)"
242.                 }
243.                 else {
244.                         local xtitle_input `"xtitle(`xtitle')"'
245.                 }
246. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
247.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
248.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
249.                 }
250.                 else {
251.                         local ytitle_input `"ytitle(`ytitle')"'
252.                 }
253. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
254.                         local title_input `"title(`title')"'
255.                 }
256. 
.                 if `__dbg' {
257.                         di as txt "  xtitle_input: `xtitle_input'"
258.                         di as txt "  ytitle_input: `ytitle_input'"
259.                         di as txt "  title_input : `title_input'"
260.                 }
261.                 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>                         yline(0)
262. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
263. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`saving'", "/")
264.             if `p' > 0 {
265.                 local outdir = substr("`saving'", 1, `p'-1)
266.                 if !direxists("`saving'") {
267.                     if `__dbg' di as txt "  Creating output directory: `saving'"
268.                     capture mkdir "`saving'"
269.                     if _rc & !direxists("`saving'") {
270.                         di as error "Output directory does not exist and could not be created
> : `saving'"
271.                         exit 601
272.                     }
273.                 }
274.             }
275. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `saving'"
276. 
.             if "`replace'" != "" graph export "`saving'", as(pdf) replace
277.             else                graph export "`saving'", as(pdf)
278.         }
279. 
.     restore
280. 
.     if `__dbg' {
281.         di as txt "hdfe_catyear_plot DEBUG END"
282.         di as txt "------------------------------------------------------------"
283.     }
284. end

. 
. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000l.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  twoway plot spec (truncated to 200 chars):
    (rcap ll ul year if cat_level==0, sort pstyle(p1) lcolor(%50)) (connected b year if cat_level=
> =0, sort pstyle(p1)) (rcap ll ul year if cat_level==1, sort pstyle(p2) lcolor(%50)) (connected b
>  year if c...
  legend order: 2 4
  legend labels: label(2 `unknown function 0"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000m.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
. 
. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
165.             label values cat_level `vlab'
166.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
167.         }
168. 
.                 if `__dbgdetail' {
169.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
170.             list in 1/8, abbrev(24)
171.         }
172.                 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.        // Build twoway spec + legend mapping + plotplainblind palette
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 // Legend rows: 1 by default, 2 if more than 4 categories
.                 local ncat : word count `cats'
197.                 local legrows 1
198.                 if `ncat' > 4 local legrows 2
199. 
.                 // plotplainblind behavior:
.                 // 1 group -> black
.                 // 2 groups -> black and gray (gs10)
.                 // 3+ groups -> 7 colorblind colors in this order
.                 local collist ""
200.                 if `ncat' == 1 local collist "black"
201.                 else if `ncat' == 2 local collist "black gs10"
202.                 else local collist "sky turquoise orangebrown reddish vermillion sea ananas" 
>   // :contentReference[oaicite:1]{index=1}
203. 
.                 local ncols : word count `collist'
204.                 local ci 0
205. 
.                 foreach c of local cats {
206.                         quietly count if cat_level == `c'
207.                         if r(N) == 0 continue
208. 
.                         // Legend label: value labels if available (safe quoting)
.                         local serieslab ""
209.                         if "`vlab'" != "" {
210.                                 local tmp : label `vlab' `c'
211.                                 if `"`tmp'"' != `""' local serieslab `"`tmp'"'
212.                                 else                 local serieslab `"`c'"'
213.                         }
214.                         else {
215.                                 local serieslab `"cat=`c'"'
216.                         }
217. 
.                         // Pick color (cycle if > #colors)
.                         local ++ci
218.                         local idx = mod(`ci' - 1, `ncols') + 1
219.                         local col : word `idx' of `collist'
220. 
.                         // CI bars (exclude from legend), same color @ 50% opacity
.                         if "`noci'" == "" {
221.                                 local ++pnum
222.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort ///
>                                                 lcolor("`col'%50") legend(off))
223.                         }
224. 
.                         // Connected series (IN legend): line + markers same color
.                         local ++pnum
225.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort ///
>                                         lcolor("`col'") mcolor("`col'"))
226. 
.                         // Legend: only connected plots; label safely quoted
.                         local leg_order  `leg_order' `pnum'
227.                         local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
228.                 }
229. 
.                 if `"`plots'"' == `""' {
230.                         di as error "No series were built for plotting (plotspec empty)."
231.                         exit 2000
232.                 }
233. 
.                 if `__dbgdetail' {
234.                         di as txt "  legend order: `leg_order'"
235.                         di as txt "  legend labels: `leg_labels'"
236.                         di as txt "  legend rows: `legrows'"
237.                         di as txt "  palette used: `collist'"
238.                 }
239. 
. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
240.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
241. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
242.                 local ytitle_input ""
243.                 local title_input  ""
244. 
.                 // xtitle: default Year unless user explicitly passes xtitle("")
.                 if `"`xtitle'"' == `""' {
245.                         local xtitle_input "xtitle(Year)"
246.                 }
247.                 else {
248.                         local xtitle_input `"xtitle(`xtitle')"'
249.                 }
250. 
.                 // ytitle: default depends on baseyear, unless user supplies ytitle("")
.                 if `"`ytitle'"' == `""' {
251.                         if `baseyear' != 0 local ytitle_input `"ytitle(`varlist' (relative to
>  `baseyear')"')"'
252.                         else              local ytitle_input `"ytitle(`varlist' (adjusted mea
> n)"')"'
253.                 }
254.                 else {
255.                         local ytitle_input `"ytitle(`ytitle')"'
256.                 }
257. 
.                 // title: allow blank/off if title not supplied
.                 if `"`title'"' != `""' {
258.                         local title_input `"title(`title')"'
259.                 }
260. 
.                 if `__dbg' {
261.                         di as txt "  xtitle_input: `xtitle_input'"
262.                         di as txt "  ytitle_input: `ytitle_input'"
263.                         di as txt "  title_input : `title_input'"
264.                 }
265.                 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>                         yline(0)
266. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.         if "`saving'" != "" {
267. 
.             // Ensure output directory exists (create it if possible)
.             local p = strrpos("`saving'", "/")
268.             if `p' > 0 {
269.                 local outdir = substr("`saving'", 1, `p'-1)
270.                 if !direxists("`saving'") {
271.                     if `__dbg' di as txt "  Creating output directory: `saving'"
272.                     capture mkdir "`saving'"
273.                     if _rc & !direxists("`saving'") {
274.                         di as error "Output directory does not exist and could not be created
> : `saving'"
275.                         exit 601
276.                     }
277.                 }
278.             }
279. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `saving'"
280. 
.             if "`replace'" != "" graph export "`saving'", as(pdf) replace
281.             else                graph export "`saving'", as(pdf)
282.         }
283. 
.     restore
284. 
.     if `__dbg' {
285.         di as txt "hdfe_catyear_plot DEBUG END"
286.         di as txt "------------------------------------------------------------"
287.     }
288. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000n.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order: 2 4
  legend labels: label(2 `unknown function 0"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000o.tmp"

. 
. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
. 
. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
165.             label values cat_level `vlab'
166.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
167.         }
168. 
.                 if `__dbgdetail' {
169.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
170.             list in 1/8, abbrev(24)
171.         }
172.                 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.       // Build twoway spec + legend mapping + plotplainblind palette
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 // Legend rows: 1 by default, 2 if more than 4 categories
.                 local ncat : word count `cats'
197.                 local legrows 1
198.                 if `ncat' > 4 local legrows 2
199. 
.                 // plotplainblind palette
.                 local collist ""
200.                 if `ncat' == 1 local collist "black"
201.                 else if `ncat' == 2 local collist "black gs10"
202.                 else local collist "sky turquoise orangebrown reddish vermillion sea ananas"
203. 
.                 local ncols : word count `collist'
204.                 local ci 0
205. 
.                 foreach c of local cats {
206.                         quietly count if cat_level == `c'
207.                         if r(N) == 0 continue
208. 
.                         // Legend label (PLAIN TEXT, no quotes stored here)
.                         local serieslab ""
209.                         if "`vlab'" != "" {
210.                                 local serieslab : label `vlab' `c'
211.                                 if "`serieslab'" == "" local serieslab "`c'"
212.                         }
213.                         else {
214.                                 local serieslab "cat=`c'"
215.                         }
216.                         // strip any embedded double quotes just in case
.                         local serieslab : subinstr local serieslab `"""' "", all
217. 
.                         // Pick color (cycle if > #colors)
.                         local ++ci
218.                         local idx = mod(`ci' - 1, `ncols') + 1
219.                         local col : word `idx' of `collist'
220. 
.                         // CI bars (exclude from legend), same color @ 50% opacity
.                         if "`noci'" == "" {
221.                                 local ++pnum
222.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort ///
>                                                 lcolor("`col'%50") legend(off))
223.                         }
224. 
.                         // Connected series (IN legend): line + markers same color
.                         local ++pnum
225.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort ///
>                                         lcolor("`col'") mcolor("`col'"))
226. 
.                         // Legend: only connected plots; label safely quoted here
.                         local leg_order  `leg_order' `pnum'
227.                         local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
228.                 }
229. 
.                 if `"`plots'"' == `""' {
230.                         di as error "No series were built for plotting (plotspec empty)."
231.                         exit 2000
232.                 }
233. 
.                 if `__dbgdetail' {
234.                         di as txt "  legend order: `leg_order'"
235.                         di as txt "  legend labels: `leg_labels'"
236.                         di as txt "  legend rows: `legrows'"
237.                         di as txt "  palette used: `collist'"
238.                 }
239. 
. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
240.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
241. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
242.                 local ytitle_input ""
243.                 local title_input  ""
244. 
.                 // xtitle
.                 if `"`xtitle'"' == `""' {
245.                         local xtitle_input "xtitle(Year)"
246.                 }
247.                 else {
248.                         local xtitle_input `"xtitle(`"`xtitle'"')"'
249.                 }
250. 
.                 // ytitle
.                 if `"`ytitle'"' == `""' {
251.                         if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative 
> to `baseyear')"')"'
252.                         else local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
253.                 }
254.                 else {
255.                         local ytitle_input `"ytitle(`"`ytitle'"')"'
256.                 }
257. 
.                 // title (optional)
.                 if `"`title'"' != `""' {
258.                         local title_input `"title(`"`title'"')"'
259.                 }
260. 
. 
.                 if `__dbg' {
261.                         di as txt "  xtitle_input: `xtitle_input'"
262.                         di as txt "  ytitle_input: `ytitle_input'"
263.                         di as txt "  title_input : `title_input'"
264.                 }
265.                 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>                         yline(0)
266. 
. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.        if "`saving'" != "" {
267.     local outpath `"`saving'"'
268.     local outpath : subinstr local outpath `"""' "", all
269.     local outpath : subinstr local outpath "\" "/" , all
270. 
.     // prepend project root if relative
.     if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'",1,1) != "/" {
271.         local outpath "`__project_root'`outpath'"
272.     }
273. 
.     if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
274. 
.     local p = strrpos("`outpath'", "/")
275.     if `p' > 0 {
276.         local outdir = substr("`outpath'", 1, `p'-1)
277.         if !direxists("`outdir'") {
278.             capture mkdir "`outdir'"
279.             if _rc & !direxists("`outdir'") {
280.                 di as error "Output directory does not exist and could not be created: `outdi
> r'"
281.                 exit 601
282.             }
283.         }
284.     }
285. 
.     if "`replace'" != "" graph export "`outpath'", as(pdf) replace
286.     else                graph export "`outpath'", as(pdf)
287. }
288. 
. 
.     restore
289. 
.     if `__dbg' {
290.         di as txt "hdfe_catyear_plot DEBUG END"
291.         di as txt "------------------------------------------------------------"
292.     }
293. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000p.tmp"

. 
. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order: 2 4
  legend labels: label(2 `unknown function 0"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000q.tmp"

. ** Run Program 
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     // ============================================================
.     // Configuration: project root for relative paths
.     // ============================================================
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     // ---------------------------
.     // Debug helpers (SAFE)
.     // ---------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : "`saving'"   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     // Requirements
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     // Mark sample
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in/sample filters."
 37.         exit 2000
 38.     }
 39. 
.     // Weights (default fw=perwt unless user passed weights)
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == "" local wvar "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     // Ensure cat/year numeric for factor vars
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58.     local cattype : type `cat'
 59.     if substr("`cattype'",1,3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'",1,3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     // Guard: category variable should not also be absorbed
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     // Levels + label (capture label BEFORE we change datasets)
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     // Base year sanity check (only if baseyear != 0)
.     if `baseyear' != 0 {
102.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
103.         local found 0
104.         foreach y of local yrs {
105.             if `y' == `baseyear' local found 1
106.         }
107.         if `found' == 0 {
108.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
109.             exit 459
110.         }
111.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
112.     }
113. 
.     // Regression
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
114.     if "`vce'" == "" local vce "robust"
115.     if `__dbg' {
116.         di as txt "  Command:"
117.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
118.     }
119. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
120. 
.     // Existing coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
121.     local bnames : colnames e(b)
122.     if `__dbg' {
123.         local nb : word count `bnames'
124.         di as txt "  # coefficients in e(b): `nb'"
125.     }
126.     if `__dbgdetail' {
127.         di as txt "  First up to 30 coef names:"
128.         local shown 0
129.         foreach bn of local bnames {
130.             local ++shown
131.             di as txt "    `bn'"
132.             if `shown' >= 30 continue, break
133.         }
134.     }
135. 
.     // Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
136.     capture scalar `crit' = invttail(e(df_r), 0.025)
137.     if _rc scalar `crit' = invnormal(0.975)
138.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
139. 
.     // Post to temp dataset
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
140.     tempfile coefdata
141.     tempname posth
142.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
143. 
.     local posted 0
144.     foreach bn of local bnames {
145.         // Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
146.             local c = real(regexs(1))
147.             local y = real(regexs(2))
148. 
.             scalar __b  = _b[`bn']
149.             scalar __se = _se[`bn']
150.             scalar __ll = __b - scalar(`crit')*__se
151.             scalar __ul = __b + scalar(`crit')*__se
152. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
153.             local ++posted
154.         }
155.     }
156.     postclose `posth'
157. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
158.     if `posted' == 0 {
159.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
160.         exit 459
161.     }
162. 
.     preserve
163.         use `coefdata', clear
164. 
. 
. 
.         // Apply value label to cat_level (if available)
.         if "`vlab'" != "" {
165.             label values cat_level `vlab'
166.             if `__dbg' di as txt "  Applied value label to cat_level: `vlab'"
167.         }
168. 
.                 if `__dbgdetail' {
169.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
170.             list in 1/8, abbrev(24)
171.         }
172.                 
.         // Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
173.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
174.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
175.             quietly count if missing(base_b)
176.             if r(N) > 0 {
177.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
178.                 if `__dbgdetail' {
179.                     di as txt "Categories missing baseyear:"
180.                     bysort cat_level: gen __hasbase = !missing(base_b)
181.                     tab cat_level if __hasbase==0
182.                     drop __hasbase
183.                 }
184.                 exit 459
185.             }
186.             replace b  = b  - base_b
187.             replace ll = ll - base_b
188.             replace ul = ul - base_b
189.             drop base_b
190.         }
191. 
.       // Build twoway spec + legend mapping + plotplainblind palette
.                 if `__dbg' di as txt "[Step 10] Building plot command..."
192.                 local plots ""
193.                 local leg_order ""
194.                 local leg_labels ""
195.                 local pnum 0
196. 
.                 // Legend rows: 1 by default, 2 if more than 4 categories
.                 local ncat : word count `cats'
197.                 local legrows 1
198.                 if `ncat' > 4 local legrows 2
199. 
.                 // plotplainblind palette
.                 local collist ""
200.                 if `ncat' == 1 local collist "black"
201.                 else if `ncat' == 2 local collist "black gs10"
202.                 else local collist "sky turquoise orangebrown reddish vermillion sea ananas"
203. 
.                 local ncols : word count `collist'
204.                 local ci 0
205. 
.                 foreach c of local cats {
206.                         quietly count if cat_level == `c'
207.                         if r(N) == 0 continue
208. 
.                         // Legend label: value labels if available (store as PLAIN text)
.                         local serieslab ""
209.                         if "`vlab'" != "" {
210.                                 local tmp : label `vlab' `c'
211.                                 if "`tmp'" != "" local serieslab "`tmp'"
212.                                 else             local serieslab "`c'"
213.                         }
214.                         else {
215.                                 local serieslab "cat=`c'"
216.                         }
217.                         // remove embedded quotes just in case
.                         local serieslab : subinstr local serieslab `"""' "", all
218. 
. 
.                         // Pick color (cycle if > #colors)
.                         local ++ci
219.                         local idx = mod(`ci' - 1, `ncols') + 1
220.                         local col : word `idx' of `collist'
221. 
.                         // CI bars (exclude from legend), same color @ 50% opacity
.                         if "`noci'" == "" {
222.                                 local ++pnum
223.                                 local plots `plots' ///
>                                         (rcap ll ul year if cat_level==`c', sort ///
>                                                 lcolor("`col'%50") legend(off))
224.                         }
225. 
.                         // Connected series (IN legend): line + markers same color
.                         local ++pnum
226.                         local plots `plots' ///
>                                 (connected b year if cat_level==`c', sort ///
>                                         lcolor("`col'") mcolor("`col'"))
227. 
.                         // Legend: only connected plots; label safely quoted here
.                         local leg_order  `leg_order' `pnum'
228.                         local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
229.                 }
230. 
.                 if `"`plots'"' == `""' {
231.                         di as error "No series were built for plotting (plotspec empty)."
232.                         exit 2000
233.                 }
234. 
.                 if `__dbgdetail' {
235.                         di as txt "  legend order: `leg_order'"
236.                         di as txt "  legend labels: `leg_labels'"
237.                         di as txt "  legend rows: `legrows'"
238.                         di as txt "  palette used: `collist'"
239.                 }
240. 
. 
.                 // X axis labels: use actual year values present in coef dataset
.                 levelsof year, local(xyrs)
241.                 if `__dbg' di as txt "  X-axis years used: `xyrs'"
242. 
.                 // ---------------------------
.                 // Titles as option-strings (safe quoting)
.                 // ---------------------------
.                 local xtitle_input ""
243.                 local ytitle_input ""
244.                 local title_input  ""
245. 
.                 // xtitle
.                 if `"`xtitle'"' == `""' {
246.                         local xtitle_input "xtitle(Year)"
247.                 }
248.                 else {
249.                         local xtitle_input "xtitle(`xtitle')"
250.                 }
251. 
.                 // ytitle
.                 if `"`ytitle'"' == `""' {
252.                         if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative 
> to `baseyear')"')"'
253.                         else local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
254.                 }
255.                 else {
256.                         local ytitle_input "ytitle(`ytitle')"
257.                 }
258. 
.                 // title (optional)
.                 if `"`title'"' != `""' {
259.                         local title_input "title(`title')"
260.                 }
261. 
. 
.                 if `__dbg' {
262.                         di as txt "  xtitle_input: `xtitle_input'"
263.                         di as txt "  ytitle_input: `ytitle_input'"
264.                         di as txt "  title_input : `title_input'"
265.                 }
266.                 
.                 twoway `plots', ///
>                         `xtitle_input' ///
>                         `ytitle_input' ///
>                         `title_input' ///
>                         xlabel(`xyrs', angle(45)) ///
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>                         yline(0)
267. 
. 
. 
.         // ---------------------------
.         // Export figure (PDF) - robust path handling
.         // ---------------------------
.        if "`saving'" != "" {
268.     local outpath `"`saving'"'
269.     local outpath : subinstr local outpath `"""' "", all
270.     local outpath : subinstr local outpath "\" "/" , all
271. 
.     // prepend project root if relative
.     if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'",1,1) != "/" {
272.         local outpath "`__project_root'`outpath'"
273.     }
274. 
.     if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
275. 
.     local p = strrpos("`outpath'", "/")
276.     if `p' > 0 {
277.         local outdir = substr("`outpath'", 1, `p'-1)
278.         if !direxists("`outdir'") {
279.             capture mkdir "`outdir'"
280.             if _rc & !direxists("`outdir'") {
281.                 di as error "Output directory does not exist and could not be created: `outdi
> r'"
282.                 exit 601
283.             }
284.         }
285.     }
286. 
.     if "`replace'" != "" graph export "`outpath'", as(pdf) replace
287.     else                graph export "`outpath'", as(pdf)
288. }
289. 
. 
.     restore
290. 
.     if `__dbg' {
291.         di as txt "hdfe_catyear_plot DEBUG END"
292.         di as txt "------------------------------------------------------------"
293.     }
294. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000r.tmp"

. ** Local categorical variables
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. ** Loop over out- and in-migration 
. forvalues i = 1/2 {
  2.         
.         if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.         if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.         ** Loop over categories
.         foreach cat of local catvars {
  5.                 
.                 ** FEs 
.                 local othercats : list catvars - cat            
  6. 
.                 ** Run Regressions
.                 hdfe_catyear_plot out_`i' if sample_`i' == 1,                   ///
>                         cat(`cat')                                                              
>                         ///
>                         year(year)                                                              
>                         ///
>                         absorb(state_fips_o county_fips_o `othercats')          ///
>                         wvar(perwt) wtype(fw)                                                   
>         ///
>                         ytitle("`ytitle_txt'")                                                  
>         ///
>                         saving("${results}fig_`cat'_`i'") replace debug debugdetail
  7.                 
.         } // END CAT LOOP
  8.         
. } // END SAMPLE LOOP 
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
  Applied value label to cat_level: lb_cat_sex
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order: 2 4
  legend labels: label(2 `unknown function 0"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000s.tmp"

. 
. ** Individual-level Model
. do ${code}02_indiv_analysis_clean.do 

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  16 Dec 2025, 16:32:08

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") legend(off))
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         } ** END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`"`xtitle'"')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input `"ytitle(`"`ytitle'"')"'
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input `"title(`"`title'"')"'
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } ** END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    ** Alaska and Hawaii
unknown function ()
r(133);

end of do-file
r(133);

end of do-file

r(133);

. drop if inlist(state_fips_o, 2, 15)
(136,571 observations deleted)

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000t.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  16 Dec 2025, 16:32:51

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") legend(off))
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         } ** END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`"`xtitle'"')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input `"ytitle(`"`ytitle'"')"'
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input `"title(`"`title'"')"'
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } ** END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } ** END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
program error:  code follows on the same line as close brace
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000u.tmp"

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
variable real_inctot already defined
r(110);

end of do-file

r(110);

. drop real_inctot cat_inctot

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000v.tmp"

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug
  7. 
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C: invalid name
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000w.tmp"

. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") legend(off))
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         } ** END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`"`xtitle'"')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input `"ytitle(`"`ytitle'"')"'
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input `"title(`"`title'"')"'
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } ** END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00000x.tmp"

. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug
  7. 
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[Step 10] Building plot command...
program error:  code follows on the same line as close brace
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000010.tmp"

. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") legend(off))
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`"`xtitle'"')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input `"ytitle(`"`ytitle'"')"'
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input `"title(`"`title'"')"'
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000011.tmp"

. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug
  7. 
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[Step 10] Building plot command...
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(`Out not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000012.tmp"

. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.                 
.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") legend(off))
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`xtitle')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input "ytitle(`ytitle')"
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input "title(`title')"
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000013.tmp"

. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug
  7. 
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[Step 10] Building plot command...
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
[Step 11] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_married
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1      R
> EPLACE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o c
> at_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000014.tmp"

. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug debugdetail
  7.                         
.                         safsda
  8. 
.     } // END CAT LOOP
  9. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order : 2 4
  legend labels: label(2 `unknown function Male"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000015.tmp"

. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.                 
.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") legend(off))
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`xtitle')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input "ytitle(`ytitle')"
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input "title(`title')"
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000016.tmp"

. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug debugdetail
  7.                         
.                         safsda
  8. 
.     } // END CAT LOOP
  9. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order : 2 4
  legend labels: label(2 Male) label(4 Female)
  legend rows  : 1
  palette used : black gs10
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
[Step 11] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
command safsda is unrecognized
r(199);

end of do-file

r(199);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000017.tmp"

. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.                 
.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") )
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`xtitle')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input "ytitle(`ytitle')"
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input "title(`title')"
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000018.tmp"

. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug debugdetail
  7.                         
.                         safsda
  8. 
.     } // END CAT LOOP
  9. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015b.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015b.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015            0          0           0           0 |
  2. |         0   2016   -.00358147   .0006551   -.0048654   -.0022975 |
  3. |         0   2017   -.01718411   .0006244    -.018408   -.0159603 |
  4. |         0   2018   -.00528036   .0006493    -.006553   -.0040077 |
  5. |         0   2019   -.01558494   .0006253   -.0168105   -.0143594 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.01757465    .000622   -.0187937   -.0163556 |
  7. |         0   2021   -.00172437   .0006522   -.0030027    -.000446 |
  8. |         0   2022    .01067317   .0006762    .0093478    .0119985 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order : 2 4
  legend labels: label(2 Male) label(4 Female)
  legend rows  : 1
  palette used : black gs10
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
[Step 11] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
command safsda is unrecognized
r(199);

end of do-file

r(199);

. help reghdfe

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt ], vce(robust) absorb(cat_married)
(MWFE estimator converged in 1 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 1 HDFE group                            F(  17,5546916) =     367.38
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0052
                                                  Adj R-squared   =     0.0052
                                                  Within R-sq.    =     0.0011
                                                  Root MSE        =     0.2426

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.0034776   .0006589    -5.28   0.000     -.004769   -.0021862
  Male#2017  |  -.0168982   .0006284   -26.89   0.000    -.0181298   -.0156665
  Male#2018  |  -.0050804   .0006532    -7.78   0.000    -.0063607   -.0038002
  Male#2019  |  -.0158577   .0006289   -25.21   0.000    -.0170903    -.014625
  Male#2020  |  -.0167172   .0006238   -26.80   0.000    -.0179398   -.0154945
  Male#2021  |  -.0020888   .0006568    -3.18   0.001    -.0033762   -.0008015
  Male#2022  |   .0097692   .0006803    14.36   0.000      .008436    .0111025
  Male#2023  |  -.0094011   .0006458   -14.56   0.000    -.0106667   -.0081354
Female#2015  |   .0000216   .0006558     0.03   0.974    -.0012638     .001307
Female#2016  |  -.0056303   .0006467    -8.71   0.000    -.0068978   -.0043628
Female#2017  |  -.0116009   .0006328   -18.33   0.000    -.0128411   -.0103607
Female#2018  |  -.0147404   .0006224   -23.68   0.000    -.0159603   -.0135205
Female#2019  |  -.0203595   .0006109   -33.33   0.000    -.0215568   -.0191622
Female#2020  |   -.006726   .0006383   -10.54   0.000    -.0079772   -.0054749
Female#2021  |  -.0026078   .0006489    -4.02   0.000    -.0038796    -.001336
Female#2022  |   .0070055   .0006708    10.44   0.000     .0056907    .0083203
Female#2023  |  -.0129453   .0006338   -20.43   0.000    -.0141875   -.0117031
             |
       _cons |   .0702074   .0004739   148.16   0.000     .0692787    .0711362
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
 cat_married |         4           0           4     |
-----------------------------------------------------+

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt ], vce(robust) absorb(cat_married) n
> ocon
(MWFE estimator converged in 1 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 1 HDFE group                            F(  17,5546916) =     367.38
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0052
                                                  Adj R-squared   =     0.0052
                                                  Within R-sq.    =     0.0011
                                                  Root MSE        =     0.2426

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.0034776   .0006589    -5.28   0.000     -.004769   -.0021862
  Male#2017  |  -.0168982   .0006284   -26.89   0.000    -.0181298   -.0156665
  Male#2018  |  -.0050804   .0006532    -7.78   0.000    -.0063607   -.0038002
  Male#2019  |  -.0158577   .0006289   -25.21   0.000    -.0170903    -.014625
  Male#2020  |  -.0167172   .0006238   -26.80   0.000    -.0179398   -.0154945
  Male#2021  |  -.0020888   .0006568    -3.18   0.001    -.0033762   -.0008015
  Male#2022  |   .0097692   .0006803    14.36   0.000      .008436    .0111025
  Male#2023  |  -.0094011   .0006458   -14.56   0.000    -.0106667   -.0081354
Female#2015  |   .0000216   .0006558     0.03   0.974    -.0012638     .001307
Female#2016  |  -.0056303   .0006467    -8.71   0.000    -.0068978   -.0043628
Female#2017  |  -.0116009   .0006328   -18.33   0.000    -.0128411   -.0103607
Female#2018  |  -.0147404   .0006224   -23.68   0.000    -.0159603   -.0135205
Female#2019  |  -.0203595   .0006109   -33.33   0.000    -.0215568   -.0191622
Female#2020  |   -.006726   .0006383   -10.54   0.000    -.0079772   -.0054749
Female#2021  |  -.0026078   .0006489    -4.02   0.000    -.0038796    -.001336
Female#2022  |   .0070055   .0006708    10.44   0.000     .0056907    .0083203
Female#2023  |  -.0129453   .0006338   -20.43   0.000    -.0141875   -.0117031
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-----------------------------------------------------+
 Absorbed FE | Categories  - Redundant  = Num. Coefs |
-------------+---------------------------------------|
 cat_married |         4           0           4     |
-----------------------------------------------------+

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt ], vce(robust) nocon
(MWFE estimator converged in 1 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 1 HDFE group                            F(  17,5546919) =     385.12
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0012
                                                  Adj R-squared   =     0.0012
                                                  Within R-sq.    =     0.0012
                                                  Root MSE        =     0.2431

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.0042477   .0006599    -6.44   0.000    -.0055411   -.0029542
  Male#2017  |  -.0173665   .0006297   -27.58   0.000    -.0186007   -.0161323
  Male#2018  |   -.005938    .000655    -9.07   0.000    -.0072218   -.0046542
  Male#2019  |  -.0157131    .000631   -24.90   0.000    -.0169499   -.0144764
  Male#2020  |  -.0172763   .0006261   -27.59   0.000    -.0185035   -.0160492
  Male#2021  |  -.0020566   .0006579    -3.13   0.002     -.003346   -.0007672
  Male#2022  |   .0106315   .0006825    15.58   0.000     .0092939    .0119692
  Male#2023  |  -.0090805    .000647   -14.03   0.000    -.0103487   -.0078124
Female#2015  |  -.0015981   .0006576    -2.43   0.015    -.0028869   -.0003092
Female#2016  |  -.0076855   .0006466   -11.89   0.000    -.0089528   -.0064182
Female#2017  |  -.0136364   .0006341   -21.50   0.000    -.0148793   -.0123935
Female#2018  |  -.0169529   .0006236   -27.19   0.000    -.0181751   -.0157307
Female#2019  |   -.021578   .0006127   -35.22   0.000    -.0227789   -.0203772
Female#2020  |  -.0084356   .0006408   -13.16   0.000    -.0096915   -.0071797
Female#2021  |  -.0041172   .0006505    -6.33   0.000    -.0053922   -.0028422
Female#2022  |   .0059537   .0006723     8.86   0.000      .004636    .0072715
Female#2023  |  -.0140174   .0006352   -22.07   0.000    -.0152623   -.0127724
------------------------------------------------------------------------------

. summ out_1 if sample_1 & year == 2016 & cat_sex == 0

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
       out_1 |      2,720    .0595588    .2367112          0          1

. summ out_1 if sample_1 & year == 2016 & cat_sex == 0 [fw=perwt ]

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
       out_1 |    298,284    .0668457     .249755          0          1

. reghdfe out_1 ib.cat_sex#ib.year if sample_1 == 1 [fw = perwt ], vce(robust) nocon
invalid varlist
r(198);

. reghdfe out_1 ib.cat_sex#i.year if sample_1 == 1 [fw = perwt ], vce(robust) nocon
invalid varlist
r(198);

. reghdfe out_1 ib.cat_sex if sample_1 == 1 [fw = perwt ], vce(robust) nocon
invalid varlist
r(198);

. help ib

. reghdfe out_1 ib(0).cat_sex if sample_1 == 1 [fw = perwt ], vce(robust) nocon
(MWFE estimator converged in 1 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 1 HDFE group                            F(   1,5546935) =     129.54
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0000
                                                  Adj R-squared   =     0.0000
                                                  Within R-sq.    =     0.0000
                                                  Root MSE        =     0.2432

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
     cat_sex |
     Female  |  -.0023519   .0002066   -11.38   0.000    -.0027569   -.0019469
------------------------------------------------------------------------------

. reghdfe out_1 ib.cat_sex if sample_1 == 1 [fw = perwt ], vce(robust) nocon
invalid varlist
r(198);

. reghdfe out_1 ib(none).cat_sex if sample_1 == 1 [fw = perwt ], vce(robust) nocon
(MWFE estimator converged in 1 iterations)
note: 1.cat_sex omitted because of collinearity

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 1 HDFE group                            F(   1,5546935) =     129.54
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0000
                                                  Adj R-squared   =     0.0000
                                                  Within R-sq.    =     0.0000
                                                  Root MSE        =     0.2432

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
     cat_sex |
       Male  |   .0023519   .0002066    11.38   0.000     .0019469    .0027569
     Female  |          0  (omitted)
------------------------------------------------------------------------------

. regress out_1 ib(none).cat_sex if sample_1 == 1 [fw = perwt ], vce(robust) nocon

Linear regression                               Number of obs     =  5,546,937
                                                F(2, 5546935)     >   99999.00
                                                Prob > F          =     0.0000
                                                R-squared         =     0.0632
                                                Root MSE          =     .24324

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
     cat_sex |
       Male  |   .0643531   .0001485   433.22   0.000     .0640619    .0646442
     Female  |   .0620011   .0001437   431.61   0.000     .0617196    .0622827
------------------------------------------------------------------------------

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000019.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  16 Dec 2025, 17:00:29

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.                 
.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#ib(2019).`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") )
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`xtitle')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input "ytitle(`ytitle')"
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input "title(`title')"
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace ///
>             debug debugdetail
  7.                         
.                         safsda
  8. 
.     } // END CAT LOOP
  9. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome    : out_1
CAT()      : cat_sex
YEAR()     : year
ABSORB()   : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights    : weight= exp= wvar=perwt wtype=fw
VCE()      : 
BASEYEAR() : 0    NOCI: 
SAVING()   : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1      REPLA
> CE: replace
IF/IN      : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year/category levels and labels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex#i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_m
> arried cat_age cat_child cat_educ cat_ftotinc) vce(robust) nocons
[Step 7] Extracting coefficients...
  # coefficients in e(b): 18
  First up to 30 coef names:
    0b.cat_sex#2015.year
    0b.cat_sex#2016.year
    0b.cat_sex#2017.year
    0b.cat_sex#2018.year
    0b.cat_sex#2019b.year
    0b.cat_sex#2020.year
    0b.cat_sex#2021.year
    0b.cat_sex#2022.year
    0b.cat_sex#2023.year
    1.cat_sex#2015.year
    1.cat_sex#2016.year
    1.cat_sex#2017.year
    1.cat_sex#2018.year
    1.cat_sex#2019b.year
    1.cat_sex#2020.year
    1.cat_sex#2021.year
    1.cat_sex#2022.year
    1.cat_sex#2023.year
  CI critical value used:    1.9600
[Step 8] Posting cat×year coefficients to temp dataset...
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
  Rows posted: 18
[DebugDetail] First 8 rows of coefficient dataset:

     +------------------------------------------------------------------+
     | cat_level   year            b         se          ll          ul |
     |------------------------------------------------------------------|
  1. |         0   2015    .01558494   .0006253    .0143594    .0168105 |
  2. |         0   2016    .01200347   .0006119    .0108041    .0132028 |
  3. |         0   2017   -.00159917   .0005801   -.0027362   -.0004622 |
  4. |         0   2018    .01030458    .000606    .0091169    .0114922 |
  5. |         0   2019            0          0           0           0 |
     |------------------------------------------------------------------|
  6. |         0   2020   -.00198971   .0005761   -.0031188   -.0008606 |
  7. |         0   2021    .01386056   .0006092    .0126666    .0150545 |
  8. |         0   2022    .02625811   .0006351    .0250134    .0275028 |
     +------------------------------------------------------------------+
[Step 10] Building plot command...
  legend order : 2 4
  legend labels: label(2 Male) label(4 Female)
  legend rows  : 1
  palette used : black gs10
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  xtitle_input: xtitle(Year)
  ytitle_input: ytitle(Out-migration rate (%))
  title_input : 
[Step 11] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
command safsda is unrecognized
r(199);

end of do-file

r(199);

. help twoway

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001a.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  16 Dec 2025, 17:03:15

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.                 
.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#ib(2019).`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") )
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`xtitle')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input "ytitle(`ytitle')"
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input "title(`title')"
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0, lc(gs7)) yline(2019.5)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace 
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1.pdf saved as
    PDF format
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001b.tmp"

. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace 
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\Documents\GitHub\multnomah-county-tax\code\02_indiv_analysis_clean.do"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  16 Dec 2025, 17:05:52

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ------------------------------------------------------------
.     ** Configuration: project root (used if saving() is relative)
.     ** ------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** ------------------------------------------------------------
.     ** Debug flags (SAFE)
.     ** ------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome    : `varlist'"
 15.         di as txt "CAT()      : `cat'"
 16.         di as txt "YEAR()     : `year'"
 17.         di as txt "ABSORB()   : `absorb'"
 18.         di as txt "Weights    : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()      : `vce'"
 20.         di as txt "BASEYEAR() : `baseyear'    NOCI: `noci'"
 21.         di as txt "SAVING()   : `saving'      REPLACE: `replace'"
 22.         di as txt "IF/IN      : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** ------------------------------------------------------------
.     ** Requirements
.     ** ------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ------------------------------------------------------------
.     ** Mark estimation sample
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ------------------------------------------------------------
.     ** Resolve weights (default fw=perwt unless caller passed weights)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'" == ""  local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48. 
.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Create it or pass weights 
> explicitly."
 51.             exit 111
 52.         }
 53. 
.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ------------------------------------------------------------
.     ** Ensure cat/year numeric (factor-variable friendly)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ------------------------------------------------------------
.     ** Guard: cat variable should not also be absorbed
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ------------------------------------------------------------
.     ** Levels + labels (store label text NOW; used later for legend)
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year/category levels and labels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91. 
.     local vlab : value label `catv'
 92. 
.     if `__dbg' {
 93.         di as txt "  Years: `yrs'"
 94.         di as txt "  Cats : `cats'"
 95.         di as txt "  CAT value label: `vlab'"
 96.     }
 97. 
.     if "`yrs'" == "" | "`cats'" == "" {
 98.         di as error "No year or category levels found in estimation sample."
 99.         exit 2000
100.     }
101. 
.     ** Store label text for each category level (plain text locals)
.     foreach c of local cats {
102.         local __lab_`c' ""
103.         if "`vlab'" != "" {
104.             local tmp : label `vlab' `c'
105.             if "`tmp'" != "" local __lab_`c' "`tmp'"
106.             else             local __lab_`c' "`c'"
107.         }
108.         else {
109.             local __lab_`c' "cat=`c'"
110.         }
111.         ** Strip embedded quotes defensively
.         local __lab_`c' : subinstr local __lab_`c' `"""' "", all
112.                 
.     }
113. 
.     ** ------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** ------------------------------------------------------------
.     if `baseyear' != 0 {
114.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
115.         local found 0
116.         foreach y of local yrs {
117.             if `y' == `baseyear' local found 1
118.         }
119.         if `found' == 0 {
120.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
121.             exit 459
122.         }
123.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
124.     }
125. 
.     ** ------------------------------------------------------------
.     ** Regression
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
126.     if "`vce'" == "" local vce "robust"
127. 
.     if `__dbg' {
128.         di as txt "  Command:"
129.         di as txt "    reghdfe `varlist' i.`catv'#i.`yearv' if `touse' `wgt', absorb(`absorb'
> ) vce(`vce') nocons"
130.     }
131. 
.     quietly reghdfe `varlist' i.`catv'#ib(2019).`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce') nocons
132. 
.     ** Coefficient names
.     if `__dbg' di as txt "[Step 7] Extracting coefficients..."
133.     local bnames : colnames e(b)
134.     if `__dbg' {
135.         local nb : word count `bnames'
136.         di as txt "  # coefficients in e(b): `nb'"
137.     }
138.     if `__dbgdetail' {
139.         di as txt "  First up to 30 coef names:"
140.         local shown 0
141.         foreach bn of local bnames {
142.             local ++shown
143.             di as txt "    `bn'"
144.             if `shown' >= 30 continue, break
145.         }
146.     }
147. 
.     ** Critical value for CI (fallback to normal if df_r missing)
.     tempname crit
148.     capture scalar `crit' = invttail(e(df_r), 0.025)
149.     if _rc scalar `crit' = invnormal(0.975)
150.     if `__dbg' di as txt "  CI critical value used: " %9.4f scalar(`crit')
151. 
.     ** ------------------------------------------------------------
.     ** Post cat×year coefficients to temp dataset
.     ** ------------------------------------------------------------
.     if `__dbg' di as txt "[Step 8] Posting cat×year coefficients to temp dataset..."
152.     tempfile coefdata
153.     tempname posth
154.     postfile `posth' int cat_level int year double b se ll ul using `coefdata', replace
155. 
.     local posted 0
156.     foreach bn of local bnames {
157.         ** Accept base markers: 0b.cat#2015b.year etc.
.         if regexm("`bn'", "^([0-9]+)b?\.`catv'#([0-9]+)b?\.`yearv'$") {
158.             local c = real(regexs(1))
159.             local y = real(regexs(2))
160. 
.             scalar __b  = _b[`bn']
161.             scalar __se = _se[`bn']
162.             scalar __ll = __b - scalar(`crit')*__se
163.             scalar __ul = __b + scalar(`crit')*__se
164. 
.             post `posth' (`c') (`y') (scalar(__b)) (scalar(__se)) (scalar(__ll)) (scalar(__ul))
165.             local ++posted
166.         }
167.     }
168.     postclose `posth'
169. 
.     if `__dbg' di as txt "  Rows posted: `posted'"
170.     if `posted' == 0 {
171.         di as error "No cat×year coefficients matched the expected naming pattern. Plot canno
> t be produced."
172.         exit 459
173.     }
174. 
.     preserve
175.         use `coefdata', clear
176. 
.         if `__dbgdetail' {
177.             di as txt "[DebugDetail] First 8 rows of coefficient dataset:"
178.             list in 1/8, abbrev(24)
179.         }
180. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
181.             if `__dbg' di as txt "[Step 9] Normalizing to baseyear(`baseyear')..."
182.             bysort cat_level: egen base_b = max(cond(year == `baseyear', b, .))
183.             quietly count if missing(base_b)
184.             if r(N) > 0 {
185.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
186.                 exit 459
187.             }
188.             replace b  = b  - base_b
189.             replace ll = ll - base_b
190.             replace ul = ul - base_b
191.             drop base_b
192.         }
193. 
.         ** --------------------------------------------------------
.         ** Build twoway spec + legend mapping + plotplainblind palette
.         ** --------------------------------------------------------
.         if `__dbg' di as txt "[Step 10] Building plot command..."
194.         local plots ""
195.         local leg_order ""
196.         local leg_labels ""
197.         local pnum 0
198. 
.         local ncat : word count `cats'
199.         local legrows 1
200.         if `ncat' > 4 local legrows 2
201. 
.         ** plotplainblind palette (name colors; requires blindschemes/plotplainblind installed)
.         local collist ""
202.         if `ncat' == 1        local collist "black"
203.         else if `ncat' == 2   local collist "black gs10"
204.         else                  local collist "sky turquoise orangebrown reddish vermillion sea
>  ananas"
205. 
.         local ncols : word count `collist'
206.         local ci 0
207. 
.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             ** Series label (from stored locals)
.             local serieslab "`__lab_`c''"
211.             if "`serieslab'" == "" local serieslab "`c'"
212. 
.             ** Pick color (cycle if > #colors)
.             local ++ci
213.             local idx = mod(`ci' - 1, `ncols') + 1
214.             local col : word `idx' of `collist'
215. 
.             ** CI caps (excluded from legend), same color @ 50% opacity
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level == `c', sort ///
>                         lcolor("`col'%50") )
218.             }
219. 
.             ** Connected series (included in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level == `c', sort ///
>                     lcolor("`col'") mcolor("`col'"))
221. 
.             ** Legend: only connected series
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         } // END CAT LEVEL LOOP (plot construction)
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order : `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows  : `legrows'"
232.             di as txt "  palette used : `collist'"
233.         }
234. 
.         ** X-axis labels
.         levelsof year, local(xyrs)
235.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
236. 
.         ** --------------------------------------------------------
.         ** Titles (safe quoting)
.         ** --------------------------------------------------------
.         local xtitle_input ""
237.         local ytitle_input ""
238.         local title_input  ""
239. 
.         if `"`xtitle'"' == `""' {
240.             local xtitle_input "xtitle(Year)"
241.         }
242.         else {
243.             local xtitle_input `"xtitle(`xtitle')"'
244.         }
245. 
.         if `"`ytitle'"' == `""' {
246.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
247.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
248.         }
249.         else {
250.             local ytitle_input "ytitle(`ytitle')"
251.         }
252. 
.         if `"`title'"' != `""' {
253.             local title_input "title(`title')"
254.         }
255. 
.         if `__dbg' {
256.             di as txt "  xtitle_input: `xtitle_input'"
257.             di as txt "  ytitle_input: `ytitle_input'"
258.             di as txt "  title_input : `title_input'"
259.         }
260. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0, lc(gs7)) yline(5.5)
261. 
.         ** --------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** --------------------------------------------------------
.         if "`saving'" != "" {
262.             local outpath `"`saving'"'
263. 
.             ** Strip embedded quotes and normalize slashes
.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 11] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284.         } // END EXPORT BLOCK
285. 
.     restore
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace 
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_1.pdf saved as PDF
    format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_child_1.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_educ_1.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_ftotinc_1.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_2.pdf saved as PDF
    format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_2.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_2.pdf saved as PDF
    format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_child_2.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_educ_2.pdf saved as
    PDF format
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000001.tmp not found)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_ftotinc_2.pdf saved as
    PDF format

. 
. 
. ** ---------------------------------------------------------------------------
. ** Close log
. ** ---------------------------------------------------------------------------
. clear

. log close log_02
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 closed on:  16 Dec 2025, 20:10:12
--------------------------------------------------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001c.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 09:17:29

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   ** END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   ** END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins i.`catv', over(`yearv') saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         local catcol "`catv'"
137.         capture confirm variable `catcol'
138.         if _rc {
139.             local catcol "`cat'"
140.             capture confirm variable `catcol'
141.         }
142.         if _rc {
143.             di as error "Could not find category variable in margins output (tried: `catv' an
> d `cat')."
144.             exit 459
145.         }
146. 
.         local yearcol "`yearv'"
147.         capture confirm variable `yearcol'
148.         if _rc {
149.             local yearcol "`year'"
150.             capture confirm variable `yearcol'
151.         }
152.         if _rc {
153.             di as error "Could not find year variable in margins output (tried: `yearv' and `
> year')."
154.             exit 459
155.         }
156. 
.         ** Standardize variable names
.         rename `catcol'  cat_level
157.         rename `yearcol' year
158.         capture confirm variable _margin
159.         if _rc {
160.             di as error "margins output missing _margin. Cannot proceed."
161.             exit 459
162.         }
163.         rename _margin b
164.         capture confirm variable _se
165.         if !_rc rename _se se
166.         capture confirm variable _ci_lb
167.         if !_rc rename _ci_lb ll
168.         capture confirm variable _ci_ub
169.         if !_rc rename _ci_ub ul
170. 
.         if `__dbgdetail' {
171.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
172.             list in 1/8, abbrev(24)
173.         }
174. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
175.         if _rc {
176.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
177.             exit 459
178.         }
179. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
180.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
181.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
182.             quietly count if missing(base_b)
183.             if r(N) > 0 {
184.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
185.                 exit 459
186.             }
187.             replace b  = b  - base_b
188.             capture confirm variable ll
189.             if !_rc replace ll = ll - base_b
190.             capture confirm variable ul
191.             if !_rc replace ul = ul - base_b
192.             drop base_b
193.         }   ** END BASEYEAR NORMALIZATION
194. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
195.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
196. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
197.         capture set scheme plotplainblind
198.         if _rc {
199.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
200.         }
201.         else {
202.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
203.         }
204. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
205.         local plots ""
206.         local leg_order ""
207.         local leg_labels ""
208.         local pnum 0
209. 
.         local cats_n : word count `cats'
210.         local legrows 1
211.         if `cats_n' > 4 local legrows 2
212. 
.         local i 0
213.         foreach c of local cats {
214.             quietly count if cat_level == `c'
215.             if r(N) == 0 continue
216. 
.             local ++i
217.             local pstyle "p`i'"
218. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
219.             local __key : subinstr local __key "-" "m", all
220.             local serieslab "``__lab_`__key''"
221. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
222.                 local ++pnum
223.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
224.             }
225. 
.             ** Line (in legend)
.             local ++pnum
226.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
227. 
.             local leg_order  `leg_order' `pnum'
228.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
229.         }   ** END CATEGORY PLOT LOOP
230. 
.         if `"`plots'"' == `""' {
231.             di as error "No series were built for plotting (plotspec empty)."
232.             exit 2000
233.         }
234. 
.         if `__dbgdetail' {
235.             di as txt "  legend order: `leg_order'"
236.             di as txt "  legend labels: `leg_labels'"
237.             di as txt "  legend rows: `legrows'"
238.         }
239. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
240.         local ytitle_input ""
241.         local title_input  ""
242. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
243.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
244. 
.         if `"`ytitle'"' == `""' {
245.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
246.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
247.         }
248.         else {
249.             local ytitle_input `"ytitle(`"`ytitle'"')"'
250.         }
251. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
252. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0, lc(gs7))  xline(5.5)
253. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
254. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
255. 
.             local outpath `"`saving'"'
256.             local outpath : subinstr local outpath `"""' "", all
257.             local outpath : subinstr local outpath "\" "/" , all
258. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
259.                 local outpath "`__project_root'`outpath'"
260.             }
261. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
262. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p' - 1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
276.             else                graph export "`outpath'", as(pdf)
277. 
.         }   ** END PDF EXPORT
278. 
.     restore    ** END PRESERVE BLOCK
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "------------------------------------------------------------"
282.     }
283. 
. end

. 
. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace 
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
program error:  code follows on the same line as close brace
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001d.tmp"

. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   ** END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins i.`catv', over(`yearv') saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         local catcol "`catv'"
137.         capture confirm variable `catcol'
138.         if _rc {
139.             local catcol "`cat'"
140.             capture confirm variable `catcol'
141.         }
142.         if _rc {
143.             di as error "Could not find category variable in margins output (tried: `catv' an
> d `cat')."
144.             exit 459
145.         }
146. 
.         local yearcol "`yearv'"
147.         capture confirm variable `yearcol'
148.         if _rc {
149.             local yearcol "`year'"
150.             capture confirm variable `yearcol'
151.         }
152.         if _rc {
153.             di as error "Could not find year variable in margins output (tried: `yearv' and `
> year')."
154.             exit 459
155.         }
156. 
.         ** Standardize variable names
.         rename `catcol'  cat_level
157.         rename `yearcol' year
158.         capture confirm variable _margin
159.         if _rc {
160.             di as error "margins output missing _margin. Cannot proceed."
161.             exit 459
162.         }
163.         rename _margin b
164.         capture confirm variable _se
165.         if !_rc rename _se se
166.         capture confirm variable _ci_lb
167.         if !_rc rename _ci_lb ll
168.         capture confirm variable _ci_ub
169.         if !_rc rename _ci_ub ul
170. 
.         if `__dbgdetail' {
171.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
172.             list in 1/8, abbrev(24)
173.         }
174. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
175.         if _rc {
176.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
177.             exit 459
178.         }
179. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
180.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
181.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
182.             quietly count if missing(base_b)
183.             if r(N) > 0 {
184.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
185.                 exit 459
186.             }
187.             replace b  = b  - base_b
188.             capture confirm variable ll
189.             if !_rc replace ll = ll - base_b
190.             capture confirm variable ul
191.             if !_rc replace ul = ul - base_b
192.             drop base_b
193.         }   // END BASEYEAR NORMALIZATION
194. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
195.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
196. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
197.         capture set scheme plotplainblind
198.         if _rc {
199.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
200.         }
201.         else {
202.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
203.         }
204. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
205.         local plots ""
206.         local leg_order ""
207.         local leg_labels ""
208.         local pnum 0
209. 
.         local cats_n : word count `cats'
210.         local legrows 1
211.         if `cats_n' > 4 local legrows 2
212. 
.         local i 0
213.         foreach c of local cats {
214.             quietly count if cat_level == `c'
215.             if r(N) == 0 continue
216. 
.             local ++i
217.             local pstyle "p`i'"
218. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
219.             local __key : subinstr local __key "-" "m", all
220.             local serieslab "``__lab_`__key''"
221. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
222.                 local ++pnum
223.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
224.             }
225. 
.             ** Line (in legend)
.             local ++pnum
226.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
227. 
.             local leg_order  `leg_order' `pnum'
228.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
229.         }   ** END CATEGORY PLOT LOOP
230. 
.         if `"`plots'"' == `""' {
231.             di as error "No series were built for plotting (plotspec empty)."
232.             exit 2000
233.         }
234. 
.         if `__dbgdetail' {
235.             di as txt "  legend order: `leg_order'"
236.             di as txt "  legend labels: `leg_labels'"
237.             di as txt "  legend rows: `legrows'"
238.         }
239. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
240.         local ytitle_input ""
241.         local title_input  ""
242. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
243.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
244. 
.         if `"`ytitle'"' == `""' {
245.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
246.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
247.         }
248.         else {
249.             local ytitle_input `"ytitle(`"`ytitle'"')"'
250.         }
251. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
252. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0, lc(gs7))  xline(5.5)
253. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
254. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
255. 
.             local outpath `"`saving'"'
256.             local outpath : subinstr local outpath `"""' "", all
257.             local outpath : subinstr local outpath "\" "/" , all
258. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
259.                 local outpath "`__project_root'`outpath'"
260.             }
261. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
262. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p' - 1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
276.             else                graph export "`outpath'", as(pdf)
277. 
.         }   // END PDF EXPORT
278. 
.     restore    // END PRESERVE BLOCK
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "------------------------------------------------------------"
282.     }
283. 
. end

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001e.tmp"

. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace 
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
program error:  code follows on the same line as close brace
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001f.tmp"

. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins i.`catv', over(`yearv') saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         local catcol "`catv'"
137.         capture confirm variable `catcol'
138.         if _rc {
139.             local catcol "`cat'"
140.             capture confirm variable `catcol'
141.         }
142.         if _rc {
143.             di as error "Could not find category variable in margins output (tried: `catv' an
> d `cat')."
144.             exit 459
145.         }
146. 
.         local yearcol "`yearv'"
147.         capture confirm variable `yearcol'
148.         if _rc {
149.             local yearcol "`year'"
150.             capture confirm variable `yearcol'
151.         }
152.         if _rc {
153.             di as error "Could not find year variable in margins output (tried: `yearv' and `
> year')."
154.             exit 459
155.         }
156. 
.         ** Standardize variable names
.         rename `catcol'  cat_level
157.         rename `yearcol' year
158.         capture confirm variable _margin
159.         if _rc {
160.             di as error "margins output missing _margin. Cannot proceed."
161.             exit 459
162.         }
163.         rename _margin b
164.         capture confirm variable _se
165.         if !_rc rename _se se
166.         capture confirm variable _ci_lb
167.         if !_rc rename _ci_lb ll
168.         capture confirm variable _ci_ub
169.         if !_rc rename _ci_ub ul
170. 
.         if `__dbgdetail' {
171.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
172.             list in 1/8, abbrev(24)
173.         }
174. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
175.         if _rc {
176.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
177.             exit 459
178.         }
179. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
180.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
181.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
182.             quietly count if missing(base_b)
183.             if r(N) > 0 {
184.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
185.                 exit 459
186.             }
187.             replace b  = b  - base_b
188.             capture confirm variable ll
189.             if !_rc replace ll = ll - base_b
190.             capture confirm variable ul
191.             if !_rc replace ul = ul - base_b
192.             drop base_b
193.         }   // END BASEYEAR NORMALIZATION
194. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
195.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
196. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
197.         capture set scheme plotplainblind
198.         if _rc {
199.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
200.         }
201.         else {
202.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
203.         }
204. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
205.         local plots ""
206.         local leg_order ""
207.         local leg_labels ""
208.         local pnum 0
209. 
.         local cats_n : word count `cats'
210.         local legrows 1
211.         if `cats_n' > 4 local legrows 2
212. 
.         local i 0
213.         foreach c of local cats {
214.             quietly count if cat_level == `c'
215.             if r(N) == 0 continue
216. 
.             local ++i
217.             local pstyle "p`i'"
218. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
219.             local __key : subinstr local __key "-" "m", all
220.             local serieslab "``__lab_`__key''"
221. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
222.                 local ++pnum
223.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
224.             }
225. 
.             ** Line (in legend)
.             local ++pnum
226.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
227. 
.             local leg_order  `leg_order' `pnum'
228.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
229.         }   ** END CATEGORY PLOT LOOP
230. 
.         if `"`plots'"' == `""' {
231.             di as error "No series were built for plotting (plotspec empty)."
232.             exit 2000
233.         }
234. 
.         if `__dbgdetail' {
235.             di as txt "  legend order: `leg_order'"
236.             di as txt "  legend labels: `leg_labels'"
237.             di as txt "  legend rows: `legrows'"
238.         }
239. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
240.         local ytitle_input ""
241.         local title_input  ""
242. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
243.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
244. 
.         if `"`ytitle'"' == `""' {
245.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
246.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
247.         }
248.         else {
249.             local ytitle_input `"ytitle(`"`ytitle'"')"'
250.         }
251. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
252. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0, lc(gs7))  xline(5.5)
253. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
254. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
255. 
.             local outpath `"`saving'"'
256.             local outpath : subinstr local outpath `"""' "", all
257.             local outpath : subinstr local outpath "\" "/" , all
258. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
259.                 local outpath "`__project_root'`outpath'"
260.             }
261. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
262. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
263.             if `p' > 0 {
264.                 local outdir = substr("`outpath'", 1, `p' - 1)
265.                 if !direxists("`outdir'") {
266.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
267.                     capture mkdir "`outdir'"
268.                     if _rc & !direxists("`outdir'") {
269.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
270.                         exit 601
271.                     }
272.                 }
273.             }
274. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
275. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
276.             else                graph export "`outpath'", as(pdf)
277. 
.         }   // END PDF EXPORT
278. 
.     restore    // END PRESERVE BLOCK
279. 
.     if `__dbg' {
280.         di as txt "hdfe_catyear_plot DEBUG END"
281.         di as txt "------------------------------------------------------------"
282.     }
283. 
. end

. 
. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001g.tmp"

. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace 
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(Created by command margins; also see char list)
Could not find category variable in margins output (tried: cat_sex and cat_sex).
r(459);

end of do-file

r(459);

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt] , vce(robust) absorb(state_fips_o c
> ounty_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 3 HDFE groups                           F(  17,5546916) =     367.38
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0052
                                                  Adj R-squared   =     0.0052
                                                  Within R-sq.    =     0.0011
                                                  Root MSE        =     0.2426

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.0034776   .0006589    -5.28   0.000     -.004769   -.0021862
  Male#2017  |  -.0168982   .0006284   -26.89   0.000    -.0181298   -.0156665
  Male#2018  |  -.0050804   .0006532    -7.78   0.000    -.0063607   -.0038002
  Male#2019  |  -.0158577   .0006289   -25.21   0.000    -.0170903    -.014625
  Male#2020  |  -.0167172   .0006238   -26.80   0.000    -.0179398   -.0154945
  Male#2021  |  -.0020888   .0006568    -3.18   0.001    -.0033762   -.0008015
  Male#2022  |   .0097692   .0006803    14.36   0.000      .008436    .0111025
  Male#2023  |  -.0094011   .0006458   -14.56   0.000    -.0106667   -.0081354
Female#2015  |   .0000216   .0006558     0.03   0.974    -.0012638     .001307
Female#2016  |  -.0056303   .0006467    -8.71   0.000    -.0068978   -.0043628
Female#2017  |  -.0116009   .0006328   -18.33   0.000    -.0128411   -.0103607
Female#2018  |  -.0147404   .0006224   -23.68   0.000    -.0159603   -.0135205
Female#2019  |  -.0203595   .0006109   -33.33   0.000    -.0215568   -.0191622
Female#2020  |   -.006726   .0006383   -10.54   0.000    -.0079772   -.0054749
Female#2021  |  -.0026078   .0006489    -4.02   0.000    -.0038796    -.001336
Female#2022  |   .0070055   .0006708    10.44   0.000     .0056907    .0083203
Female#2023  |  -.0129453   .0006338   -20.43   0.000    -.0141875   -.0117031
             |
       _cons |   .0702074   .0004739   148.16   0.000     .0692787    .0711362
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. margins i.cat_sex, over(year) post

Predictive margins                                   Number of obs = 5,546,937
Model VCE: Robust

Expression: Linear prediction, predict()
Over:       year

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
year#cat_sex |
  2015#Male  |   .0702074   .0004739   148.16   0.000     .0692787    .0711362
2015#Female  |    .070229   .0004527   155.15   0.000     .0693418    .0711162
  2016#Male  |   .0667298   .0004581   145.67   0.000      .065832    .0676277
2016#Female  |   .0645771   .0004394   146.97   0.000      .063716    .0654383
  2017#Male  |   .0533093   .0004131   129.05   0.000     .0524996    .0541189
2017#Female  |   .0586065   .0004188   139.95   0.000     .0577857    .0594273
  2018#Male  |    .065127     .00045   144.74   0.000     .0642451    .0660089
2018#Female  |    .055467   .0004035   137.48   0.000     .0546762    .0562578
  2019#Male  |   .0543498   .0004131   131.56   0.000     .0535401    .0551595
2019#Female  |    .049848   .0003847   129.58   0.000      .049094    .0506019
  2020#Male  |   .0534903   .0004058   131.83   0.000      .052695    .0542855
2020#Female  |   .0634814   .0004274   148.53   0.000     .0626437    .0643191
  2021#Male  |   .0681186   .0004548   149.79   0.000     .0672273    .0690099
2021#Female  |   .0675997   .0004428   152.67   0.000     .0667319    .0684675
  2022#Male  |   .0799767   .0004874   164.09   0.000     .0790214     .080932
2022#Female  |    .077213   .0004746   162.70   0.000     .0762828    .0781431
  2023#Male  |   .0608064   .0004385   138.67   0.000      .059947    .0616658
2023#Female  |   .0572621   .0004203   136.24   0.000     .0564384    .0580859
------------------------------------------------------------------------------

.     tempfile __margdata

. margins i.cat_sex, over(year) post saving(`__margdata')
margins cannot work with its own posted results
r(322);

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt] , vce(robust) absorb(state_fips_o c
> ounty_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 3 HDFE groups                           F(  17,5546916) =     367.38
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0052
                                                  Adj R-squared   =     0.0052
                                                  Within R-sq.    =     0.0011
                                                  Root MSE        =     0.2426

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.0034776   .0006589    -5.28   0.000     -.004769   -.0021862
  Male#2017  |  -.0168982   .0006284   -26.89   0.000    -.0181298   -.0156665
  Male#2018  |  -.0050804   .0006532    -7.78   0.000    -.0063607   -.0038002
  Male#2019  |  -.0158577   .0006289   -25.21   0.000    -.0170903    -.014625
  Male#2020  |  -.0167172   .0006238   -26.80   0.000    -.0179398   -.0154945
  Male#2021  |  -.0020888   .0006568    -3.18   0.001    -.0033762   -.0008015
  Male#2022  |   .0097692   .0006803    14.36   0.000      .008436    .0111025
  Male#2023  |  -.0094011   .0006458   -14.56   0.000    -.0106667   -.0081354
Female#2015  |   .0000216   .0006558     0.03   0.974    -.0012638     .001307
Female#2016  |  -.0056303   .0006467    -8.71   0.000    -.0068978   -.0043628
Female#2017  |  -.0116009   .0006328   -18.33   0.000    -.0128411   -.0103607
Female#2018  |  -.0147404   .0006224   -23.68   0.000    -.0159603   -.0135205
Female#2019  |  -.0203595   .0006109   -33.33   0.000    -.0215568   -.0191622
Female#2020  |   -.006726   .0006383   -10.54   0.000    -.0079772   -.0054749
Female#2021  |  -.0026078   .0006489    -4.02   0.000    -.0038796    -.001336
Female#2022  |   .0070055   .0006708    10.44   0.000     .0056907    .0083203
Female#2023  |  -.0129453   .0006338   -20.43   0.000    -.0141875   -.0117031
             |
       _cons |   .0702074   .0004739   148.16   0.000     .0692787    .0711362
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. margins i.cat_sex, over(year) post saving(`__margdata')

Predictive margins                                   Number of obs = 5,546,937
Model VCE: Robust

Expression: Linear prediction, predict()
Over:       year

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
year#cat_sex |
  2015#Male  |   .0702074   .0004739   148.16   0.000     .0692787    .0711362
2015#Female  |    .070229   .0004527   155.15   0.000     .0693418    .0711162
  2016#Male  |   .0667298   .0004581   145.67   0.000      .065832    .0676277
2016#Female  |   .0645771   .0004394   146.97   0.000      .063716    .0654383
  2017#Male  |   .0533093   .0004131   129.05   0.000     .0524996    .0541189
2017#Female  |   .0586065   .0004188   139.95   0.000     .0577857    .0594273
  2018#Male  |    .065127     .00045   144.74   0.000     .0642451    .0660089
2018#Female  |    .055467   .0004035   137.48   0.000     .0546762    .0562578
  2019#Male  |   .0543498   .0004131   131.56   0.000     .0535401    .0551595
2019#Female  |    .049848   .0003847   129.58   0.000      .049094    .0506019
  2020#Male  |   .0534903   .0004058   131.83   0.000      .052695    .0542855
2020#Female  |   .0634814   .0004274   148.53   0.000     .0626437    .0643191
  2021#Male  |   .0681186   .0004548   149.79   0.000     .0672273    .0690099
2021#Female  |   .0675997   .0004428   152.67   0.000     .0667319    .0684675
  2022#Male  |   .0799767   .0004874   164.09   0.000     .0790214     .080932
2022#Female  |    .077213   .0004746   162.70   0.000     .0762828    .0781431
  2023#Male  |   .0608064   .0004385   138.67   0.000      .059947    .0616658
2023#Female  |   .0572621   .0004203   136.24   0.000     .0564384    .0580859
------------------------------------------------------------------------------

.  use `__margdata', clear
(Created by command margins; also see char list)

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt] , vce(robust) absorb(state_fips_o c
> ounty_fips_o cat_married)
variable out_1 not found
r(111);

. clear

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001h.tmp"

. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
end of do-file

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt] , vce(robust) absorb(state_fips_o c
> ounty_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 3 HDFE groups                           F(  17,5546916) =     367.38
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0052
                                                  Adj R-squared   =     0.0052
                                                  Within R-sq.    =     0.0011
                                                  Root MSE        =     0.2426

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.0034776   .0006589    -5.28   0.000     -.004769   -.0021862
  Male#2017  |  -.0168982   .0006284   -26.89   0.000    -.0181298   -.0156665
  Male#2018  |  -.0050804   .0006532    -7.78   0.000    -.0063607   -.0038002
  Male#2019  |  -.0158577   .0006289   -25.21   0.000    -.0170903    -.014625
  Male#2020  |  -.0167172   .0006238   -26.80   0.000    -.0179398   -.0154945
  Male#2021  |  -.0020888   .0006568    -3.18   0.001    -.0033762   -.0008015
  Male#2022  |   .0097692   .0006803    14.36   0.000      .008436    .0111025
  Male#2023  |  -.0094011   .0006458   -14.56   0.000    -.0106667   -.0081354
Female#2015  |   .0000216   .0006558     0.03   0.974    -.0012638     .001307
Female#2016  |  -.0056303   .0006467    -8.71   0.000    -.0068978   -.0043628
Female#2017  |  -.0116009   .0006328   -18.33   0.000    -.0128411   -.0103607
Female#2018  |  -.0147404   .0006224   -23.68   0.000    -.0159603   -.0135205
Female#2019  |  -.0203595   .0006109   -33.33   0.000    -.0215568   -.0191622
Female#2020  |   -.006726   .0006383   -10.54   0.000    -.0079772   -.0054749
Female#2021  |  -.0026078   .0006489    -4.02   0.000    -.0038796    -.001336
Female#2022  |   .0070055   .0006708    10.44   0.000     .0056907    .0083203
Female#2023  |  -.0129453   .0006338   -20.43   0.000    -.0141875   -.0117031
             |
       _cons |   .0702074   .0004739   148.16   0.000     .0692787    .0711362
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. do "C:\Users\ji252\Documents\GitHub\multnomah-county-tax\code\02_indiv_analysis_clean.do"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 09:57:45

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string asis) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   ** END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   ** END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   ** END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   ** END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
247. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
248. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
249. 
.             local outpath `"`saving'"'
250.             local outpath : subinstr local outpath `"""' "", all
251.             local outpath : subinstr local outpath "\" "/" , all
252. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
253.                 local outpath "`__project_root'`outpath'"
254.             }
255. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
256. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
257.             if `p' > 0 {
258.                 local outdir = substr("`outpath'", 1, `p' - 1)
259.                 if !direxists("`outdir'") {
260.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
261.                     capture mkdir "`outdir'"
262.                     if _rc & !direxists("`outdir'") {
263.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
264.                         exit 601
265.                     }
266.                 }
267.             }
268. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
269. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
270.             else                graph export "`outpath'", as(pdf)
271. 
.         }   ** END PDF EXPORT
272. 
.     restore    ** END PRESERVE BLOCK
273. 
.     if `__dbg' {
274.         di as txt "hdfe_catyear_plot DEBUG END"
275.         di as txt "------------------------------------------------------------"
276.     }
277. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C: invalid name
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001i.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:00:34

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   ** END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   ** END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   ** END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   ** END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
247. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
248. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
249. 
.             local outpath `"`saving'"'
250.             local outpath : subinstr local outpath `"""' "", all
251.             local outpath : subinstr local outpath "\" "/" , all
252. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
253.                 local outpath "`__project_root'`outpath'"
254.             }
255. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
256. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
257.             if `p' > 0 {
258.                 local outdir = substr("`outpath'", 1, `p' - 1)
259.                 if !direxists("`outdir'") {
260.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
261.                     capture mkdir "`outdir'"
262.                     if _rc & !direxists("`outdir'") {
263.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
264.                         exit 601
265.                     }
266.                 }
267.             }
268. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
269. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
270.             else                graph export "`outpath'", as(pdf)
271. 
.         }   ** END PDF EXPORT
272. 
.     restore    ** END PRESERVE BLOCK
273. 
.     if `__dbg' {
274.         di as txt "hdfe_catyear_plot DEBUG END"
275.         di as txt "------------------------------------------------------------"
276.     }
277. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
program error:  code follows on the same line as close brace
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001j.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:03:05

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   ** END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
247. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
248. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
249. 
.             local outpath `"`saving'"'
250.             local outpath : subinstr local outpath `"""' "", all
251.             local outpath : subinstr local outpath "\" "/" , all
252. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
253.                 local outpath "`__project_root'`outpath'"
254.             }
255. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
256. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
257.             if `p' > 0 {
258.                 local outdir = substr("`outpath'", 1, `p' - 1)
259.                 if !direxists("`outdir'") {
260.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
261.                     capture mkdir "`outdir'"
262.                     if _rc & !direxists("`outdir'") {
263.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
264.                         exit 601
265.                     }
266.                 }
267.             }
268. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
269. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
270.             else                graph export "`outpath'", as(pdf)
271. 
.         }   // END PDF EXPORT
272. 
.     restore    // END PRESERVE BLOCK
273. 
.     if `__dbg' {
274.         di as txt "hdfe_catyear_plot DEBUG END"
275.         di as txt "------------------------------------------------------------"
276.     }
277. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
program error:  code follows on the same line as close brace
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001k.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:05:13

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50) legend(off))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle'))
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             yline(0)
247. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
248. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
249. 
.             local outpath `"`saving'"'
250.             local outpath : subinstr local outpath `"""' "", all
251.             local outpath : subinstr local outpath "\" "/" , all
252. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
253.                 local outpath "`__project_root'`outpath'"
254.             }
255. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
256. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
257.             if `p' > 0 {
258.                 local outdir = substr("`outpath'", 1, `p' - 1)
259.                 if !direxists("`outdir'") {
260.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
261.                     capture mkdir "`outdir'"
262.                     if _rc & !direxists("`outdir'") {
263.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
264.                         exit 601
265.                     }
266.                 }
267.             }
268. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
269. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
270.             else                graph export "`outpath'", as(pdf)
271. 
.         }   // END PDF EXPORT
272. 
.     restore    // END PRESERVE BLOCK
273. 
.     if `__dbg' {
274.         di as txt "hdfe_catyear_plot DEBUG END"
275.         di as txt "------------------------------------------------------------"
276.     }
277. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
default prediction is a function of possibly stochastic quantities other than e(b)
r(498);

end of do-file

r(498);

. clear

. sysuse auto
(1978 automobile data)

. twoway scatter rep78 price

. twoway scatter rep78 price, pstyle(p2)

. twoway scatter rep78 price, pcolor(p2)
option pcolor() not allowed
r(198);

. help twoway

. twoway scatter rep78 price, mcolor(p2)
(note:  named style p2 not found in class color, default attributes used)
(note:  named style p2 not found in class color, default attributes used)

. twoway line rep78 price, pstyle(p2)

. twoway line rep78 price, pstyle(p3)

. twoway line rep78 price, pstyle(p3) lp(solid)

. help connect

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001l.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:18:40

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         yscale(range(0 .)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             xline(5.5)
247. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
248. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
249. 
.             local outpath `"`saving'"'
250.             local outpath : subinstr local outpath `"""' "", all
251.             local outpath : subinstr local outpath "\" "/" , all
252. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
253.                 local outpath "`__project_root'`outpath'"
254.             }
255. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
256. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
257.             if `p' > 0 {
258.                 local outdir = substr("`outpath'", 1, `p' - 1)
259.                 if !direxists("`outdir'") {
260.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
261.                     capture mkdir "`outdir'"
262.                     if _rc & !direxists("`outdir'") {
263.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
264.                         exit 601
265.                     }
266.                 }
267.             }
268. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
269. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
270.             else                graph export "`outpath'", as(pdf)
271. 
.         }   // END PDF EXPORT
272. 
.     restore    // END PRESERVE BLOCK
273. 
.     if `__dbg' {
274.         di as txt "hdfe_catyear_plot DEBUG END"
275.         di as txt "------------------------------------------------------------"
276.     }
277. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001m.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:28:43

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ------------------------------------------------------------
.                 ** Y-axis: force inclusion of 0 and extend to max CI bound
.                 ** ------------------------------------------------------------
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on the axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If you want the axis to start at 0 when baseyear==0 (levels, not diffs)
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Round bounds to "nice" 2-decimal endpoints
.                 local __ylow  = floor(`__ymin'*100)/100
254.                 local __yhigh = ceil(`__ymax'*100)/100
255. 
.                 ** Choose a "nice" tick step (about 5 intervals), rounded up to 0.01
.                 local __span = `__yhigh' - `__ylow'
256.                 local __ystep = ceil((`__span'/5)/0.01)*0.01
257.                 if `__ystep' <= 0 local __ystep = 0.01
258. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel(`__ylow'(`__ystep'
> )`__yhigh', format(%4.2f))"'
259. 
.                 
.                 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         yscale(range(0 .)) ///
>             legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             xline(2019.5)
260. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
261. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
262. 
.             local outpath `"`saving'"'
263.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284. 
.         }   // END PDF EXPORT
285. 
.     restore    // END PRESERVE BLOCK
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001n.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:36:19

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ------------------------------------------------------------
.                 ** Y-axis: force inclusion of 0 and extend to max CI bound
.                 ** ------------------------------------------------------------
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on the axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If you want the axis to start at 0 when baseyear==0 (levels, not diffs)
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Round bounds to "nice" 2-decimal endpoints
.                 local __ylow  = floor(`__ymin'*100)/100
254.                 local __yhigh = ceil(`__ymax'*100)/100
255. 
.                 ** Choose a "nice" tick step (about 5 intervals), rounded up to 0.01
.                 local __span = `__yhigh' - `__ylow'
256.                 local __ystep = ceil((`__span'/5)/0.01)*0.01
257.                 if `__ystep' <= 0 local __ystep = 0.01
258. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel(`__ylow'(`__ystep'
> )`__yhigh', format(%4.2f))"'
259.                 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) ///
>             xline(2019.5)
260. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
261. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
262. 
.             local outpath `"`saving'"'
263.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284. 
.         }   // END PDF EXPORT
285. 
.     restore    // END PRESERVE BLOCK
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _married_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_age
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_married cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_age
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_age
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_age##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> sex cat_married cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001o.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 10:52:56

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ------------------------------------------------------------
.                 ** Y-axis: force inclusion of 0 and extend to max CI bound
.                 ** ------------------------------------------------------------
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on the axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If you want the axis to start at 0 when baseyear==0 (levels, not diffs)
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Round bounds to "nice" 2-decimal endpoints
.                 local __ylow  = floor(`__ymin'*100)/100
254.                 local __yhigh = ceil(`__ymax'*100)/100
255. 
.                 ** Choose a "nice" tick step (about 5 intervals), rounded up to 0.01
.                 local __span = `__yhigh' - `__ylow'
256.                 local __ystep = ceil((`__span'/5)/0.01)*0.01
257.                 if `__ystep' <= 0 local __ystep = 0.01
258. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel(`__ylow'(`__ystep'
> )`__yhigh', format(%4.2f))"'
259.                 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) 
260. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
261. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
262. 
.             local outpath `"`saving'"'
263.             local outpath : subinstr local outpath `"""' "", all
264.             local outpath : subinstr local outpath "\" "/" , all
265. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
266.                 local outpath "`__project_root'`outpath'"
267.             }
268. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
269. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
270.             if `p' > 0 {
271.                 local outdir = substr("`outpath'", 1, `p' - 1)
272.                 if !direxists("`outdir'") {
273.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
274.                     capture mkdir "`outdir'"
275.                     if _rc & !direxists("`outdir'") {
276.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
277.                         exit 601
278.                     }
279.                 }
280.             }
281. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
282. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
283.             else                graph export "`outpath'", as(pdf)
284. 
.         }   // END PDF EXPORT
285. 
.     restore    // END PRESERVE BLOCK
286. 
.     if `__dbg' {
287.         di as txt "hdfe_catyear_plot DEBUG END"
288.         di as txt "------------------------------------------------------------"
289.     }
290. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,539 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,354 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001p.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 11:06:42

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `"`serieslab'"')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ------------------------------------------------------------
.                 ** Y-axis: round "nice" ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then rounds to a nice step.
.                 ** ------------------------------------------------------------
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0), anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming for ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep'))
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple of step; min down similarly
.                 local __yhigh = ceil(`__ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exactly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel(`__ylow'(`__ystep'
> )`__yhigh', nogrid)"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) 
270. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
271. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpath `"""' "", all
274.             local outpath : subinstr local outpath "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
276.                 local outpath "`__project_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'") {
286.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
293.             else                graph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "------------------------------------------------------------"
299.     }
300. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,539 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,354 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _married_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_age
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_married cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_age
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_age
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_age##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> sex cat_married cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _age_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_child
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_married cat_age cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_child_1   REPLACE
> : replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_child
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1 2 3
  CAT value label: cat_child
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_child##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o ca
> t_sex cat_married cat_age cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _child_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_child_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_educ
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_married cat_age cat_child cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_educ_1   REPLACE:
>  replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_educ
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_educ
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_educ##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat
> _sex cat_married cat_age cat_child cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _educ_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_educ_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_ftotinc
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_married cat_age cat_child cat_educ
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_ftotinc_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_ftotinc
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4 5 6 7
  CAT value label: cat_ftotinc
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_ftotinc##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_married cat_age cat_child cat_educ) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
invalid label specifier, :  0(.).:
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001q.tmp"

. ** Categorical variables to iterate over
. local catvars "cat_married cat_sex cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug debugdetail
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +--------------------------------------------------------------------------------------+
  1. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          1        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.629638 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0418242  |   134.6025  |        0  |  5.547664  |  5.711612  |    Married  |  2015  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  2. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          2        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.331183 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0476789  |   153.7615  |        0  |  7.237734  |  7.424633  |    Married  |  2016  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  3. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          3        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.169612 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0389293  |   132.7951  |        0  |  5.093312  |  5.245912  |    Married  |  2017  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  4. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          4        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.873425 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0413863  |   141.9172  |        0  |  5.792309  |   5.95454  |    Married  |  2018  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  5. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          5        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 4.284228 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0356699  |   120.1075  |        0  |  4.214317  |   4.35414  |    Married  |  2019  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  6. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          6        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 4.921739 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0376503  |   130.7224  |        0  |  4.847946  |  4.995532  |    Married  |  2020  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  7. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          7        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.552225 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0442641  |   148.0256  |        0  |  6.465468  |  6.638981  |    Married  |  2021  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  8. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          8        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.998009 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0505815  |   158.1211  |        0  |  7.898871  |  8.097147  |    Married  |  2022  |
     +--------------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4 6 8
  legend labels: label(2 `unknown function Married"') label()
r(133);

end of do-file

r(133);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001r.tmp"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 12:57:39

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ------------------------------------------------------------
.                 ** Y-axis: round "nice" ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then rounds to a nice step.
.                 ** ------------------------------------------------------------
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0), anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming for ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep'))
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple of step; min down similarly
.                 local __yhigh = ceil(`__ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exactly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel(`__ylow'(`__ystep'
> )`__yhigh', nogrid)"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) 
270. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
271. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpath `"""' "", all
274.             local outpath : subinstr local outpath "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
276.                 local outpath "`__project_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'") {
286.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
293.             else                graph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "------------------------------------------------------------"
299.     }
300. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)    // Alaska and Hawaii
(136,571 observations deleted)

. 
. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,539 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,354 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,893,859 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,061,905 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,920 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,893,859 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,380,619 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,893,859 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     20,759        0.10        0.10
             $0 |  1,748,089        8.37        8.47
        $1-$25K |  6,204,378       29.69       38.16
      $25K-$50K |  4,981,113       23.84       62.00
     $50K-$100K |  4,947,578       23.68       85.68
    $100K-$200K |  2,211,136       10.58       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,182,418       39.16       39.16
        $1-$25K |  3,428,895       16.41       55.57
      $25K-$50K |  3,290,630       15.75       71.32
     $50K-$100K |  3,729,590       17.85       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,859 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     16,135        0.08        0.08
             $0 |  7,365,326       35.25       35.33
        $1-$25K |  3,756,344       17.98       53.31
      $25K-$50K |  3,476,928       16.64       69.95
     $50K-$100K |  3,876,560       18.55       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00
(20,893,767 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_married cat_sex cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace debug debugdetail
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_married
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_sex cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_married
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_married
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_married##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_sex cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +--------------------------------------------------------------------------------------+
  1. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          1        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.629638 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0418242  |   134.6025  |        0  |  5.547664  |  5.711612  |    Married  |  2015  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  2. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          2        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.331183 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0476789  |   153.7615  |        0  |  7.237734  |  7.424633  |    Married  |  2016  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  3. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          3        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.169612 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0389293  |   132.7951  |        0  |  5.093312  |  5.245912  |    Married  |  2017  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  4. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          4        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.873425 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0413863  |   141.9172  |        0  |  5.792309  |   5.95454  |    Married  |  2018  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  5. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          5        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 4.284228 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0356699  |   120.1075  |        0  |  4.214317  |   4.35414  |    Married  |  2019  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  6. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          6        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 4.921739 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0376503  |   130.7224  |        0  |  4.847946  |  4.995532  |    Married  |  2020  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  7. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          7        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.552225 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0442641  |   148.0256  |        0  |  6.465468  |  6.638981  |    Married  |  2021  |
     +--------------------------------------------------------------------------------------+

     +--------------------------------------------------------------------------------------+
  8. |       _deriv        |       _term        |       _predict        |        _at        |
     |            .        |       _cons        |              .        |          8        |
     |--------------------------------------------------------------------------------------|
     |                                                                    _atopt |        b |
     | cat_married=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.998009 |
     |--------------------------------------------------------------------------------------|
     |       se  | _statistic  |  _pvalue  |        ll  |        ul  |  cat_level  |  year  |
     | .0505815  |   158.1211  |        0  |  7.898871  |  8.097147  |    Married  |  2022  |
     +--------------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4 6 8
  legend labels: label(2 Married) label(4 Separated) label(6 Divorced / Widowed) label(8 Single)
  legend rows: 1
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _married_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_married_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_sex
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_age cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_sex
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1
  CAT value label: lb_cat_sex
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_sex##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_age cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +-----------------------------------------------------------------------------------------+
  1. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          1        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.101542 | .0472017 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |      150.451   |         0   |   7.009029   |   7.194056   |        Male    |   2015    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  2. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          2        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.743395 |  .045487 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     148.2489   |         0   |   6.654243   |   6.832548   |        Male    |   2016    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  3. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          3        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.383132 | .0410547 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     131.1211   |         0   |   5.302666   |   5.463597   |        Male    |   2017    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  4. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          4        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.573506 | .0447089 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     147.0292   |         0   |   6.485878   |   6.661134   |        Male    |   2018    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  5. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          5        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.543049 | .0410833 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     134.9223   |         0   |   5.462527   |    5.62357   |        Male    |   2019    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  6. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          6        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.344078 |   .04049 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     131.9852   |         0   |   5.264719   |   5.423437   |        Male    |   2020    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  7. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          7        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.929105 |  .045073 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     153.7307   |         0   |   6.840764   |   7.017447   |        Male    |   2021    |
     +-----------------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------------+
  8. |        _deriv        |        _term        |        _predict        |        _at        |
     |             .        |        _cons        |               .        |          8        |
     |-----------------------------------------------------------------------------------------|
     |                                                            _atopt |        b |       se |
     | cat_sex=(0 1) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 8.168859 | .0484969 |
     |-----------------------------------------------------------------------------------------|
     |   _statistic   |   _pvalue   |         ll   |         ul   |   cat_level    |   year    |
     |     168.4408   |         0   |   8.073807   |   8.263911   |        Male    |   2022    |
     +-----------------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4
  legend labels: label(2 Male) label(4 Female)
  legend rows: 1
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _sex_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_age
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_sex cat_child cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_1   REPLACE: 
> replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_age
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_age
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_age##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat_
> married cat_sex cat_child cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +----------------------------------------------------------------------------------+
  1. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         1        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 16.02189 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1597371  |   100.3016  |       0  | 15.70881  | 16.33497  |     18-24  |  2015  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  2. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         2        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 11.28406 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1348863  |   83.65607  |       0  | 11.01968  | 11.54843  |     18-24  |  2016  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  3. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         3        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |  9.18228 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1264052  |   72.64164  |       0  |  8.93453  | 9.430029  |     18-24  |  2017  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  4. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         4        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 10.39457 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     |  .139515  |   74.50503  |       0  | 10.12113  | 10.66802  |     18-24  |  2018  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  5. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         5        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |  14.9246 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1542476  |   96.75742  |       0  | 14.62228  | 15.22692  |     18-24  |  2019  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  6. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         6        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 11.16525 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1391164  |   80.25834  |       0  | 10.89259  | 11.43791  |     18-24  |  2020  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  7. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         7        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |  11.9572 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1449019  |   82.51926  |       0  |  11.6732  |  12.2412  |     18-24  |  2021  |
     +----------------------------------------------------------------------------------+

     +----------------------------------------------------------------------------------+
  8. |       _deriv       |       _term       |       _predict       |       _at        |
     |            .       |       _cons       |              .       |         8        |
     |----------------------------------------------------------------------------------|
     |                                                                _atopt |        b |
     | cat_age=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 15.23976 |
     |----------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  | cat_level  |  year  |
     | .1553371  |   98.10767  |       0  | 14.93531  | 15.54422  |     18-24  |  2022  |
     +----------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4 6 8
  legend labels: label(2 18-24) label(4 25-44) label(6 45-64) label(8 65+)
  legend rows: 1
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _age_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_age_1.pdf saved as PDF
    format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_child
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_sex cat_age cat_educ cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_child_1   REPLACE
> : replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_child
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 0 1 2 3
  CAT value label: cat_child
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_child##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o ca
> t_married cat_sex cat_age cat_educ cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +------------------------------------------------------------------------------------+
  1. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         1        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.458775 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     | .0410298  |   181.7893  |       0  | 7.378358  | 7.539192  |  0 Children  |  2015  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  2. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         2        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.179592 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     | .0405554  |   177.0316  |       0  | 7.100104  | 7.259079  |  0 Children  |  2016  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  3. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         3        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.589154 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     |  .038775  |   169.9329  |       0  | 6.513156  | 6.665151  |  0 Children  |  2017  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  4. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         4        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.586322 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     | .0380978  |   172.8792  |       0  | 6.511652  | 6.660993  |  0 Children  |  2018  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  5. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         5        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.630853 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     | .0348323  |   161.6559  |       0  | 5.562582  | 5.699122  |  0 Children  |  2019  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  6. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         6        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |  6.66776 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     | .0379589  |   175.6575  |       0  | 6.593362  | 6.742158  |  0 Children  |  2020  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  7. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         7        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 7.551964 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     | .0404956  |   186.4883  |       0  | 7.472594  | 7.631334  |  0 Children  |  2021  |
     +------------------------------------------------------------------------------------+

     +------------------------------------------------------------------------------------+
  8. |       _deriv       |       _term        |       _predict        |       _at        |
     |            .       |       _cons        |              .        |         8        |
     |------------------------------------------------------------------------------------|
     |                                                                  _atopt |        b |
     | cat_child=(0 1 2 3) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 8.653642 |
     |------------------------------------------------------------------------------------|
     |       se  | _statistic  | _pvalue  |       ll  |       ul  |   cat_level  |  year  |
     |  .042672  |   202.7943  |       0  | 8.570006  | 8.737277  |  0 Children  |  2022  |
     +------------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4 6 8
  legend labels: label(2 0 Children) label(4 1 Child) label(6 2 Children) label(8 3+ Children)
  legend rows: 1
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _child_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_child_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_educ
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_sex cat_age cat_child cat_ftotinc
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_educ_1   REPLACE:
>  replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_educ
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4
  CAT value label: cat_educ
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_educ##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o cat
> _married cat_sex cat_age cat_child cat_ftotinc) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +-----------------------------------------------------------------------------------+
  1. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         1        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 6.165936 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .0924648 |   66.68415  |       0  | 5.984708  | 6.347163  | Less than HS  | 2015  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  2. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         2        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 3.261986 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .0695444 |   46.90508  |       0  | 3.125681  |  3.39829  | Less than HS  | 2016  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  3. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         3        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |  5.49867 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .0994404 |   55.29615  |       0  |  5.30377  | 5.693569  | Less than HS  | 2017  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  4. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         4        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 3.830198 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .0758525 |   50.49537  |       0  |  3.68153  | 3.978866  | Less than HS  | 2018  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  5. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         5        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 4.024476 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .0796703 |   50.51411  |       0  | 3.868325  | 4.180627  | Less than HS  | 2019  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  6. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         6        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.603014 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .1040952 |   53.82587  |       0  | 5.398992  | 5.807037  | Less than HS  | 2020  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  7. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         7        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 2.483652 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .0634028 |   39.17257  |       0  | 2.359385  | 2.607919  | Less than HS  | 2021  |
     +-----------------------------------------------------------------------------------+

     +-----------------------------------------------------------------------------------+
  8. |       _deriv       |       _term       |       _predict        |       _at        |
     |            .       |       _cons       |              .        |         8        |
     |-----------------------------------------------------------------------------------|
     |                                                                 _atopt |        b |
     | cat_educ=(1 2 3 4) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) | 5.454694 |
     |-----------------------------------------------------------------------------------|
     |       se | _statistic  | _pvalue  |       ll  |       ul  |    cat_level  | year  |
     | .1007683 |   54.13104  |       0  | 5.257191  | 5.652196  | Less than HS  | 2022  |
     +-----------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4 6 8
  legend labels: label(2 Less than HS) label(4 HS Diploma) label(6 Some College) label(8 College D
> egree)
  legend rows: 1
[Step 10] Exporting graph to: C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat
> _educ_1.pdf
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_educ_1.pdf saved as
    PDF format
hdfe_catyear_plot DEBUG END
------------------------------------------------------------
------------------------------------------------------------
hdfe_catyear_plot DEBUG START
Outcome   : out_1
CAT()     : cat_ftotinc
YEAR()    : year
ABSORB()  : state_fips_o county_fips_o cat_married cat_sex cat_age cat_child cat_educ
Weights   : weight= exp= wvar=perwt wtype=fw
VCE()     : 
BASEYEAR(): 0   NOCI: 
SAVING()  : C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_ftotinc_1   REPLA
> CE: replace
IF/IN     : if sample_1 == 1 
------------------------------------------------------------
[Step 1] Marking estimation sample...
  N (after filters):       51,613
[Step 2] Resolving weights...
  Using default weights: [fw=perwt]
[Step 3] Harmonizing CAT/YEAR types...
  CAT already numeric -> cat_ftotinc
  YEAR already numeric -> year
[Step 4] Validating absorb()...
[Step 5] Collecting year and category levels...
  Years: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Cats : 1 2 3 4 5 6 7
  CAT value label: cat_ftotinc
[Step 6] Running reghdfe...
  Command:
    reghdfe out_1 i.cat_ftotinc##i.year if __000000 [fw=perwt], absorb(state_fips_o county_fips_o 
> cat_married cat_sex cat_age cat_child cat_educ) vce(robust)
[Step 7] Computing margins and saving results...
(Created by command margins; also see char list)
[DebugDetail] First 8 rows of margins dataset:

     +---------------------------------------------------------------------------------+
  1. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         1       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |  1.841794 |  .  |          .  |       .  |  .  |  .  | Negative income  | 2015  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  2. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         2       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     | -1.717222 |  .  |          .  |       .  |  .  |  .  | Negative income  | 2016  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  3. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         3       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |         . |  .  |          .  |       .  |  .  |  .  | Negative income  | 2017  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  4. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         4       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |  1.397488 |  .  |          .  |       .  |  .  |  .  | Negative income  | 2018  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  5. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         5       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |  1.177221 |  .  |          .  |       .  |  .  |  .  | Negative income  | 2019  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  6. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         6       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |         . |  .  |          .  |       .  |  .  |  .  | Negative income  | 2020  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  7. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         7       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |   1.57282 |  .  |          .  |       .  |  .  |  .  | Negative income  | 2021  |
     +---------------------------------------------------------------------------------+

     +---------------------------------------------------------------------------------+
  8. |       _deriv       |       _term       |       _predict       |       _at       |
     |            .       |       _cons       |              .       |         8       |
     |---------------------------------------------------------------------------------|
     |                                                                          _atopt |
     | cat_ftotinc=(1 2 3 4 5 6 7) year=(2015 2016 2017 2018 2019 2020 2021 2022 2023) |
     |---------------------------------------------------------------------------------|
     |         b | se  | _statistic  | _pvalue  | ll  | ul  |       cat_level  | year  |
     |  1.570895 |  .  |          .  |       .  |  .  |  .  | Negative income  | 2022  |
     +---------------------------------------------------------------------------------+
2015 2016 2017 2018 2019 2020 2021 2022 2023
  X-axis years used: 2015 2016 2017 2018 2019 2020 2021 2022 2023
  Using scheme: plotplainblind (was plotplainblind)
[Step 9] Building plot command...
  legend order: 2 4 6 8 10 12 14
  legend labels: label(2 Negative income) label(4 $0) label(6 $1-$25K) label(8 $25K-$50K) label(10
>  $50K-$100K) label(12 $100K-$200K) label(14 $200K+)
  legend rows: 2
invalid label specifier, :  0(.).:
r(198);

end of do-file

r(198);

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 [fw = perwt] , vce(robust) absorb(state_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)
warning: variance matrix is nonsymmetric or highly singular.

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 3 HDFE groups                           F(  60,5546873) =    4302.23
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0083
                                                  Adj R-squared   =     0.0083
                                                  Within R-sq.    =     0.0043
                                                  Root MSE        =    24.2231

---------------------------------------------------------------------------------------
                      |               Robust
                out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
----------------------+----------------------------------------------------------------
     cat_ftotinc#year |
Negative income#2016  |   1.175393          .        .       .            .           .
Negative income#2017  |          0  (empty)
Negative income#2018  |   2.629347          .        .       .            .           .
Negative income#2019  |   1.031658          .        .       .            .           .
Negative income#2020  |          0  (empty)
Negative income#2021  |   1.124776          .        .       .            .           .
Negative income#2022  |   .7770976          .        .       .            .           .
Negative income#2023  |   .2849292          .        .       .            .           .
             $0#2015  |   2.588211          .        .       .            .           .
             $0#2016  |   7.616616          .        .       .            .           .
             $0#2017  |   7.014249          .        .       .            .           .
             $0#2018  |   15.29865          .        .       .            .           .
             $0#2019  |   13.84534          .        .       .            .           .
             $0#2020  |    4.16589          .        .       .            .           .
             $0#2021  |   14.86405          .        .       .            .           .
             $0#2022  |   5.662908          .        .       .            .           .
             $0#2023  |   3.226018          .        .       .            .           .
        $1-$25K#2015  |   9.441682          .        .       .            .           .
        $1-$25K#2016  |   9.837394          .        .       .            .           .
        $1-$25K#2017  |   7.096863          .        .       .            .           .
        $1-$25K#2018  |   7.200828          .        .       .            .           .
        $1-$25K#2019  |   8.280888          .        .       .            .           .
        $1-$25K#2020  |   7.608156          .        .       .            .           .
        $1-$25K#2021  |   6.645658          .        .       .            .           .
        $1-$25K#2022  |   7.901017          .        .       .            .           .
        $1-$25K#2023  |   5.240575          .        .       .            .           .
      $25K-$50K#2015  |   9.094453          .        .       .            .           .
      $25K-$50K#2016  |   8.667246          .        .       .            .           .
      $25K-$50K#2017  |   5.803244          .        .       .            .           .
      $25K-$50K#2018  |   8.295483          .        .       .            .           .
      $25K-$50K#2019  |   9.093346          .        .       .            .           .
      $25K-$50K#2020  |    8.22331          .        .       .            .           .
      $25K-$50K#2021  |   7.591884          .        .       .            .           .
      $25K-$50K#2022  |   9.806387          .        .       .            .           .
      $25K-$50K#2023  |   5.309003          .        .       .            .           .
     $50K-$100K#2015  |   9.146895          .        .       .            .           .
     $50K-$100K#2016  |   9.082859          .        .       .            .           .
     $50K-$100K#2017  |   8.180181          .        .       .            .           .
     $50K-$100K#2018  |   7.224007          .        .       .            .           .
     $50K-$100K#2019  |   6.273264          .        .       .            .           .
     $50K-$100K#2020  |   8.302922          .        .       .            .           .
     $50K-$100K#2021  |   8.574805          .        .       .            .           .
     $50K-$100K#2022  |   8.667383          .        .       .            .           .
     $50K-$100K#2023  |    6.67062          .        .       .            .           .
    $100K-$200K#2015  |   8.551944          .        .       .            .           .
    $100K-$200K#2016  |   8.166886          .        .       .            .           .
    $100K-$200K#2017  |    7.00262          .        .       .            .           .
    $100K-$200K#2018  |   8.228494          .        .       .            .           .
    $100K-$200K#2019  |   6.437026          .        .       .            .           .
    $100K-$200K#2020  |    8.66453          .        .       .            .           .
    $100K-$200K#2021  |   9.263812          .        .       .            .           .
    $100K-$200K#2022  |   11.14872          .        .       .            .           .
    $100K-$200K#2023  |   9.636455          .        .       .            .           .
         $200K+#2015  |   10.97731          .        .       .            .           .
         $200K+#2016  |   8.051451          .        .       .            .           .
         $200K+#2017  |   11.39635          .        .       .            .           .
         $200K+#2018  |   9.580095          .        .       .            .           .
         $200K+#2019  |   7.830397          .        .       .            .           .
         $200K+#2020  |   6.603962          .        .       .            .           .
         $200K+#2021  |   11.08602          .        .       .            .           .
         $200K+#2022  |   11.98021          .        .       .            .           .
         $200K+#2023  |   11.66082          .        .       .            .           .
                      |
                _cons |  -2.117785          .        .       .            .           .
---------------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. tab cat_ftotinc

   Total family |
         income |
     categories |
(real 2023 USD) |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |      7,238        0.03        0.03
             $0 |    226,387        1.08        1.12
        $1-$25K |  2,249,309       10.77       11.88
      $25K-$50K |  3,258,513       15.60       27.48
     $50K-$100K |  5,975,505       28.60       56.08
    $100K-$200K |  6,147,777       29.42       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,893,859      100.00

. reghdfe out_1 i.cat_ftotinc#i.year if sample_2 == 1 [fw = perwt] , vce(robust) absorb(state_fips_o county_fips_o cat_married)
--Break--
r(1);

. reghdfe out_1 i.cat_sex#i.year if sample_1 == 1 [fw = perwt] , vce(robust) ab
> sorb(state_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =  5,546,937
Absorbing 3 HDFE groups                           F(  17,5546916) =     367.38
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0052
                                                  Adj R-squared   =     0.0052
                                                  Within R-sq.    =     0.0011
                                                  Root MSE        =    24.2619

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
cat_sex#year |
  Male#2016  |  -.3477605   .0658877    -5.28   0.000    -.4768981   -.2186229
  Male#2017  |  -1.689816   .0628384   -26.89   0.000    -1.812977   -1.566654
  Male#2018  |  -.5080424   .0653213    -7.78   0.000    -.6360697    -.380015
  Male#2019  |  -1.585765     .06289   -25.21   0.000    -1.709027   -1.462503
  Male#2020  |  -1.671716   .0623803   -26.80   0.000    -1.793979   -1.549453
  Male#2021  |   -.208884   .0656803    -3.18   0.001    -.3376151    -.080153
  Male#2022  |   .9769234    .068025    14.36   0.000     .8435968     1.11025
  Male#2023  |  -.9401057   .0645759   -14.56   0.000    -1.066672   -.8135393
Female#2015  |   .0021557    .065583     0.03   0.974    -.1263848    .1306961
Female#2016  |  -.5630321   .0646697    -8.71   0.000    -.6897824   -.4362817
Female#2017  |  -1.160092   .0632772   -18.33   0.000    -1.284113   -1.036071
Female#2018  |  -1.474043   .0622414   -23.68   0.000    -1.596034   -1.352052
Female#2019  |  -2.035948   .0610888   -33.33   0.000     -2.15568   -1.916216
Female#2020  |  -.6726029   .0638348   -10.54   0.000    -.7977168    -.547489
Female#2021  |  -.2607758   .0648885    -4.02   0.000     -.387955   -.1335966
Female#2022  |   .7005518   .0670836    10.44   0.000     .5690704    .8320332
Female#2023  |   -1.29453   .0633794   -20.43   0.000    -1.418751   -1.170309
             |
       _cons |   7.020744   .0473864   148.16   0.000     6.927868     7.11362
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. tab cat_ftotinc year

   Total family |
         income |
     categories |                    year
(real 2023 USD) |      2015       2016       2017       2018 |     Total
----------------+--------------------------------------------+----------
Negative income |       584        609        791        822 |     7,238 
             $0 |    26,739     26,280     26,587     25,884 |   226,387 
        $1-$25K |   260,504    255,904    259,142    255,330 | 2,249,309 
      $25K-$50K |   385,373    377,803    376,378    374,108 | 3,258,513 
     $50K-$100K |   668,682    661,840    664,973    669,703 | 5,975,505 
    $100K-$200K |   651,864    662,501    671,310    683,873 | 6,147,777 
         $200K+ |   290,786    308,694    316,476    329,847 | 3,029,130 
----------------+--------------------------------------------+----------
          Total | 2,284,532  2,293,631  2,315,657  2,339,567 |20,893,859 


   Total family |
         income |
     categories |                    year
(real 2023 USD) |      2019       2020       2021       2022 |     Total
----------------+--------------------------------------------+----------
Negative income |       786        644        962      1,029 |     7,238 
             $0 |    23,323     17,360     27,070     26,924 |   226,387 
        $1-$25K |   237,660    186,227    260,796    271,970 | 2,249,309 
      $25K-$50K |   353,562    275,713    363,260    380,372 | 3,258,513 
     $50K-$100K |   674,850    527,757    676,878    712,684 | 5,975,505 
    $100K-$200K |   720,185    583,082    705,559    719,002 | 6,147,777 
         $200K+ |   370,801    309,367    360,532    358,877 | 3,029,130 
----------------+--------------------------------------------+----------
          Total | 2,381,167  1,900,150  2,395,057  2,470,858 |20,893,859 


   Total family |
         income |
     categories |    year
(real 2023 USD) |      2023 |     Total
----------------+-----------+----------
Negative income |     1,011 |     7,238 
             $0 |    26,220 |   226,387 
        $1-$25K |   261,776 | 2,249,309 
      $25K-$50K |   371,944 | 3,258,513 
     $50K-$100K |   718,138 | 5,975,505 
    $100K-$200K |   750,401 | 6,147,777 
         $200K+ |   383,750 | 3,029,130 
----------------+-----------+----------
          Total | 2,513,240 |20,893,859 

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(robust) absorb(stat
> e_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)
warning: variance matrix is nonsymmetric or highly singular.

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  60,  51549) =      35.17
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0075
                                                  Adj R-squared   =     0.0062
                                                  Within R-sq.    =     0.0029
                                                  Root MSE        =    23.6001

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_ftotinc#|
        year |
Negative .. #|
       2016  |    1.49997          .        .       .            .           .
Negative .. #|
       2017  |          0  (empty)
Negative .. #|
       2018  |    2.99994          .        .       .            .           .
Negative .. #|
       2019  |   1.234211          .        .       .            .           .
Negative .. #|
       2020  |          0  (empty)
Negative .. #|
       2021  |    1.49997          .        .       .            .           .
Negative .. #|
       2022  |    .288076          .        .       .            .           .
Negative .. #|
       2023  |   .9999801          .        .       .            .           .
    $0#2015  |   4.073198          .        .       .            .           .
    $0#2016  |   5.609354          .        .       .            .           .
    $0#2017  |   5.854043          .        .       .            .           .
    $0#2018  |   14.19697          .        .       .            .           .
    $0#2019  |   17.69172          .        .       .            .           .
    $0#2020  |   6.220691          .        .       .            .           .
    $0#2021  |   9.313381          .        .       .            .           .
    $0#2022  |   5.362216          .        .       .            .           .
    $0#2023  |   5.511796          .        .       .            .           .
    $1-$25K #|
       2015  |   8.931585          .        .       .            .           .
    $1-$25K #|
       2016  |   9.535397          .        .       .            .           .
    $1-$25K #|
       2017  |   7.532446          .        .       .            .           .
    $1-$25K #|
       2018  |   8.113149          .        .       .            .           .
    $1-$25K #|
       2019  |   10.25213          .        .       .            .           .
    $1-$25K #|
       2020  |   8.407665          .        .       .            .           .
    $1-$25K #|
       2021  |   7.574782          .        .       .            .           .
    $1-$25K #|
       2022  |    7.71816          .        .       .            .           .
    $1-$25K #|
       2023  |   5.934847          .        .       .            .           .
  $25K-$50K #|
       2015  |   8.141711          .        .       .            .           .
  $25K-$50K #|
       2016  |   8.569513          .        .       .            .           .
  $25K-$50K #|
       2017  |   5.745917          .        .       .            .           .
  $25K-$50K #|
       2018  |   8.054434          .        .       .            .           .
  $25K-$50K #|
       2019  |   8.462833          .        .       .            .           .
  $25K-$50K #|
       2020  |   7.807325          .        .       .            .           .
  $25K-$50K #|
       2021  |   7.377488          .        .       .            .           .
  $25K-$50K #|
       2022  |   9.477475          .        .       .            .           .
  $25K-$50K #|
       2023  |    5.89211          .        .       .            .           .
 $50K-$100K #|
       2015  |   8.398955          .        .       .            .           .
 $50K-$100K #|
       2016  |   8.718321          .        .       .            .           .
 $50K-$100K #|
       2017  |   7.200398          .        .       .            .           .
 $50K-$100K #|
       2018  |   7.955259          .        .       .            .           .
 $50K-$100K #|
       2019  |   6.786337          .        .       .            .           .
 $50K-$100K #|
       2020  |    8.87987          .        .       .            .           .
 $50K-$100K #|
       2021  |   8.598122          .        .       .            .           .
 $50K-$100K #|
       2022  |    8.03324          .        .       .            .           .
 $50K-$100K #|
       2023  |   7.481225          .        .       .            .           .
$100K-$200K #|
       2015  |   8.624451          .        .       .            .           .
$100K-$200K #|
       2016  |   7.568963          .        .       .            .           .
$100K-$200K #|
       2017  |   7.235867          .        .       .            .           .
$100K-$200K #|
       2018  |   7.853425          .        .       .            .           .
$100K-$200K #|
       2019  |   6.709715          .        .       .            .           .
$100K-$200K #|
       2020  |   9.557321          .        .       .            .           .
$100K-$200K #|
       2021  |   8.404917          .        .       .            .           .
$100K-$200K #|
       2022  |    9.67297          .        .       .            .           .
$100K-$200K #|
       2023  |    9.63654          .        .       .            .           .
$200K+#2015  |   7.767626          .        .       .            .           .
$200K+#2016  |   7.210952          .        .       .            .           .
$200K+#2017  |   9.981555          .        .       .            .           .
$200K+#2018  |   9.504325          .        .       .            .           .
$200K+#2019  |   8.138367          .        .       .            .           .
$200K+#2020  |    6.18413          .        .       .            .           .
$200K+#2021  |   10.73668          .        .       .            .           .
$200K+#2022  |   11.21869          .        .       .            .           .
$200K+#2023  |   9.818454          .        .       .            .           .
             |
       _cons |  -2.308414          .        .       .            .           .
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(hc1) absorb(state_f
> ips_o county_fips_o cat_married)
vcetype 'hc1' not allowed
r(9);

. help reghdfe

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(unac) absorb(state_
> fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  60,  51549) =       2.50
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0075
                                                  Adj R-squared   =     0.0062
                                                  Within R-sq.    =     0.0029
                                                  Root MSE        =    23.6001

------------------------------------------------------------------------------
       out_1 | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_ftotinc#|
        year |
Negative .. #|
       2016  |    1.49997   20.43889     0.07   0.941    -38.56045     41.5604
Negative .. #|
       2017  |          0  (empty)
Negative .. #|
       2018  |    2.99994   28.90581     0.10   0.917    -53.65573    59.65561
Negative .. #|
       2019  |   1.234211   19.26958     0.06   0.949    -36.53436    39.00279
Negative .. #|
       2020  |          0  (empty)
Negative .. #|
       2021  |    1.49997   23.60062     0.06   0.949    -44.75748    47.75742
Negative .. #|
       2022  |    .288076    28.9115     0.01   0.992    -56.37875    56.95491
Negative .. #|
       2023  |   .9999801    21.5441     0.05   0.963    -41.22667    43.22663
    $0#2015  |   4.073198   16.95512     0.24   0.810    -29.15901     37.3054
    $0#2016  |   5.609354   16.92501     0.33   0.740    -27.56384    38.78255
    $0#2017  |   5.854043   16.93921     0.35   0.730    -27.34698    39.05507
    $0#2018  |   14.19697   17.00021     0.84   0.404    -19.12361    47.51755
    $0#2019  |   17.69172   16.96385     1.04   0.297     -15.5576    50.94104
    $0#2020  |   6.220691   17.12153     0.36   0.716    -27.33768    39.77906
    $0#2021  |   9.313381   16.92146     0.55   0.582    -23.85284     42.4796
    $0#2022  |   5.362216   16.93528     0.32   0.752    -27.83111    38.55554
    $0#2023  |   5.511796   16.92507     0.33   0.745    -27.66151     38.6851
    $1-$25K #|
       2015  |   8.931585   16.71477     0.53   0.593    -23.82952    41.69269
    $1-$25K #|
       2016  |   9.535397   16.71662     0.57   0.568    -23.22935    42.30015
    $1-$25K #|
       2017  |   7.532446   16.71382     0.45   0.652    -25.22681     40.2917
    $1-$25K #|
       2018  |   8.113149   16.71637     0.49   0.627     -24.6511     40.8774
    $1-$25K #|
       2019  |   10.25213   16.71937     0.61   0.540      -22.518    43.02226
    $1-$25K #|
       2020  |   8.407665   16.72506     0.50   0.615    -24.37363    41.18896
    $1-$25K #|
       2021  |   7.574782   16.71427     0.45   0.650    -25.18534    40.33491
    $1-$25K #|
       2022  |    7.71816    16.7148     0.46   0.644    -25.04301    40.47933
    $1-$25K #|
       2023  |   5.934847   16.71745     0.36   0.723    -26.83152    38.70121
  $25K-$50K #|
       2015  |   8.141711   16.70657     0.49   0.626    -24.60333    40.88675
  $25K-$50K #|
       2016  |   8.569513   16.70725     0.51   0.608    -24.17687    41.31589
  $25K-$50K #|
       2017  |   5.745917   16.70744     0.34   0.731    -27.00083    38.49266
  $25K-$50K #|
       2018  |   8.054434   16.70836     0.48   0.630    -24.69412    40.80298
  $25K-$50K #|
       2019  |   8.462833   16.70998     0.51   0.613    -24.28889    41.21456
  $25K-$50K #|
       2020  |   7.807325   16.71587     0.47   0.640    -24.95594    40.57059
  $25K-$50K #|
       2021  |   7.377488   16.70983     0.44   0.659    -25.37395    40.12893
  $25K-$50K #|
       2022  |   9.477475   16.70839     0.57   0.571    -23.27114    42.22609
  $25K-$50K #|
       2023  |    5.89211   16.70968     0.35   0.724    -26.85902    38.64324
 $50K-$100K #|
       2015  |   8.398955   16.69931     0.50   0.615    -24.33187    41.12978
 $50K-$100K #|
       2016  |   8.718321   16.69895     0.52   0.602    -24.01179    41.44843
 $50K-$100K #|
       2017  |   7.200398   16.69887     0.43   0.666    -25.52956    39.93035
 $50K-$100K #|
       2018  |   7.955259   16.69975     0.48   0.634    -24.77642    40.68694
 $50K-$100K #|
       2019  |   6.786337   16.69914     0.41   0.684    -25.94414    39.51681
 $50K-$100K #|
       2020  |    8.87987   16.70258     0.53   0.595    -23.85736     41.6171
 $50K-$100K #|
       2021  |   8.598122   16.69847     0.51   0.607    -24.13104    41.32729
 $50K-$100K #|
       2022  |    8.03324    16.6995     0.48   0.630    -24.69794    40.76442
 $50K-$100K #|
       2023  |   7.481225   16.69965     0.45   0.654    -25.25027    40.21272
$100K-$200K #|
       2015  |   8.624451   16.69862     0.52   0.606    -24.10502    41.35392
$100K-$200K #|
       2016  |   7.568963   16.69865     0.45   0.650    -25.16056    40.29848
$100K-$200K #|
       2017  |   7.235867   16.69852     0.43   0.665     -25.4934    39.96514
$100K-$200K #|
       2018  |   7.853425   16.69832     0.47   0.638    -24.87546    40.58231
$100K-$200K #|
       2019  |   6.709715   16.69767     0.40   0.688    -26.01789    39.43732
$100K-$200K #|
       2020  |   9.557321   16.69967     0.57   0.567     -23.1742    42.28884
$100K-$200K #|
       2021  |   8.404917   16.69737     0.50   0.615    -24.32209    41.13192
$100K-$200K #|
       2022  |    9.67297   16.69784     0.58   0.562    -23.05496     42.4009
$100K-$200K #|
       2023  |    9.63654   16.69765     0.58   0.564    -23.09103    42.36411
$200K+#2015  |   7.767626   16.71077     0.46   0.642    -24.98564    40.52089
$200K+#2016  |   7.210952    16.7081     0.43   0.666     -25.5371      39.959
$200K+#2017  |   9.981555   16.70836     0.60   0.550    -22.76699     42.7301
$200K+#2018  |   9.504325   16.70487     0.57   0.569    -23.23739    42.24604
$200K+#2019  |   8.138367   16.70453     0.49   0.626    -24.60267     40.8794
$200K+#2020  |    6.18413    16.7055     0.37   0.711    -26.55882    38.92708
$200K+#2021  |   10.73668   16.70316     0.64   0.520    -22.00168    43.47504
$200K+#2022  |   11.21869   16.70471     0.67   0.502    -21.52272    43.96009
$200K+#2023  |   9.818454   16.70335     0.59   0.557    -22.92028    42.55719
             |
       _cons |  -2.308414   16.68853    -0.14   0.890     -35.0181    30.40127
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(unadj) absorb(state
> _fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  60,  51549) =       2.50
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0075
                                                  Adj R-squared   =     0.0062
                                                  Within R-sq.    =     0.0029
                                                  Root MSE        =    23.6001

------------------------------------------------------------------------------
       out_1 | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_ftotinc#|
        year |
Negative .. #|
       2016  |    1.49997   20.43889     0.07   0.941    -38.56045     41.5604
Negative .. #|
       2017  |          0  (empty)
Negative .. #|
       2018  |    2.99994   28.90581     0.10   0.917    -53.65573    59.65561
Negative .. #|
       2019  |   1.234211   19.26958     0.06   0.949    -36.53436    39.00279
Negative .. #|
       2020  |          0  (empty)
Negative .. #|
       2021  |    1.49997   23.60062     0.06   0.949    -44.75748    47.75742
Negative .. #|
       2022  |    .288076    28.9115     0.01   0.992    -56.37875    56.95491
Negative .. #|
       2023  |   .9999801    21.5441     0.05   0.963    -41.22667    43.22663
    $0#2015  |   4.073198   16.95512     0.24   0.810    -29.15901     37.3054
    $0#2016  |   5.609354   16.92501     0.33   0.740    -27.56384    38.78255
    $0#2017  |   5.854043   16.93921     0.35   0.730    -27.34698    39.05507
    $0#2018  |   14.19697   17.00021     0.84   0.404    -19.12361    47.51755
    $0#2019  |   17.69172   16.96385     1.04   0.297     -15.5576    50.94104
    $0#2020  |   6.220691   17.12153     0.36   0.716    -27.33768    39.77906
    $0#2021  |   9.313381   16.92146     0.55   0.582    -23.85284     42.4796
    $0#2022  |   5.362216   16.93528     0.32   0.752    -27.83111    38.55554
    $0#2023  |   5.511796   16.92507     0.33   0.745    -27.66151     38.6851
    $1-$25K #|
       2015  |   8.931585   16.71477     0.53   0.593    -23.82952    41.69269
    $1-$25K #|
       2016  |   9.535397   16.71662     0.57   0.568    -23.22935    42.30015
    $1-$25K #|
       2017  |   7.532446   16.71382     0.45   0.652    -25.22681     40.2917
    $1-$25K #|
       2018  |   8.113149   16.71637     0.49   0.627     -24.6511     40.8774
    $1-$25K #|
       2019  |   10.25213   16.71937     0.61   0.540      -22.518    43.02226
    $1-$25K #|
       2020  |   8.407665   16.72506     0.50   0.615    -24.37363    41.18896
    $1-$25K #|
       2021  |   7.574782   16.71427     0.45   0.650    -25.18534    40.33491
    $1-$25K #|
       2022  |    7.71816    16.7148     0.46   0.644    -25.04301    40.47933
    $1-$25K #|
       2023  |   5.934847   16.71745     0.36   0.723    -26.83152    38.70121
  $25K-$50K #|
       2015  |   8.141711   16.70657     0.49   0.626    -24.60333    40.88675
  $25K-$50K #|
       2016  |   8.569513   16.70725     0.51   0.608    -24.17687    41.31589
  $25K-$50K #|
       2017  |   5.745917   16.70744     0.34   0.731    -27.00083    38.49266
  $25K-$50K #|
       2018  |   8.054434   16.70836     0.48   0.630    -24.69412    40.80298
  $25K-$50K #|
       2019  |   8.462833   16.70998     0.51   0.613    -24.28889    41.21456
  $25K-$50K #|
       2020  |   7.807325   16.71587     0.47   0.640    -24.95594    40.57059
  $25K-$50K #|
       2021  |   7.377488   16.70983     0.44   0.659    -25.37395    40.12893
  $25K-$50K #|
       2022  |   9.477475   16.70839     0.57   0.571    -23.27114    42.22609
  $25K-$50K #|
       2023  |    5.89211   16.70968     0.35   0.724    -26.85902    38.64324
 $50K-$100K #|
       2015  |   8.398955   16.69931     0.50   0.615    -24.33187    41.12978
 $50K-$100K #|
       2016  |   8.718321   16.69895     0.52   0.602    -24.01179    41.44843
 $50K-$100K #|
       2017  |   7.200398   16.69887     0.43   0.666    -25.52956    39.93035
 $50K-$100K #|
       2018  |   7.955259   16.69975     0.48   0.634    -24.77642    40.68694
 $50K-$100K #|
       2019  |   6.786337   16.69914     0.41   0.684    -25.94414    39.51681
 $50K-$100K #|
       2020  |    8.87987   16.70258     0.53   0.595    -23.85736     41.6171
 $50K-$100K #|
       2021  |   8.598122   16.69847     0.51   0.607    -24.13104    41.32729
 $50K-$100K #|
       2022  |    8.03324    16.6995     0.48   0.630    -24.69794    40.76442
 $50K-$100K #|
       2023  |   7.481225   16.69965     0.45   0.654    -25.25027    40.21272
$100K-$200K #|
       2015  |   8.624451   16.69862     0.52   0.606    -24.10502    41.35392
$100K-$200K #|
       2016  |   7.568963   16.69865     0.45   0.650    -25.16056    40.29848
$100K-$200K #|
       2017  |   7.235867   16.69852     0.43   0.665     -25.4934    39.96514
$100K-$200K #|
       2018  |   7.853425   16.69832     0.47   0.638    -24.87546    40.58231
$100K-$200K #|
       2019  |   6.709715   16.69767     0.40   0.688    -26.01789    39.43732
$100K-$200K #|
       2020  |   9.557321   16.69967     0.57   0.567     -23.1742    42.28884
$100K-$200K #|
       2021  |   8.404917   16.69737     0.50   0.615    -24.32209    41.13192
$100K-$200K #|
       2022  |    9.67297   16.69784     0.58   0.562    -23.05496     42.4009
$100K-$200K #|
       2023  |    9.63654   16.69765     0.58   0.564    -23.09103    42.36411
$200K+#2015  |   7.767626   16.71077     0.46   0.642    -24.98564    40.52089
$200K+#2016  |   7.210952    16.7081     0.43   0.666     -25.5371      39.959
$200K+#2017  |   9.981555   16.70836     0.60   0.550    -22.76699     42.7301
$200K+#2018  |   9.504325   16.70487     0.57   0.569    -23.23739    42.24604
$200K+#2019  |   8.138367   16.70453     0.49   0.626    -24.60267     40.8794
$200K+#2020  |    6.18413    16.7055     0.37   0.711    -26.55882    38.92708
$200K+#2021  |   10.73668   16.70316     0.64   0.520    -22.00168    43.47504
$200K+#2022  |   11.21869   16.70471     0.67   0.502    -21.52272    43.96009
$200K+#2023  |   9.818454   16.70335     0.59   0.557    -22.92028    42.55719
             |
       _cons |  -2.308414   16.68853    -0.14   0.890     -35.0181    30.40127
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(robust) absorb(stat
> e_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)
warning: variance matrix is nonsymmetric or highly singular.

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  60,  51549) =      35.17
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0075
                                                  Adj R-squared   =     0.0062
                                                  Within R-sq.    =     0.0029
                                                  Root MSE        =    23.6001

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_ftotinc#|
        year |
Negative .. #|
       2016  |    1.49997          .        .       .            .           .
Negative .. #|
       2017  |          0  (empty)
Negative .. #|
       2018  |    2.99994          .        .       .            .           .
Negative .. #|
       2019  |   1.234211          .        .       .            .           .
Negative .. #|
       2020  |          0  (empty)
Negative .. #|
       2021  |    1.49997          .        .       .            .           .
Negative .. #|
       2022  |    .288076          .        .       .            .           .
Negative .. #|
       2023  |   .9999801          .        .       .            .           .
    $0#2015  |   4.073198          .        .       .            .           .
    $0#2016  |   5.609354          .        .       .            .           .
    $0#2017  |   5.854043          .        .       .            .           .
    $0#2018  |   14.19697          .        .       .            .           .
    $0#2019  |   17.69172          .        .       .            .           .
    $0#2020  |   6.220691          .        .       .            .           .
    $0#2021  |   9.313381          .        .       .            .           .
    $0#2022  |   5.362216          .        .       .            .           .
    $0#2023  |   5.511796          .        .       .            .           .
    $1-$25K #|
       2015  |   8.931585          .        .       .            .           .
    $1-$25K #|
       2016  |   9.535397          .        .       .            .           .
    $1-$25K #|
       2017  |   7.532446          .        .       .            .           .
    $1-$25K #|
       2018  |   8.113149          .        .       .            .           .
    $1-$25K #|
       2019  |   10.25213          .        .       .            .           .
    $1-$25K #|
       2020  |   8.407665          .        .       .            .           .
    $1-$25K #|
       2021  |   7.574782          .        .       .            .           .
    $1-$25K #|
       2022  |    7.71816          .        .       .            .           .
    $1-$25K #|
       2023  |   5.934847          .        .       .            .           .
  $25K-$50K #|
       2015  |   8.141711          .        .       .            .           .
  $25K-$50K #|
       2016  |   8.569513          .        .       .            .           .
  $25K-$50K #|
       2017  |   5.745917          .        .       .            .           .
  $25K-$50K #|
       2018  |   8.054434          .        .       .            .           .
  $25K-$50K #|
       2019  |   8.462833          .        .       .            .           .
  $25K-$50K #|
       2020  |   7.807325          .        .       .            .           .
  $25K-$50K #|
       2021  |   7.377488          .        .       .            .           .
  $25K-$50K #|
       2022  |   9.477475          .        .       .            .           .
  $25K-$50K #|
       2023  |    5.89211          .        .       .            .           .
 $50K-$100K #|
       2015  |   8.398955          .        .       .            .           .
 $50K-$100K #|
       2016  |   8.718321          .        .       .            .           .
 $50K-$100K #|
       2017  |   7.200398          .        .       .            .           .
 $50K-$100K #|
       2018  |   7.955259          .        .       .            .           .
 $50K-$100K #|
       2019  |   6.786337          .        .       .            .           .
 $50K-$100K #|
       2020  |    8.87987          .        .       .            .           .
 $50K-$100K #|
       2021  |   8.598122          .        .       .            .           .
 $50K-$100K #|
       2022  |    8.03324          .        .       .            .           .
 $50K-$100K #|
       2023  |   7.481225          .        .       .            .           .
$100K-$200K #|
       2015  |   8.624451          .        .       .            .           .
$100K-$200K #|
       2016  |   7.568963          .        .       .            .           .
$100K-$200K #|
       2017  |   7.235867          .        .       .            .           .
$100K-$200K #|
       2018  |   7.853425          .        .       .            .           .
$100K-$200K #|
       2019  |   6.709715          .        .       .            .           .
$100K-$200K #|
       2020  |   9.557321          .        .       .            .           .
$100K-$200K #|
       2021  |   8.404917          .        .       .            .           .
$100K-$200K #|
       2022  |    9.67297          .        .       .            .           .
$100K-$200K #|
       2023  |    9.63654          .        .       .            .           .
$200K+#2015  |   7.767626          .        .       .            .           .
$200K+#2016  |   7.210952          .        .       .            .           .
$200K+#2017  |   9.981555          .        .       .            .           .
$200K+#2018  |   9.504325          .        .       .            .           .
$200K+#2019  |   8.138367          .        .       .            .           .
$200K+#2020  |    6.18413          .        .       .            .           .
$200K+#2021  |   10.73668          .        .       .            .           .
$200K+#2022  |   11.21869          .        .       .            .           .
$200K+#2023  |   9.818454          .        .       .            .           .
             |
       _cons |  -2.308414          .        .       .            .           .
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. reghdfe out_1 i.cat_incwage #i.year if sample_1 == 1 , vce(robust) absorb(sta
> te_fips_o county_fips_o cat_married)
# invalid name
r(198);

. reghdfe out_1 i.cat_incwage#i.year if sample_1 == 1 , vce(robust) absorb(stat
> e_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  53,  51556) =       3.39
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0080
                                                  Adj R-squared   =     0.0069
                                                  Within R-sq.    =     0.0034
                                                  Root MSE        =    23.5924

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_incwage#|
        year |
    $0#2016  |    .831175    .660698     1.26   0.208    -.4637998     2.12615
    $0#2017  |    .295682   .6402992     0.46   0.644    -.9593108    1.550675
    $0#2018  |   .8756901   .6628592     1.32   0.186    -.4235205    2.174901
    $0#2019  |   .1953404    .632294     0.31   0.757    -1.043962    1.434643
    $0#2020  |   .6294782   .6883762     0.91   0.360    -.7197461    1.978702
    $0#2021  |   .4278748   .6254512     0.68   0.494    -.7980159    1.653765
    $0#2022  |   2.117011   .7016197     3.02   0.003     .7418292    3.492193
    $0#2023  |  -.0355339   .6227763    -0.06   0.954    -1.256182    1.185114
    $1-$25K #|
       2015  |   5.394043   1.078083     5.00   0.000      3.28099    7.507097
    $1-$25K #|
       2016  |    3.83298   1.013564     3.78   0.000     1.846385    5.819575
    $1-$25K #|
       2017  |   1.373431    .866789     1.58   0.113    -.3254845    3.072346
    $1-$25K #|
       2018  |   2.738719   .9629817     2.84   0.004     .8512655    4.626173
    $1-$25K #|
       2019  |   3.011496   .9951493     3.03   0.002     1.060994    4.961999
    $1-$25K #|
       2020  |   4.510957   1.171236     3.85   0.000     2.215323    6.806591
    $1-$25K #|
       2021  |   4.565164   1.050821     4.34   0.000     2.505545    6.624783
    $1-$25K #|
       2022  |   2.992148   1.011913     2.96   0.003     1.008788    4.975509
    $1-$25K #|
       2023  |   2.461741   1.037572     2.37   0.018     .4280891    4.495394
  $25K-$50K #|
       2015  |   1.868994   .8889708     2.10   0.036     .1266022    3.611386
  $25K-$50K #|
       2016  |   3.086494   .9564347     3.23   0.001     1.211873    4.961116
  $25K-$50K #|
       2017  |   .0335606    .787357     0.04   0.966    -1.509667    1.576788
  $25K-$50K #|
       2018  |   2.735229   .9528014     2.87   0.004     .8677292     4.60273
  $25K-$50K #|
       2019  |   2.611433   .9431839     2.77   0.006     .7627828    4.460082
  $25K-$50K #|
       2020  |   2.821169    1.03504     2.73   0.006     .7924794    4.849858
  $25K-$50K #|
       2021  |   3.646523   1.021082     3.57   0.000     1.645192    5.647854
  $25K-$50K #|
       2022  |   2.189429   .9360133     2.34   0.019      .354834    4.024025
  $25K-$50K #|
       2023  |   2.286571   .9552771     2.39   0.017     .4142179    4.158923
 $50K-$100K #|
       2015  |   2.540343   .8426536     3.01   0.003      .888734    4.191953
 $50K-$100K #|
       2016  |   1.458526   .8019054     1.82   0.069    -.1132165    3.030269
 $50K-$100K #|
       2017  |   2.319625   .8329759     2.78   0.005     .6869841    3.952266
 $50K-$100K #|
       2018  |   1.995484   .8236303     2.42   0.015     .3811599    3.609807
 $50K-$100K #|
       2019  |   1.252819   .7835012     1.60   0.110    -.2828514    2.788489
 $50K-$100K #|
       2020  |   2.764596   .9118507     3.03   0.002     .9773593    4.551832
 $50K-$100K #|
       2021  |   1.814807   .7909043     2.29   0.022     .2646267    3.364987
 $50K-$100K #|
       2022  |   3.476368   .8644798     4.02   0.000     1.781979    5.170757
 $50K-$100K #|
       2023  |   2.722319   .8097144     3.36   0.001     1.135271    4.309367
$100K-$200K #|
       2015  |   1.979643    1.05021     1.88   0.059    -.0787791    4.038065
$100K-$200K #|
       2016  |   1.071967   .9611105     1.12   0.265    -.8118193    2.955753
$100K-$200K #|
       2017  |   2.500831   1.097176     2.28   0.023      .350356    4.651306
$100K-$200K #|
       2018  |   2.407151   1.010789     2.38   0.017     .4259945    4.388307
$100K-$200K #|
       2019  |   1.123305   .9101989     1.23   0.217    -.6606939    2.907304
$100K-$200K #|
       2020  |   .7442977   .9457551     0.79   0.431    -1.109392    2.597987
$100K-$200K #|
       2021  |   4.111122   1.064395     3.86   0.000     2.024898    6.197346
$100K-$200K #|
       2022  |    4.53338   1.147552     3.95   0.000     2.284168    6.782593
$100K-$200K #|
       2023  |   3.284341   1.066135     3.08   0.002     1.194705    5.373977
$200K+#2015  |    1.50285   1.994322     0.75   0.451    -2.406042    5.411741
$200K+#2016  |  -.8958256   1.280084    -0.70   0.484    -3.404803    1.613152
$200K+#2017  |   .4077552   1.525718     0.27   0.789    -2.582667    3.398177
$200K+#2018  |   2.498365   1.761315     1.42   0.156    -.9538295    5.950559
$200K+#2019  |  -.8664599   1.173343    -0.74   0.460    -3.166224    1.433304
$200K+#2020  |   .2076473   1.402795     0.15   0.882    -2.541846     2.95714
$200K+#2021  |   3.396012    1.74459     1.95   0.052    -.0234017    6.815426
$200K+#2022  |   4.488103   1.867951     2.40   0.016     .8268999    8.149307
$200K+#2023  |   5.590677   1.950221     2.87   0.004     1.768224     9.41313
             |
       _cons |   4.034558   .4494762     8.98   0.000      3.15358    4.915536
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. reghdfe out_1 i.cat_incearn#i.year if sample_1 == 1 , vce(robust) absorb(stat
> e_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)
warning: missing F statistic; dropped variables due to collinearity or too few 
> clusters

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  62,  51547) =          .
                                                  Prob > F        =          .
                                                  R-squared       =     0.0086
                                                  Adj R-squared   =     0.0074
                                                  Within R-sq.    =     0.0041
                                                  Root MSE        =    23.5868

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_incearn#|
        year |
Negative .. #|
       2016  |    1.19227    .607653     1.96   0.050     .0012644    2.383276
Negative .. #|
       2017  |   23.75729   13.95411     1.70   0.089    -3.592897    51.10748
Negative .. #|
       2018  |   1.706534   .5219139     3.27   0.001     .6835778    2.729491
Negative .. #|
       2019  |    .200369    .731012     0.27   0.784    -1.232422     1.63316
Negative .. #|
       2020  |   1.963617   .4769365     4.12   0.000     1.028816    2.898417
Negative .. #|
       2021  |   1.963617   .4769365     4.12   0.000     1.028816    2.898417
Negative .. #|
       2022  |   101.9636   .4769365   213.79   0.000     101.0288    102.8984
Negative .. #|
       2023  |   .9861491   .8184179     1.20   0.228    -.6179581    2.590256
    $0#2015  |   4.802942   .6808405     7.05   0.000     3.468488    6.137396
    $0#2016  |   5.457719   .6962724     7.84   0.000     4.093018     6.82242
    $0#2017  |   4.840354   .6714565     7.21   0.000     3.524292    6.156415
    $0#2018  |   5.595128    .710824     7.87   0.000     4.201905     6.98835
    $0#2019  |   5.235852   .6820549     7.68   0.000     3.899018    6.572687
    $0#2020  |   5.067239   .7161464     7.08   0.000     3.663585    6.470893
    $0#2021  |   4.740982   .6421124     7.38   0.000     3.482436    5.999529
    $0#2022  |   6.450845   .7316261     8.82   0.000     5.016851     7.88484
    $0#2023  |   4.513364   .6494705     6.95   0.000     3.240395    5.786332
    $1-$25K #|
       2015  |   9.727971   1.000471     9.72   0.000     7.767039     11.6889
    $1-$25K #|
       2016  |   8.386216   .9614612     8.72   0.000     6.501743    10.27069
    $1-$25K #|
       2017  |   6.177791   .8347326     7.40   0.000     4.541706    7.813875
    $1-$25K #|
       2018  |   7.853083   .9332339     8.41   0.000     6.023935    9.682231
    $1-$25K #|
       2019  |   7.370686   .9307327     7.92   0.000      5.54644    9.194931
    $1-$25K #|
       2020  |   9.541367   1.113636     8.57   0.000      7.35863     11.7241
    $1-$25K #|
       2021  |   9.791467   1.020103     9.60   0.000     7.792054    11.79088
    $1-$25K #|
       2022  |   8.133935   .9698191     8.39   0.000      6.23308    10.03479
    $1-$25K #|
       2023  |   7.100435   .9774944     7.26   0.000     5.184536    9.016333
  $25K-$50K #|
       2015  |   6.513607   .8621908     7.55   0.000     4.823705     8.20351
  $25K-$50K #|
       2016  |    8.02593   .9353151     8.58   0.000     6.192703    9.859157
  $25K-$50K #|
       2017  |   4.723415   .7689579     6.14   0.000      3.21625     6.23058
  $25K-$50K #|
       2018  |    7.15268   .9086843     7.87   0.000      5.37165    8.933711
  $25K-$50K #|
       2019  |   7.014897   .9001587     7.79   0.000     5.250577    8.779217
  $25K-$50K #|
       2020  |   7.493226   1.010447     7.42   0.000      5.51274    9.473712
  $25K-$50K #|
       2021  |   8.541089   .9985481     8.55   0.000     6.583925    10.49825
  $25K-$50K #|
       2022  |   7.079946   .9219138     7.68   0.000     5.272986    8.886906
  $25K-$50K #|
       2023  |   6.822968   .9104733     7.49   0.000     5.038431    8.607505
 $50K-$100K #|
       2015  |   7.227397   .8306305     8.70   0.000     5.599353    8.855441
 $50K-$100K #|
       2016  |   6.251723   .7948951     7.86   0.000      4.69372    7.809725
 $50K-$100K #|
       2017  |   7.167097   .8245196     8.69   0.000     5.551031    8.783164
 $50K-$100K #|
       2018  |    6.61764   .8057214     8.21   0.000     5.038418    8.196862
 $50K-$100K #|
       2019  |   6.058939    .773034     7.84   0.000     4.543785    7.574094
 $50K-$100K #|
       2020  |   7.569835   .9035949     8.38   0.000      5.79878     9.34089
 $50K-$100K #|
       2021  |   6.500227   .7790884     8.34   0.000     4.973206    8.027248
 $50K-$100K #|
       2022  |   8.491269   .8654444     9.81   0.000     6.794989    10.18755
 $50K-$100K #|
       2023  |   7.621155   .8115298     9.39   0.000     6.030549    9.211762
$100K-$200K #|
       2015  |   6.481696   1.010427     6.41   0.000      4.50125    8.462142
$100K-$200K #|
       2016  |   5.811684   .9436669     6.16   0.000     3.962087     7.66128
$100K-$200K #|
       2017  |   6.867316   1.050851     6.54   0.000     4.807638    8.926994
$100K-$200K #|
       2018  |   7.225745   .9897703     7.30   0.000     5.285785    9.165704
$100K-$200K #|
       2019  |   5.862441   .8988361     6.52   0.000     4.100713    7.624169
$100K-$200K #|
       2020  |   5.394315   .9303833     5.80   0.000     3.570754    7.217875
$100K-$200K #|
       2021  |   8.550352   1.023369     8.36   0.000     6.544538    10.55617
$100K-$200K #|
       2022  |   8.898786   1.105598     8.05   0.000     6.731802    11.06577
$100K-$200K #|
       2023  |    7.88356   1.035622     7.61   0.000     5.853731     9.91339
$200K+#2015  |   5.943724   1.770315     3.36   0.001     2.473889    9.413559
$200K+#2016  |   3.702712   1.195969     3.10   0.002     1.358601    6.046823
$200K+#2017  |   6.370212   1.632441     3.90   0.000     3.170611    9.569813
$200K+#2018  |   6.649934   1.593877     4.17   0.000     3.525919    9.773949
$200K+#2019  |   3.752539   1.104635     3.40   0.001     1.587442    5.917635
$200K+#2020  |   4.589747   1.273144     3.61   0.000     2.094372    7.085123
$200K+#2021  |   7.563743    1.60847     4.70   0.000     4.411126    10.71636
$200K+#2022  |   8.936028   1.748495     5.11   0.000     5.508959     12.3631
$200K+#2023  |   10.36347   1.827892     5.67   0.000     6.780784    13.94616
             |
       _cons |  -.7625754   .4557438    -1.67   0.094    -1.655838    .1306871
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(robust) absorb(stat
> e_fips_o county_fips_o cat_married)
--Break--
r(1);

. summ ftotinc

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
     ftotinc | 20,893,859    103442.1    109052.7     -21500    3164000

. summ ftotinc, de

                           ftotinc
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0         -21500
 5%        10400         -21500
10%        18600         -21500       Obs          20,893,859
25%        39640         -21500       Sum of wgt.    20893859

50%        75001                      Mean           103442.1
                        Largest       Std. dev.      109052.7
75%       129000        2907600
90%       205900        2907600       Variance       1.19e+10
95%       285000        3164000       Skewness       3.595562
99%       573000        3164000       Kurtosis        25.1107

. reghdfe out_1 i.cat_ftotinc#i.year if sample_1 == 1 , vce(robust) absorb(stat
> e_fips_o county_fips_o cat_married)
(MWFE estimator converged in 2 iterations)
warning: variance matrix is nonsymmetric or highly singular.

HDFE Linear regression                            Number of obs   =     51,613
Absorbing 3 HDFE groups                           F(  60,  51549) =      35.17
                                                  Prob > F        =     0.0000
                                                  R-squared       =     0.0075
                                                  Adj R-squared   =     0.0062
                                                  Within R-sq.    =     0.0029
                                                  Root MSE        =    23.6001

------------------------------------------------------------------------------
             |               Robust
       out_1 | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-------------+----------------------------------------------------------------
 cat_ftotinc#|
        year |
Negative .. #|
       2016  |    1.49997          .        .       .            .           .
Negative .. #|
       2017  |          0  (empty)
Negative .. #|
       2018  |    2.99994          .        .       .            .           .
Negative .. #|
       2019  |   1.234211          .        .       .            .           .
Negative .. #|
       2020  |          0  (empty)
Negative .. #|
       2021  |    1.49997          .        .       .            .           .
Negative .. #|
       2022  |    .288076          .        .       .            .           .
Negative .. #|
       2023  |   .9999801          .        .       .            .           .
    $0#2015  |   4.073198          .        .       .            .           .
    $0#2016  |   5.609354          .        .       .            .           .
    $0#2017  |   5.854043          .        .       .            .           .
    $0#2018  |   14.19697          .        .       .            .           .
    $0#2019  |   17.69172          .        .       .            .           .
    $0#2020  |   6.220691          .        .       .            .           .
    $0#2021  |   9.313381          .        .       .            .           .
    $0#2022  |   5.362216          .        .       .            .           .
    $0#2023  |   5.511796          .        .       .            .           .
    $1-$25K #|
       2015  |   8.931585          .        .       .            .           .
    $1-$25K #|
       2016  |   9.535397          .        .       .            .           .
    $1-$25K #|
       2017  |   7.532446          .        .       .            .           .
    $1-$25K #|
       2018  |   8.113149          .        .       .            .           .
    $1-$25K #|
       2019  |   10.25213          .        .       .            .           .
    $1-$25K #|
       2020  |   8.407665          .        .       .            .           .
    $1-$25K #|
       2021  |   7.574782          .        .       .            .           .
    $1-$25K #|
       2022  |    7.71816          .        .       .            .           .
    $1-$25K #|
       2023  |   5.934847          .        .       .            .           .
  $25K-$50K #|
       2015  |   8.141711          .        .       .            .           .
  $25K-$50K #|
       2016  |   8.569513          .        .       .            .           .
  $25K-$50K #|
       2017  |   5.745917          .        .       .            .           .
  $25K-$50K #|
       2018  |   8.054434          .        .       .            .           .
  $25K-$50K #|
       2019  |   8.462833          .        .       .            .           .
  $25K-$50K #|
       2020  |   7.807325          .        .       .            .           .
  $25K-$50K #|
       2021  |   7.377488          .        .       .            .           .
  $25K-$50K #|
       2022  |   9.477475          .        .       .            .           .
  $25K-$50K #|
       2023  |    5.89211          .        .       .            .           .
 $50K-$100K #|
       2015  |   8.398955          .        .       .            .           .
 $50K-$100K #|
       2016  |   8.718321          .        .       .            .           .
 $50K-$100K #|
       2017  |   7.200398          .        .       .            .           .
 $50K-$100K #|
       2018  |   7.955259          .        .       .            .           .
 $50K-$100K #|
       2019  |   6.786337          .        .       .            .           .
 $50K-$100K #|
       2020  |    8.87987          .        .       .            .           .
 $50K-$100K #|
       2021  |   8.598122          .        .       .            .           .
 $50K-$100K #|
       2022  |    8.03324          .        .       .            .           .
 $50K-$100K #|
       2023  |   7.481225          .        .       .            .           .
$100K-$200K #|
       2015  |   8.624451          .        .       .            .           .
$100K-$200K #|
       2016  |   7.568963          .        .       .            .           .
$100K-$200K #|
       2017  |   7.235867          .        .       .            .           .
$100K-$200K #|
       2018  |   7.853425          .        .       .            .           .
$100K-$200K #|
       2019  |   6.709715          .        .       .            .           .
$100K-$200K #|
       2020  |   9.557321          .        .       .            .           .
$100K-$200K #|
       2021  |   8.404917          .        .       .            .           .
$100K-$200K #|
       2022  |    9.67297          .        .       .            .           .
$100K-$200K #|
       2023  |    9.63654          .        .       .            .           .
$200K+#2015  |   7.767626          .        .       .            .           .
$200K+#2016  |   7.210952          .        .       .            .           .
$200K+#2017  |   9.981555          .        .       .            .           .
$200K+#2018  |   9.504325          .        .       .            .           .
$200K+#2019  |   8.138367          .        .       .            .           .
$200K+#2020  |    6.18413          .        .       .            .           .
$200K+#2021  |   10.73668          .        .       .            .           .
$200K+#2022  |   11.21869          .        .       .            .           .
$200K+#2023  |   9.818454          .        .       .            .           .
             |
       _cons |  -2.308414          .        .       .            .           .
------------------------------------------------------------------------------

Absorbed degrees of freedom:
-------------------------------------------------------+
   Absorbed FE | Categories  - Redundant  = Num. Coefs |
---------------+---------------------------------------|
  state_fips_o |         1           0           1     |
 county_fips_o |         1           1           0     |
   cat_married |         4           1           3    ?|
-------------------------------------------------------+
? = number of redundant parameters may be higher

. tab cat_ftotinc year

   Total family |
         income |
     categories |                    year
(real 2023 USD) |      2015       2016       2017       2018 |     Total
----------------+--------------------------------------------+----------
Negative income |       584        609        791        822 |     7,238 
             $0 |    26,739     26,280     26,587     25,884 |   226,387 
        $1-$25K |   260,504    255,904    259,142    255,330 | 2,249,309 
      $25K-$50K |   385,373    377,803    376,378    374,108 | 3,258,513 
     $50K-$100K |   668,682    661,840    664,973    669,703 | 5,975,505 
    $100K-$200K |   651,864    662,501    671,310    683,873 | 6,147,777 
         $200K+ |   290,786    308,694    316,476    329,847 | 3,029,130 
----------------+--------------------------------------------+----------
          Total | 2,284,532  2,293,631  2,315,657  2,339,567 |20,893,859 


   Total family |
         income |
     categories |                    year
(real 2023 USD) |      2019       2020       2021       2022 |     Total
----------------+--------------------------------------------+----------
Negative income |       786        644        962      1,029 |     7,238 
             $0 |    23,323     17,360     27,070     26,924 |   226,387 
        $1-$25K |   237,660    186,227    260,796    271,970 | 2,249,309 
      $25K-$50K |   353,562    275,713    363,260    380,372 | 3,258,513 
     $50K-$100K |   674,850    527,757    676,878    712,684 | 5,975,505 
    $100K-$200K |   720,185    583,082    705,559    719,002 | 6,147,777 
         $200K+ |   370,801    309,367    360,532    358,877 | 3,029,130 
----------------+--------------------------------------------+----------
          Total | 2,381,167  1,900,150  2,395,057  2,470,858 |20,893,859 


   Total family |
         income |
     categories |    year
(real 2023 USD) |      2023 |     Total
----------------+-----------+----------
Negative income |     1,011 |     7,238 
             $0 |    26,220 |   226,387 
        $1-$25K |   261,776 | 2,249,309 
      $25K-$50K |   371,944 | 3,258,513 
     $50K-$100K |   718,138 | 5,975,505 
    $100K-$200K |   750,401 | 6,147,777 
         $200K+ |   383,750 | 3,029,130 
----------------+-----------+----------
          Total | 2,513,240 |20,893,859 

. tab cat_ftotinc year if sample_1 == 1

   Total family |
         income |
     categories |                    year
(real 2023 USD) |      2015       2016       2017       2018 |     Total
----------------+--------------------------------------------+----------
Negative income |         2          4          0          1 |        19 
             $0 |        62         70         66         53 |       557 
        $1-$25K |       629        590        653        594 |     5,296 
      $25K-$50K |       917        882        871        833 |     7,254 
     $50K-$100K |     1,544      1,594      1,611      1,470 |    13,609 
    $100K-$200K |     1,699      1,690      1,722      1,748 |    15,847 
         $200K+ |       769        878        864      1,054 |     9,031 
----------------+--------------------------------------------+----------
          Total |     5,622      5,708      5,787      5,753 |    51,613 


   Total family |
         income |
     categories |                    year
(real 2023 USD) |      2019       2020       2021       2022 |     Total
----------------+--------------------------------------------+----------
Negative income |         6          0          2          1 |        19 
             $0 |        60         38         71         67 |       557 
        $1-$25K |       536        454        641        628 |     5,296 
      $25K-$50K |       768        604        776        827 |     7,254 
     $50K-$100K |     1,565      1,181      1,659      1,507 |    13,609 
    $100K-$200K |     1,863      1,521      1,926      1,812 |    15,847 
         $200K+ |     1,076      1,007      1,171      1,055 |     9,031 
----------------+--------------------------------------------+----------
          Total |     5,874      4,805      6,246      5,897 |    51,613 


   Total family |
         income |
     categories |    year
(real 2023 USD) |      2023 |     Total
----------------+-----------+----------
Negative income |         3 |        19 
             $0 |        70 |       557 
        $1-$25K |       571 |     5,296 
      $25K-$50K |       776 |     7,254 
     $50K-$100K |     1,478 |    13,609 
    $100K-$200K |     1,866 |    15,847 
         $200K+ |     1,157 |     9,031 
----------------+-----------+----------
          Total |     5,921 |    51,613 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001s.tmp"

. /****************************************************************************
> ***
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *****************************************************************************
> **/
. 
. ** --------------------------------------------------------------------------
> -
. ** Start log file
. ** --------------------------------------------------------------------------
> -
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
-------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_
> log_individual_2025-12-16.log
  log type:  text
 opened on:  17 Dec 2025, 14:23:25

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately aft
> er
. **   levelsof (before moving into the posted coefficient dataset) to avoid an
> y
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** --------------------------------------------------------------------------
> -
. ** --------------------------------------------------------------------------
> -
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional
>  means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** --------------------------------------------------------------------------
> -
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ----------------------------------------------------------------------
> -
.     ** Configuration: project root for relative paths
.     ** ----------------------------------------------------------------------
> -
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-ta
> x/"
  4. 
.     ** ----------------------------------------------------------------------
> -
.     ** Debug flags
.     ** ----------------------------------------------------------------------
> -
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "-------------------------------------------------------
> -----"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype
> =`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "-------------------------------------------------------
> -----"
 24.     }
 25. 
.     ** ----------------------------------------------------------------------
> -
.     ** Requirements
.     ** ----------------------------------------------------------------------
> -
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe,
>  replace"
 28.         exit 198
 29.     }
 30. 
.     ** ----------------------------------------------------------------------
> -
.     ** Mark sample
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filter
> s."
 37.         exit 2000
 38.     }
 39. 
.     ** ----------------------------------------------------------------------
> -
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either 
> create it or pass weights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ----------------------------------------------------------------------
> -
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly 
> converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ----------------------------------------------------------------------
> -
.     ** Guard: CAT should not also be absorbed
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb
> '. Remove it from absorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ----------------------------------------------------------------------
> -
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample
> ."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserv
> e/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** ----------------------------------------------------------------------
> -
.     ** Base year sanity check (only if baseyear != 0)
.     ** ----------------------------------------------------------------------
> -
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation samp
> le years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** ----------------------------------------------------------------------
> -
.     ** Regression (supports margins over CAT × YEAR)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `w
> gt', absorb(`absorb') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** ----------------------------------------------------------------------
> -
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdat
> a', replace) post
134. 
.     ** ----------------------------------------------------------------------
> -
.     ** Plot using the saved margins dataset
.     ** ----------------------------------------------------------------------
> -
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The s
> aved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the ord
> er supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is ca
> lled with: margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is ca
> lled with: margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot pl
> ot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear
> (`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, 
> .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in basey
> ear(`baseyear'). Cannot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** ------------------------------------------------------------------
> -
.         ** Plot styling: use plotplainblind palette if available (scheme-leve
> l)
.         ** ------------------------------------------------------------------
> -
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; u
> sing current scheme: `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__o
> ldscheme')"
197.         }
198. 
.         ** ------------------------------------------------------------------
> -
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** ------------------------------------------------------------------
> -
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty
> )."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** ------------------------------------------------------------------
> -
.         ** Titles (safe quoting)
.         ** ------------------------------------------------------------------
> -
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"
> '
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (re
> lative to `baseyear')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adj
> usted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ----------------------------------------------------------
> --
.                 ** Y-axis: round "nice" ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then rounds to a nice step.
.                 ** ----------------------------------------------------------
> --
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0), anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming for ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep'))
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple of step; min down similar
> ly
.                 local __yhigh = ceil(`__ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exactly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel
> (`__ylow'(`__ystep')`__yhigh', nogrid)"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows'
> ) position(6)) 
270. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
271. 
.         ** ------------------------------------------------------------------
> -
.         ** Export figure (PDF) - robust path handling
.         ** ------------------------------------------------------------------
> -
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpath `"""' "", all
274.             local outpath : subinstr local outpath "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1
> ) != "/" {
276.                 local outpath "`__project_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creating output directory: `ou
> tdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'") {
286.                         di as error "Output directory does not exist and c
> ould not be created: `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
293.             else                graph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "-------------------------------------------------------
> -----"
299.     }
300. 
. end

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Load ACS migration data
. ** --------------------------------------------------------------------------
> -
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                                   // Error in migration
>  place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // Alaska and Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                                     // Negative Family In
> come       
(7,238 observations deleted)

.  ---------------------------------------------------------------------------
- is not a valid command name
r(199);

end of do-file

r(199);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001t.tmp"

. /****************************************************************************
> ***
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *****************************************************************************
> **/
. 
. ** --------------------------------------------------------------------------
> -
. ** Start log file
. ** --------------------------------------------------------------------------
> -
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
-------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_
> log_individual_2025-12-16.log
  log type:  text
 opened on:  17 Dec 2025, 14:24:09

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately aft
> er
. **   levelsof (before moving into the posted coefficient dataset) to avoid an
> y
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** --------------------------------------------------------------------------
> -
. ** --------------------------------------------------------------------------
> -
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional
>  means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** --------------------------------------------------------------------------
> -
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ----------------------------------------------------------------------
> -
.     ** Configuration: project root for relative paths
.     ** ----------------------------------------------------------------------
> -
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-ta
> x/"
  4. 
.     ** ----------------------------------------------------------------------
> -
.     ** Debug flags
.     ** ----------------------------------------------------------------------
> -
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "-------------------------------------------------------
> -----"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype
> =`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "-------------------------------------------------------
> -----"
 24.     }
 25. 
.     ** ----------------------------------------------------------------------
> -
.     ** Requirements
.     ** ----------------------------------------------------------------------
> -
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe,
>  replace"
 28.         exit 198
 29.     }
 30. 
.     ** ----------------------------------------------------------------------
> -
.     ** Mark sample
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filter
> s."
 37.         exit 2000
 38.     }
 39. 
.     ** ----------------------------------------------------------------------
> -
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either 
> create it or pass weights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ----------------------------------------------------------------------
> -
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly 
> converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ----------------------------------------------------------------------
> -
.     ** Guard: CAT should not also be absorbed
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb
> '. Remove it from absorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ----------------------------------------------------------------------
> -
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample
> ."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserv
> e/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** ----------------------------------------------------------------------
> -
.     ** Base year sanity check (only if baseyear != 0)
.     ** ----------------------------------------------------------------------
> -
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation samp
> le years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** ----------------------------------------------------------------------
> -
.     ** Regression (supports margins over CAT × YEAR)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `w
> gt', absorb(`absorb') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** ----------------------------------------------------------------------
> -
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdat
> a', replace) post
134. 
.     ** ----------------------------------------------------------------------
> -
.     ** Plot using the saved margins dataset
.     ** ----------------------------------------------------------------------
> -
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The s
> aved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the ord
> er supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is ca
> lled with: margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is ca
> lled with: margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot pl
> ot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear
> (`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, 
> .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in basey
> ear(`baseyear'). Cannot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** ------------------------------------------------------------------
> -
.         ** Plot styling: use plotplainblind palette if available (scheme-leve
> l)
.         ** ------------------------------------------------------------------
> -
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; u
> sing current scheme: `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__o
> ldscheme')"
197.         }
198. 
.         ** ------------------------------------------------------------------
> -
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** ------------------------------------------------------------------
> -
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty
> )."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** ------------------------------------------------------------------
> -
.         ** Titles (safe quoting)
.         ** ------------------------------------------------------------------
> -
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"
> '
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (re
> lative to `baseyear')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adj
> usted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ----------------------------------------------------------
> --
.                 ** Y-axis: round "nice" ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then rounds to a nice step.
.                 ** ----------------------------------------------------------
> --
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0), anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming for ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep'))
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple of step; min down similar
> ly
.                 local __yhigh = ceil(`__ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exactly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel
> (`__ylow'(`__ystep')`__yhigh', nogrid)"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows'
> ) position(6)) 
270. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
271. 
.         ** ------------------------------------------------------------------
> -
.         ** Export figure (PDF) - robust path handling
.         ** ------------------------------------------------------------------
> -
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpath `"""' "", all
274.             local outpath : subinstr local outpath "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1
> ) != "/" {
276.                 local outpath "`__project_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creating output directory: `ou
> tdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'") {
286.                         di as error "Output directory does not exist and c
> ould not be created: `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
293.             else                graph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "-------------------------------------------------------
> -----"
299.     }
300. 
. end

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Load ACS migration data
. ** --------------------------------------------------------------------------
> -
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                                   // Error in migration
>  place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // Alaska and Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                                     // Negative Family In
> come       
(7,238 observations deleted)

. 
. ** --------------------------------------------------------------------------
> -
. ** Multnomah indicators and samples
. ** --------------------------------------------------------------------------
> -
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,253 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,335 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Covariate categories
. ** --------------------------------------------------------------------------
> -
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,886,621 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,057,842 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,776 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,886,621 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Real income (2023 USD) and income categories
. ** --------------------------------------------------------------------------
> -
. gen tmp1 = cpi99 if year == 2023
(18,374,392 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,886,621 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     15,082        0.07        0.07
             $0 |  1,747,061        8.36        8.44
        $1-$25K |  6,203,845       29.70       38.14
      $25K-$50K |  4,981,113       23.85       61.99
     $50K-$100K |  4,947,578       23.69       85.68
    $100K-$200K |  2,211,136       10.59       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,175,889       39.14       39.14
        $1-$25K |  3,428,186       16.41       55.56
      $25K-$50K |  3,290,630       15.75       71.31
     $50K-$100K |  3,729,590       17.86       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     13,905        0.07        0.07
             $0 |  7,360,938       35.24       35.31
        $1-$25K |  3,755,724       17.98       53.29
      $25K-$50K |  3,476,928       16.65       69.94
     $50K-$100K |  3,876,560       18.56       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,529 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |    226,387        1.08        1.08
        $1-$25K |  2,249,309       10.77       11.85
      $25K-$50K |  3,258,513       15.60       27.45
     $50K-$100K |  5,975,505       28.61       56.06
    $100K-$200K |  6,147,777       29.43       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Analysis loops
. ** --------------------------------------------------------------------------
> -
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_cat_sex_
    > 1.pdf saved as PDF format
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001u.tmp"

. /****************************************************************************
> ***
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *****************************************************************************
> **/
. 
. ** --------------------------------------------------------------------------
> -
. ** Start log file
. ** --------------------------------------------------------------------------
> -
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
-------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_
> log_individual_2025-12-16.log
  log type:  text
 opened on:  17 Dec 2025, 14:30:36

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately aft
> er
. **   levelsof (before moving into the posted coefficient dataset) to avoid an
> y
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** --------------------------------------------------------------------------
> -
. ** --------------------------------------------------------------------------
> -
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional
>  means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** --------------------------------------------------------------------------
> -
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ----------------------------------------------------------------------
> -
.     ** Configuration: project root for relative paths
.     ** ----------------------------------------------------------------------
> -
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-ta
> x/"
  4. 
.     ** ----------------------------------------------------------------------
> -
.     ** Debug flags
.     ** ----------------------------------------------------------------------
> -
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "-------------------------------------------------------
> -----"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype
> =`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "-------------------------------------------------------
> -----"
 24.     }
 25. 
.     ** ----------------------------------------------------------------------
> -
.     ** Requirements
.     ** ----------------------------------------------------------------------
> -
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe,
>  replace"
 28.         exit 198
 29.     }
 30. 
.     ** ----------------------------------------------------------------------
> -
.     ** Mark sample
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filter
> s."
 37.         exit 2000
 38.     }
 39. 
.     ** ----------------------------------------------------------------------
> -
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either 
> create it or pass weights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** ----------------------------------------------------------------------
> -
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly 
> converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** ----------------------------------------------------------------------
> -
.     ** Guard: CAT should not also be absorbed
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb
> '. Remove it from absorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ----------------------------------------------------------------------
> -
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample
> ."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserv
> e/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** ----------------------------------------------------------------------
> -
.     ** Base year sanity check (only if baseyear != 0)
.     ** ----------------------------------------------------------------------
> -
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation samp
> le years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** ----------------------------------------------------------------------
> -
.     ** Regression (supports margins over CAT × YEAR)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `w
> gt', absorb(`absorb') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** ----------------------------------------------------------------------
> -
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** ----------------------------------------------------------------------
> -
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdat
> a', replace) post
134. 
.     ** ----------------------------------------------------------------------
> -
.     ** Plot using the saved margins dataset
.     ** ----------------------------------------------------------------------
> -
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The s
> aved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the ord
> er supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is ca
> lled with: margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is ca
> lled with: margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot pl
> ot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear
> (`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, 
> .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in basey
> ear(`baseyear'). Cannot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** ------------------------------------------------------------------
> -
.         ** Plot styling: use plotplainblind palette if available (scheme-leve
> l)
.         ** ------------------------------------------------------------------
> -
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; u
> sing current scheme: `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__o
> ldscheme')"
197.         }
198. 
.         ** ------------------------------------------------------------------
> -
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** ------------------------------------------------------------------
> -
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty
> )."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** ------------------------------------------------------------------
> -
.         ** Titles (safe quoting)
.         ** ------------------------------------------------------------------
> -
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"
> '
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (re
> lative to `baseyear')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adj
> usted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ----------------------------------------------------------
> --
.                 ** Y-axis: round "nice" ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then rounds to a nice step.
.                 ** ----------------------------------------------------------
> --
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0), anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming for ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep'))
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple of step; min down similar
> ly
.                 local __yhigh = ceil(`__ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exactly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel
> (`__ylow'(`__ystep')`__yhigh')"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows'
> ) position(6)) 
270. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
271. 
.         ** ------------------------------------------------------------------
> -
.         ** Export figure (PDF) - robust path handling
.         ** ------------------------------------------------------------------
> -
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpath `"""' "", all
274.             local outpath : subinstr local outpath "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1
> ) != "/" {
276.                 local outpath "`__project_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creating output directory: `ou
> tdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'") {
286.                         di as error "Output directory does not exist and c
> ould not be created: `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
293.             else                graph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "-------------------------------------------------------
> -----"
299.     }
300. 
. end

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Load ACS migration data
. ** --------------------------------------------------------------------------
> -
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                                   // Error in migration
>  place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // Alaska and Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                                     // Negative Family In
> come       
(7,238 observations deleted)

. 
. ** --------------------------------------------------------------------------
> -
. ** Multnomah indicators and samples
. ** --------------------------------------------------------------------------
> -
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,253 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,335 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Covariate categories
. ** --------------------------------------------------------------------------
> -
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,886,621 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,057,842 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,776 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,886,621 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Real income (2023 USD) and income categories
. ** --------------------------------------------------------------------------
> -
. gen tmp1 = cpi99 if year == 2023
(18,374,392 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,886,621 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     15,082        0.07        0.07
             $0 |  1,747,061        8.36        8.44
        $1-$25K |  6,203,845       29.70       38.14
      $25K-$50K |  4,981,113       23.85       61.99
     $50K-$100K |  4,947,578       23.69       85.68
    $100K-$200K |  2,211,136       10.59       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,175,889       39.14       39.14
        $1-$25K |  3,428,186       16.41       55.56
      $25K-$50K |  3,290,630       15.75       71.31
     $50K-$100K |  3,729,590       17.86       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     13,905        0.07        0.07
             $0 |  7,360,938       35.24       35.31
        $1-$25K |  3,755,724       17.98       53.29
      $25K-$50K |  3,476,928       16.65       69.94
     $50K-$100K |  3,876,560       18.56       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,529 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |    226,387        1.08        1.08
        $1-$25K |  2,249,309       10.77       11.85
      $25K-$50K |  3,258,513       15.60       27.45
     $50K-$100K |  5,975,505       28.61       56.06
    $100K-$200K |  6,147,777       29.43       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** --------------------------------------------------------------------------
> -
. ** Analysis loops
. ** --------------------------------------------------------------------------
> -
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\Documents\GitHub\multnomah-county-tax\code\02_indiv_analysis_clean.do"

. /*******************************************************************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> *******************************************************************************/
. 
. ** ---------------------------------------------------------------------------
. ** Start log file
. ** ---------------------------------------------------------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_individual_2025
> -12-16.log
  log type:  text
 opened on:  17 Dec 2025, 15:45:43

. 
. 
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) nocons
. ** - Posts:     cell means and CIs for each cat×year coefficient
. ** - Plots:     one connected series per category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store those labels immediately after
. **   levelsof (before moving into the posted coefficient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opacity.
. ** ---------------------------------------------------------------------------
. ** ---------------------------------------------------------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction and absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficients) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means).
. **   - baseyear(#) => plot within-CAT differences relative to that year.
. ** ---------------------------------------------------------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABSORB(string) ///
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -----------------------------------------------------------------------
.     ** Configuration: project root for relative paths
.     ** -----------------------------------------------------------------------
.     local __project_root "C:/Users/ji252/Documents/GitHub/multnomah-county-tax/"
  4. 
.     ** -----------------------------------------------------------------------
.     ** Debug flags
.     ** -----------------------------------------------------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' exp=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------------------------------------"
 24.     }
 25. 
.     ** -----------------------------------------------------------------------
.     ** Requirements
.     ** -----------------------------------------------------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install with: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** -----------------------------------------------------------------------
.     ** Mark sample
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(`varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available after applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** -----------------------------------------------------------------------
.     ** Weights (default fw=perwt unless caller provided weights)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable `wvar' not found. Either create it or pass w
> eights explicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default weights: `wgt'"
 55.     }
 56. 
.     ** -----------------------------------------------------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`__year') force
 71.         capture assert !missing(`__year') if `touse'
 72.         if _rc {
 73.             di as error "Year variable is string and could not be cleanly converted to numeri
> c."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already numeric -> `yearv'"
 82.     }
 83. 
.     ** -----------------------------------------------------------------------
.     ** Guard: CAT should not also be absorbed
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' appears in absorb(): `absorb'. Remove it from a
> bsorb() for this run."
 86.         exit 198
 87.     }
 88. 
.     ** -----------------------------------------------------------------------
.     ** Levels and labels (save labels NOW, before switching datasets)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year and category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yrs)
 90.     quietly levelsof `catv'  if `touse', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels found in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tmp'"
108.         }
109.         local __lab : subinstr local __lab `"""' "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -----------------------------------------------------------------------
.     ** Base year sanity check (only if baseyear != 0)
.     ** -----------------------------------------------------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -----------------------------------------------------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', absorb(`absorb
> ') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -----------------------------------------------------------------------
.     ** Margins: conditional means by CAT over YEAR (save to dataset)
.     ** -----------------------------------------------------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(`yrs')) saving(`__margdata', replace) post
134. 
.     ** -----------------------------------------------------------------------
.     ** Plot using the saved margins dataset
.     ** -----------------------------------------------------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins output
.         ** We compute margins using at(): at(cat levels × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) and _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _at1. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _at2. Ensure margins is called with: margins,
>  at(`catv'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normalizing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(cond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have no observations in baseyear(`baseyear'). Ca
> nnot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used: `xyrs'"
190. 
.         ** -------------------------------------------------------------------
.         ** Plot styling: use plotplainblind palette if available (scheme-level)
.         ** -------------------------------------------------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblind scheme not available; using current scheme
> : `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme: plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -------------------------------------------------------------------
.         ** Build twoway spec + legend mapping (one label per series)
.         **   - CI and line share the same pstyle; CI uses 50% opacity.
.         ** -------------------------------------------------------------------
.         if `__dbg' di as txt "[Step 9] Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe key)
.             local __key "`c'"
213.             local __key : subinstr local __key "-" "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`c', sort ///
>                         pstyle(`pstyle') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c', sort ///
>                     pstyle(`pstyle') lp(solid) msym(O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order'"
230.             di as txt "  legend labels: `leg_labels'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -------------------------------------------------------------------
.         ** Titles (safe quoting)
.         ** -------------------------------------------------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "xtitle(Year)"
237.         else                    local xtitle_input `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input `"ytitle(`"`varlist' (relative to `baseyear
> ')"')"'
240.             else              local ytitle_input `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"title(`"`title'"')"'
246. 
.                 ** ------------------------------------------------------------
.                 ** Y-axis: round "nice" ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then rounds to a nice step.
.                 ** ------------------------------------------------------------
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0), anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming for ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep'))
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple of step; min down similarly
.                 local __yhigh = ceil(`__ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exactly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`__ylow' `__yhigh')) ylabel(`__ylow'(`__ystep'
> )`__yhigh')"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///           
>                         legend(order(`leg_order') `leg_labels' rows(`legrows') position(6)) 
270. 
.         ** Restore scheme (if we successfully switched)
.         capture set scheme `__oldscheme'
271. 
.         ** -------------------------------------------------------------------
.         ** Export figure (PDF) - robust path handling
.         ** -------------------------------------------------------------------
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpath `"""' "", all
274.             local outpath : subinstr local outpath "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") & substr("`outpath'", 1, 1) != "/" {
276.                 local outpath "`__project_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creating output directory: `outdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'") {
286.                         di as error "Output directory does not exist and could not be created
> : `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outpath'", as(pdf) replace
293.             else                graph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "------------------------------------------------------------"
299.     }
300. 
. end

. 
. 
. ** ---------------------------------------------------------------------------
. ** Load ACS migration data
. ** ---------------------------------------------------------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                                   // Error in migration place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // Alaska and Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                                     // Negative Family Income       
(7,238 observations deleted)

. 
. ** ---------------------------------------------------------------------------
. ** Multnomah indicators and samples
. ** ---------------------------------------------------------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multnomah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,253 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,335 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Covariate categories
. ** ---------------------------------------------------------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,886,621 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,057,842 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,776 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,886,621 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Real income (2023 USD) and income categories
. ** ---------------------------------------------------------------------------
. gen tmp1 = cpi99 if year == 2023
(18,374,392 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,886,621 differences between real_inctot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     15,082        0.07        0.07
             $0 |  1,747,061        8.36        8.44
        $1-$25K |  6,203,845       29.70       38.14
      $25K-$50K |  4,981,113       23.85       61.99
     $50K-$100K |  4,947,578       23.69       85.68
    $100K-$200K |  2,211,136       10.59       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incwage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,175,889       39.14       39.14
        $1-$25K |  3,428,186       16.41       55.56
      $25K-$50K |  3,290,630       15.75       71.31
     $50K-$100K |  3,729,590       17.86       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incearn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     13,905        0.07        0.07
             $0 |  7,360,938       35.24       35.31
        $1-$25K |  3,755,724       17.98       53.29
      $25K-$50K |  3,476,928       16.65       69.94
     $50K-$100K |  3,876,560       18.56       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,529 differences between real_ftotinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |    226,387        1.08        1.08
        $1-$25K |  2,249,309       10.77       11.85
      $25K-$50K |  3,258,513       15.60       27.45
     $50K-$100K |  5,975,505       28.61       56.06
    $100K-$200K |  6,147,777       29.43       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00

. 
. label var cat_inctot  "Total personal income categories (real 2023 USD)"

. label var cat_incwage "Total wage income categories (real 2023 USD)"

. label var cat_incearn "Total earned income categories (real 2023 USD)"

. label var cat_ftotinc "Total family income categories (real 2023 USD)"

. 
. 
. ** ---------------------------------------------------------------------------
. ** Analysis loops
. ** ---------------------------------------------------------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_sex cat_married cat_age cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_sex_1.pdf saved as PDF format
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_married_1.pdf saved as PDF
    format
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_age_1.pdf saved as PDF format
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_child_1.pdf saved as PDF
    format
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\
> STD91a0_00001v.tmp"

. /*************************************
> **************************************
> ****
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-le
> vel migration analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.ise
> lin@yale.edu
> **************************************
> **************************************
> ***/
. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Start log file
. ** -----------------------------------
> --------------------------------------
> --
. capture log close log_02

. log using "${logs}02_log_individual_${
> date}", replace text name(log_02)
----------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/Gi
> tHub/multnomah-county-tax/code/logs/02
> _log_individual_2025-12-16.log
  log type:  text
 opened on:  17 Dec 2025, 16:42:21

. 
. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year
> , absorb(...) nocons
. ** - Posts:     cell means and CIs for
>  each cat×year coefficient
. ** - Plots:     one connected series p
> er category + optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS
> . We store those labels immediately af
> ter
. **   levelsof (before moving into the 
> posted coefficient dataset) to avoid a
> ny
. **   issues from dataset swaps.
. ** - CI and line use the same color; C
> I uses 50% opacity.
. ** -----------------------------------
> --------------------------------------
> --
. ** -----------------------------------
> --------------------------------------
> --
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR 
> interaction and absorbed fixed effects
> .
. **   2) Use margins (rather than reghd
> fe coefficients) to compute conditiona
> l means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one 
> series per CAT (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (con
> ditional means).
. **   - baseyear(#) => plot within-CAT 
> differences relative to that year.
. ** -----------------------------------
> --------------------------------------
> --
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] 
> [fw aw pw iw] , ///
>         CAT(varname) YEAR(varname) ABS
> ORB(string) ///
>         [ WVAR(varname) WTYPE(string) 
> ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string)
>  YTITLE(string) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Configuration: project root for
>  relative paths
.     ** -------------------------------
> --------------------------------------
> --
.     local __project_root "C:/Users/ji2
> 52/Documents/GitHub/multnomah-county-t
> ax/"
  4. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Debug flags
.     ** -------------------------------
> --------------------------------------
> --
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 
> 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "----------------
> --------------------------------------
> ------"
 13.         di as txt "hdfe_catyear_plo
> t DEBUG START"
 14.         di as txt "Outcome   : `var
> list'"
 15.         di as txt "CAT()     : `cat
> '"
 16.         di as txt "YEAR()    : `yea
> r'"
 17.         di as txt "ABSORB()  : `abs
> orb'"
 18.         di as txt "Weights   : weig
> ht=`weight' exp=`exp' wvar=`wvar' wtyp
> e=`wtype'"
 19.         di as txt "VCE()     : `vce
> '"
 20.         di as txt "BASEYEAR(): `bas
> eyear'   NOCI: `noci'"
 21.         di as txt "SAVING()  : `sav
> ing'   REPLACE: `replace'"
 22.         di as txt "IF/IN     : `if'
>  `in'"
 23.         di as txt "----------------
> --------------------------------------
> ------"
 24.     }
 25. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Requirements
.     ** -------------------------------
> --------------------------------------
> --
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not fo
> und. Install with: ssc install reghdfe
> , replace"
 28.         exit 198
 29.     }
 30. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Mark sample
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 1] Mar
> king estimation sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `tous
> e' & !missing(`varlist', `cat', `year'
> )
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (afte
> r filters): " %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observation
> s available after applying if/in filte
> rs."
 37.         exit 2000
 38.     }
 39. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Weights (default fw=perwt unles
> s caller provided weights)
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 2] Res
> olving weights..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']
> "
 43.         if `__dbg' di as txt "  Usi
> ng caller-provided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wv
> ar  "perwt"
 47.         if "`wtype'" == "" local wt
> ype "fw"
 48.         capture confirm variable `w
> var'
 49.         if _rc {
 50.             di as error "Default we
> ight variable `wvar' not found. Either
>  create it or pass weights explicitly.
> "
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']
> "
 54.         if `__dbg' di as txt "  Usi
> ng default weights: `wgt'"
 55.     }
 56. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Ensure CAT/YEAR numeric for fac
> tor variables
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 3] Har
> monizing CAT/YEAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) ==
>  "str" {
 60.         quietly encode `cat' if `to
> use', gen(`__cat')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Enc
> oded string CAT -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT
>  already numeric -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) =
> = "str" {
 70.         quietly destring `year' if 
> `touse', gen(`__year') force
 71.         capture assert !missing(`__
> year') if `touse'
 72.         if _rc {
 73.             di as error "Year varia
> ble is string and could not be cleanly
>  converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Des
> tring YEAR -> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEA
> R already numeric -> `yearv'"
 82.     }
 83. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Guard: CAT should not also be a
> bsorbed
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 4] Val
> idating absorb()..."
 84.     if regexm(" `absorb' ", " `catv
> ' ") {
 85.         di as error "Category varia
> ble `catv' appears in absorb(): `absor
> b'. Remove it from absorb() for this r
> un."
 86.         exit 198
 87.     }
 88. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Levels and labels (save labels 
> NOW, before switching datasets)
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 5] Col
> lecting year and category levels..."
 89.     quietly levelsof `yearv' if `to
> use', local(yrs)
 90.     quietly levelsof `catv'  if `to
> use', local(cats)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" 
> {
 93.         di as error "No year or cat
> egory levels found in estimation sampl
> e."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value labe
> l: `vlab'"
100.     }
101. 
.     ** Save category label text into l
> ocals (avoids label-loss during preser
> ve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr loca
> l __key "-" "m", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vl
> ab' `c'
107.             if "`__tmp'" != "" loca
> l __lab "`__tmp'"
108.         }
109.         local __lab : subinstr loca
> l __lab `"""' "", all
110.         local __lab_`__key' "`__lab
> '"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Base year sanity check (only if
>  baseyear != 0)
.     ** -------------------------------
> --------------------------------------
> --
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step
>  5b] Checking baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' lo
> cal found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`
> baseyear') not found in estimation sam
> ple years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  bas
> eyear OK: `baseyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Regression (supports margins ov
> er CAT × YEAR)
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 6] Run
> ning reghdfe..."
125.     if "`vce'" == "" local vce "rob
> ust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `var
> list' i.`catv'##i.`yearv' if `touse' `
> wgt', absorb(`absorb') vce(`vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'
> ##i.`yearv' if `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Margins: conditional means by C
> AT over YEAR (save to dataset)
.     ** -------------------------------
> --------------------------------------
> --
.     if `__dbg' di as txt "[Step 7] Com
> puting margins and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`ca
> ts') `yearv'=(`yrs')) saving(`__margda
> ta', replace) post
134. 
.     ** -------------------------------
> --------------------------------------
> --
.     ** Plot using the saved margins da
> taset
.     ** -------------------------------
> --------------------------------------
> --
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR colum
> ns in margins output
.         ** We compute margins using at
> (): at(cat levels × year levels). The 
> saved dataset
.         ** therefore stores the grid i
> n _at1 (cat) and _at2 (year) in the or
> der supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins ou
> tput missing _at1. Ensure margins is c
> alled with: margins, at(`catv'=(`cats'
> ) `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _a
> t2
142.         if _rc {
143.             di as error "margins ou
> tput missing _at2. Ensure margins is c
> alled with: margins, at(`catv'=(`cats'
> ) `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _marg
> in
149.         if _rc {
150.             di as error "margins ou
> tput missing _margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_m
> argin
155.         if !_rc rename _se_margin s
> e
156.         else {
157.             capture confirm variabl
> e _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_l
> b
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _c
> i_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail
> ] First 8 rows of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and 
> sorted
.         capture confirm numeric variab
> le year
169.         if _rc {
170.             di as error "Year in ma
> rgins dataset is not numeric; cannot p
> lot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to b
> aseyear (within-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[
> Step 8] Normalizing margins to baseyea
> r(`baseyear')..."
175.             bysort cat_level: egen 
> base_b = max(cond(year==`baseyear', b,
>  .))
176.             quietly count if missin
> g(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some c
> ategories have no observations in base
> year(`baseyear'). Cannot normalize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_
> b
182.             capture confirm variabl
> e ll
183.             if !_rc replace ll = ll
>  - base_b
184.             capture confirm variabl
> e ul
185.             if !_rc replace ul = ul
>  - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALI
> ZATION
188. 
.         ** X axis labels (years presen
> t in margins results)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-a
> xis years used: `xyrs'"
190. 
.         ** ---------------------------
> --------------------------------------
> --
.         ** Plot styling: use plotplain
> blind palette if available (scheme-lev
> el)
.         ** ---------------------------
> --------------------------------------
> --
.         local __oldscheme "`c(scheme)'
> "
191.         capture set scheme plotplai
> nblind
192.         if _rc {
193.             if `__dbg' di as txt " 
>  plotplainblind scheme not available; 
> using current scheme: `__oldscheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt " 
>  Using scheme: plotplainblind (was `__
> oldscheme')"
197.         }
198. 
.         ** ---------------------------
> --------------------------------------
> --
.         ** Build twoway spec + legend 
> mapping (one label per series)
.         **   - CI and line share the s
> ame pstyle; CI uses 50% opacity.
.         ** ---------------------------
> --------------------------------------
> --
.         if `__dbg' di as txt "[Step 9]
>  Building plot command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cat
> s'
204.         local legrows 1
205.         if `cats_n' > 4 local legro
> ws 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_le
> vel == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved labe
> l text (safe key)
.             local __key "`c'"
213.             local __key : subinstr 
> local __key "-" "m", all
214.             local serieslab "`__lab
> _`__key''"
215. 
.             ** CI (excluded from legen
> d)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots'
>  ///
>                     (rcap ll ul year i
> f cat_level==`c', sort ///
>                         pstyle(`pstyle
> ') lcolor(%50))
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if c
> at_level==`c', sort ///
>                     pstyle(`pstyle') l
> p(solid) msym(O) )
221. 
.             local leg_order  `leg_orde
> r' `pnum'
222.             local leg_labels `leg_l
> abels' label(`pnum' `serieslab')
223.         }   // END CATEGORY PLOT LO
> OP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series 
> were built for plotting (plotspec empt
> y)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend ord
> er: `leg_order'"
230.             di as txt "  legend lab
> els: `leg_labels'"
231.             di as txt "  legend row
> s: `legrows'"
232.         }
233. 
.         ** ---------------------------
> --------------------------------------
> --
.         ** Titles (safe quoting)
.         ** ---------------------------
> --------------------------------------
> --
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local 
> xtitle_input "xtitle(Year)"
237.         else                    loc
> al xtitle_input `"xtitle(`"`xtitle'"')
> "'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 loca
> l ytitle_input `"ytitle(`"`varlist' (r
> elative to `baseyear')"')"'
240.             else              local
>  ytitle_input `"ytitle(`"`varlist' (ad
> justed mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"yt
> itle(`"`ytitle'"')"'
244.         }
245. 
.         if `"`title'"' != `""' local t
> itle_input `"title(`"`title'"')"'
246. 
.                 ** -------------------
> --------------------------------------
> ---
.                 ** Y-axis: round "nice
> " ticks (e.g., 0,2,4,6,8,10)
.                 ** Uses CI bounds to s
> et max, then rounds to a nice step.
.                 ** -------------------
> --------------------------------------
> ---
. 
.                 quietly summarize ll, 
> meanonly
247.                 local __ymin = r(mi
> n)
248. 
.                 quietly summarize ul, 
> meanonly
249.                 local __ymax = r(ma
> x)
250. 
.                 ** Always include 0 on
>  axis
.                 if `__ymin' > 0 local 
> __ymin = 0
251.                 if `__ymax' < 0 loc
> al __ymax = 0
252. 
.                 ** If plotting levels 
> (baseyear==0), anchor at 0
.                 if `baseyear' == 0 loc
> al __ymin = 0
253. 
.                 ** Add a little headro
> om (5%)
.                 local __ymax = `__ymax
> ' * 1.05
254. 
.                 ** Decide on a "nice" 
> step aiming for ~5 intervals
.                 local __span = `__ymax
> ' - `__ymin'
255.                 if `__span' <= 0 lo
> cal __span = 1
256. 
.                 local __rawstep = `__s
> pan'/5
257. 
.                 ** Snap step to {1,2,5
> } * 10^k
.                 local __k = floor(log1
> 0(`__rawstep'))
258.                 local __base = 10^`
> __k'
259.                 local __mant = `__r
> awstep'/`__base'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  lo
> cal __m = 2
262.                 if `__mant' > 2  lo
> cal __m = 5
263.                 if `__mant' > 5  lo
> cal __m = 10
264. 
.                 local __ystep = `__m' 
> * `__base'
265. 
.                 ** Round max up to nea
> rest multiple of step; min down simila
> rly
.                 local __yhigh = ceil(`
> __ymax'/`__ystep') * `__ystep'
266.                 local __ylow  = flo
> or(`__ymin'/`__ystep') * `__ystep'
267. 
.                 ** For levels, ensure 
> bottom is exactly 0
.                 if `baseyear' == 0 loc
> al __ylow = 0
268. 
.                 local __yaxis_opts `"y
> scale(range(`__ylow' `__yhigh')) ylabe
> l(`__ylow'(`__ystep')`__yhigh')"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) 
> ///
>                         `__yaxis_opts'
>  ///           
>                         legend(order(`
> leg_order') `leg_labels' rows(`legrows
> ') position(6)) 
270. 
.         ** Restore scheme (if we succe
> ssfully switched)
.         capture set scheme `__oldschem
> e'
271. 
.         ** ---------------------------
> --------------------------------------
> --
.         ** Export figure (PDF) - robus
> t path handling
.         ** ---------------------------
> --------------------------------------
> --
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinst
> r local outpath `"""' "", all
274.             local outpath : subinst
> r local outpath "\" "/" , all
275. 
.             ** Prepend project root if
>  relative
.             if !regexm("`outpath'", "^
> [A-Za-z]:/") & substr("`outpath'", 1, 
> 1) != "/" {
276.                 local outpath "`__p
> roject_root'`outpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\
> .pdf$") local outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory
>  exists
.             local p = strrpos("`outpat
> h'", "/")
280.             if `p' > 0 {
281.                 local outdir = subs
> tr("`outpath'", 1, `p' - 1)
282.                 if !direxists("`out
> dir'") {
283.                     if `__dbg' di a
> s txt "  Creating output directory: `o
> utdir'"
284.                     capture mkdir "
> `outdir'"
285.                     if _rc & !direx
> ists("`outdir'") {
286.                         di as error
>  "Output directory does not exist and 
> could not be created: `outdir'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Ste
> p 10] Exporting graph to: `outpath'"
292. 
.             if "`replace'" != "" graph
>  export "`outpath'", as(pdf) replace
293.             else                gra
> ph export "`outpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plo
> t DEBUG END"
298.         di as txt "----------------
> --------------------------------------
> ------"
299.     }
300. 
. end

. 
. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Load ACS migration data
. ** -----------------------------------
> --------------------------------------
> --
. use "${data}working/acs_migration_file
> ", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                 
>                   // Error in migratio
> n place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)   
>   // Alaska and Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                   
>                   // Negative Family I
> ncome       
(7,238 observations deleted)

. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Multnomah indicators and samples
. ** -----------------------------------
> --------------------------------------
> --
. gen multnomah_o = (state_fips_o == 41 
> & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 
> & county_fips_d == 51)

. 
. gen sample_1 = (multnomah_o == 1)     
>  // Multnomah in origin-year

. gen sample_2 = (multnomah_o != 1)     
>  // Not Multnomah in origin-year

. label var sample_1 "Out-migration Samp
> le"

. label var sample_2 "In-migration Sampl
> e"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,253 real changes made)

. label var out_1 "Moved out of Multnoma
> h"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,335 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Covariate categories
. ** -----------------------------------
> --------------------------------------
> --
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,886,621 differences between age and 
> cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Fe
> male", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed")
>  ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,057,842 differences between marst and
>  cat_married)

. label var cat_married "Marriage catego
> ries"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,776 differences between nchild and 
> cat_child)

. label var cat_child "Number of Childre
> n"

. 
. ** Kids at home
. recode yngch ///
>     (99      = 0 "0 Children") ///
>     (0/4     = 1 "0-4") ///
>     (5/12    = 2 "5-12") ///
>     (13-17   = 3 "13-17")       ///
>         (18/max   = 3 "18+"), ///
>     gen(cat_yngch)
unknown el 13-17 in rule
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\
> STD91a0_00001w.tmp"

. 
. ** Kids at home
. recode yngch ///
>     (99      = 0 "0 Children") ///
>     (0/4     = 1 "0-4") ///
>     (5/12    = 2 "5-12") ///
>     (13/17   = 3 "13-17")       ///
>         (18/max   = 4 "18+"), ///
>     gen(cat_yngch)
(20,465,990 differences between yngch an
> d cat_yngch)

. label var cat_yngch "Age of youngest c
> hild"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), //
> /
>     gen(cat_educ)
(20,886,621 differences between educd an
> d cat_educ)

. label var cat_educ "Education categori
> es"

. 
. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Real income (2023 USD) and income c
> ategories
. ** -----------------------------------
> --------------------------------------
> --
. gen tmp1 = cpi99 if year == 2023
(18,374,392 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage 
> incearn ftotinc {
  2. 
.     gen real_`var' = round(`var' * cpi
> )
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative i
> ncome") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") 
> ///
>         (25000/49999   = 4 "$25K-$50K"
> ) ///
>         (50000/99999   = 5 "$50K-$100K
> ") ///
>         (100000/199999 = 6 "$100K-$200
> K") ///
>         (200000/max    = 7 "$200K+"), 
> ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,886,621 differences between real_inc
> tot and cat_inctot)

      RECODE of |
    real_inctot |      Freq.     Percent
>         Cum.
----------------+-----------------------
> ------------
Negative income |     15,082        0.07
>         0.07
             $0 |  1,747,061        8.36
>         8.44
        $1-$25K |  6,203,845       29.70
>        38.14
      $25K-$50K |  4,981,113       23.85
>        61.99
     $50K-$100K |  4,947,578       23.69
>        85.68
    $100K-$200K |  2,211,136       10.59
>        96.26
         $200K+ |    780,806        3.74
>       100.00
----------------+-----------------------
> ------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_inc
> wage and cat_incwage)

      RECODE of |
   real_incwage |      Freq.     Percent
>         Cum.
----------------+-----------------------
> ------------
             $0 |  8,175,889       39.14
>        39.14
        $1-$25K |  3,428,186       16.41
>        55.56
      $25K-$50K |  3,290,630       15.75
>        71.31
     $50K-$100K |  3,729,590       17.86
>        89.17
    $100K-$200K |  1,743,819        8.35
>        97.52
         $200K+ |    518,507        2.48
>       100.00
----------------+-----------------------
> ------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_inc
> earn and cat_incearn)

      RECODE of |
   real_incearn |      Freq.     Percent
>         Cum.
----------------+-----------------------
> ------------
Negative income |     13,905        0.07
>         0.07
             $0 |  7,360,938       35.24
>        35.31
        $1-$25K |  3,755,724       17.98
>        53.29
      $25K-$50K |  3,476,928       16.65
>        69.94
     $50K-$100K |  3,876,560       18.56
>        88.50
    $100K-$200K |  1,823,201        8.73
>        97.23
         $200K+ |    579,365        2.77
>       100.00
----------------+-----------------------
> ------------
          Total | 20,886,621      100.00
(20,886,529 differences between real_fto
> tinc and cat_ftotinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent
>         Cum.
----------------+-----------------------
> ------------
             $0 |    226,387        1.08
>         1.08
        $1-$25K |  2,249,309       10.77
>        11.85
      $25K-$50K |  3,258,513       15.60
>        27.45
     $50K-$100K |  5,975,505       28.61
>        56.06
    $100K-$200K |  6,147,777       29.43
>        85.50
         $200K+ |  3,029,130       14.50
>       100.00
----------------+-----------------------
> ------------
          Total | 20,886,621      100.00

. 
. label var cat_inctot  "Total personal 
> income categories (real 2023 USD)"

. label var cat_incwage "Total wage inco
> me categories (real 2023 USD)"

. label var cat_incearn "Total earned in
> come categories (real 2023 USD)"

. label var cat_ftotinc "Total family in
> come categories (real 2023 USD)"

. 
. 
. ** -----------------------------------
> --------------------------------------
> --
. ** Analysis loops
. ** -----------------------------------
> --------------------------------------
> --
. 
. ** Categorical variables to iterate ov
> er
. local catvars "cat_yngch cat_sex cat_m
> arried cat_age cat_child cat_educ cat_
> ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-
> migration rate (%)"
  3.     if `i' == 2 local ytitle_txt "I
> n-migration rate (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories
>  (but not the focal one)
.         local othercats : list catvars
>  - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if s
> ample_`i' == 1, ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county
> _fips_o `othercats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Su
> rvey Year (t=2)") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat
> '_`i'") ///
>             replace
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_yngch_1.pdf saved as PDF
    format
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_sex_1.pdf saved as PDF format
(Created by command margins; also see ch
> ar list)
2015 2016 2017 2018 2019 2020 2021 2022 
> 2023
file
    C:/Users/ji252/Documents/GitHub/mu
    > ltnomah-county-tax/results/fig_c
    > at_married_1.pdf saved as PDF
    format
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00001x.tmp"

. ** Determine set of common in- and out-migration counties for Multnomah
. use ${working}irs_county_flow.dta, clear 
file irs_county_flow.dta not found
r(601);

end of do-file

r(601);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000020.tmp"

. ** Determine set of common in- and out-migration counties for Multnomah
. use ${data}working/irs_county_flow.dta, clear 

. 
. ** Merge with ACS county data 
. merge 1:1 year fips_o fips_d using ${data}working/acs_county_flow
variable fips_o not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000021
> .tmp"

. /***************************************************
> **************************
> * Program:                      01_clean_data.do 
> * Author(s):            John Iselin 
> * Date Updated:         October 19, 2025
> 
> *** Demographic data via IPUMS NHGIS 
> ** Via https://www.nhgis.org/
> ** Downloaded on October 19, 2025
> ** EXTRACT DETAILS in "nhgis0031_ts_nominal_county_c
> odebook"
> 
> *** Economic data via BEA Regional Economic Accounts
>  (CAINC1)
> ** Via https://apps.bea.gov/regional/downloadzip.htm
> 
> *** ACS individual data via IPUMS USA 
> ** Via https://usa.ipums.org/usa/index.shtml
> ** Downloaded via R program 
> 
> *** IRS SOI County-Level Migration Files
> ** Via https://www.irs.gov/statistics/soi-tax-stats-
> migration-data
> 
> *** IRS SOI County-Level Files
> ** Via https://www.irs.gov/statistics/soi-tax-stats-
> county-data
> 
> *** NYTimes COVID Cases and Deaths 
> ** Via https://github.com/nytimes/covid-19-data
> 
> ****************************************************
> ***************************/
. 
. ** Start log file 
. capture log close log_01

. log using "${logs}01_log_data_clean_${pr_name}_${dat
> e}", replace text name(log_01)
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/code/logs/01_log_data_clean_multnomah_202
    > 5-12-16.log not found)
------------------------------------------------------
      name:  log_01
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/01_log_data_clean_multnomah_20
> 25-12-16.log
  log type:  text
 opened on:  17 Dec 2025, 17:48:17

. 
. //--------------------------------------------------
. // STEP 0: Preliminary Set-Up 
. //--------------------------------------------------
. 
. ** Define labels 
. label define lb_move_type       0 "ERROR"           
>                     ///
>                                                     
>     1 "Non-movers"                  ///
>                                                     
>     2 "All movers"                  ///
>                                                     
>     3 "Domestic movers"             ///
>                                                     
>     4 "Within-state movers" ///
>                                                     
>     5 "Inter-state movers"  ///
>                                                     
>     6 "Foreign movers", modify

.                                                     
>     
. label define lb_agi             1 "Under $1"        
>             ///
>                                                     
>     2 "$1 under $10K"               ///
>                                                     
>     3 "$10K under $25K"             ///
>                                                     
>     4 "$25K under $50K"             ///
>                                                     
>     5 "$50K under $75K"             ///
>                                                     
>     6 "$75K under $100K"    ///
>                                                     
>     7 "$100K under $200K"   ///
>                                                     
>     8 "$200K or more", modify                       
>                                 

. 
. 
. ** Define Programs
. 
. ** Make FIPS code from state and county fips codes 
. capture program drop make_fips

. program define make_fips
  1.     syntax varlist(min=2 max=2 numeric), GEN(name
> )
  2. 
.     quietly {
  3.         tempvar s c
  4. 
.         local v1 : word 1 of `varlist'
  5.         local v2 : word 2 of `varlist'
  6. 
.         gen `s' = string(`v1', "%02.0f")
  7.         gen `c' = string(`v2', "%03.0f")
  8. 
.         gen `gen' = real(`s' + `c')
  9.     }
 10. end

. 
. ** Reclassify suppressed values as 0 
. 
. capture program drop unsuppress

. program define unsuppress
  1.     syntax varlist
  2. 
.     foreach v of varlist `varlist' {
  3.         replace `v' = 0 if `v' == -1
  4.     }
  5. end

. 
. //--------------------------------------------------
. // STEP -1: Acquire raw data (automated where possib
> le)
. //--------------------------------------------------
. /*
> This block downloads public-use source data directly
>  from official URLs if not present locally.
> 
> Automated downloads included:
>   - IRS SOI county-to-county migration: countyinflow
> YYZZ.csv / countyoutflowYYZZ.csv
>   - IRS SOI county data: YYincyallagi.csv
>   - BEA Regional Economic Accounts (CAINC1): CAINC1.
> zip (unzips to CAINC1__ALL_AREAS_*.csv and related f
> iles)
> 
> */
. 
. * Ensure expected directory structure exists
. capture mkdir "${data}"

. capture mkdir "${data}working"

. capture mkdir "${data}demographic"

. capture mkdir "${data}demographic/CAINC1"

. capture mkdir "${data}demographic/nhgis0031_csv"

. capture mkdir "${data}irs"

. capture mkdir "${data}covid"

. 
. * ----------------------------
. * IRS SOI: migration files
. * ----------------------------
. local irs_base "https://www.irs.gov/pub/irs-soi"

. 
. forvalues yy = 15/21 {
  2.     local zz = `yy' + 1
  3.     local fn_out "countyoutflow`yy'`zz'.csv"
  4.     local fn_in  "countyinflow`yy'`zz'.csv"
  5. 
.     capture confirm file "${data}irs/`fn_out'"
  6.     if _rc {
  7.         di as txt "Downloading (IRS SOI) `fn_out'
>  ..."
  8.         copy "`irs_base'/`fn_out'" "${data}irs/`f
> n_out'", replace
  9.     }
 10. 
.     capture confirm file "${data}irs/`fn_in'"
 11.     if _rc {
 12.         di as txt "Downloading (IRS SOI) `fn_in' 
> ..."
 13.         copy "`irs_base'/`fn_in'" "${data}irs/`fn
> _in'", replace
 14.     }
 15. }

. 
. * ----------------------------
. * IRS SOI: county income (AGI) files
. * ----------------------------
. forvalues yy = 15/22 {
  2.     local fn_inc "`yy'incyallagi.csv"
  3. 
.     capture confirm file "${data}irs/`fn_inc'"
  4.     if _rc {
  5.         di as txt "Downloading (IRS SOI) `fn_inc'
>  ..."
  6.         copy "`irs_base'/`fn_inc'" "${data}irs/`f
> n_inc'", replace
  7.     }
  8. }

. 
. * ----------------------------
. * BEA Regional: CAINC1.zip
. * ----------------------------
. local bea_dir "${data}demographic/CAINC1"

. local bea_url "https://apps.bea.gov/regional/zip/CAI
> NC1.zip"

. local bea_zip "`bea_dir'/CAINC1.zip"

. 
. * If we don't already have a CAINC1 "_ALL_AREAS" fil
> e, download + unzip the ZIP.
. local bea_files : dir "`bea_dir'" files "CAINC1__ALL
> _AREAS_*.csv"

. if "`bea_files'"=="" {
.     local bea_files : dir "`bea_dir'" files "CAINC1_
> _ALL_STATES_*.csv"
. }

. 
. if "`bea_files'"=="" {
.     di as txt "Downloading (BEA) CAINC1.zip ..."
Downloading (BEA) CAINC1.zip ...
.     copy "`bea_url'" "`bea_zip'", replace
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/demographic/CAINC1/CAINC1.zip not
    found)
. 
.     local curdir "`c(pwd)'"
.     cd "`bea_dir'"
C:\Users\ji252\Documents\GitHub\multnomah-county-tax\d
> ata\demographic\CAINC1
.     unzipfile "CAINC1.zip", replace
    inflating: CAINC1__ALL_AREAS_1969_2023.csv
    inflating: CAINC1__definition.xml
    inflating: CAINC1__Footnotes.html
    inflating: CAINC1_AK_1969_2023.csv
    inflating: CAINC1_AL_1969_2023.csv
    inflating: CAINC1_AR_1969_2023.csv
    inflating: CAINC1_AZ_1969_2023.csv
    inflating: CAINC1_CA_1969_2023.csv
    inflating: CAINC1_CO_1969_2023.csv
    inflating: CAINC1_CSA_1969_2023.csv
    inflating: CAINC1_CT_1969_2023.csv
    inflating: CAINC1_DC_1969_2023.csv
    inflating: CAINC1_DE_1969_2023.csv
    inflating: CAINC1_FL_1969_2023.csv
    inflating: CAINC1_GA_1969_2023.csv
    inflating: CAINC1_HI_1969_2023.csv
    inflating: CAINC1_IA_1969_2023.csv
    inflating: CAINC1_ID_1969_2023.csv
    inflating: CAINC1_IL_1969_2023.csv
    inflating: CAINC1_IN_1969_2023.csv
    inflating: CAINC1_KS_1969_2023.csv
    inflating: CAINC1_KY_1969_2023.csv
    inflating: CAINC1_LA_1969_2023.csv
    inflating: CAINC1_MA_1969_2023.csv
    inflating: CAINC1_MD_1969_2023.csv
    inflating: CAINC1_MDIV_1969_2023.csv
    inflating: CAINC1_ME_1969_2023.csv
    inflating: CAINC1_MI_1969_2023.csv
    inflating: CAINC1_MIC_1969_2023.csv
    inflating: CAINC1_MN_1969_2023.csv
    inflating: CAINC1_MO_1969_2023.csv
    inflating: CAINC1_MS_1969_2023.csv
    inflating: CAINC1_MSA_1969_2023.csv
    inflating: CAINC1_MT_1969_2023.csv
    inflating: CAINC1_NC_1969_2023.csv
    inflating: CAINC1_ND_1969_2023.csv
    inflating: CAINC1_NE_1969_2023.csv
    inflating: CAINC1_NH_1969_2023.csv
    inflating: CAINC1_NJ_1969_2023.csv
    inflating: CAINC1_NM_1969_2023.csv
    inflating: CAINC1_NV_1969_2023.csv
    inflating: CAINC1_NY_1969_2023.csv
    inflating: CAINC1_OH_1969_2023.csv
    inflating: CAINC1_OK_1969_2023.csv
    inflating: CAINC1_OR_1969_2023.csv
    inflating: CAINC1_PA_1969_2023.csv
    inflating: CAINC1_PORT_1969_2023.csv
    inflating: CAINC1_RI_1969_2023.csv
    inflating: CAINC1_SC_1969_2023.csv
    inflating: CAINC1_SD_1969_2023.csv
    inflating: CAINC1_TN_1969_2023.csv
    inflating: CAINC1_TX_1969_2023.csv
    inflating: CAINC1_US_1969_2023.csv
    inflating: CAINC1_UT_1969_2023.csv
    inflating: CAINC1_VA_1969_2023.csv
    inflating: CAINC1_VT_1969_2023.csv
    inflating: CAINC1_WA_1969_2023.csv
    inflating: CAINC1_WI_1969_2023.csv
    inflating: CAINC1_WV_1969_2023.csv
    inflating: CAINC1_WY_1969_2023.csv

successfully unzipped CAINC1.zip to current directory
total processed:  60
        skipped:  0
      extracted:  60
.     cd "`curdir'"
C:\Users\ji252\Documents\GitHub\multnomah-county-tax
. 
.     capture erase "`bea_zip'"
. }

. 
. * ----------------------------
. * NYTimes COVID Data 
. * ----------------------------
. local covid_dir "${data}covid"

. local covid_url "https://raw.githubusercontent.com/n
> ytimes/covid-19-data/master/us-counties.csv"

. 
. * If we don't already have a COVID file, download.
. local covid_file : dir "`covid_dir'" files "covid_ny
> t.csv"

. if "`covid_file'"=="" {
.     local covid_file : dir "`covid_dir'" files "covi
> d_nyt.csv"
. }

. 
. if "`covid_file'"=="" {
.     di as txt "Downloading (COVID)  ..."
Downloading (COVID)  ...
.     copy "`covid_url'" "`covid_dir'/covid_nyt.csv", 
> replace
. }

. 
. 
. 
. //--------------------------------------------------
> ---------
. // STEP 1: Import and Clean Demographic Data via IPU
> MS + BEA  
. //--------------------------------------------------
> ---------
. 
. ** Import data 
. import delimited        ///
>         "${data}demographic/nhgis0031_csv/nhgis0031_
> ts_nominal_county.csv", clear 
(encoding automatically selected: ISO-8859-1)
(15 vars, 54,673 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:        54,673                  
    Variables:            15                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
gisjoin         str8    %9s                   GISJOIN
year            str9    %9s                   YEAR
state           str20   %20s                  STATE
statefp         byte    %8.0g                 STATEFP
statenh         int     %8.0g                 STATENH
county          str46   %46s                  COUNTY
countyfp        int     %8.0g                 COUNTYFP
countynh        int     %8.0g                 COUNTYNH
name            str59   %59s                  NAME
av0aa           long    %12.0g                AV0AA
d15aa           long    %12.0g                D15AA
d15ab           long    %12.0g                D15AB
b79aa           long    %12.0g                B79AA
av0aam          long    %12.0g                AV0AAM
b79aam          long    %8.0g                 B79AAM
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Drop unnecc variables 
. drop gisjoin statenh countynh name 

. 
. ** Rename 
. rename state state_name 

. rename statefp state_fips 

. rename county county_name 

. rename countyfp county_fips 

. rename av0aa population 

. rename d15aa pop_urban 

. rename d15ab pop_rural 

. rename b79aa median_income 

. rename av0aam population_margin

. rename b79aam median_income_margin 

. 
. ** Create urban percent 
. gen percent_urban = pop_urban / population
(45,090 missing values generated)

. 
. ** Label variables 
. label var state_name "State name"

. label var state_fips "State FIPS code"

. label var county_name "County name"

. label var county_fips "County FIPS code"

. label var population "Population count"

. label var pop_rural "Rural population count"

. label var pop_urban "Urban population count"

. label var percent_urban "Percent of population in ur
> ban areas"

. label var median_income "Median household income (pr
> ior year)"

. label var population_margin "ACS margin for error: p
> opulation"

. label var median_income_margin "ACS margin for error
> : median income"

. 
. ** Save as temporary file 
. tempfile demo

. save `demo'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000002
    > .tmp saved as .dta format

. 
. ** Create three datasets 
. 
. ** (1) Basic state and county IDs 
. keep if year == "2020" 
(51,452 observations deleted)

. keep state* county* 

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save as state and county Ids 
. save "${data}working/ids", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/ids.dta saved

. clear  

. 
. ** (2) Population data 
. use `demo'

. keep if !missing(pop_urban) 
(45,090 observations deleted)

. tab year 

       YEAR |      Freq.     Percent        Cum.
------------+-----------------------------------
       2000 |      3,141       32.78       32.78
       2010 |      3,221       33.61       66.39
       2020 |      3,221       33.61      100.00
------------+-----------------------------------
      Total |      9,583      100.00

. 
. ** Keep 2020 
. keep if year == "2020"
(6,362 observations deleted)

. drop year median_income* population_margin

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save data
. save "${data}working/population_2020", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/population_2020.dta saved

. clear  

. 
. ** (3) 2015-2019 ACS data 
. use `demo'

. keep if !missing(median_income) 
(6,447 observations deleted)

. tab year 

       YEAR |      Freq.     Percent        Cum.
------------+-----------------------------------
       2000 |      3,141        6.51        6.51
  2006-2010 |      3,221        6.68       13.19
  2007-2011 |      3,221        6.68       19.87
  2008-2012 |      3,221        6.68       26.55
  2009-2013 |      3,221        6.68       33.23
  2010-2014 |      3,220        6.68       39.91
  2011-2015 |      3,219        6.67       46.58
  2012-2016 |      3,220        6.68       53.26
  2013-2017 |      3,220        6.68       59.93
  2014-2018 |      3,219        6.67       66.61
  2015-2019 |      3,220        6.68       73.29
  2016-2020 |      3,220        6.68       79.96
  2017-2021 |      3,220        6.68       86.64
  2018-2022 |      3,221        6.68       93.32
  2019-2023 |      3,222        6.68      100.00
------------+-----------------------------------
      Total |     48,226      100.00

. 
. ** Keep 2020 
. keep if year == "2015-2019"
(45,006 observations deleted)

. drop year pop_rural pop_urban percent_urban

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save data
. save "${data}working/acs_2015_2019_data", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/acs_2015_2019_data.dta saved

. 
. ** Rename for merge 
. rename population population_acs

. 
. ** Merge with other data 
. merge 1:1 state_fips county_fips using "${data}worki
> ng/population_2020",                ///
>         keep(match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                             3,219  
    -----------------------------------------

. 
. ** Save data
. save "${data}working/demographics_2020", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/demographics_2020.dta saved

. 
. ** Load BEA Data 
. import delimited "${data}demographic/CAINC1/CAINC1__
> ALL_AREAS_1969_2023.csv",   ///
>         clear 
(encoding automatically selected: ISO-8859-1)
(63 vars, 9,604 obs)

. 
. ** Drop unnecc variables 
. drop region tablename industryclassification unit ge
> oname 

. 
. ** Drop empty cells 
. drop if missing(linecode)
(4 observations deleted)

. 
. ** Update names 
. rename geofips fips 

. replace fips = subinstr(fips, `"""', "", .)
(9,600 real changes made)

. destring fips, replace 
fips: all characters numeric; replaced as long

. 
. ** Keep population and per-capita income, dropping p
> ersonal income (total)
. tab description linecode

                      |  LineCode
          Description |         1 |     Total
----------------------+-----------+----------
Per capita personal.. |         0 |     3,200 
Personal income (th.. |     3,200 |     3,200 
Population (persons.. |         0 |     3,200 
----------------------+-----------+----------
                Total |     3,200 |     9,600 


                      |  LineCode
          Description |         2 |     Total
----------------------+-----------+----------
Per capita personal.. |         0 |     3,200 
Personal income (th.. |         0 |     3,200 
Population (persons.. |     3,200 |     3,200 
----------------------+-----------+----------
                Total |     3,200 |     9,600 


                      |  LineCode
          Description |         3 |     Total
----------------------+-----------+----------
Per capita personal.. |     3,200 |     3,200 
Personal income (th.. |         0 |     3,200 
Population (persons.. |         0 |     3,200 
----------------------+-----------+----------
                Total |     3,200 |     9,600 

. drop if linecode == 1   
(3,200 observations deleted)

. drop description

.         
. ** Get V* to be in terms of years 
. ** V9 == 1969 
. forvalues i = 9/63 {
  2.         
.         local j = 1960 + `i'
  3.         rename v`i' value`j'
  4.         
. } // END I LOOP 

. 
. ** Reshape 
. reshape long value, i(fips linecode) j(year)
(j = 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978
>  1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1
> 989 1990 1991 1992 1993 1994 1995 1996 1997 1998 199
> 9 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 
> 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 20
> 20 2021 2022 2023)

Data                               Wide   ->   Long
------------------------------------------------------
> -----------------------
Number of observations            6,400   ->   352,000
>      
Number of variables                  57   ->   4      
>      
j variable (55 values)                    ->   year
xij variables:
      value1969 value1970 ... value2023   ->   value
------------------------------------------------------
> -----------------------

. reshape wide value, i(fips year ) j(linecode)
(j = 2 3)

Data                               Long   ->   Wide
------------------------------------------------------
> -----------------------
Number of observations          352,000   ->   176,000
>      
Number of variables                   4   ->   4      
>      
j variable (2 values)          linecode   ->   (droppe
> d)
xij variables:
                                  value   ->   value2 
> value3
------------------------------------------------------
> -----------------------

. 
. ** Keep years 
. keep if inrange(year, 2015, 2023)
(147,200 observations deleted)

. 
. ** Rename values 
. rename value2 population 

. rename value3 per_capita_income

. 
. ** Drop if missing values 
. drop if population == "(NA)"
(239 observations deleted)

. 
. ** Keep only counties with all observations 
. bysort fips: gen ct = _N 

. tab ct

         ct |      Freq.     Percent        Cum.
------------+-----------------------------------
          4 |          8        0.03        0.03
          5 |          5        0.02        0.05
          9 |     28,548       99.95      100.00
------------+-----------------------------------
      Total |     28,561      100.00

. keep if ct == 9
(13 observations deleted)

. drop ct

. 
. ** Destring 
. destring population, replace 
population: all characters numeric; replaced as long

. destring per_capita_income, replace 
per_capita_income: all characters numeric; replaced as
>  long

. 
. ** Save data
. save "${data}working/bea_economics", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/bea_economics.dta saved

. 
. //--------------------------------------------------
> --
. // STEP 2: Import and Clean NYTimes COVID-19 Data 
. //--------------------------------------------------
> --
.  
. ** Import data 
. import delimited using "${data}covid/covid_nyt.csv",
>  varnames(1) clear case(lower) 
(encoding automatically selected: ISO-8859-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832                  
    Variables:             6                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
date            str10   %10s                  
county          str35   %35s                  
state           str24   %24s                  
fips            long    %12.0g                
cases           long    %12.0g                
deaths          long    %8.0g                 
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to 13may2022, but
                with gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_name, force 

Duplicates in terms of fips state_name county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000004
    > .tmp saved as .dta format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_names', keep(mast
> er match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,646,784  
    -----------------------------------------

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state county cases de
> aths 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/population_2020
> ", keep(match) nogen  
(variable county_name was str35, now str46 to
       accommodate using data's values)
(variable fips was long, now double to accommodate
       using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,643,408  
    -----------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/covid_cleaned.dta saved

. 
. ** Generate Clustering Variables 
. 
. ** Keep one observation per month 
. keep year month fips state_name county_name cases_cu
> m deaths_cum population

. collapse (sum) cases deaths population, by(year mont
> h fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Generate per capita figures
. replace cases = 1000 * cases / population
(82,955 real changes made)

. replace deaths = 1000 * deaths / population
(74,723 real changes made)

. drop population 

. 
. ** Reshape wide 
. reshape wide cases deaths, i(fips state_name county_
> name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 2
> 0 21 22 23 24 25 26 27 28 29)

Data                               Long   ->   Wide
------------------------------------------------------
> -----------------------
Number of observations           90,828   ->   3,132  
>      
Number of variables                   6   ->   61     
>      
j variable (29 values)             date   ->   (droppe
> d)
xij variables:
                              cases_cum   ->   cases_c
> um1 cases_cum2 ... cases_cum29
                             deaths_cum   ->   deaths_
> cum1 deaths_cum2 ... deaths_cum29
------------------------------------------------------
> -----------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned_wide.dta, replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/covid_cleaned_wide.dta saved

. clear

. 
. //--------------------------------------------------
> --
. // STEP 3: Import and Clean ACS Micro Data via IPUMS
>  
. //--------------------------------------------------
> --
. 
. ** Load data 
. forvalues y = 2015(1)2023 {
  2.         
.         ** Import CSV
.         import delimited using "${data}acs/acs_`y'",
>  varnames(1) clear case(lower)
  3.         
.         ** Save as temporary data 
.         tempfile acs_`y'
  4.         save `acs_`y''
  5.         clear 
  6.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-8859-1)
(57 vars, 2,997,503 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000005
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,007,847 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000006
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,038,696 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000007
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,060,442 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000008
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,087,291 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000009
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 2,454,160 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000a
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,092,079 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000b
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(55 vars, 3,190,848 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000c
    > .tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(55 vars, 3,228,659 obs)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000d
    > .tmp saved as .dta format

. 
. ** Append data 
. forvalues y = 2015(1)2023 {
  2.         
.         append using `acs_`y''  
  3.         
. } // END YEAR LOOP 
(variable cbserial was long, now double to
       accommodate using data's values)

. 
. ** Des 
. tab year 

       year |      Freq.     Percent        Cum.
------------+-----------------------------------
       2015 |  2,997,503       11.04       11.04
       2016 |  3,007,847       11.08       22.11
       2017 |  3,038,696       11.19       33.30
       2018 |  3,060,442       11.27       44.57
       2019 |  3,087,291       11.37       55.94
       2020 |  2,454,160        9.04       64.98
       2021 |  3,092,079       11.39       76.36
       2022 |  3,190,848       11.75       88.11
       2023 |  3,228,659       11.89      100.00
------------+-----------------------------------
      Total | 27,157,525      100.00

. 
. ** Define # of adults and kids in HHs 
. gen adult = age >= 18 

. gen child = age < 18 

. bysort year serial: gen hh_size = _N 

. bysort year serial: egen hh_adult_ct = total(adult)

. bysort year serial: egen hh_child_ct = total(child)

. 
. ** Sample 18+
. drop if child == 1 
(5,629,869 observations deleted)

. drop child adult 

. 
. ** Sample not living abroad last year 
. drop if migplac1 > 56 
(108,862 observations deleted)

. drop if migrate1 == 4 
(0 observations deleted)

. 
. ** Rename variables 
. rename statefip state_fips_d

. rename countyfip county_fips_d 

. 
. ** Set up origin data 
. fre migrate1

migrate1
------------------------------------------------------
> -----
              |      Freq.    Percent      Valid      
>  Cum.
--------------+---------------------------------------
> -----
Valid   1     |   1.92e+07      89.51      89.51      
> 89.51
        2     |    1809920       8.45       8.45      
> 97.96
        3     |     436745       2.04       2.04     1
> 00.00
        Total |   2.14e+07     100.00     100.00      
>      
------------------------------------------------------
> -----

. drop migrate1d

. tab migplac1

   migplac1 |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 | 19,172,129       89.51       89.51
          1 |     31,329        0.15       89.66
          2 |      5,825        0.03       89.68
          4 |     54,912        0.26       89.94
          5 |     21,714        0.10       90.04
          6 |    260,673        1.22       91.26
          8 |     52,539        0.25       91.50
          9 |     21,577        0.10       91.61
         10 |      5,369        0.03       91.63
         11 |      8,664        0.04       91.67
         12 |    152,989        0.71       92.38
         13 |     71,263        0.33       92.72
         15 |      9,845        0.05       92.76
         16 |     13,536        0.06       92.83
         17 |     86,306        0.40       93.23
         18 |     47,941        0.22       93.45
         19 |     21,469        0.10       93.55
         20 |     22,338        0.10       93.66
         21 |     31,888        0.15       93.81
         22 |     28,776        0.13       93.94
         23 |      7,911        0.04       93.98
         24 |     40,223        0.19       94.17
         25 |     48,684        0.23       94.39
         26 |     65,444        0.31       94.70
         27 |     35,177        0.16       94.86
         28 |     16,994        0.08       94.94
         29 |     45,200        0.21       95.15
         30 |      7,453        0.03       95.19
         31 |     13,567        0.06       95.25
         32 |     24,785        0.12       95.37
         33 |      8,787        0.04       95.41
         34 |     50,561        0.24       95.64
         35 |     12,299        0.06       95.70
         36 |    118,674        0.55       96.26
         37 |     70,555        0.33       96.59
         38 |      5,884        0.03       96.61
         39 |     81,541        0.38       96.99
         40 |     28,921        0.14       97.13
         41 |     36,246        0.17       97.30
         42 |     76,201        0.36       97.65
         44 |      6,551        0.03       97.68
         45 |     33,552        0.16       97.84
         46 |      6,067        0.03       97.87
         47 |     48,061        0.22       98.09
         48 |    197,912        0.92       99.02
         49 |     25,798        0.12       99.14
         50 |      4,106        0.02       99.16
         51 |     64,560        0.30       99.46
         53 |     64,790        0.30       99.76
         54 |     10,532        0.05       99.81
         55 |     35,653        0.17       99.98
         56 |      5,023        0.02      100.00
------------+-----------------------------------
      Total | 21,418,794      100.00

. rename migplac1 state_fips_o

. tab migcounty1

 migcounty1 |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 | 19,952,847       93.16       93.16
          1 |     35,752        0.17       93.32
          3 |     58,525        0.27       93.60
          5 |     21,286        0.10       93.70
          7 |     13,720        0.06       93.76
          9 |     11,958        0.06       93.82
         11 |     23,663        0.11       93.93
         13 |     53,927        0.25       94.18
         15 |      7,126        0.03       94.21
         17 |     21,840        0.10       94.31
         19 |     24,348        0.11       94.43
         20 |      2,061        0.01       94.44
         21 |     12,848        0.06       94.50
         23 |      7,725        0.04       94.53
         25 |     21,090        0.10       94.63
         27 |     15,274        0.07       94.70
         29 |     32,454        0.15       94.85
         31 |     57,529        0.27       95.12
         33 |     33,851        0.16       95.28
         35 |     24,912        0.12       95.40
         37 |     72,280        0.34       95.73
         39 |     10,381        0.05       95.78
         41 |      8,696        0.04       95.82
         43 |      8,893        0.04       95.86
         45 |      5,998        0.03       95.89
         47 |     22,821        0.11       96.00
         49 |     21,522        0.10       96.10
         51 |     17,488        0.08       96.18
         53 |     17,759        0.08       96.26
         55 |     12,676        0.06       96.32
         57 |     18,309        0.09       96.41
         59 |     30,944        0.14       96.55
         61 |     31,725        0.15       96.70
         63 |     12,421        0.06       96.76
         65 |     18,670        0.09       96.85
         67 |     29,982        0.14       96.99
         69 |      4,036        0.02       97.01
         71 |     27,649        0.13       97.13
         73 |     36,959        0.17       97.31
         75 |     11,968        0.06       97.36
         77 |      8,293        0.04       97.40
         79 |      7,681        0.04       97.44
         81 |     30,275        0.14       97.58
         83 |      9,053        0.04       97.62
         85 |     28,918        0.14       97.76
         87 |      6,680        0.03       97.79
         89 |     10,158        0.05       97.83
         91 |     15,565        0.07       97.91
         93 |      4,960        0.02       97.93
         95 |     19,883        0.09       98.02
         97 |     19,460        0.09       98.11
         99 |     19,554        0.09       98.21
        101 |     14,457        0.07       98.27
        103 |     18,351        0.09       98.36
        105 |      7,421        0.03       98.39
        107 |      5,600        0.03       98.42
        109 |     10,761        0.05       98.47
        111 |     14,844        0.07       98.54
        113 |     30,918        0.14       98.68
        115 |      4,818        0.02       98.71
        117 |      7,798        0.04       98.74
        119 |     14,739        0.07       98.81
        121 |     10,181        0.05       98.86
        123 |      3,671        0.02       98.88
        125 |      9,036        0.04       98.92
        127 |      2,348        0.01       98.93
        129 |      1,814        0.01       98.94
        133 |      5,313        0.02       98.96
        135 |      7,844        0.04       99.00
        139 |      5,952        0.03       99.03
        141 |      6,936        0.03       99.06
        143 |      4,286        0.02       99.08
        145 |      1,975        0.01       99.09
        147 |      2,327        0.01       99.10
        149 |      2,146        0.01       99.11
        151 |      1,900        0.01       99.12
        153 |      5,155        0.02       99.14
        157 |     11,532        0.05       99.20
        159 |        751        0.00       99.20
        160 |        149        0.00       99.20
        161 |      4,716        0.02       99.22
        163 |     13,817        0.06       99.29
        165 |      2,418        0.01       99.30
        167 |      5,023        0.02       99.32
        169 |        850        0.00       99.33
        171 |        529        0.00       99.33
        173 |        264        0.00       99.33
        179 |      1,879        0.01       99.34
        183 |     11,521        0.05       99.39
        185 |        871        0.00       99.40
        187 |      2,303        0.01       99.41
        189 |      6,599        0.03       99.44
        191 |        759        0.00       99.44
        197 |      3,401        0.02       99.46
        201 |     29,158        0.14       99.59
        209 |      2,664        0.01       99.60
        215 |      3,046        0.01       99.62
        223 |        758        0.00       99.62
        227 |        946        0.00       99.63
        245 |      3,068        0.01       99.64
        251 |      1,020        0.00       99.65
        257 |        850        0.00       99.65
        303 |      3,247        0.02       99.67
        309 |      2,351        0.01       99.68
        313 |        456        0.00       99.68
        329 |      1,177        0.01       99.68
        339 |      3,176        0.01       99.70
        355 |      2,646        0.01       99.71
        367 |        977        0.00       99.72
        375 |      1,001        0.00       99.72
        381 |      1,199        0.01       99.73
        423 |      1,497        0.01       99.73
        439 |     14,652        0.07       99.80
        441 |      1,419        0.01       99.81
        451 |        952        0.00       99.81
        453 |     12,549        0.06       99.87
        479 |      1,301        0.01       99.88
        485 |      1,288        0.01       99.88
        491 |      4,036        0.02       99.90
        510 |     10,140        0.05       99.95
        550 |      1,187        0.01       99.95
        650 |      1,031        0.00       99.96
        700 |      1,438        0.01       99.97
        710 |        466        0.00       99.97
        760 |      2,799        0.01       99.98
        810 |      3,933        0.02      100.00
------------+-----------------------------------
      Total | 21,418,794      100.00

. rename migcounty1 county_fips_o

. 
. ** Use migrate1 to update values 
. 
. ** Within same house 
. replace state_fips_o = state_fips_d if migrate1 == 1
(19,172,129 real changes made)

. replace county_fips_o = county_fips_d if migrate1 ==
>  1 
(11,640,515 real changes made)

. 
. ** Within same state 
. replace state_fips_o = state_fips_d if migrate1 == 2
(0 real changes made)

. 
. ** Generate county IDS 
. foreach x in "o" "d" {
  2.         
.         make_fips state_fips_`x' county_fips_`x', ge
> n(fips_`x')
  3. 
. }

. 
. ** Check for within-state migration 
. gen same_county = fips_o == fips_d 

. tab year same_county

           |      same_county
      year |         0          1 |     Total
-----------+----------------------+----------
      2015 |    89,492  2,245,481 | 2,334,973 
      2016 |    91,109  2,255,901 | 2,347,010 
      2017 |    93,553  2,278,348 | 2,371,901 
      2018 |    96,080  2,306,022 | 2,402,102 
      2019 |    96,088  2,344,171 | 2,440,259 
      2020 |    71,827  1,877,155 | 1,948,982 
      2021 |    97,600  2,361,518 | 2,459,118 
      2022 |   106,231  2,430,426 | 2,536,657 
      2023 |    98,226  2,479,566 | 2,577,792 
-----------+----------------------+----------
     Total |   840,206 20,578,588 |21,418,794 

. tab year same_county if migrate1 == 2

           |      same_county
      year |         0          1 |     Total
-----------+----------------------+----------
      2015 |    42,597    172,956 |   215,553 
      2016 |    43,823    172,091 |   215,914 
      2017 |    45,058    174,386 |   219,444 
      2018 |    46,477    173,182 |   219,659 
      2019 |    46,329    168,101 |   214,430 
      2020 |    34,625    119,307 |   153,932 
      2021 |    46,470    148,925 |   195,395 
      2022 |    50,584    141,717 |   192,301 
      2023 |    47,498    135,794 |   183,292 
-----------+----------------------+----------
     Total |   403,461  1,406,459 | 1,809,920 

. 
. ** Tag HH head 
. gen byte hh_head = (relate == 1)

. 
. ** Compress file 
. compress 
  variable state_fips_o was int now byte
  variable hh_size was float now byte
  variable hh_adult_ct was float now byte
  variable hh_child_ct was float now byte
  variable same_county was float now byte
  (278,444,322 bytes saved)

. 
. ** Save 
. save "${data}working/acs_migration_file", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/acs_migration_file.dta saved

. 
. // Keep only observations with valid origin/destinat
> ion counties and YEAR
. drop if missing(year) | missing(fips_o) | missing(fi
> ps_d)
(0 observations deleted)

. 
. // Clean income (treat missing as 0; keep negative v
> alues as reported)
. replace inctot = 0 if missing(inctot)
(0 real changes made)

. gen double income_wt = inctot * perwt

. label var income_wt "Person income (INCTOT) weighted
>  by PERWT"

. 
. // --- Persons + income totals by origin/destination
> /year
. preserve

. keep year fips_o fips_d perwt income_wt

. collapse (sum) persons=perwt income_total=income_wt,
>  by(year fips_o fips_d)

. tempfile acs_pi

. save `acs_pi'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000f
    > .tmp saved as .dta format

. restore

. 
. // --- Households by origin/destination/year
. // Use HHWT among household heads (RELATE==1) if ava
> ilable; else PERNUM==1 fallback.
. 
. preserve

. keep if hh_head
(10,269,992 observations deleted)

. keep year fips_o fips_d hhwt

. collapse (sum) households=hhwt, by(year fips_o fips_
> d)

. tempfile acs_hh

. save `acs_hh'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000h
    > .tmp saved as .dta format

. restore

. 
. // --- Merge persons/income with households
. use `acs_pi', clear

. merge 1:1 year fips_o fips_d using `acs_hh', nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                        45,163
        from master                    45,163  
        from using                          0  

    Matched                           162,899  
    -----------------------------------------

. 
. label var persons "Estimated number of persons (sum 
> PERWT)"

. label var households "Estimated number of households
>  (sum HHWT among heads)"

. label var income_total "Estimated total personal inc
> ome (sum INCTOT*PERWT)"

. 
. // --- Derive state/county components for merges wit
> h name crosswalk
. gen int state_fips_o  = floor(fips_o/1000)

. gen int county_fips_o = mod(fips_o,1000)

. gen int state_fips_d  = floor(fips_d/1000)

. gen int county_fips_d = mod(fips_d,1000)

. 
. label var state_fips_o "State FIPS (origin)"

. label var county_fips_o "County FIPS (origin)"

. label var state_fips_d "State FIPS (destination)"

. label var county_fips_d "County FIPS (destination)"

. 
. // --- Merge in names (from NHGIS IDs snapshot)
. preserve

. use "${data}working/ids", clear

. rename (state_fips county_fips state_name county_nam
> e) (state_fips_o county_fips_o state_name_o county_n
> ame_o)

. tempfile ids_o

. save `ids_o'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000j
    > .tmp saved as .dta format

. keep state_fips_o state_name_o 

. duplicates drop 

Duplicates in terms of all variables

(3,169 observations deleted)

. tempfile state_ids_o

. save `state_ids_o'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000k
    > .tmp saved as .dta format

. restore

. merge m:1 state_fips_o county_fips_o using `ids_o', 
> keep(master match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                        46,997
        from master                    46,997  
        from using                          0  

    Matched                           161,065  
    -----------------------------------------

. drop state_name_o 

. merge m:1 state_fips_o using `state_ids_o', keep(mas
> ter match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           208,062  
    -----------------------------------------

. 
. preserve

. use "${data}working/ids", clear

. rename (state_fips county_fips state_name county_nam
> e) (state_fips_d county_fips_d state_name_d county_n
> ame_d)

. tempfile ids_d

. save `ids_d'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000m
    > .tmp saved as .dta format

. keep state_fips_d state_name_d 

. duplicates drop 

Duplicates in terms of all variables

(3,169 observations deleted)

. tempfile state_ids_d

. save `state_ids_d'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000n
    > .tmp saved as .dta format

. restore

. 
. merge m:1 state_fips_d county_fips_d using `ids_d', 
> keep(master match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                        50,197
        from master                    50,197  
        from using                          0  

    Matched                           157,865  
    -----------------------------------------

. drop state_name_d

. merge m:1 state_fips_d using `state_ids_d', keep(mas
> ter match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           208,062  
    -----------------------------------------

. order year ///
>     state_fips_o county_fips_o state_name_o county_n
> ame_o fips_o ///
>     state_fips_d county_fips_d state_name_d county_n
> ame_d fips_d ///
>     persons households income_total

. 
. sort year state_fips_o county_fips_o state_fips_d co
> unty_fips_d

. 
. replace county_name_o = "Other" if county_fips_o == 
> 0 
(46,948 real changes made)

. replace county_name_d = "Other" if county_fips_d == 
> 0 
(49,676 real changes made)

. 
. save "${data}working/acs_county_flow", replace
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/acs_county_flow.dta saved

. 
. // Optional: Multnomah-focused flow extract (origin 
> = Multnomah County, OR)
. // Multnomah County, OR = state 41, county 051
. preserve

. keep if state_fips_o == 41 & county_fips_o == 51
(207,316 observations deleted)

. save "${data}working/multnomah_acs_flow", replace
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/multnomah_acs_flow.dta saved

. clear

. 
. 
. 
. //--------------------------------------------------
> --
. // STEP 4: Import and Clean IRS Migration Data 
. //--------------------------------------------------
> --
. 
. ** Loop over years 
. forvalues y = 15(1)21 {
  2.         
.         local start = `y'
  3.         local end = `y' + 1 
  4.         
.         ** Import data (out)
.         import delimited "${data}irs/countyoutflow`s
> tart'`end'.csv", clear 
  5.         
.         ** Describe data 
.         des 
  6.         
.         ** Generate year 
.         gen year = 2000 + `y' 
  7.         
.         ** Drop Regional Values 
.         drop if y2_state == "DS"
  8.         
.         ** Drop Foreign Migration 
.         drop if y2_state == "FR"
  9.         
.         ** Drop observations without a county
.         drop if y1_countyfips == 0 
 10.         
.         ** Deal with suppressed values 
.         unsuppress n1 n2 agi
 11.         
.         ** Drop unnecc variables 
.         drop y2_state y2_countyname
 12.                 
.         ** Create two versions: gross and net 
.         tempfile tmp
 13.         save `tmp'
 14.         
.         ** Gross first 
.         
.         ** Keep gross categories 
.         keep if ///
>                 (y1_statefips == y2_statefips & y1_c
> ountyfips == y2_countyfips) |       ///
>                 inlist(y2_statefips, 96, 97, 98)
 15. 
.         ** Clean up 
.         gen move_type = 0 
 16.         
.         ** Stayers 
.         replace move_type = 1 if        (y1_statefip
> s == y2_statefips) &        ///
>                                                     
>             (y1_countyfips == y2_countyfips) 
 17.         
.         ** Movers
.         replace move_type = 2 if        y2_statefips
>  == 96              // ALL 
 18.         replace move_type = 3 if        y2_statef
> ips == 97 &    ///
>                                                     
>             y2_countyfips == 0              // Domes
> tic Total
 19.         replace move_type = 4 if        y2_statef
> ips == 97 &    ///
>                                                     
>             y2_countyfips == 1              // Withi
> n-state
 20.         replace move_type = 5 if        y2_statef
> ips == 97 &    ///
>                                                     
>             y2_countyfips == 3              // Betwe
> en-states 
 21.         replace move_type = 6 if        y2_statef
> ips == 98              // Foreign 
 22.         
.         ** Label movers 
.         label values move_type lb_move_type 
 23.         
.         ** Generate total category 
.         foreach var of varlist n1 n2 agi {
 24.                 
.                 gen tmp = `var' if inlist(move_type,
>  1, 2)
 25.                 bysort y1_statefips y1_countyfips
> : egen `var'_total = total(tmp)
 26.                 drop tmp 
 27.                 
.         } // END VAR LOOP 
 28.         
.         ** Drop unnecc variables 
.         drop y2_* 
 29.         
.         ** Sort 
.         sort year y1_statefips y1_countyfips move_ty
> pe 
 30. 
.         ** Order 
.         order year y1_statefips y1_countyfips move_t
> ype 
 31.         
.         ** Rename 
.         rename y1_countyfips county_fips 
 32.         rename y1_statefips state_fips 
 33.         
.         ** Label variables 
.         label var year "Tax year (year before move)"
 34.         label var state_fips "State FIPS code (or
> igin state)"
 35.         label var county_fips "County FIPS code (
> origin county)"
 36.         label var move_type "Mover category"
 37.         label var n1 "Number of returns"
 38.         label var n2 "Number of exemptions"
 39.         label var agi "Adjusted Gross Income"
 40.         label var n1_total "Number of returns, co
> unty total (origin)"
 41.         label var n2_total "Number of exemptions,
>  county total (origin)"
 42.         label var agi_total "Adjusted Gross Incom
> e, county total (origin)"
 43.         
.         ** Save 
.         save "${data}working/irs_county_gross_out_`y
> '", replace 
 44.         
.         ** Create version for merge with net 
.         keep if move_type == 3 
 45.         
.         ** Rename variables 
.         rename n1 n1_mover
 46.         rename n2 n2_mover 
 47.         rename agi agi_mover 
 48.         
.         label var n1_mover "Number of domestic mover
>  returns"
 49.         label var n2_mover "Number of domestic mo
> ver exemptions"
 50.         label var agi_mover "Adjusted Gross Incom
> e, domestic movers"
 51.         
.         ** Save as temp file 
.         tempfile merge 
 52.         save `merge'
 53.         clear 
 54.         
.         ** Next, create flow file 
.         use `tmp', clear 
 55.         
.         ** Drop aggregate values 
.         drop if inlist(y2_statefips, 96, 97, 98)
 56.         drop if (y1_statefips == y2_statefips & y
> 1_countyfips == y2_countyfips) 
 57.         
.         ** Sort 
.         sort year y1_statefips y1_countyfips y2_stat
> efips y2_countyfips 
 58. 
.         ** Order 
.         order year y1_statefips y1_countyfips y2_sta
> tefips y2_countyfips
 59. 
.         
.         ** Rename 
.         rename y1_countyfips county_fips 
 60.         rename y1_statefips state_fips 
 61.         rename y2_countyfips y2_county_fips 
 62.         rename y2_statefips y2_state_fips       
 63.         
.         ** Label variables 
.         label var year "Tax year (year before move)"
 64.         label var state_fips "State FIPS code (or
> igin state)"
 65.         label var county_fips "County FIPS code (
> origin county)"
 66.         label var y2_state_fips "State FIPS code 
> (dest. state)"
 67.         label var y2_county_fips "County FIPS cod
> e (dest. county)"      
 68.         label var n1 "Number of returns"
 69.         label var n2 "Number of exemptions"
 70.         label var agi "Adjusted Gross Income"
 71.         
.         ** Merge with county of origin data 
.         merge m:1 state_fips county_fips using `merg
> e', nogen keep(master match)
 72.         
.         ** Rename 
.         rename state_fips state_fips_o
 73.         rename county_fips county_fips_o
 74.         rename y2_* *_d 
 75.         
.         ** Dropo unnecc variable 
.         drop move_type 
 76.         
.         ** Save 
.         save "${data}working/irs_county_flow_`y'", r
> eplace 
 77.         clear
 78.         
.         ** Import data (in)
.         import delimited "${data}irs/countyinflow`st
> art'`end'.csv", clear 
 79.         
.         ** Describe data 
.         des 
 80. 
.         ** Generate year 
.         gen year = 2000 + `y' 
 81.         
.         ** Drop Regional Values 
.         drop if y1_state == "DS"
 82.         
.         ** Drop Foreign Migration 
.         drop if y1_state == "FR"
 83.         
.         ** Drop observations with no county ID 
.         drop if y2_countyfips == 0 
 84.         
.         ** Keep gross categories 
.         keep if ///
>                 (y1_statefips == y2_statefips & y1_c
> ountyfips == y2_countyfips) |       ///
>                 inlist(y1_statefips, 96, 97, 98)
 85. 
.         ** Clean up 
.         gen move_type = 0 
 86.         
.         ** Deal with suppressed values 
.         unsuppress n1 n2 agi
 87.         
.         ** Stayers 
.         replace move_type = 1 if        (y1_statefip
> s == y2_statefips) &        ///
>                                                     
>             (y1_countyfips == y2_countyfips) 
 88.         
.         ** Movers
.         replace move_type = 2 if        y1_statefips
>  == 96              // ALL 
 89.         replace move_type = 3 if        y1_statef
> ips == 97 &    ///
>                                                     
>             y1_countyfips == 0              // Domes
> tic Total
 90.         replace move_type = 4 if        y1_statef
> ips == 97 &    ///
>                                                     
>             y1_countyfips == 1              // Withi
> n-state
 91.         replace move_type = 5 if        y1_statef
> ips == 97 &    ///
>                                                     
>             y1_countyfips == 3              // Betwe
> en-states 
 92.         replace move_type = 6 if        y1_statef
> ips == 98              // Foreign 
 93.         
.         ** Label move variable  
.         label values move_type lb_move_type 
 94.         
.         ** Generate total category 
.         foreach var of varlist n1 n2 agi {
 95.                 
.                 gen tmp = `var' if inlist(move_type,
>  1, 2)
 96.                 bysort y2_statefips y2_countyfips
> : egen `var'_total = total(tmp)
 97.                 drop tmp 
 98.                 
.         } // END VAR LOOP 
 99.         
.         ** Drop unnecc variables 
.         drop y1_*
100.         
.         ** Sort 
.         sort year y2_statefips y2_countyfips move_ty
> pe 
101. 
.         ** Order 
.         order year y2_statefips y2_countyfips move_t
> ype 
102.         
.         ** Rename 
.         rename y2_countyfips county_fips 
103.         rename y2_statefips state_fips 
104.         
.         ** Label variables 
.         label var year "Tax year (year before move)"
105.         label var state_fips "State FIPS code (de
> st. state)"
106.         label var county_fips "County FIPS code (
> dest. county)"
107.         label var move_type "Mover category"
108.         label var n1 "Number of returns"
109.         label var n2 "Number of exemptions"
110.         label var agi "Adjusted Gross Income"
111.         label var n1_total "Number of returns, co
> unty total (dest.)"
112.         label var n2_total "Number of exemptions,
>  county total (dest.)"
113.         label var agi_total "Adjusted Gross Incom
> e, county total (dest.)"
114.         
.         ** Save 
.         save "${data}working/irs_county_gross_in_`y'
> ", replace 
115.         clear 
116.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-8859-1)
(9 vars, 86,481 obs)

Contains data
 Observations:        86,481                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,289 observations deleted)
(2,937 observations deleted)
(254 observations deleted)
(2,056 real changes made)
(2,056 real changes made)
(2,056 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000p
    > .tmp saved as .dta format
(50,007 observations deleted)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,291 real changes made)
(11,712 missing values generated)
(11,712 missing values generated)
(11,712 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_15.dta
    saved
(14,853 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000q
    > .tmp saved as .dta format
(14,853 observations deleted)
(3,141 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            50,007  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_15.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 86,330 obs)

Contains data
 Observations:        86,330                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,315 observations deleted)
(2,814 observations deleted)
(254 observations deleted)
(50,005 observations deleted)
(2,041 real changes made)
(2,041 real changes made)
(2,041 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,239 real changes made)
(11,660 missing values generated)
(11,660 missing values generated)
(11,660 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_15.dta
    saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 98,948 obs)

Contains data
 Observations:        98,948                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,372 observations deleted)
(2,360 observations deleted)
(254 observations deleted)
(1,877 real changes made)
(1,877 real changes made)
(1,877 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000r
    > .tmp saved as .dta format
(63,249 observations deleted)
(3,140 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,141 real changes made)
(2,010 real changes made)
(11,432 missing values generated)
(11,432 missing values generated)
(11,432 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_16.dta
    saved
(14,572 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000s
    > .tmp saved as .dta format
(14,573 observations deleted)
(3,140 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            63,249  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_16.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 98,874 obs)

Contains data
 Observations:        98,874                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,432 observations deleted)
(2,282 observations deleted)
(254 observations deleted)
(63,249 observations deleted)
(1,788 real changes made)
(1,788 real changes made)
(1,788 real changes made)
(3,140 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(1,955 real changes made)
(11,376 missing values generated)
(11,376 missing values generated)
(11,376 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_16.dta
    saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,820 obs)

Contains data
 Observations:        87,820                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,300 observations deleted)
(2,364 observations deleted)
(254 observations deleted)
(1,942 real changes made)
(1,942 real changes made)
(1,942 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000t
    > .tmp saved as .dta format
(52,173 observations deleted)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,026 real changes made)
(11,447 missing values generated)
(11,447 missing values generated)
(11,447 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_17.dta
    saved
(14,588 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000u
    > .tmp saved as .dta format
(14,588 observations deleted)
(3,141 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            52,173  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_17.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,932 obs)

Contains data
 Observations:        87,932                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,368 observations deleted)
(2,403 observations deleted)
(254 observations deleted)
(52,174 observations deleted)
(1,919 real changes made)
(1,919 real changes made)
(1,919 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,030 real changes made)
(11,451 missing values generated)
(11,451 missing values generated)
(11,451 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_17.dta
    saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 83,878 obs)

Contains data
 Observations:        83,878                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,919 observations deleted)
(2,298 observations deleted)
(0 observations deleted)
(53 real changes made)
(53 real changes made)
(53 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000v
    > .tmp saved as .dta format
(51,090 observations deleted)
(3,141 real changes made)
(3,107 real changes made)
(3,107 real changes made)
(3,103 real changes made)
(2,778 real changes made)
(335 real changes made)
(9,323 missing values generated)
(9,323 missing values generated)
(9,323 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_18.dta
    saved
(12,464 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000w
    > .tmp saved as .dta format
(12,430 observations deleted)
(3,141 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            34
        from master                        34  
        from using                          0  

    Matched                            51,056  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_18.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 83,762 obs)

Contains data
 Observations:        83,762                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,890 observations deleted)
(2,290 observations deleted)
(0 observations deleted)
(51,090 observations deleted)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3,141 real changes made)
(3,086 real changes made)
(3,086 real changes made)
(3,082 real changes made)
(2,729 real changes made)
(368 real changes made)
(9,265 missing values generated)
(9,265 missing values generated)
(9,265 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_18.dta
    saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,325 obs)

Contains data
 Observations:        87,325                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,937 observations deleted)
(2,272 observations deleted)
(0 observations deleted)
(62 real changes made)
(62 real changes made)
(62 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000x
    > .tmp saved as .dta format
(54,560 observations deleted)
(3,142 real changes made)
(3,104 real changes made)
(3,104 real changes made)
(3,101 real changes made)
(2,773 real changes made)
(332 real changes made)
(9,310 missing values generated)
(9,310 missing values generated)
(9,310 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_19.dta
    saved
(12,452 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000010
    > .tmp saved as .dta format
(12,414 observations deleted)
(3,142 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            38
        from master                        38  
        from using                          0  

    Matched                            54,522  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_19.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,552 obs)

Contains data
 Observations:        87,552                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,060 observations deleted)
(2,323 observations deleted)
(0 observations deleted)
(54,560 observations deleted)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3,142 real changes made)
(3,102 real changes made)
(3,102 real changes made)
(3,097 real changes made)
(2,805 real changes made)
(361 real changes made)
(9,365 missing values generated)
(9,365 missing values generated)
(9,365 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_19.dta
    saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 89,511 obs)

Contains data
 Observations:        89,511                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,963 observations deleted)
(2,175 observations deleted)
(0 observations deleted)
(79 real changes made)
(79 real changes made)
(79 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000011
    > .tmp saved as .dta format
(56,831 observations deleted)
(3,143 real changes made)
(3,097 real changes made)
(3,097 real changes made)
(3,094 real changes made)
(2,787 real changes made)
(324 real changes made)
(9,302 missing values generated)
(9,302 missing values generated)
(9,302 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_20.dta
    saved
(12,445 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000012
    > .tmp saved as .dta format
(12,399 observations deleted)
(3,143 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            46
        from master                        46  
        from using                          0  

    Matched                            56,785  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_20.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 89,850 obs)

Contains data
 Observations:        89,850                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,132 observations deleted)
(2,263 observations deleted)
(0 observations deleted)
(56,835 observations deleted)
(1 real change made)
(1 real change made)
(1 real change made)
(3,143 real changes made)
(3,101 real changes made)
(3,101 real changes made)
(3,098 real changes made)
(2,838 real changes made)
(339 real changes made)
(9,376 missing values generated)
(9,376 missing values generated)
(9,376 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_20.dta
    saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 90,409 obs)

Contains data
 Observations:        90,409                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,962 observations deleted)
(2,223 observations deleted)
(0 observations deleted)
(64 real changes made)
(64 real changes made)
(64 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000013
    > .tmp saved as .dta format
(57,644 observations deleted)
(3,144 real changes made)
(3,107 real changes made)
(3,107 real changes made)
(3,103 real changes made)
(2,790 real changes made)
(329 real changes made)
(9,329 missing values generated)
(9,329 missing values generated)
(9,329 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out_21.dta
    saved
(12,473 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000014
    > .tmp saved as .dta format
(12,436 observations deleted)
(3,144 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            37
        from master                        37  
        from using                          0  

    Matched                            57,607  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow_21.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 90,498 obs)

Contains data
 Observations:        90,498                  
    Variables:             9                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,093 observations deleted)
(2,179 observations deleted)
(0 observations deleted)
(57,640 observations deleted)
(1 real change made)
(1 real change made)
(1 real change made)
(3,144 real changes made)
(3,098 real changes made)
(3,098 real changes made)
(3,094 real changes made)
(2,822 real changes made)
(330 real changes made)
(9,344 missing values generated)
(9,344 missing values generated)
(9,344 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in_21.dta
    saved

. 
. ** Append data 
. 
. ** Loop over datasets 
. foreach file in "irs_county_gross_in" "irs_county_gr
> oss_out" "irs_county_flow"{
  2.         
.                 
.         ** Loop over years 
.         forvalues y = 15(1)21 {
  3. 
.                 ** Append 
.                 append using "${data}working/`file'_
> `y'"
  4.                 
.         } // END YEAR LOOP 
  5.         
.         
.         ** Order and sort flow file 
.         if "`file'" == "irs_county_flow" {
  6.                 
.                 ** Loop over orgin and destination s
> tate 
.                 foreach x in "o" "d" {
  7.                         
.                         ** Rename 
.                         rename *_fips_`x' *_fips 
  8.                         
.                         ** Merge with county and sta
> te names 
.                         merge m:1 state_fips county_
> fips using "${data}working/ids",    ///
>                                 keep(match) nogen 
  9.                                 
.                         ** Rename 
.                         rename *_fips *_fips_`x' 
 10.                         rename *_name *_name_`x' 
 11.                         
.                         ** Generate county IDS 
.                         make_fips state_fips_`x' cou
> nty_fips_`x', gen(fips_`x')
 12.                         
.                 } // END ORIGIN / DESTINATION LOOP 
 13.                 
.                 ** Order file 
.                 order year state_*_o county_*_o stat
> e_*_d county_*_d  
 14.                 sort year state_*_o county_*_o st
> ate_*_d county_*_d  
 15. 
.         } // END MIGRATION FLOW IF-STATEMENT 
 16.         
.         else {
 17.                 
.                 ** Merge with county and state names
>  
.                 merge m:1 state_fips county_fips usi
> ng "${data}working/ids",    ///
>                                 keep(match) nogen 
 18.                                 
.                 ** Order 
.                 order year state_* county* move_type
 19.                 
.         } 
 20.         
.         ** Save file 
.         save "${data}working/`file'", replace 
 21.         clear 
 22.         
. } // END FILE LOOP 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           115,567  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_in.dta
    saved

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           115,611  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross_out.dta
    saved

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           384,896  
    -----------------------------------------

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           362,678  
    -----------------------------------------
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_flow.dta saved

. 
. ** Create gross file with in and out migration 
. use "${data}working/irs_county_gross_in", clear 

. 
. ** Rename 
. rename n1 n1_in_

. rename n2 n2_in_

. rename agi agi_in_

. rename *_total *_total_in

. 
. ** Reshape 
. reshape wide n1_in_ n2_in_ agi_in_, i(year state_fip
> s county_fips) j(move_type)
(j = 1 2 3 4 5 6)

Data                               Long   ->   Wide
------------------------------------------------------
> -----------------------
Number of observations          115,567   ->   21,980 
>      
Number of variables                  13   ->   27     
>      
j variable (6 values)         move_type   ->   (droppe
> d)
xij variables:
                                 n1_in_   ->   n1_in_1
>  n1_in_2 ... n1_in_6
                                 n2_in_   ->   n2_in_1
>  n2_in_2 ... n2_in_6
                                agi_in_   ->   agi_in_
> 1 agi_in_2 ... agi_in_6
------------------------------------------------------
> -----------------------

. 
. ** Define locals 
. local txt1 "Non-movers"

. local txt2 "All movers"                 

. local txt3 "Domestic movers"            

. local txt4 "Within-state movers"        

. local txt5 "Inter-state movers" 

. local txt6 "Foreign movers"

. 
. ** Label variables, in loop 
. foreach n of numlist 1(1)6 {
  2.         
.         label var n1_in_`n' "Returns, in-migration, 
> `txt`n''"
  3.         label var n2_in_`n' "Exemptions, in-migra
> tion, `txt`n''"
  4.         label var agi_in_`n' "AGI, in-migration, 
> `txt`n''"
  5. 
. } // END NUMLIST LOOP 

. 
. ** Preserve 
. tempfile gross_in

. save `gross_in'
file
    C:\Users\ji252\AppData\Local\Temp\ST_91a0_000015
    > .tmp saved as .dta format

. clear

. 
. ** Create gross file with in and out migration 
. use "${data}working/irs_county_gross_out", clear 

. 
. ** Rename 
. rename n1 n1_out_

. rename n2 n2_out_

. rename agi agi_out_

. rename *_total *_total_out

. 
. ** Reshape 
. reshape wide n1_out_ n2_out_ agi_out_, i(year state_
> fips county_fips) j(move_type)
(j = 1 2 3 4 5 6)

Data                               Long   ->   Wide
------------------------------------------------------
> -----------------------
Number of observations          115,611   ->   21,980 
>      
Number of variables                  13   ->   27     
>      
j variable (6 values)         move_type   ->   (droppe
> d)
xij variables:
                                n1_out_   ->   n1_out_
> 1 n1_out_2 ... n1_out_6
                                n2_out_   ->   n2_out_
> 1 n2_out_2 ... n2_out_6
                               agi_out_   ->   agi_out
> _1 agi_out_2 ... agi_out_6
------------------------------------------------------
> -----------------------

. 
. ** Define locals 
. local txt1 "Non-movers"

. local txt2 "All movers"                 

. local txt3 "Domestic movers"            

. local txt4 "Within-state movers"        

. local txt5 "Inter-state movers" 

. local txt6 "Foreign movers"

. 
. ** Label variables, in loop 
. foreach n of numlist 1(1)6 {
  2.         
.         label var n1_out_`n' "Returns, out-migration
> , `txt`n''"
  3.         label var n2_out_`n' "Exemptions, out-mig
> ration, `txt`n''"
  4.         label var agi_out_`n' "AGI, out-migration
> , `txt`n''"
  5. 
. } // END NUMLIST LOOP 

. 
. ** Merge data 
. merge 1:1 year state_fips county_fips using `gross_i
> n', keep(match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            21,980  
    -----------------------------------------

. 
. ** Text for correct matching (non-movers should matc
> h perfectly)
. summ n*_*_1 agi_*_1

    Variable |        Obs        Mean    Std. dev.    
>    Min        Max
-------------+----------------------------------------
> -----------------
    n1_out_1 |     21,979    37461.71    123155.4     
>      0    3944880
    n2_out_1 |     21,979    78000.79    252081.2     
>      0    7841705
     n1_in_1 |     21,979    37461.71    123155.4     
>      0    3944880
     n2_in_1 |     21,979    78000.79    252081.2     
>      0    7841705
   agi_out_1 |     21,979     3214755    1.23e+07     
>  -8051   4.30e+08
-------------+----------------------------------------
> -----------------
    agi_in_1 |     21,979     3214755    1.23e+07     
>  -8051   4.30e+08

. 
. ** Define net migration variables 
. 
. ** Loop over variable
. foreach a in "n1" "n2" "agi" {
  2. 
.         if "`a'" == "n1" local txt "Returns"
  3.         else if "`a'" == "n2" local txt "Exemptio
> ns"
  4.         else if "`a'" == "agi" local txt "AGI"
  5. 
.         ** Loop over type of movers 
.         forvalues n = 2/6 {
  6.                 
.                 ** Clean up missing values 
.                 replace `a'_in_`n' = 0 if missing(`a
> '_in_`n')
  7.                 replace `a'_out_`n' = 0 if missin
> g(`a'_out_`n')
  8. 
.                 ** Generate net 
.                 gen `a'_net_`n' = `a'_in_`n' - `a'_o
> ut_`n'
  9.                 label var `a'_net_`n' "`txt', net
> -migration, `txt`n''"
 10. 
.         } // END MOVER TYPE LOOP 
 11. 
. } // END VARIABLE LOOP 
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)

. 
. ** Generate fips variable
. *make_fips state_fips county_fips, gen(fips)
. 
. ** Save file 
. save "${data}working/irs_county_gross", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_gross.dta saved

. clear

. 
. //--------------------------------------------------
> ---
. // STEP 4: Import and Clean IRS County-Level Aggr. D
> ata 
. //--------------------------------------------------
> ---
. 
. ** Loop over years 
. forvalues y = 15(1)22 {
  2.         
.         
.         ** Import data (out)
.         import delimited "${data}irs/`y'incyallagi.c
> sv", clear 
  3. 
.         ** Describe data 
.         des 
  4.         
.         ** Generate year 
.         gen year = 2000 + `y' 
  5.         
.         ** Define AGI groups 
.         label var agi_stub "AGI Brackets"
  6.         label values agi_stub lb_agi 
  7.         
.         ** Define set of variables to keep 
.         keep state* county* agi_stub year n1 mars1 m
> ars2 mars4 n2 elderly       ///
>                 a00100 n02650 a02650 n00200 a00200 
  8.                 
.         ** Rename variables 
.         rename a00100 agi 
  9.         rename n02650 n_total_inc
 10.         rename a02650 a_total_inc
 11.         rename n00200 n_wage
 12.         rename a00200 a_wage 
 13.         rename statefips state_fips
 14.         rename state state_abb 
 15.         rename countyfips county_fips 
 16.         rename countyname county_name 
 17.         
.         ** Rescale 
.         replace agi = 1000 * agi 
 18.         replace a_total_inc = 1000 * a_total_inc
 19.         replace a_wage = 1000 * a_wage 
 20.         
.         ** Label 
.         label var n1 "Number of returns"
 21.         label var mars1 "Number of single returns
> "
 22.         label var mars1 "Number of MFJ returns"
 23.         label var mars1 "Number of HoH returns"
 24.         label var n2 "Number of individuals"
 25.         label var elderly "Number of returns with
>  one individual over 60"
 26.         label var agi "Adjusted Gross Income (AGI
> )"
 27.         label var n_total_inc "Number of returns 
> with total income"
 28.         label var a_total_inc "Total income amoun
> t"
 29.         label var n_wage "Number of returns with 
> wage income"
 30.         label var a_wage "Wage income amount"
 31.         
.         ** Sort 
.         sort year state_fips county_fips agi_stub 
 32.         
.         ** Order 
.         order year state* county* agi_stub 
 33.         
.         ** Save 
.         save "${data}working/irs_county_all_`y'", re
> place 
 34.         
.         clear 
 35.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-8859-1)
(132 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           132                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
prep            long    %12.0g                PREP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %8.0g                 TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
ral             long    %8.0g                 RAL
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %8.0g                 N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %8.0g                 N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n03230          long    %8.0g                 N03230
a03230          long    %8.0g                 A03230
n03240          int     %8.0g                 N03240
a03240          long    %12.0g                A03240
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %8.0g                 N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07220          long    %12.0g                N07220
a07220          long    %12.0g                A07220
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %8.0g                 N09750
a09750          long    %8.0g                 A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %8.0g                 N85530
a85530          long    %12.0g                A85530
n85300          long    %8.0g                 N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,283 real changes made)
variable a_total_inc was long now double
(25,283 real changes made)
variable a_wage was long now double
(24,576 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_15.dta saved
(encoding automatically selected: ISO-8859-1)
(148 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           148                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
prep            long    %12.0g                PREP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %12.0g                TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
ral             long    %12.0g                RAL
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n03230          long    %8.0g                 N03230
a03230          long    %12.0g                A03230
n03240          int     %8.0g                 N03240
a03240          long    %12.0g                A03240
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %12.0g                N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %12.0g                N18450
a18450          long    %12.0g                A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %12.0g                A18800
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %12.0g                N19550
a19550          long    %12.0g                A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20800          long    %12.0g                N20800
a20800          long    %12.0g                A20800
n21020          long    %8.0g                 N21020
a21020          long    %12.0g                A21020
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %12.0g                N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %12.0g                N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07220          long    %12.0g                N07220
a07220          long    %12.0g                A07220
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %12.0g                N09750
a09750          long    %12.0g                A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,267 real changes made)
variable a_total_inc was long now double
(25,267 real changes made)
variable a_wage was long now double
(24,662 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_16.dta saved
(encoding automatically selected: ISO-8859-1)
(154 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           154                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %12.0g                CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %12.0g                TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n03230          long    %8.0g                 N03230
a03230          long    %8.0g                 A03230
n03240          long    %8.0g                 N03240
a03240          long    %12.0g                A03240
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %12.0g                N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %12.0g                N18450
a18450          long    %12.0g                A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %12.0g                A18800
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %8.0g                 N19550
a19550          long    %8.0g                 A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20800          long    %12.0g                N20800
a20800          long    %12.0g                A20800
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %12.0g                N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %12.0g                N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07220          long    %12.0g                N07220
a07220          long    %12.0g                A07220
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %12.0g                N09750
a09750          long    %12.0g                A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %12.0g                N12000
a12000          long    %12.0g                A12000
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,280 real changes made)
variable a_total_inc was long now double
(25,280 real changes made)
variable a_wage was long now double
(24,634 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_17.dta saved
(encoding automatically selected: ISO-8859-1)
(154 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           154                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %8.0g                 CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %8.0g                 TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01750          long    %12.0g                N01750
a01750          long    %12.0g                A01750
schf            long    %8.0g                 SCHF
n02300          long    %8.0g                 N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %8.0g                 N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %8.0g                 N09750
a09750          long    %8.0g                 A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %8.0g                 N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %8.0g                 N12000
a12000          long    %12.0g                A12000
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,325 real changes made)
variable a_total_inc was long now double
(25,325 real changes made)
variable a_wage was long now double
(24,672 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_18.dta saved
(encoding automatically selected: ISO-8859-1)
(153 vars, 25,544 obs)

Contains data
 Observations:        25,544                  
    Variables:           153                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str24   %24s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %12.0g                CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          float   %9.0g                 A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          int     %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %12.0g                N07180
a07180          long    %12.0g                A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %12.0g                N12000
a12000          long    %12.0g                A12000
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,363 real changes made)
(25,363 real changes made)
variable a_wage was long now double
(24,724 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_19.dta saved
(encoding automatically selected: ISO-8859-1)
(166 vars, 25,545 obs)

Contains data
 Observations:        25,545                  
    Variables:           166                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %8.0g                 CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
vrtcrind        long    %8.0g                 VRTCRIND
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          float   %9.0g                 A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %8.0g                 N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            float   %9.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %8.0g                 N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %8.0g                 N03210
a03210          long    %8.0g                 A03210
n02910          long    %12.0g                N02910
a02910          long    %12.0g                A02910
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          int     %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %8.0g                 N19550
a19550          long    %8.0g                 A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          int     %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %8.0g                 N85770
a85770          long    %12.0g                A85770
n85775          long    %8.0g                 N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %8.0g                 N10960
a10960          long    %8.0g                 A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n11450          long    %8.0g                 N11450
a11450          long    %8.0g                 A11450
n10970          long    %12.0g                N10970
a10970          long    %12.0g                A10970
n10971          long    %12.0g                N10971
a10971          long    %12.0g                A10971
n10973          long    %12.0g                N10973
a10973          long    %12.0g                A10973
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %8.0g                 N12000
a12000          long    %12.0g                A12000
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,410 real changes made)
(25,410 real changes made)
variable a_wage was long now double
(24,896 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_20.dta saved
(encoding automatically selected: ISO-8859-1)
(168 vars, 25,552 obs)

Contains data
 Observations:        25,552                  
    Variables:           168                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %12.0g                CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
vrtcrind        long    %12.0g                VRTCRIND
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          float   %9.0g                 A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            float   %9.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n02910          long    %12.0g                N02910
a02910          long    %12.0g                A02910
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %8.0g                 N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          int     %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %8.0g                 N19550
a19550          long    %8.0g                 A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %8.0g                 N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          int     %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n11450          long    %8.0g                 N11450
a11450          long    %12.0g                A11450
n11520          long    %12.0g                N11520
a11520          long    %12.0g                A11520
n11530          long    %8.0g                 N11530
a11530          long    %12.0g                A11530
n10970          long    %12.0g                N10970
a10970          long    %12.0g                A10970
n10971          long    %12.0g                N10971
a10971          long    %12.0g                A10971
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %12.0g                N12000
a12000          long    %12.0g                A12000
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,456 real changes made)
(25,456 real changes made)
variable a_wage was long now double
(24,659 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_21.dta saved
(encoding automatically selected: ISO-8859-1)
(166 vars, 25,552 obs)

Contains data
 Observations:        25,552                  
    Variables:           166                  
------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable
>  label
------------------------------------------------------
statefips       byte    %8.0g                 STATEFIP
                                  > S
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFI
                                  > PS
countyname      str20   %20s                  COUNTYNA
                                  > ME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %8.0g                 CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
vrtcrind        long    %8.0g                 VRTCRIND
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VI
                                  > TA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00400          long    %8.0g                 N00400
a00400          long    %12.0g                A00400
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %8.0g                 N00700
a00700          long    %8.0g                 A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %8.0g                 N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n25870          long    %8.0g                 N25870
a25870          long    %12.0g                A25870
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %8.0g                 N03210
a03210          long    %8.0g                 A03210
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          int     %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          int     %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59661          long    %12.0g                N59661
a59661          long    %8.0g                 A59661
n59662          long    %12.0g                N59662
a59662          long    %12.0g                A59662
n59663          long    %12.0g                N59663
a59663          long    %12.0g                A59663
n59664          long    %8.0g                 N59664
a59664          long    %12.0g                A59664
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %8.0g                 N10960
a10960          long    %8.0g                 A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %8.0g                 N12000
a12000          long    %12.0g                A12000
------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,400 real changes made)
variable a_total_inc was long now double
(25,400 real changes made)
variable a_wage was long now double
(24,693 real changes made)
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all_22.dta saved

. 
. ** Append data 
. 
. ** Loop over years 
. forvalues y = 15(1)22 {
  2. 
.         ** Append 
.         append using "${data}working/irs_county_all_
> `y'"
  3.                 
.         } // END YEAR LOOP 
(variable county_name was str20, now str24 to
       accommodate using data's values)

.         
. ** Save file 
. save "${data}working/irs_county_all", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all.dta saved

.         
. ** Generate fips variable
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save file 
. save "${data}working/irs_county_all", replace 
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/data/working/irs_county_all.dta saved

. 
. ** Close log
. log close log_01
      name:  log_01
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/01_log_data_clean_multnomah_20
> 25-12-16.log
  log type:  text
 closed on:  17 Dec 2025, 17:59:09
------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000022
> .tmp"

. use ${data}working/irs_county_flow.dta, clear 

. 
. ** Merge with ACS county data 
. merge 1:1 year fips_o fips_d using ${data}working/ac
> s_county_flow
(variable state_fips_o was byte, now int to
       accommodate using data's values)
(variable state_fips_d was byte, now int to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                       453,076
        from master                   303,846  (_merge
> ==1)
        from using                    149,230  (_merge
> ==2)

    Matched                            58,832  (_merge
> ==3)
    -----------------------------------------

. 
. 
end of do-file

. drop fips

. tab state_fips_d if _merge == 2

 State FIPS |
code (dest. |
     state) |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |      2,373        1.59        1.59
          2 |        660        0.44        2.03
          4 |      2,925        1.96        3.99
          5 |      1,566        1.05        5.04
          6 |      9,810        6.57       11.62
          8 |      2,842        1.90       13.52
          9 |      1,852        1.24       14.76
         10 |        600        0.40       15.16
         11 |        538        0.36       15.52
         12 |     13,396        8.98       24.50
         13 |      6,150        4.12       28.62
         15 |        908        0.61       29.23
         16 |      1,106        0.74       29.97
         17 |      4,329        2.90       32.87
         18 |      3,795        2.54       35.42
         19 |      1,487        1.00       36.41
         20 |      1,519        1.02       37.43
         21 |      2,149        1.44       38.87
         22 |      2,178        1.46       40.33
         23 |        951        0.64       40.97
         24 |      3,349        2.24       43.21
         25 |      2,750        1.84       45.05
         26 |      4,045        2.71       47.76
         27 |      2,066        1.38       49.15
         28 |      1,322        0.89       50.03
         29 |      2,723        1.82       51.86
         30 |        793        0.53       52.39
         31 |      1,041        0.70       53.09
         32 |      1,377        0.92       54.01
         33 |        738        0.49       54.51
         34 |      3,552        2.38       56.89
         35 |      1,362        0.91       57.80
         36 |      5,991        4.01       61.81
         37 |      6,718        4.50       66.31
         38 |        537        0.36       66.67
         39 |      5,280        3.54       70.21
         40 |      1,735        1.16       71.38
         41 |      2,748        1.84       73.22
         42 |      5,249        3.52       76.73
         44 |        768        0.51       77.25
         45 |      3,184        2.13       79.38
         46 |        496        0.33       79.71
         47 |      4,129        2.77       82.48
         48 |     11,237        7.53       90.01
         49 |      1,943        1.30       91.31
         50 |        502        0.34       91.65
         51 |      4,637        3.11       94.76
         53 |      3,852        2.58       97.34
         54 |        769        0.52       97.85
         55 |      2,617        1.75       99.61
         56 |        586        0.39      100.00
------------+-----------------------------------
      Total |    149,230      100.00

. tab state_name_d   _merge

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |     5,169 |     7,861 
              Alaska |       872 |     1,575 
             Arizona |     5,722 |    10,448 
            Arkansas |     3,696 |     5,450 
          California |    15,481 |    33,754 
            Colorado |    10,393 |    13,369 
         Connecticut |     1,707 |     4,389 
            Delaware |       925 |     1,950 
District of Columbia |       828 |     1,842 
             Florida |    26,476 |    47,035 
             Georgia |    14,827 |    22,464 
              Hawaii |     1,424 |     2,757 
               Idaho |     2,944 |     4,075 
            Illinois |     7,008 |    13,473 
             Indiana |     6,796 |    11,500 
                Iowa |     4,050 |     5,644 
              Kansas |     3,228 |     4,917 
            Kentucky |     5,188 |     7,709 
           Louisiana |     4,386 |     6,980 
               Maine |     1,616 |     2,598 
            Maryland |     4,824 |     9,964 
       Massachusetts |     5,311 |     8,485 
            Michigan |     7,682 |    13,206 
           Minnesota |     6,404 |     9,128 
         Mississippi |     3,635 |     5,049 
            Missouri |     6,704 |    10,132 
             Montana |     1,695 |     2,488 
            Nebraska |     2,046 |     3,245 
              Nevada |     3,049 |     5,355 
       New Hampshire |     1,632 |     2,370 
          New Jersey |     4,715 |    10,848 
          New Mexico |     2,301 |     3,787 
            New York |    10,670 |    19,523 
      North Carolina |    13,695 |    22,955 
        North Dakota |     1,048 |     1,602 
                Ohio |     9,034 |    16,063 
            Oklahoma |     4,698 |     6,630 
              Oregon |     5,149 |     9,179 
        Pennsylvania |     9,043 |    16,534 
        Rhode Island |       800 |     1,762 
      South Carolina |     8,064 |    11,563 
        South Dakota |     1,263 |     1,759 
           Tennessee |     8,948 |    14,074 
               Texas |    25,844 |    44,075 
                Utah |     2,764 |     5,411 
             Vermont |       955 |     1,457 
            Virginia |    13,154 |    18,911 
          Washington |     7,575 |    13,349 
       West Virginia |     1,729 |     2,498 
           Wisconsin |     5,864 |     9,315 
             Wyoming |       815 |     1,401 
---------------------+-----------+----------
               Total |   303,846 |   511,908 


                     |  Matching
                     |   result
                     | from merge
          State name | Using onl |     Total
---------------------+-----------+----------
             Alabama |     2,373 |     7,861 
              Alaska |       660 |     1,575 
             Arizona |     2,925 |    10,448 
            Arkansas |     1,566 |     5,450 
          California |     9,810 |    33,754 
            Colorado |     2,842 |    13,369 
         Connecticut |     1,852 |     4,389 
            Delaware |       600 |     1,950 
District of Columbia |       538 |     1,842 
             Florida |    13,396 |    47,035 
             Georgia |     6,150 |    22,464 
              Hawaii |       908 |     2,757 
               Idaho |     1,106 |     4,075 
            Illinois |     4,329 |    13,473 
             Indiana |     3,795 |    11,500 
                Iowa |     1,487 |     5,644 
              Kansas |     1,519 |     4,917 
            Kentucky |     2,149 |     7,709 
           Louisiana |     2,178 |     6,980 
               Maine |       951 |     2,598 
            Maryland |     3,349 |     9,964 
       Massachusetts |     2,750 |     8,485 
            Michigan |     4,045 |    13,206 
           Minnesota |     2,066 |     9,128 
         Mississippi |     1,322 |     5,049 
            Missouri |     2,723 |    10,132 
             Montana |       793 |     2,488 
            Nebraska |     1,041 |     3,245 
              Nevada |     1,377 |     5,355 
       New Hampshire |       738 |     2,370 
          New Jersey |     3,552 |    10,848 
          New Mexico |     1,362 |     3,787 
            New York |     5,991 |    19,523 
      North Carolina |     6,718 |    22,955 
        North Dakota |       537 |     1,602 
                Ohio |     5,280 |    16,063 
            Oklahoma |     1,735 |     6,630 
              Oregon |     2,748 |     9,179 
        Pennsylvania |     5,249 |    16,534 
        Rhode Island |       768 |     1,762 
      South Carolina |     3,184 |    11,563 
        South Dakota |       496 |     1,759 
           Tennessee |     4,129 |    14,074 
               Texas |    11,237 |    44,075 
                Utah |     1,943 |     5,411 
             Vermont |       502 |     1,457 
            Virginia |     4,637 |    18,911 
          Washington |     3,852 |    13,349 
       West Virginia |       769 |     2,498 
           Wisconsin |     2,617 |     9,315 
             Wyoming |       586 |     1,401 
---------------------+-----------+----------
               Total |   149,230 |   511,908 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       319 |     7,861 
              Alaska |        43 |     1,575 
             Arizona |     1,801 |    10,448 
            Arkansas |       188 |     5,450 
          California |     8,463 |    33,754 
            Colorado |       134 |    13,369 
         Connecticut |       830 |     4,389 
            Delaware |       425 |     1,950 
District of Columbia |       476 |     1,842 
             Florida |     7,163 |    47,035 
             Georgia |     1,487 |    22,464 
              Hawaii |       425 |     2,757 
               Idaho |        25 |     4,075 
            Illinois |     2,136 |    13,473 
             Indiana |       909 |    11,500 
                Iowa |       107 |     5,644 
              Kansas |       170 |     4,917 
            Kentucky |       372 |     7,709 
           Louisiana |       416 |     6,980 
               Maine |        31 |     2,598 
            Maryland |     1,791 |     9,964 
       Massachusetts |       424 |     8,485 
            Michigan |     1,479 |    13,206 
           Minnesota |       658 |     9,128 
         Mississippi |        92 |     5,049 
            Missouri |       705 |    10,132 
             Montana |         0 |     2,488 
            Nebraska |       158 |     3,245 
              Nevada |       929 |     5,355 
       New Hampshire |         0 |     2,370 
          New Jersey |     2,581 |    10,848 
          New Mexico |       124 |     3,787 
            New York |     2,862 |    19,523 
      North Carolina |     2,542 |    22,955 
        North Dakota |        17 |     1,602 
                Ohio |     1,749 |    16,063 
            Oklahoma |       197 |     6,630 
              Oregon |     1,282 |     9,179 
        Pennsylvania |     2,242 |    16,534 
        Rhode Island |       194 |     1,762 
      South Carolina |       315 |    11,563 
        South Dakota |         0 |     1,759 
           Tennessee |       997 |    14,074 
               Texas |     6,994 |    44,075 
                Utah |       704 |     5,411 
             Vermont |         0 |     1,457 
            Virginia |     1,120 |    18,911 
          Washington |     1,922 |    13,349 
       West Virginia |         0 |     2,498 
           Wisconsin |       834 |     9,315 
             Wyoming |         0 |     1,401 
---------------------+-----------+----------
               Total |    58,832 |   511,908 

. sum fips if _merge == 1
fips ambiguous abbreviation
r(111);

. sum fips_d  if _merge == 1

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
      fips_d |    303,846    28999.01    16081.94       1001      56045

. sum fips_d  if _merge == 2

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
      fips_d |    149,230    28512.72    15943.56       1000      56021

. sum fips_d  if _merge == 3

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
      fips_d |     58,832    27114.48    16612.38       1003      55139

. sort year fips_o fips_d

. pwd
C:\Users\ji252\Documents\GitHub\multnomah-county-tax

. export excel using "data/test.xlsx", firstrow replace
option firstrow incorrectly specified
r(198);

. export excel using "data/test.xlsx", firstrow(names) replace
invalid argument names in option firstrow(); may be variables or varlabels
r(198);

. export excel using "data/test.xlsx", firstrow(variables) replace
file data/test.xlsx saved

. tab year _merge

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |    38,679     14,718      8,204 |    61,601 
      2016 |    51,034     13,915      9,097 |    74,046 
      2017 |    40,506     14,691      8,547 |    63,744 
      2018 |    39,472     14,655      8,498 |    62,625 
      2019 |    42,808     14,587      8,637 |    66,032 
      2020 |    46,403     11,901      7,312 |    65,616 
      2021 |    44,944     14,530      8,537 |    68,011 
      2022 |         0     25,626          0 |    25,626 
      2023 |         0     24,607          0 |    24,607 
-----------+---------------------------------+----------
     Total |   303,846    149,230     58,832 |   511,908 

. drop if year >= 2022
(50,233 observations deleted)

. export excel using "data/test.xlsx", firstrow(variables) replace
file data/test.xlsx saved

. tab year _merge

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |    38,679     14,718      8,204 |    61,601 
      2016 |    51,034     13,915      9,097 |    74,046 
      2017 |    40,506     14,691      8,547 |    63,744 
      2018 |    39,472     14,655      8,498 |    62,625 
      2019 |    42,808     14,587      8,637 |    66,032 
      2020 |    46,403     11,901      7,312 |    65,616 
      2021 |    44,944     14,530      8,537 |    68,011 
-----------+---------------------------------+----------
     Total |   303,846     98,997     58,832 |   461,675 

. tab year _merge if county_fips_d == 0

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Using onl |     Total
-----------+-----------+----------
      2015 |     5,468 |     5,468 
      2016 |     5,592 |     5,592 
      2017 |     5,528 |     5,528 
      2018 |     5,492 |     5,492 
      2019 |     5,601 |     5,601 
      2020 |     4,809 |     4,809 
      2021 |     5,714 |     5,714 
-----------+-----------+----------
     Total |    38,204 |    38,204 

. tab year _merge if county_fips_d == 0 |county_fips_o == 0

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Using onl |     Total
-----------+-----------+----------
      2015 |     9,502 |     9,502 
      2016 |     9,586 |     9,586 
      2017 |     9,522 |     9,522 
      2018 |     9,489 |     9,489 
      2019 |     9,618 |     9,618 
      2020 |     8,098 |     8,098 
      2021 |     9,514 |     9,514 
-----------+-----------+----------
     Total |    65,329 |    65,329 

. tab year _merge if county_fips_d != 0 & county_fips_o != 0

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |    38,679      5,216      8,204 |    52,099 
      2016 |    51,034      4,329      9,097 |    64,460 
      2017 |    40,506      5,169      8,547 |    54,222 
      2018 |    39,472      5,166      8,498 |    53,136 
      2019 |    42,808      4,969      8,637 |    56,414 
      2020 |    46,403      3,803      7,312 |    57,518 
      2021 |    44,944      5,016      8,537 |    58,497 
-----------+---------------------------------+----------
     Total |   303,846     33,668     58,832 |   396,346 

. tab state_name_o _merge if county_fips_d != 0 & county_fips_o != 0

                     |    Matching result from merge
          State name | Master on  Using onl  Matched ( |     Total
---------------------+---------------------------------+----------
             Alabama |     4,987        491        353 |     5,831 
              Alaska |     1,019        118        125 |     1,262 
             Arizona |     4,832        482      1,382 |     6,696 
            Arkansas |     3,574        299        229 |     4,102 
          California |    19,733      2,566      9,006 |    31,305 
            Colorado |     9,165        124         92 |     9,381 
         Connecticut |     2,493        801      1,059 |     4,353 
            Delaware |       845        213        294 |     1,352 
District of Columbia |       764        108        459 |     1,331 
             Florida |    20,450      2,751      5,256 |    28,457 
             Georgia |    13,779      1,281      1,351 |    16,411 
              Hawaii |     1,541        200        424 |     2,165 
               Idaho |     2,250         30         19 |     2,299 
            Illinois |     8,956      1,448      2,621 |    13,025 
             Indiana |     6,998      1,199      1,055 |     9,252 
                Iowa |     4,285        278        164 |     4,727 
              Kansas |     3,545        212        200 |     3,957 
            Kentucky |     5,301        376        382 |     6,059 
           Louisiana |     4,908        492        474 |     5,874 
               Maine |     1,457        128         34 |     1,619 
            Maryland |     5,645        935      1,921 |     8,501 
       Massachusetts |     6,341        178        392 |     6,911 
            Michigan |     8,148      1,203      1,791 |    11,142 
           Minnesota |     6,402        560        796 |     7,758 
         Mississippi |     3,934        162         88 |     4,184 
            Missouri |     6,792        657        782 |     8,231 
             Montana |     1,458          0          0 |     1,458 
            Nebraska |     2,135        282        204 |     2,621 
              Nevada |     2,765        198        763 |     3,726 
       New Hampshire |     1,664          0          0 |     1,664 
          New Jersey |     7,277      1,269      3,268 |    11,814 
          New Mexico |     2,310        200        102 |     2,612 
            New York |    14,493      1,843      4,299 |    20,635 
      North Carolina |    11,788      1,470      2,014 |    15,272 
        North Dakota |     1,150         71         37 |     1,258 
                Ohio |     9,633      1,543      1,851 |    13,027 
            Oklahoma |     4,632        267        226 |     5,125 
              Oregon |     4,351        553      1,026 |     5,930 
        Pennsylvania |     9,654      1,679      2,632 |    13,965 
        Rhode Island |       942        208        220 |     1,370 
      South Carolina |     6,170        309        160 |     6,639 
        South Dakota |     1,186          0          0 |     1,186 
           Tennessee |     8,099        713        827 |     9,639 
               Texas |    23,343      2,849      6,131 |    32,323 
                Utah |     2,511        455        599 |     3,565 
             Vermont |       931          0          0 |       931 
            Virginia |    13,577        894      1,071 |    15,542 
          Washington |     7,036        756      1,673 |     9,465 
       West Virginia |     1,798          0          0 |     1,798 
           Wisconsin |     5,922        817        980 |     7,719 
             Wyoming |       877          0          0 |       877 
---------------------+---------------------------------+----------
               Total |   303,846     33,668     58,832 |   396,346 

. gen nonmover = fips_d == fips_o

. tab nonmover  _merge

           |    Matching result from merge
  nonmover | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
         0 |   303,846     95,651     58,832 |   458,329 
         1 |         0      3,346          0 |     3,346 
-----------+---------------------------------+----------
     Total |   303,846     98,997     58,832 |   461,675 

. drop if nonmover == 1
(3,346 observations deleted)

. drop if county_fips_d == 0 |county_fips_o == 0
(64,993 observations deleted)

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000023.tmp"

. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_d == 51)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000024
> .tmp"

. 
. use ${data}working/irs_county_flow.dta, clear 

. 
. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000025
> .tmp"

. ** Determine set of common in- and out-migration cou
> nties for Multnomah
. use ${data}working/acs_county_flow.dta, clear 

. 
. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
end of do-file

. tab multnomah_d

multnomah_d |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |    207,259       99.61       99.61
          1 |        803        0.39      100.00
------------+-----------------------------------
      Total |    208,062      100.00

. tab multnomah_o

multnomah_o |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |    207,316       99.64       99.64
          1 |        746        0.36      100.00
------------+-----------------------------------
      Total |    208,062      100.00

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000026
> .tmp"

. /***************************************************
> ****************************
> File Name:              02_descriptives.do
> Creator:                John Iselin
> Date Update:    December 17, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform descriptive analysis
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> ****************************************************
> ***************************/
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_descriptives_${date}", repl
> ace text name(log_02)
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/code/logs/02_log_descriptives_2025-12-16.
    > log not found)
------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_descriptives_2025-12-16
> .log
  log type:  text
 opened on:  17 Dec 2025, 18:36:53

. 
. ** Determine set of common in- and out-migration cou
> nties for Multnomah
. use ${data}working/irs_county_flow.dta, clear 

. 
. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. ** Loop over samples 
. foreach x in "o" "d" {
  2.         
.         ** Preserve 
.         preserve 
  3.         
.         ** Keep Multnomah
.         keep if multnomah_o == 1 
  4.         
.         ** Export data 
.         export excel using "${data}multnomah.xlsx", 
>     ///
>                 sheet(irs_`x', replace ) firstrow(va
> riables) 
  5.                 
.         ** Clear and restore 
.         clear 
  6.         restore
  7.                 
. } // END ORIGIN-DESTINATION LOOP 
(361,546 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved
(361,546 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved

. 
. ** Determine set of common in- and out-migration cou
> nties for Multnomah
. use ${data}working/acs_county_flow.dta, clear 

. 
. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. ** Loop over samples 
. foreach x in "o" "d" {
  2.         
.         ** Preserve 
.         preserve 
  3.         
.         ** Keep Multnomah
.         keep if multnomah_o == 1 
  4.         
.         ** Export data 
.         export excel using "${data}multnomah.xlsx", 
>     ///
>                 sheet(acs_`x', replace ) firstrow(va
> riables) 
  5.                 
.         ** Clear and restore 
.         clear 
  6.         restore
  7.                 
. } // END ORIGIN-DESTINATION LOOP 
(207,316 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved
(207,316 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved

. 
. ** Close log
. clear 

. log close log_02
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_descriptives_2025-12-16
> .log
  log type:  text
 closed on:  17 Dec 2025, 18:36:54
------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000027
> .tmp"

. /***************************************************
> ****************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration 
> analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> ****************************************************
> ***************************/
. 
. ** -------------------------------------------------
> --------------------------
. ** Start log file
. ** -------------------------------------------------
> --------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replac
> e text name(log_02)
------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_individual_2025-12-16.l
> og
  log type:  text
 opened on:  17 Dec 2025, 18:37:00

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) 
> nocons
. ** - Posts:     cell means and CIs for each cat×year
>  coefficient
. ** - Plots:     one connected series per category + 
> optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store tho
> se labels immediately after
. **   levelsof (before moving into the posted coeffic
> ient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opa
> city.
. ** -------------------------------------------------
> --------------------------
. ** -------------------------------------------------
> --------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction an
> d absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficient
> s) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT
>  (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means
> ).
. **   - baseyear(#) => plot within-CAT differences re
> lative to that year.
. ** -------------------------------------------------
> --------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] 
> , ///
>         CAT(varname) YEAR(varname) ABSORB(string) //
> /
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string
> ) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ---------------------------------------------
> --------------------------
.     ** Configuration: project root for relative path
> s
.     ** ---------------------------------------------
> --------------------------
.     local __project_root "C:/Users/ji252/Documents/G
> itHub/multnomah-county-tax/"
  4. 
.     ** ---------------------------------------------
> --------------------------
.     ** Debug flags
.     ** ---------------------------------------------
> --------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------
> ------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' ex
> p=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI:
>  `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE
> : `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------
> ------------------------------"
 24.     }
 25. 
.     ** ---------------------------------------------
> --------------------------
.     ** Requirements
.     ** ---------------------------------------------
> --------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install w
> ith: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ---------------------------------------------
> --------------------------
.     ** Mark sample
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimatio
> n sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(
> `varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " 
> %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available af
> ter applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ---------------------------------------------
> --------------------------
.     ** Weights (default fw=perwt unless caller provi
> ded weights)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights
> ..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-prov
> ided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable 
> `wvar' not found. Either create it or pass weights e
> xplicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default wei
> ghts: `wgt'"
 55.     }
 56. 
.     ** ---------------------------------------------
> --------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/Y
> EAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__c
> at')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CA
> T -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numer
> ic -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`
> __year') force
 71.         capture assert !missing(`__year') if `tou
> se'
 72.         if _rc {
 73.             di as error "Year variable is string 
> and could not be cleanly converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> 
> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already nume
> ric -> `yearv'"
 82.     }
 83. 
.     ** ---------------------------------------------
> --------------------------
.     ** Guard: CAT should not also be absorbed
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb
> ()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' app
> ears in absorb(): `absorb'. Remove it from absorb() 
> for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ---------------------------------------------
> --------------------------
.     ** Levels and labels (save labels NOW, before sw
> itching datasets)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year a
> nd category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yr
> s)
 90.     quietly levelsof `catv'  if `touse', local(ca
> ts)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels f
> ound in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids 
> label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m
> ", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tm
> p'"
108.         }
109.         local __lab : subinstr local __lab `"""' 
> "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** ---------------------------------------------
> --------------------------
.     ** Base year sanity check (only if baseyear != 0
> )
.     ** ---------------------------------------------
> --------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking 
> baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not
>  found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `bas
> eyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** ---------------------------------------------
> --------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..
> ."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'
> ##i.`yearv' if `touse' `wgt', absorb(`absorb') vce(`
> vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if
>  `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** ---------------------------------------------
> --------------------------
.     ** Margins: conditional means by CAT over YEAR (
> save to dataset)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins
>  and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(
> `yrs')) saving(`__margdata', replace) post
134. 
.     ** ---------------------------------------------
> --------------------------
.     ** Plot using the saved margins dataset
.     ** ---------------------------------------------
> --------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins 
> output
.         ** We compute margins using at(): at(cat lev
> els × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) a
> nd _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _
> at1. Ensure margins is called with: margins, at(`cat
> v'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _
> at2. Ensure margins is called with: margins, at(`cat
> v'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _
> margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows
>  of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset 
> is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (withi
> n-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normal
> izing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(c
> ond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have
>  no observations in baseyear(`baseyear'). Cannot nor
> malize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins r
> esults)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used
> : `xyrs'"
190. 
.         ** -----------------------------------------
> --------------------------
.         ** Plot styling: use plotplainblind palette 
> if available (scheme-level)
.         ** -----------------------------------------
> --------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblin
> d scheme not available; using current scheme: `__old
> scheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme:
>  plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -----------------------------------------
> --------------------------
.         ** Build twoway spec + legend mapping (one l
> abel per series)
.         **   - CI and line share the same pstyle; CI
>  uses 50% opacity.
.         ** -----------------------------------------
> --------------------------
.         if `__dbg' di as txt "[Step 9] Building plot
>  command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe k
> ey)
.             local __key "`c'"
213.             local __key : subinstr local __key "-
> " "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`
> c', sort ///
>                         pstyle(`pstyle') lcolor(%50)
> )
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c',
>  sort ///
>                     pstyle(`pstyle') lp(solid) msym(
> O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`
> pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for
>  plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order
> '"
230.             di as txt "  legend labels: `leg_labe
> ls'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -----------------------------------------
> --------------------------
.         ** Titles (safe quoting)
.         ** -----------------------------------------
> --------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "
> xtitle(Year)"
237.         else                    local xtitle_inpu
> t `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input
>  `"ytitle(`"`varlist' (relative to `baseyear')"')"'
240.             else              local ytitle_input 
> `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle
> '"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"t
> itle(`"`title'"')"'
246. 
.                 ** ---------------------------------
> ---------------------------
.                 ** Y-axis: round "nice" ticks (e.g.,
>  0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then r
> ounds to a nice step.
.                 ** ---------------------------------
> ---------------------------
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0),
>  anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming fo
> r ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep')
> )
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__bas
> e'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple 
> of step; min down similarly
.                 local __yhigh = ceil(`__ymax'/`__yst
> ep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`_
> _ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exac
> tly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`_
> _ylow' `__yhigh')) ylabel(`__ylow'(`__ystep')`__yhig
> h')"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///          
>  
>                         legend(order(`leg_order') `l
> eg_labels' rows(`legrows') position(6)) 
270. 
.         ** Restore scheme (if we successfully switch
> ed)
.         capture set scheme `__oldscheme'
271. 
.         ** -----------------------------------------
> --------------------------
.         ** Export figure (PDF) - robust path handlin
> g
.         ** -----------------------------------------
> --------------------------
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpat
> h `"""' "", all
274.             local outpath : subinstr local outpat
> h "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") &
>  substr("`outpath'", 1, 1) != "/" {
276.                 local outpath "`__project_root'`o
> utpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local 
> outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'"
> , 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creat
> ing output directory: `outdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'
> ") {
286.                         di as error "Output direc
> tory does not exist and could not be created: `outdi
> r'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exportin
> g graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outp
> ath'", as(pdf) replace
293.             else                graph export "`ou
> tpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "------------------------------
> ------------------------------"
299.     }
300. 
. end

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Load ACS migration data
. ** -------------------------------------------------
> --------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                               
>     // Error in migration place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // Alaska an
> d Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                                 
>     // Negative Family Income       
(7,238 observations deleted)

. 
. ** -------------------------------------------------
> --------------------------
. ** Multnomah indicators and samples
. ** -------------------------------------------------
> --------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah 
> in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multno
> mah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,253 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,335 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Covariate categories
. ** -------------------------------------------------
> --------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,886,621 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,057,842 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,776 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Kids at home
. recode yngch ///
>     (99      = 0 "0 Children") ///
>     (0/4     = 1 "0-4") ///
>     (5/12    = 2 "5-12") ///
>     (13/17   = 3 "13-17")       ///
>         (18/max   = 4 "18+"), ///
>     gen(cat_yngch)
(20,465,990 differences between yngch and cat_yngch)

. label var cat_yngch "Age of youngest child"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,886,621 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Real income (2023 USD) and income categories
. ** -------------------------------------------------
> --------------------------
. gen tmp1 = cpi99 if year == 2023
(18,374,392 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotin
> c {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,886,621 differences between real_inctot and cat_in
> ctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     15,082        0.07        0.07
             $0 |  1,747,061        8.36        8.44
        $1-$25K |  6,203,845       29.70       38.14
      $25K-$50K |  4,981,113       23.85       61.99
     $50K-$100K |  4,947,578       23.69       85.68
    $100K-$200K |  2,211,136       10.59       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incwage and cat_i
> ncwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,175,889       39.14       39.14
        $1-$25K |  3,428,186       16.41       55.56
      $25K-$50K |  3,290,630       15.75       71.31
     $50K-$100K |  3,729,590       17.86       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incearn and cat_i
> ncearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     13,905        0.07        0.07
             $0 |  7,360,938       35.24       35.31
        $1-$25K |  3,755,724       17.98       53.29
      $25K-$50K |  3,476,928       16.65       69.94
     $50K-$100K |  3,876,560       18.56       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,529 differences between real_ftotinc and cat_f
> totinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |    226,387        1.08        1.08
        $1-$25K |  2,249,309       10.77       11.85
      $25K-$50K |  3,258,513       15.60       27.45
     $50K-$100K |  5,975,505       28.61       56.06
    $100K-$200K |  6,147,777       29.43       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00

. 
. label var cat_inctot  "Total personal income categor
> ies (real 2023 USD)"

. label var cat_incwage "Total wage income categories 
> (real 2023 USD)"

. label var cat_incearn "Total earned income categorie
> s (real 2023 USD)"

. label var cat_ftotinc "Total family income categorie
> s (real 2023 USD)"

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Analysis loops
. ** -------------------------------------------------
> --------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_yngch cat_sex cat_married cat_age
>  cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate
>  (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration ra
> te (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the 
> focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1
> , ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `other
> cats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2
> )") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000028
> .tmp"

. /***************************************************
> ****************************
> File Name:              02_descriptives.do
> Creator:                John Iselin
> Date Update:    December 17, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform descriptive analysis
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> ****************************************************
> ***************************/
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_descriptives_${date}", repl
> ace text name(log_02)
------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_descriptives_2025-12-16
> .log
  log type:  text
 opened on:  17 Dec 2025, 18:51:32

. 
. ** Determine set of common in- and out-migration cou
> nties for Multnomah
. use ${data}working/irs_county_flow.dta, clear 

. 
. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. ** Loop over samples 
. foreach x in "o" "d" {
  2.         
.         ** Preserve 
.         preserve 
  3.         
.         ** Keep Multnomah
.         keep if multnomah_`x' == 1 
  4.         
.         ** Export data 
.         export excel using "${data}multnomah.xlsx", 
>     ///
>                 sheet(irs_`x', replace ) firstrow(va
> riables) 
  5.                 
.         ** Clear and restore 
.         clear 
  6.         restore
  7.                 
. } // END ORIGIN-DESTINATION LOOP 
(361,546 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved
(361,434 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved

. 
. ** Determine set of common in- and out-migration cou
> nties for Multnomah
. use ${data}working/acs_county_flow.dta, clear 

. 
. ** Tag Multnomah
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. ** Loop over samples 
. foreach x in "o" "d" {
  2.         
.         ** Preserve 
.         preserve 
  3.         
.         ** Keep Multnomah
.         keep if multnomah_`x' == 1 
  4.         
.         ** Export data 
.         export excel using "${data}multnomah.xlsx", 
>     ///
>                 sheet(acs_`x', replace ) firstrow(va
> riables) 
  5.                 
.         ** Clear and restore 
.         clear 
  6.         restore
  7.                 
. } // END ORIGIN-DESTINATION LOOP 
(207,316 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved
(207,259 observations deleted)
file C:/Users/ji252/Documents/GitHub/multnomah-county-
> tax/data/multnomah.xlsx saved

. 
. ** Close log
. clear 

. log close log_02
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_descriptives_2025-12-16
> .log
  log type:  text
 closed on:  17 Dec 2025, 18:51:35
------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\Documents\GitHub\multnomah-county
> -tax\code\02_indiv_analysis_clean.do"

. /***************************************************
> ****************************
> File Name:       02_indiv_analysis.do
> Creator:         John Iselin
> Date Update:     November 29, 2025
> 
> Called by:       00_multnomah.do
> 
> Purpose:         Perform individual-level migration 
> analysis.
> 
> Authors:         John Iselin
> 
> For more information, contact john.iselin@yale.edu
> ****************************************************
> ***************************/
. 
. ** -------------------------------------------------
> --------------------------
. ** Start log file
. ** -------------------------------------------------
> --------------------------
. capture log close log_02

. log using "${logs}02_log_individual_${date}", replac
> e text name(log_02)
------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_individual_2025-12-16.l
> og
  log type:  text
 opened on:  17 Dec 2025, 18:51:41

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Program: hdfe_catyear_plot
. **
. ** - Runs:      reghdfe y i.cat#i.year, absorb(...) 
> nocons
. ** - Posts:     cell means and CIs for each cat×year
>  coefficient
. ** - Plots:     one connected series per category + 
> optional CI caps
. ** - Exports:   PDF via graph export
. **
. ** Notes:
. ** - Legend uses category VALUE LABELS. We store tho
> se labels immediately after
. **   levelsof (before moving into the posted coeffic
> ient dataset) to avoid any
. **   issues from dataset swaps.
. ** - CI and line use the same color; CI uses 50% opa
> city.
. ** -------------------------------------------------
> --------------------------
. ** -------------------------------------------------
> --------------------------
. ** Program: hdfe_catyear_plot
. **
. ** Purpose:
. **   1) Run reghdfe with a CAT × YEAR interaction an
> d absorbed fixed effects.
. **   2) Use margins (rather than reghdfe coefficient
> s) to compute conditional means:
. **        margins i.CAT, over(YEAR)
. **   3) Plot margins by YEAR with one series per CAT
>  (CI optional).
. **
. ** Notes:
. **   - baseyear(0) => plot levels (conditional means
> ).
. **   - baseyear(#) => plot within-CAT differences re
> lative to that year.
. ** -------------------------------------------------
> --------------------------
. capture program drop hdfe_catyear_plot

. program define hdfe_catyear_plot
  1.     version 16.0
  2. 
.     syntax varname(numeric) [if] [in] [fw aw pw iw] 
> , ///
>         CAT(varname) YEAR(varname) ABSORB(string) //
> /
>         [ WVAR(varname) WTYPE(string) ///
>           VCE(string) ///
>           TITLE(string) XTITLE(string) YTITLE(string
> ) ///
>           NOCI ///
>           BASEYEAR(integer 0) ///
>           SAVING(string) REPLACE ///
>           DEBUG DEBUGDETAIL ]
  3. 
.     ** ---------------------------------------------
> --------------------------
.     ** Configuration: project root for relative path
> s
.     ** ---------------------------------------------
> --------------------------
.     local __project_root "C:/Users/ji252/Documents/G
> itHub/multnomah-county-tax/"
  4. 
.     ** ---------------------------------------------
> --------------------------
.     ** Debug flags
.     ** ---------------------------------------------
> --------------------------
.     local __dbg 0
  5.     local __dbgdetail 0
  6.     if "`debug'" != "" local __dbg 1
  7.     if "`debugdetail'" != "" {
  8.         local __dbg 1
  9.         local __dbgdetail 1
 10.     }
 11. 
.     if `__dbg' {
 12.         di as txt "------------------------------
> ------------------------------"
 13.         di as txt "hdfe_catyear_plot DEBUG START"
 14.         di as txt "Outcome   : `varlist'"
 15.         di as txt "CAT()     : `cat'"
 16.         di as txt "YEAR()    : `year'"
 17.         di as txt "ABSORB()  : `absorb'"
 18.         di as txt "Weights   : weight=`weight' ex
> p=`exp' wvar=`wvar' wtype=`wtype'"
 19.         di as txt "VCE()     : `vce'"
 20.         di as txt "BASEYEAR(): `baseyear'   NOCI:
>  `noci'"
 21.         di as txt "SAVING()  : `saving'   REPLACE
> : `replace'"
 22.         di as txt "IF/IN     : `if' `in'"
 23.         di as txt "------------------------------
> ------------------------------"
 24.     }
 25. 
.     ** ---------------------------------------------
> --------------------------
.     ** Requirements
.     ** ---------------------------------------------
> --------------------------
.     capture which reghdfe
 26.     if _rc {
 27.         di as error "reghdfe not found. Install w
> ith: ssc install reghdfe, replace"
 28.         exit 198
 29.     }
 30. 
.     ** ---------------------------------------------
> --------------------------
.     ** Mark sample
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 1] Marking estimatio
> n sample..."
 31.     marksample touse, strok
 32.     quietly replace `touse' = `touse' & !missing(
> `varlist', `cat', `year')
 33. 
.     quietly count if `touse'
 34.     if `__dbg' di as txt "  N (after filters): " 
> %12.0gc r(N)
 35.     if r(N) == 0 {
 36.         di as error "No observations available af
> ter applying if/in filters."
 37.         exit 2000
 38.     }
 39. 
.     ** ---------------------------------------------
> --------------------------
.     ** Weights (default fw=perwt unless caller provi
> ded weights)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 2] Resolving weights
> ..."
 40.     local wgt ""
 41.     if "`weight'" != "" {
 42.         local wgt "[`weight'=`exp']"
 43.         if `__dbg' di as txt "  Using caller-prov
> ided weights: `wgt'"
 44.     }
 45.     else {
 46.         if "`wvar'"  == "" local wvar  "perwt"
 47.         if "`wtype'" == "" local wtype "fw"
 48.         capture confirm variable `wvar'
 49.         if _rc {
 50.             di as error "Default weight variable 
> `wvar' not found. Either create it or pass weights e
> xplicitly."
 51.             exit 111
 52.         }
 53.         local wgt "[`wtype'=`wvar']"
 54.         if `__dbg' di as txt "  Using default wei
> ghts: `wgt'"
 55.     }
 56. 
.     ** ---------------------------------------------
> --------------------------
.     ** Ensure CAT/YEAR numeric for factor variables
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 3] Harmonizing CAT/Y
> EAR types..."
 57.     tempvar __cat __year
 58. 
.     local cattype : type `cat'
 59.     if substr("`cattype'", 1, 3) == "str" {
 60.         quietly encode `cat' if `touse', gen(`__c
> at')
 61.         local catv `__cat'
 62.         if `__dbg' di as txt "  Encoded string CA
> T -> `catv'"
 63.     }
 64.     else {
 65.         local catv `cat'
 66.         if `__dbg' di as txt "  CAT already numer
> ic -> `catv'"
 67.     }
 68. 
.     local yeartype : type `year'
 69.     if substr("`yeartype'", 1, 3) == "str" {
 70.         quietly destring `year' if `touse', gen(`
> __year') force
 71.         capture assert !missing(`__year') if `tou
> se'
 72.         if _rc {
 73.             di as error "Year variable is string 
> and could not be cleanly converted to numeric."
 74.             exit 459
 75.         }
 76.         local yearv `__year'
 77.         if `__dbg' di as txt "  Destring YEAR -> 
> `yearv'"
 78.     }
 79.     else {
 80.         local yearv `year'
 81.         if `__dbg' di as txt "  YEAR already nume
> ric -> `yearv'"
 82.     }
 83. 
.     ** ---------------------------------------------
> --------------------------
.     ** Guard: CAT should not also be absorbed
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 4] Validating absorb
> ()..."
 84.     if regexm(" `absorb' ", " `catv' ") {
 85.         di as error "Category variable `catv' app
> ears in absorb(): `absorb'. Remove it from absorb() 
> for this run."
 86.         exit 198
 87.     }
 88. 
.     ** ---------------------------------------------
> --------------------------
.     ** Levels and labels (save labels NOW, before sw
> itching datasets)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 5] Collecting year a
> nd category levels..."
 89.     quietly levelsof `yearv' if `touse', local(yr
> s)
 90.     quietly levelsof `catv'  if `touse', local(ca
> ts)
 91.     local vlab : value label `catv'
 92. 
.     if "`yrs'" == "" | "`cats'" == "" {
 93.         di as error "No year or category levels f
> ound in estimation sample."
 94.         exit 2000
 95.     }
 96. 
.     if `__dbg' {
 97.         di as txt "  Years: `yrs'"
 98.         di as txt "  Cats : `cats'"
 99.         di as txt "  CAT value label: `vlab'"
100.     }
101. 
.     ** Save category label text into locals (avoids 
> label-loss during preserve/use)
.     foreach c of local cats {
102.         local __key "`c'"
103.         local __key : subinstr local __key "-" "m
> ", all
104. 
.         local __lab "`c'"
105.         if "`vlab'" != "" {
106.             local __tmp : label `vlab' `c'
107.             if "`__tmp'" != "" local __lab "`__tm
> p'"
108.         }
109.         local __lab : subinstr local __lab `"""' 
> "", all
110.         local __lab_`__key' "`__lab'"
111.     }   // END CAT LABEL SAVE LOOP
112. 
.     ** ---------------------------------------------
> --------------------------
.     ** Base year sanity check (only if baseyear != 0
> )
.     ** ---------------------------------------------
> --------------------------
.     if `baseyear' != 0 {
113.         if `__dbg' di as txt "[Step 5b] Checking 
> baseyear()..."
114.         local found 0
115.         foreach y of local yrs {
116.             if `y' == `baseyear' local found 1
117.         }
118.         if `found' == 0 {
119.             di as error "baseyear(`baseyear') not
>  found in estimation sample years: `yrs'"
120.             exit 459
121.         }
122.         if `__dbg' di as txt "  baseyear OK: `bas
> eyear'"
123.     }   // END BASEYEAR CHECK
124. 
.     ** ---------------------------------------------
> --------------------------
.     ** Regression (supports margins over CAT × YEAR)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 6] Running reghdfe..
> ."
125.     if "`vce'" == "" local vce "robust"
126.     if `__dbg' {
127.         di as txt "  Command:"
128.         di as txt "    reghdfe `varlist' i.`catv'
> ##i.`yearv' if `touse' `wgt', absorb(`absorb') vce(`
> vce')"
129.     }
130. 
.     quietly reghdfe `varlist' i.`catv'##i.`yearv' if
>  `touse' `wgt', ///
>         absorb(`absorb') vce(`vce')
131. 
.     ** ---------------------------------------------
> --------------------------
.     ** Margins: conditional means by CAT over YEAR (
> save to dataset)
.     ** ---------------------------------------------
> --------------------------
.     if `__dbg' di as txt "[Step 7] Computing margins
>  and saving results..."
132.     tempfile __margdata
133.     quietly margins, at(`catv'=(`cats') `yearv'=(
> `yrs')) saving(`__margdata', replace) post
134. 
.     ** ---------------------------------------------
> --------------------------
.     ** Plot using the saved margins dataset
.     ** ---------------------------------------------
> --------------------------
.     preserve
135. 
.         use `__margdata', clear
136. 
.         ** Identify CAT and YEAR columns in margins 
> output
.         ** We compute margins using at(): at(cat lev
> els × year levels). The saved dataset
.         ** therefore stores the grid in _at1 (cat) a
> nd _at2 (year) in the order supplied.
.         capture confirm variable _at1
137.         if _rc {
138.             di as error "margins output missing _
> at1. Ensure margins is called with: margins, at(`cat
> v'=(`cats') `yearv'=(`yrs')) saving(...)"
139.             exit 459
140.         }
141.         capture confirm variable _at2
142.         if _rc {
143.             di as error "margins output missing _
> at2. Ensure margins is called with: margins, at(`cat
> v'=(`cats') `yearv'=(`yrs')) saving(...)"
144.             exit 459
145.         }
146. 
.         ** Standardize variable names
.         rename _at1 cat_level
147.         rename _at2 year
148. 
.         capture confirm variable _margin
149.         if _rc {
150.             di as error "margins output missing _
> margin. Cannot proceed."
151.             exit 459
152.         }
153.         rename _margin b
154. 
.         capture confirm variable _se_margin
155.         if !_rc rename _se_margin se
156.         else {
157.             capture confirm variable _se
158.             if !_rc rename _se se
159.         }
160. 
.         capture confirm variable _ci_lb
161.         if !_rc rename _ci_lb ll
162.         capture confirm variable _ci_ub
163.         if !_rc rename _ci_ub ul
164. if `__dbgdetail' {
165.             di as txt "[DebugDetail] First 8 rows
>  of margins dataset:"
166.             list in 1/8, abbrev(24)
167.         }
168. 
.         ** Ensure year is numeric and sorted
.         capture confirm numeric variable year
169.         if _rc {
170.             di as error "Year in margins dataset 
> is not numeric; cannot plot on x-axis."
171.             exit 459
172.         }
173. 
.         ** Optional normalization to baseyear (withi
> n-category)
.         if `baseyear' != 0 {
174.             if `__dbg' di as txt "[Step 8] Normal
> izing margins to baseyear(`baseyear')..."
175.             bysort cat_level: egen base_b = max(c
> ond(year==`baseyear', b, .))
176.             quietly count if missing(base_b)
177.             if r(N) > 0 {
178.                 di as error "Some categories have
>  no observations in baseyear(`baseyear'). Cannot nor
> malize."
179.                 exit 459
180.             }
181.             replace b  = b  - base_b
182.             capture confirm variable ll
183.             if !_rc replace ll = ll - base_b
184.             capture confirm variable ul
185.             if !_rc replace ul = ul - base_b
186.             drop base_b
187.         }   // END BASEYEAR NORMALIZATION
188. 
.         ** X axis labels (years present in margins r
> esults)
.         levelsof year, local(xyrs)
189.         if `__dbg' di as txt "  X-axis years used
> : `xyrs'"
190. 
.         ** -----------------------------------------
> --------------------------
.         ** Plot styling: use plotplainblind palette 
> if available (scheme-level)
.         ** -----------------------------------------
> --------------------------
.         local __oldscheme "`c(scheme)'"
191.         capture set scheme plotplainblind
192.         if _rc {
193.             if `__dbg' di as txt "  plotplainblin
> d scheme not available; using current scheme: `__old
> scheme'"
194.         }
195.         else {
196.             if `__dbg' di as txt "  Using scheme:
>  plotplainblind (was `__oldscheme')"
197.         }
198. 
.         ** -----------------------------------------
> --------------------------
.         ** Build twoway spec + legend mapping (one l
> abel per series)
.         **   - CI and line share the same pstyle; CI
>  uses 50% opacity.
.         ** -----------------------------------------
> --------------------------
.         if `__dbg' di as txt "[Step 9] Building plot
>  command..."
199.         local plots ""
200.         local leg_order ""
201.         local leg_labels ""
202.         local pnum 0
203. 
.         local cats_n : word count `cats'
204.         local legrows 1
205.         if `cats_n' > 4 local legrows 2
206. 
.         local i 0
207.         foreach c of local cats {
208.             quietly count if cat_level == `c'
209.             if r(N) == 0 continue
210. 
.             local ++i
211.             local pstyle "p`i'"
212. 
.             ** Retrieve pre-saved label text (safe k
> ey)
.             local __key "`c'"
213.             local __key : subinstr local __key "-
> " "m", all
214.             local serieslab "`__lab_`__key''"
215. 
.             ** CI (excluded from legend)
.             if "`noci'" == "" {
216.                 local ++pnum
217.                 local plots `plots' ///
>                     (rcap ll ul year if cat_level==`
> c', sort ///
>                         pstyle(`pstyle') lcolor(%50)
> )
218.             }
219. 
.             ** Line (in legend)
.             local ++pnum
220.             local plots `plots' ///
>                 (connected b year if cat_level==`c',
>  sort ///
>                     pstyle(`pstyle') lp(solid) msym(
> O) )
221. 
.             local leg_order  `leg_order' `pnum'
222.             local leg_labels `leg_labels' label(`
> pnum' `serieslab')
223.         }   // END CATEGORY PLOT LOOP
224. 
.         if `"`plots'"' == `""' {
225.             di as error "No series were built for
>  plotting (plotspec empty)."
226.             exit 2000
227.         }
228. 
.         if `__dbgdetail' {
229.             di as txt "  legend order: `leg_order
> '"
230.             di as txt "  legend labels: `leg_labe
> ls'"
231.             di as txt "  legend rows: `legrows'"
232.         }
233. 
.         ** -----------------------------------------
> --------------------------
.         ** Titles (safe quoting)
.         ** -----------------------------------------
> --------------------------
.         local xtitle_input ""
234.         local ytitle_input ""
235.         local title_input  ""
236. 
.         if `"`xtitle'"' == `""' local xtitle_input "
> xtitle(Year)"
237.         else                    local xtitle_inpu
> t `"xtitle(`"`xtitle'"')"'
238. 
.         if `"`ytitle'"' == `""' {
239.             if `baseyear' != 0 local ytitle_input
>  `"ytitle(`"`varlist' (relative to `baseyear')"')"'
240.             else              local ytitle_input 
> `"ytitle(`"`varlist' (adjusted mean)"')"'
241.         }
242.         else {
243.             local ytitle_input `"ytitle(`"`ytitle
> '"')"'
244.         }
245. 
.         if `"`title'"' != `""' local title_input `"t
> itle(`"`title'"')"'
246. 
.                 ** ---------------------------------
> ---------------------------
.                 ** Y-axis: round "nice" ticks (e.g.,
>  0,2,4,6,8,10)
.                 ** Uses CI bounds to set max, then r
> ounds to a nice step.
.                 ** ---------------------------------
> ---------------------------
. 
.                 quietly summarize ll, meanonly
247.                 local __ymin = r(min)
248. 
.                 quietly summarize ul, meanonly
249.                 local __ymax = r(max)
250. 
.                 ** Always include 0 on axis
.                 if `__ymin' > 0 local __ymin = 0
251.                 if `__ymax' < 0 local __ymax = 0
252. 
.                 ** If plotting levels (baseyear==0),
>  anchor at 0
.                 if `baseyear' == 0 local __ymin = 0
253. 
.                 ** Add a little headroom (5%)
.                 local __ymax = `__ymax' * 1.05
254. 
.                 ** Decide on a "nice" step aiming fo
> r ~5 intervals
.                 local __span = `__ymax' - `__ymin'
255.                 if `__span' <= 0 local __span = 1
256. 
.                 local __rawstep = `__span'/5
257. 
.                 ** Snap step to {1,2,5} * 10^k
.                 local __k = floor(log10(`__rawstep')
> )
258.                 local __base = 10^`__k'
259.                 local __mant = `__rawstep'/`__bas
> e'
260. 
.                 local __m = 1
261.                 if `__mant' > 1  local __m = 2
262.                 if `__mant' > 2  local __m = 5
263.                 if `__mant' > 5  local __m = 10
264. 
.                 local __ystep = `__m' * `__base'
265. 
.                 ** Round max up to nearest multiple 
> of step; min down similarly
.                 local __yhigh = ceil(`__ymax'/`__yst
> ep') * `__ystep'
266.                 local __ylow  = floor(`__ymin'/`_
> _ystep') * `__ystep'
267. 
.                 ** For levels, ensure bottom is exac
> tly 0
.                 if `baseyear' == 0 local __ylow = 0
268. 
.                 local __yaxis_opts `"yscale(range(`_
> _ylow' `__yhigh')) ylabel(`__ylow'(`__ystep')`__yhig
> h')"'
269. 
.         twoway `plots', ///
>             `xtitle_input' ///
>             `ytitle_input' ///
>             `title_input' ///
>             xlabel(`xyrs', angle(45)) ///
>                         `__yaxis_opts' ///          
>  
>                         legend(order(`leg_order') `l
> eg_labels' rows(`legrows') position(6)) 
270. 
.         ** Restore scheme (if we successfully switch
> ed)
.         capture set scheme `__oldscheme'
271. 
.         ** -----------------------------------------
> --------------------------
.         ** Export figure (PDF) - robust path handlin
> g
.         ** -----------------------------------------
> --------------------------
.         if "`saving'" != "" {
272. 
.             local outpath `"`saving'"'
273.             local outpath : subinstr local outpat
> h `"""' "", all
274.             local outpath : subinstr local outpat
> h "\" "/" , all
275. 
.             ** Prepend project root if relative
.             if !regexm("`outpath'", "^[A-Za-z]:/") &
>  substr("`outpath'", 1, 1) != "/" {
276.                 local outpath "`__project_root'`o
> utpath'"
277.             }
278. 
.             ** Ensure .pdf extension
.             if !regexm("`outpath'", "\.pdf$") local 
> outpath "`outpath'.pdf"
279. 
.             ** Ensure output directory exists
.             local p = strrpos("`outpath'", "/")
280.             if `p' > 0 {
281.                 local outdir = substr("`outpath'"
> , 1, `p' - 1)
282.                 if !direxists("`outdir'") {
283.                     if `__dbg' di as txt "  Creat
> ing output directory: `outdir'"
284.                     capture mkdir "`outdir'"
285.                     if _rc & !direxists("`outdir'
> ") {
286.                         di as error "Output direc
> tory does not exist and could not be created: `outdi
> r'"
287.                         exit 601
288.                     }
289.                 }
290.             }
291. 
.             if `__dbg' di as txt "[Step 10] Exportin
> g graph to: `outpath'"
292. 
.             if "`replace'" != "" graph export "`outp
> ath'", as(pdf) replace
293.             else                graph export "`ou
> tpath'", as(pdf)
294. 
.         }   // END PDF EXPORT
295. 
.     restore    // END PRESERVE BLOCK
296. 
.     if `__dbg' {
297.         di as txt "hdfe_catyear_plot DEBUG END"
298.         di as txt "------------------------------
> ------------------------------"
299.     }
300. 
. end

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Load ACS migration data
. ** -------------------------------------------------
> --------------------------
. use "${data}working/acs_migration_file", replace

. 
. ** Sample restrictions
. drop if qmigplc1 == 4                               
>     // Error in migration place 
(388,364 observations deleted)

. drop if inlist(state_fips_o, 2, 15)     // Alaska an
> d Hawaii
(136,571 observations deleted)

. drop if ftotinc < 0                                 
>     // Negative Family Income       
(7,238 observations deleted)

. 
. ** -------------------------------------------------
> --------------------------
. ** Multnomah indicators and samples
. ** -------------------------------------------------
> --------------------------
. gen multnomah_o = (state_fips_o == 41 & county_fips_
> o == 51)

. gen multnomah_d = (state_fips_d == 41 & county_fips_
> d == 51)

. 
. gen sample_1 = (multnomah_o == 1)      // Multnomah 
> in origin-year

. gen sample_2 = (multnomah_o != 1)      // Not Multno
> mah in origin-year

. label var sample_1 "Out-migration Sample"

. label var sample_2 "In-migration Sample"

. 
. gen out_1 = (same_county == 0)

. replace out_1 = out_1 * 100
(674,253 real changes made)

. label var out_1 "Moved out of Multnomah"

. 
. gen out_2 = (multnomah_d == 1)

. replace out_2 = out_2 * 100 
(51,335 real changes made)

. label var out_2 "Moved to Multnomah"

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Covariate categories
. ** -------------------------------------------------
> --------------------------
. 
. ** Age
. recode age ///
>     (18/24   = 1 "18-24") ///
>     (25/44   = 2 "25-44") ///
>     (45/64   = 3 "45-64") ///
>     (65/max  = 4 "65+"), ///
>     gen(cat_age)
(20,886,621 differences between age and cat_age)

. label var cat_age "Age categories"

. 
. ** Sex
. gen cat_sex = (sex == 2)

. label var cat_sex "Female indicator"

. label define lb_cat_sex 0 "Male" 1 "Female", replace

. label values cat_sex lb_cat_sex

. 
. ** Marital status
. recode marst ///
>     (1       = 1 "Married") ///
>     (2/3     = 2 "Separated") ///
>     (4/5     = 3 "Divorced / Widowed") ///
>     (6       = 4 "Single"), ///
>     gen(cat_married)
(9,057,842 differences between marst and cat_married)

. label var cat_married "Marriage categories"

. 
. ** Kids at home
. recode nchild ///
>     (0       = 0 "0 Children") ///
>     (1       = 1 "1 Child") ///
>     (2       = 2 "2 Children") ///
>     (3/max   = 3 "3+ Children"), ///
>     gen(cat_child)
(412,776 differences between nchild and cat_child)

. label var cat_child "Number of Children"

. 
. ** Kids at home
. recode yngch ///
>     (99      = 0 "0 Children") ///
>     (0/4     = 1 "0-4") ///
>     (5/12    = 2 "5-12") ///
>     (13/17   = 3 "13-17")       ///
>         (18/max   = 4 "18+"), ///
>     gen(cat_yngch)
(20,465,990 differences between yngch and cat_yngch)

. label var cat_yngch "Age of youngest child"

. 
. ** Education
. recode educd ///
>     (min/61  = 1 "Less than HS") ///
>     (62/71   = 2 "HS Diploma") ///
>     (80/100  = 3 "Some College") ///
>     (101/max = 4 "College Degree"), ///
>     gen(cat_educ)
(20,886,621 differences between educd and cat_educ)

. label var cat_educ "Education categories"

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Real income (2023 USD) and income categories
. ** -------------------------------------------------
> --------------------------
. gen tmp1 = cpi99 if year == 2023
(18,374,392 missing values generated)

. egen tmp2 = mean(tmp1)

. gen cpi = cpi99 / tmp2

. drop tmp1 tmp2

. 
. foreach var of varlist inctot incwage incearn ftotin
> c {
  2. 
.     gen real_`var' = round(`var' * cpi)
  3. 
.     recode real_`var' ///
>         (min/-1        = 1 "Negative income") ///
>         (0             = 2 "$0") ///
>         (1/24999       = 3 "$1-$25K") ///
>         (25000/49999   = 4 "$25K-$50K") ///
>         (50000/99999   = 5 "$50K-$100K") ///
>         (100000/199999 = 6 "$100K-$200K") ///
>         (200000/max    = 7 "$200K+"), ///
>         gen(cat_`var')
  4. 
.     tab cat_`var', missing
  5. 
. } // END INCOME LOOP
(20,886,621 differences between real_inctot and cat_in
> ctot)

      RECODE of |
    real_inctot |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     15,082        0.07        0.07
             $0 |  1,747,061        8.36        8.44
        $1-$25K |  6,203,845       29.70       38.14
      $25K-$50K |  4,981,113       23.85       61.99
     $50K-$100K |  4,947,578       23.69       85.68
    $100K-$200K |  2,211,136       10.59       96.26
         $200K+ |    780,806        3.74      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incwage and cat_i
> ncwage)

      RECODE of |
   real_incwage |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |  8,175,889       39.14       39.14
        $1-$25K |  3,428,186       16.41       55.56
      $25K-$50K |  3,290,630       15.75       71.31
     $50K-$100K |  3,729,590       17.86       89.17
    $100K-$200K |  1,743,819        8.35       97.52
         $200K+ |    518,507        2.48      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,621 differences between real_incearn and cat_i
> ncearn)

      RECODE of |
   real_incearn |      Freq.     Percent        Cum.
----------------+-----------------------------------
Negative income |     13,905        0.07        0.07
             $0 |  7,360,938       35.24       35.31
        $1-$25K |  3,755,724       17.98       53.29
      $25K-$50K |  3,476,928       16.65       69.94
     $50K-$100K |  3,876,560       18.56       88.50
    $100K-$200K |  1,823,201        8.73       97.23
         $200K+ |    579,365        2.77      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00
(20,886,529 differences between real_ftotinc and cat_f
> totinc)

      RECODE of |
   real_ftotinc |      Freq.     Percent        Cum.
----------------+-----------------------------------
             $0 |    226,387        1.08        1.08
        $1-$25K |  2,249,309       10.77       11.85
      $25K-$50K |  3,258,513       15.60       27.45
     $50K-$100K |  5,975,505       28.61       56.06
    $100K-$200K |  6,147,777       29.43       85.50
         $200K+ |  3,029,130       14.50      100.00
----------------+-----------------------------------
          Total | 20,886,621      100.00

. 
. label var cat_inctot  "Total personal income categor
> ies (real 2023 USD)"

. label var cat_incwage "Total wage income categories 
> (real 2023 USD)"

. label var cat_incearn "Total earned income categorie
> s (real 2023 USD)"

. label var cat_ftotinc "Total family income categorie
> s (real 2023 USD)"

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Analysis loops
. ** -------------------------------------------------
> --------------------------
. 
. ** Categorical variables to iterate over
. local catvars "cat_yngch cat_sex cat_married cat_age
>  cat_child cat_educ cat_ftotinc"

. 
. forvalues i = 1/2 {
  2. 
.     if `i' == 1 local ytitle_txt "Out-migration rate
>  (%)"
  3.     if `i' == 2 local ytitle_txt "In-migration ra
> te (%)"
  4. 
.     foreach cat of local catvars {
  5. 
.         ** Absorb all other categories (but not the 
> focal one)
.         local othercats : list catvars - cat
  6. 
.         ** Run regression and plot
.         hdfe_catyear_plot out_`i' if sample_`i' == 1
> , ///
>             cat(`cat') ///
>             year(year) ///
>             absorb(state_fips_o county_fips_o `other
> cats') ///
>             wvar(perwt) wtype(fw) ///
>                         xtitle("ACS Survey Year (t=2
> )") ///
>             ytitle("`ytitle_txt'") ///
>             saving("${results}fig_`cat'_`i'") ///
>             replace
  7.                         
.     } // END CAT LOOP
  8. 
. } // END SAMPLE LOOP
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_yngch_1.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_sex_1.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_married_1.pdf saved as
    PDF format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_age_1.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_child_1.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_educ_1.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_ftotinc_1.pdf saved as
    PDF format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_yngch_2.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_sex_2.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_married_2.pdf saved as
    PDF format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_age_2.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_child_2.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_educ_2.pdf saved as PDF
    format
(Created by command margins; also see char list)
2015 2016 2017 2018 2019 2020 2021 2022 2023
file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/results/fig_cat_ftotinc_2.pdf saved as
    PDF format

. 
. 
. ** -------------------------------------------------
> --------------------------
. ** Close log
. ** -------------------------------------------------
> --------------------------
. clear

. log close log_02
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_individual_2025-12-16.l
> og
  log type:  text
 closed on:  18 Dec 2025, 03:41:33
------------------------------------------------------

. 
end of do-file

. clear

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000029
> .tmp"

. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wi
> de.dta,     ///
>         gen(covid_merge) keep(master match )
no variables defined
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002a
> .tmp"

. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_20
> 20",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_m
> erge==1)
        from using                          0  (demo_m
> erge==2)

    Matched                            21,974  (demo_m
> erge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         6 |       202 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         0 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |         0 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |         6 |    21,980 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       202 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        30 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       931 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_econom
> ics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate
       using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_m
> erge==1)
        from using                          0  (econ_m
> erge==2)

    Matched                            21,608  (econ_m
> erge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         0 |       196 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         9 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |       357 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |       366 |    21,974 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       196 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        21 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       574 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wi
> de.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_
> merge==1)
        from using                          0  (covid_
> merge==2)

    Matched                            21,545  (covid_
> merge==3)
    -----------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002b
> .tmp"

. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     Total
----------------------+-----------+----------
              Alabama |         0 |       469 
               Alaska |        28 |       196 
              Arizona |         0 |       105 
             Arkansas |         0 |       525 
           California |         0 |       406 
             Colorado |         0 |       448 
          Connecticut |         0 |        48 
             Delaware |         0 |        21 
 District of Columbia |         0 |         7 
              Florida |         0 |       469 
              Georgia |         0 |     1,113 
               Hawaii |         0 |        21 
                Idaho |         0 |       308 
             Illinois |         0 |       714 
              Indiana |         0 |       644 
                 Iowa |         0 |       693 
               Kansas |         0 |       735 
             Kentucky |         0 |       840 
            Louisiana |         0 |       448 
                Maine |         0 |       112 
             Maryland |         0 |       168 
        Massachusetts |         0 |        98 
             Michigan |         0 |       581 
            Minnesota |         0 |       609 
          Mississippi |         0 |       574 
             Missouri |         0 |       805 
              Montana |         0 |       392 
             Nebraska |         0 |       651 
               Nevada |         0 |       119 
        New Hampshire |         0 |        70 
           New Jersey |         0 |       147 
           New Mexico |         0 |       231 
             New York |        35 |       434 
       North Carolina |         0 |       700 
         North Dakota |         0 |       371 
                 Ohio |         0 |       616 
             Oklahoma |         0 |       539 
               Oregon |         0 |       252 
         Pennsylvania |         0 |       469 
         Rhode Island |         0 |        35 
       South Carolina |         0 |       322 
         South Dakota |         0 |       462 
            Tennessee |         0 |       665 
                Texas |         0 |     1,778 
                 Utah |         0 |       203 
              Vermont |         0 |        98 
             Virginia |         0 |       574 
           Washington |         0 |       273 
        West Virginia |         0 |       385 
            Wisconsin |         0 |       504 
              Wyoming |         0 |       161 
----------------------+-----------+----------
                Total |        63 |    21,608 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     Total
----------------------+-----------+----------
              Alabama |       469 |       469 
               Alaska |       168 |       196 
              Arizona |       105 |       105 
             Arkansas |       525 |       525 
           California |       406 |       406 
             Colorado |       448 |       448 
          Connecticut |        48 |        48 
             Delaware |        21 |        21 
 District of Columbia |         7 |         7 
              Florida |       469 |       469 
              Georgia |     1,113 |     1,113 
               Hawaii |        21 |        21 
                Idaho |       308 |       308 
             Illinois |       714 |       714 
              Indiana |       644 |       644 
                 Iowa |       693 |       693 
               Kansas |       735 |       735 
             Kentucky |       840 |       840 
            Louisiana |       448 |       448 
                Maine |       112 |       112 
             Maryland |       168 |       168 
        Massachusetts |        98 |        98 
             Michigan |       581 |       581 
            Minnesota |       609 |       609 
          Mississippi |       574 |       574 
             Missouri |       805 |       805 
              Montana |       392 |       392 
             Nebraska |       651 |       651 
               Nevada |       119 |       119 
        New Hampshire |        70 |        70 
           New Jersey |       147 |       147 
           New Mexico |       231 |       231 
             New York |       399 |       434 
       North Carolina |       700 |       700 
         North Dakota |       371 |       371 
                 Ohio |       616 |       616 
             Oklahoma |       539 |       539 
               Oregon |       252 |       252 
         Pennsylvania |       469 |       469 
         Rhode Island |        35 |        35 
       South Carolina |       322 |       322 
         South Dakota |       462 |       462 
            Tennessee |       665 |       665 
                Texas |     1,778 |     1,778 
                 Utah |       203 |       203 
              Vermont |        98 |        98 
             Virginia |       574 |       574 
           Washington |       273 |       273 
        West Virginia |       385 |       385 
            Wisconsin |       504 |       504 
              Wyoming |       161 |       161 
----------------------+-----------+----------
                Total |    21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
end of do-file

. tab fips if covid_merge == 1

       fips |      Freq.     Percent        Cum.
------------+-----------------------------------
       2060 |          7       11.11       11.11
       2105 |          7       11.11       22.22
       2164 |          7       11.11       33.33
       2282 |          7       11.11       44.44
      36005 |          7       11.11       55.56
      36047 |          7       11.11       66.67
      36061 |          7       11.11       77.78
      36081 |          7       11.11       88.89
      36085 |          7       11.11      100.00
------------+-----------------------------------
      Total |         63      100.00

. tab fips if covid_merge == 2
no observations

. sort covid_merge

. help kmeans

. help kmeans

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002c
> .tmp"

. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text
>  name(log_02)
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county
    > -tax/code/logs/02_log_sdid_2025-12-16.log not
    found)
------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah
> -county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 12:49:23

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_20
> 20",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_m
> erge==1)
        from using                          0  (demo_m
> erge==2)

    Matched                            21,974  (demo_m
> erge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         6 |       202 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         0 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |         0 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |         6 |    21,980 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       202 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        30 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       931 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_econom
> ics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate
       using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_m
> erge==1)
        from using                          0  (econ_m
> erge==2)

    Matched                            21,608  (econ_m
> erge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         0 |       196 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         9 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |       357 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |       366 |    21,974 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       196 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        21 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       574 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wi
> de.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_
> merge==1)
        from using                          0  (covid_
> merge==2)

    Matched                            21,545  (covid_
> merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     Total
----------------------+-----------+----------
              Alabama |         0 |       469 
               Alaska |        28 |       196 
              Arizona |         0 |       105 
             Arkansas |         0 |       525 
           California |         0 |       406 
             Colorado |         0 |       448 
          Connecticut |         0 |        48 
             Delaware |         0 |        21 
 District of Columbia |         0 |         7 
              Florida |         0 |       469 
              Georgia |         0 |     1,113 
               Hawaii |         0 |        21 
                Idaho |         0 |       308 
             Illinois |         0 |       714 
              Indiana |         0 |       644 
                 Iowa |         0 |       693 
               Kansas |         0 |       735 
             Kentucky |         0 |       840 
            Louisiana |         0 |       448 
                Maine |         0 |       112 
             Maryland |         0 |       168 
        Massachusetts |         0 |        98 
             Michigan |         0 |       581 
            Minnesota |         0 |       609 
          Mississippi |         0 |       574 
             Missouri |         0 |       805 
              Montana |         0 |       392 
             Nebraska |         0 |       651 
               Nevada |         0 |       119 
        New Hampshire |         0 |        70 
           New Jersey |         0 |       147 
           New Mexico |         0 |       231 
             New York |        35 |       434 
       North Carolina |         0 |       700 
         North Dakota |         0 |       371 
                 Ohio |         0 |       616 
             Oklahoma |         0 |       539 
               Oregon |         0 |       252 
         Pennsylvania |         0 |       469 
         Rhode Island |         0 |        35 
       South Carolina |         0 |       322 
         South Dakota |         0 |       462 
            Tennessee |         0 |       665 
                Texas |         0 |     1,778 
                 Utah |         0 |       203 
              Vermont |         0 |        98 
             Virginia |         0 |       574 
           Washington |         0 |       273 
        West Virginia |         0 |       385 
            Wisconsin |         0 |       504 
              Wyoming |         0 |       161 
----------------------+-----------+----------
                Total |        63 |    21,608 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     Total
----------------------+-----------+----------
              Alabama |       469 |       469 
               Alaska |       168 |       196 
              Arizona |       105 |       105 
             Arkansas |       525 |       525 
           California |       406 |       406 
             Colorado |       448 |       448 
          Connecticut |        48 |        48 
             Delaware |        21 |        21 
 District of Columbia |         7 |         7 
              Florida |       469 |       469 
              Georgia |     1,113 |     1,113 
               Hawaii |        21 |        21 
                Idaho |       308 |       308 
             Illinois |       714 |       714 
              Indiana |       644 |       644 
                 Iowa |       693 |       693 
               Kansas |       735 |       735 
             Kentucky |       840 |       840 
            Louisiana |       448 |       448 
                Maine |       112 |       112 
             Maryland |       168 |       168 
        Massachusetts |        98 |        98 
             Michigan |       581 |       581 
            Minnesota |       609 |       609 
          Mississippi |       574 |       574 
             Missouri |       805 |       805 
              Montana |       392 |       392 
             Nebraska |       651 |       651 
               Nevada |       119 |       119 
        New Hampshire |        70 |        70 
           New Jersey |       147 |       147 
           New Mexico |       231 |       231 
             New York |       399 |       434 
       North Carolina |       700 |       700 
         North Dakota |       371 |       371 
                 Ohio |       616 |       616 
             Oklahoma |       539 |       539 
               Oregon |       252 |       252 
         Pennsylvania |       469 |       469 
         Rhode Island |        35 |        35 
       South Carolina |       322 |       322 
         South Dakota |       462 |       462 
            Tennessee |       665 |       665 
                Texas |     1,778 |     1,778 
                 Utah |       203 |       203 
              Vermont |        98 |        98 
             Virginia |       574 |       574 
           Washington |       273 |       273 
        West Virginia |       385 |       385 
            Wisconsin |       504 |       504 
              Wyoming |       161 |       161 
----------------------+-----------+----------
                Total |    21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County,
>  Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah
>  County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base population
> s
. tab year county_name if missing(n1_in_1 ) | n1_in_1 
> == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      | State name
          County name | Connect.. |     Total
----------------------+-----------+----------
     Fairfield County |         6 |         6 
      Hartford County |         6 |         6 
    Litchfield County |         6 |         6 
        Loving County |         0 |         6 
     Middlesex County |         6 |         6 
     New Haven County |         6 |         6 
    New London County |         6 |         6 
       Tolland County |         6 |         6 
       Windham County |         6 |         6 
----------------------+-----------+----------
                Total |        48 |        54 


                      | State name
          County name |     Texas |     Total
----------------------+-----------+----------
     Fairfield County |         0 |         6 
      Hartford County |         0 |         6 
    Litchfield County |         0 |         6 
        Loving County |         6 |         6 
     Middlesex County |         0 |         6 
     New Haven County |         0 |         6 
    New London County |         0 |         6 
       Tolland County |         0 |         6 
       Windham County |         0 |         6 
----------------------+-----------+----------
                Total |         6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA
> , HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
------------------------------------------------------
> -------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs             
>   3,079
25%            0              0       Sum of wgt.     
>   3,079

50%     .3256337                      Mean           .
> 3521437
                        Largest       Std. dev.       
> .332065
75%     .6326353              1
90%      .847923              1       Variance       .
> 1102672
95%     .9372299              1       Skewness       .
> 3661052
99%     .9972304              1       Kurtosis       1
> .763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff
> ' & year == 2020

                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         0 |     Total
----------------------+-----------+----------
               Alaska |         1 |         1 
              Arizona |         1 |         1 
           California |        15 |        15 
             Colorado |         4 |         4 
             Delaware |         1 |         1 
 District of Columbia |         1 |         1 
              Florida |        13 |        13 
              Georgia |         8 |         8 
               Hawaii |         1 |         1 
                Idaho |         1 |         1 
             Illinois |         5 |         5 
              Indiana |         3 |         3 
                 Iowa |         1 |         1 
               Kansas |         2 |         2 
             Kentucky |         2 |         2 
            Louisiana |         3 |         3 
             Maryland |         3 |         3 
        Massachusetts |         5 |         5 
             Michigan |         3 |         3 
            Minnesota |         3 |         3 
             Missouri |         4 |         4 
             Nebraska |         2 |         2 
               Nevada |         3 |         3 
           New Jersey |        10 |        10 
           New Mexico |         2 |         2 
             New York |         9 |         9 
       North Carolina |         4 |         4 
                 Ohio |         6 |         6 
             Oklahoma |         1 |         1 
               Oregon |         1 |         2 
         Pennsylvania |         4 |         4 
         Rhode Island |         2 |         2 
            Tennessee |         2 |         2 
                Texas |        11 |        11 
                 Utah |         4 |         4 
             Virginia |        10 |        10 
           Washington |         1 |         1 
            Wisconsin |         1 |         1 
----------------------+-----------+----------
                Total |       153 |       154 


                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         1 |     Total
----------------------+-----------+----------
               Alaska |         0 |         1 
              Arizona |         0 |         1 
           California |         0 |        15 
             Colorado |         0 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         0 |        13 
              Georgia |         0 |         8 
               Hawaii |         0 |         1 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         0 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         0 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         9 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         1 |         2 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         0 |        11 
                 Utah |         0 |         4 
             Virginia |         0 |        10 
           Washington |         0 |         1 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |         1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // Al
> l counties 

. label var sample_urban95 "Urban counties (top 5%) (e
> xcluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff
> ' & year == 2020

                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         0 |     Total
----------------------+-----------+----------
           California |         6 |         6 
             Colorado |         2 |         2 
 District of Columbia |         1 |         1 
              Florida |         4 |         4 
              Georgia |         5 |         5 
             Illinois |         2 |         2 
              Indiana |         1 |         1 
            Louisiana |         1 |         1 
             Maryland |         1 |         1 
        Massachusetts |         1 |         1 
             Michigan |         1 |         1 
            Minnesota |         1 |         1 
             Missouri |         1 |         1 
               Nevada |         1 |         1 
           New Jersey |         6 |         6 
             New York |         7 |         7 
       North Carolina |         1 |         1 
                 Ohio |         1 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         2 |         2 
         Rhode Island |         1 |         1 
                Texas |         3 |         3 
                 Utah |         2 |         2 
             Virginia |         8 |         8 
            Wisconsin |         1 |         1 
----------------------+-----------+----------
                Total |        60 |        61 


                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         1 |     Total
----------------------+-----------+----------
           California |         0 |         6 
             Colorado |         0 |         2 
 District of Columbia |         0 |         1 
              Florida |         0 |         4 
              Georgia |         0 |         5 
             Illinois |         0 |         2 
              Indiana |         0 |         1 
            Louisiana |         0 |         1 
             Maryland |         0 |         1 
        Massachusetts |         0 |         1 
             Michigan |         0 |         1 
            Minnesota |         0 |         1 
             Missouri |         0 |         1 
               Nevada |         0 |         1 
           New Jersey |         0 |         6 
             New York |         0 |         7 
       North Carolina |         0 |         1 
                 Ohio |         0 |         1 
               Oregon |         1 |         1 
         Pennsylvania |         0 |         2 
         Rhode Island |         0 |         1 
                Texas |         0 |         3 
                 Utah |         0 |         2 
             Virginia |         0 |         8 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |         1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // Al
> l counties 

. label var sample_urban98 "Urban counties (top 1%) (e
> xcluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_m
> erge == 3 , k(10) gen(kmean)
command kmeans is unrecognized
r(199);

end of do-file

r(199);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002d
> .tmp"

. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_m
> erge == 3 , k(10) gen(kmean)
cluster name: _clus_1

. 
end of do-file

. tab multnomah kmean if year == 2020

 Indicator |
       for |
 Multnomah |
   County, |      Cluster ID
    Oregon |         1          2 |     Total
-----------+----------------------+----------
         0 |        10         12 |       129 
         1 |         0          0 |         1 
-----------+----------------------+----------
     Total |        10         12 |       130 


 Indicator |
       for |
 Multnomah |
   County, |      Cluster ID
    Oregon |         3          4 |     Total
-----------+----------------------+----------
         0 |        14         22 |       129 
         1 |         0          0 |         1 
-----------+----------------------+----------
     Total |        14         22 |       130 


 Indicator |
       for |
 Multnomah |
   County, |      Cluster ID
    Oregon |         5          6 |     Total
-----------+----------------------+----------
         0 |        16          8 |       129 
         1 |         0          0 |         1 
-----------+----------------------+----------
     Total |        16          8 |       130 


 Indicator |
       for |
 Multnomah |
   County, |      Cluster ID
    Oregon |         7          8 |     Total
-----------+----------------------+----------
         0 |         3         15 |       129 
         1 |         1          0 |         1 
-----------+----------------------+----------
     Total |         4         15 |       130 


 Indicator |
       for |
 Multnomah |
   County, |      Cluster ID
    Oregon |         9         10 |     Total
-----------+----------------------+----------
         0 |        22          7 |       129 
         1 |         0          0 |         1 
-----------+----------------------+----------
     Total |        22          7 |       130 

. tab kmean multnomah  if year == 2020

           |     Indicator for
           |   Multnomah County,
           |        Oregon
Cluster ID |         0          1 |     Total
-----------+----------------------+----------
         1 |        10          0 |        10 
         2 |        12          0 |        12 
         3 |        14          0 |        14 
         4 |        22          0 |        22 
         5 |        16          0 |        16 
         6 |         8          0 |         8 
         7 |         3          1 |         4 
         8 |        15          0 |        15 
         9 |        22          0 |        22 
        10 |         7          0 |         7 
-----------+----------------------+----------
     Total |       129          1 |       130 

. tab state_name kmean if year == 2020

                      | Cluster ID
           State name |         1 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         1 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         2 |        13 
              Georgia |         2 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         0 |         3 
            Minnesota |         1 |         3 
             Missouri |         0 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         0 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         1 |         4 
         Rhode Island |         1 |         2 
            Tennessee |         0 |         2 
                Texas |         1 |        11 
                 Utah |         0 |         4 
             Virginia |         1 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |        10 |       130 


                      | Cluster ID
           State name |         2 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         1 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         0 |        13 
              Georgia |         0 |         8 
                Idaho |         0 |         1 
             Illinois |         2 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         1 |         2 
             Kentucky |         0 |         2 
            Louisiana |         1 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         0 |         3 
            Minnesota |         1 |         3 
             Missouri |         1 |         4 
             Nebraska |         0 |         2 
               Nevada |         1 |         3 
           New Jersey |         0 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         4 
       North Carolina |         0 |         4 
                 Ohio |         4 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         0 |        11 
                 Utah |         0 |         4 
             Virginia |         0 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |        12 |       130 


                      | Cluster ID
           State name |         3 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         0 |         4 
             Delaware |         1 |         1 
 District of Columbia |         0 |         1 
              Florida |         5 |        13 
              Georgia |         1 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         1 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         1 |         3 
            Minnesota |         1 |         3 
             Missouri |         0 |         4 
             Nebraska |         0 |         2 
               Nevada |         1 |         3 
           New Jersey |         1 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         4 
       North Carolina |         1 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         0 |        11 
                 Utah |         1 |         4 
             Virginia |         0 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |        14 |       130 


                      | Cluster ID
           State name |         4 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         0 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         2 |        13 
              Georgia |         3 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         2 |         3 
        Massachusetts |         1 |         5 
             Michigan |         2 |         3 
            Minnesota |         0 |         3 
             Missouri |         1 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         1 |        10 
           New Mexico |         1 |         2 
             New York |         0 |         4 
       North Carolina |         3 |         4 
                 Ohio |         2 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         1 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         2 |        11 
                 Utah |         0 |         4 
             Virginia |         1 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |        22 |       130 


                      | Cluster ID
           State name |         5 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         1 |         4 
             Delaware |         0 |         1 
 District of Columbia |         1 |         1 
              Florida |         1 |        13 
              Georgia |         0 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         1 |         3 
        Massachusetts |         1 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         0 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         0 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         2 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         1 |        11 
                 Utah |         0 |         4 
             Virginia |         8 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |        16 |       130 


                      | Cluster ID
           State name |         6 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         0 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         0 |        13 
              Georgia |         1 |         8 
                Idaho |         0 |         1 
             Illinois |         2 |         5 
              Indiana |         2 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         0 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         3 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         0 |        11 
                 Utah |         0 |         4 
             Virginia |         0 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |         8 |       130 


                      | Cluster ID
           State name |         7 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         0 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         0 |        13 
              Georgia |         0 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         0 |         3 
        Massachusetts |         1 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         1 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         0 |        10 
           New Mexico |         1 |         2 
             New York |         0 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         1 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         0 |        11 
                 Utah |         0 |         4 
             Virginia |         0 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |         4 |       130 


                      | Cluster ID
           State name |         8 |     Total
----------------------+-----------+----------
              Arizona |         1 |         1 
             Colorado |         0 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         1 |        13 
              Georgia |         0 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         1 |         2 
             Kentucky |         0 |         2 
            Louisiana |         1 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         0 |         4 
             Nebraska |         1 |         2 
               Nevada |         0 |         3 
           New Jersey |         2 |        10 
           New Mexico |         0 |         2 
             New York |         3 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         0 |         2 
                Texas |         3 |        11 
                 Utah |         1 |         4 
             Virginia |         0 |        10 
            Wisconsin |         1 |         1 
----------------------+-----------+----------
                Total |        15 |       130 


                      | Cluster ID
           State name |         9 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         1 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         1 |        13 
              Georgia |         1 |         8 
                Idaho |         1 |         1 
             Illinois |         1 |         5 
              Indiana |         0 |         3 
                 Iowa |         1 |         1 
               Kansas |         0 |         2 
             Kentucky |         2 |         2 
            Louisiana |         1 |         3 
             Maryland |         0 |         3 
        Massachusetts |         2 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         1 |         4 
             Nebraska |         1 |         2 
               Nevada |         1 |         3 
           New Jersey |         3 |        10 
           New Mexico |         0 |         2 
             New York |         0 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         1 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         0 |         2 
            Tennessee |         1 |         2 
                Texas |         2 |        11 
                 Utah |         1 |         4 
             Virginia |         0 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |        22 |       130 


                      | Cluster ID
           State name |        10 |     Total
----------------------+-----------+----------
              Arizona |         0 |         1 
             Colorado |         0 |         4 
             Delaware |         0 |         1 
 District of Columbia |         0 |         1 
              Florida |         1 |        13 
              Georgia |         0 |         8 
                Idaho |         0 |         1 
             Illinois |         0 |         5 
              Indiana |         0 |         3 
                 Iowa |         0 |         1 
               Kansas |         0 |         2 
             Kentucky |         0 |         2 
            Louisiana |         0 |         3 
             Maryland |         0 |         3 
        Massachusetts |         0 |         5 
             Michigan |         0 |         3 
            Minnesota |         0 |         3 
             Missouri |         0 |         4 
             Nebraska |         0 |         2 
               Nevada |         0 |         3 
           New Jersey |         0 |        10 
           New Mexico |         0 |         2 
             New York |         1 |         4 
       North Carolina |         0 |         4 
                 Ohio |         0 |         6 
             Oklahoma |         0 |         1 
               Oregon |         0 |         1 
         Pennsylvania |         0 |         4 
         Rhode Island |         1 |         2 
            Tennessee |         1 |         2 
                Texas |         2 |        11 
                 Utah |         1 |         4 
             Virginia |         0 |        10 
            Wisconsin |         0 |         1 
----------------------+-----------+----------
                Total |         7 |       130 

. tab state_name kmean if year == 2020

                      |                                                  Cluster ID
           State name |         1          2          3          4          5          6          7          8          9         10 |     Total
----------------------+--------------------------------------------------------------------------------------------------------------+----------
              Arizona |         0          0          0          0          0          0          0          1          0          0 |         1 
             Colorado |         1          1          0          0          1          0          0          0          1          0 |         4 
             Delaware |         0          0          1          0          0          0          0          0          0          0 |         1 
 District of Columbia |         0          0          0          0          1          0          0          0          0          0 |         1 
              Florida |         2          0          5          2          1          0          0          1          1          1 |        13 
              Georgia |         2          0          1          3          0          1          0          0          1          0 |         8 
                Idaho |         0          0          0          0          0          0          0          0          1          0 |         1 
             Illinois |         0          2          0          0          0          2          0          0          1          0 |         5 
              Indiana |         0          0          1          0          0          2          0          0          0          0 |         3 
                 Iowa |         0          0          0          0          0          0          0          0          1          0 |         1 
               Kansas |         0          1          0          0          0          0          0          1          0          0 |         2 
             Kentucky |         0          0          0          0          0          0          0          0          2          0 |         2 
            Louisiana |         0          1          0          0          0          0          0          1          1          0 |         3 
             Maryland |         0          0          0          2          1          0          0          0          0          0 |         3 
        Massachusetts |         0          0          0          1          1          0          1          0          2          0 |         5 
             Michigan |         0          0          1          2          0          0          0          0          0          0 |         3 
            Minnesota |         1          1          1          0          0          0          0          0          0          0 |         3 
             Missouri |         0          1          0          1          0          0          1          0          1          0 |         4 
             Nebraska |         0          0          0          0          0          0          0          1          1          0 |         2 
               Nevada |         0          1          1          0          0          0          0          0          1          0 |         3 
           New Jersey |         0          0          1          1          0          3          0          2          3          0 |        10 
           New Mexico |         0          0          0          1          0          0          1          0          0          0 |         2 
             New York |         0          0          0          0          0          0          0          3          0          1 |         4 
       North Carolina |         0          0          1          3          0          0          0          0          0          0 |         4 
                 Ohio |         0          4          0          2          0          0          0          0          0          0 |         6 
             Oklahoma |         0          0          0          0          0          0          0          0          1          0 |         1 
               Oregon |         0          0          0          0          0          0          1          0          0          0 |         1 
         Pennsylvania |         1          0          0          1          2          0          0          0          0          0 |         4 
         Rhode Island |         1          0          0          0          0          0          0          0          0          1 |         2 
            Tennessee |         0          0          0          0          0          0          0          0          1          1 |         2 
                Texas |         1          0          0          2          1          0          0          3          2          2 |        11 
                 Utah |         0          0          1          0          0          0          0          1          1          1 |         4 
             Virginia |         1          0          0          1          8          0          0          0          0          0 |        10 
            Wisconsin |         0          0          0          0          0          0          0          1          0          0 |         1 
----------------------+--------------------------------------------------------------------------------------------------------------+----------
                Total |        10         12         14         22         16          8          4         15         22          7 |       130 

. drop kmean

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002e.tmp"

. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_2

. 
end of do-file

. tab state_name kmean if year == 2020

                      |                       Cluster ID
           State name |         1          2          3          4          5 |     Total
----------------------+-------------------------------------------------------+----------
              Arizona |         0          0          1          0          0 |         1 
             Colorado |         1          2          0          0          1 |         4 
             Delaware |         0          1          0          0          0 |         1 
 District of Columbia |         1          0          0          0          0 |         1 
              Florida |         0          6          1          1          5 |        13 
              Georgia |         0          2          1          0          5 |         8 
                Idaho |         0          1          0          0          0 |         1 
             Illinois |         0          3          0          0          2 |         5 
              Indiana |         0          3          0          0          0 |         3 
                 Iowa |         0          0          1          0          0 |         1 
               Kansas |         0          0          1          0          1 |         2 
             Kentucky |         0          2          0          0          0 |         2 
            Louisiana |         0          1          1          0          1 |         3 
             Maryland |         1          0          0          0          2 |         3 
        Massachusetts |         2          2          0          0          1 |         5 
             Michigan |         0          1          0          0          2 |         3 
            Minnesota |         0          1          0          0          2 |         3 
             Missouri |         1          2          0          0          1 |         4 
             Nebraska |         0          1          1          0          0 |         2 
               Nevada |         0          2          0          0          1 |         3 
           New Jersey |         0          7          2          0          1 |        10 
           New Mexico |         1          0          0          0          1 |         2 
             New York |         0          0          3          1          0 |         4 
       North Carolina |         0          1          0          0          3 |         4 
                 Ohio |         0          0          0          0          6 |         6 
             Oklahoma |         0          1          0          0          0 |         1 
               Oregon |         1          0          0          0          0 |         1 
         Pennsylvania |         2          0          0          0          2 |         4 
         Rhode Island |         0          0          0          1          1 |         2 
            Tennessee |         0          1          0          1          0 |         2 
                Texas |         1          2          3          2          3 |        11 
                 Utah |         0          2          1          1          0 |         4 
             Virginia |         8          0          0          0          2 |        10 
            Wisconsin |         0          0          1          0          0 |         1 
----------------------+-------------------------------------------------------+----------
                Total |        19         44         17          7         43 |       130 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002f.tmp"

.  
. ** Import data 
. import delimited using "${data}covid/covid_nyt.csv", varnames(1) clear case(lower) 
(encoding automatically selected: ISO-8859-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832                  
    Variables:             6                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
date            str10   %10s                  
county          str35   %35s                  
state           str24   %24s                  
fips            long    %12.0g                
cases           long    %12.0g                
deaths          long    %8.0g                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to 13may2022, but with gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_name, force 

Duplicates in terms of fips state_name county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000003.tmp saved as .dta format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_names', keep(master match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,646,784  
    -----------------------------------------

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state county cases deaths 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/population_2020", keep(match) nogen  
(variable county_name was str35, now str46 to accommodate using data's values)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,643,408  
    -----------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned.dta saved

. 
. ** Generate Clustering Variables 
. 
. ** Keep one observation per month 
. keep year month fips state_name county_name cases_cum deaths_cum population

. collapse (sum) cases deaths population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Generate per capita figures
. replace cases = 1000 * cases / population
(82,955 real changes made)

. replace deaths = 1000 * deaths / population
(74,723 real changes made)

. drop population 

. 
. ** Reshape wide 
. reshape wide cases deaths, i(fips state_name county_name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations           90,828   ->   3,132       
Number of variables                   6   ->   61          
j variable (29 values)             date   ->   (dropped)
xij variables:
                              cases_cum   ->   cases_cum1 cases_cum2 ... cases_cum29
                             deaths_cum   ->   deaths_cum1 deaths_cum2 ... deaths_cum29
-----------------------------------------------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned_wide.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned_wide.dta saved

. clear

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002g.tmp"

. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 12:53:56

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
end of do-file

. use ${data}working/covid_cleaned_wide.dta, clear

. use ${data}working/covid_cleaned.dta, replace 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002h.tmp"

. keep year month fips state_name county_name cases_cum deaths_cum population

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002i.tmp"

.  
. ** Import data 
. import delimited using "${data}covid/covid_nyt.csv", varnames(1) clear case(lower) 
(encoding automatically selected: ISO-8859-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832                  
    Variables:             6                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
date            str10   %10s                  
county          str35   %35s                  
state           str24   %24s                  
fips            long    %12.0g                
cases           long    %12.0g                
deaths          long    %8.0g                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to 13may2022, but with gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_name, force 

Duplicates in terms of fips state_name county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000003.tmp saved as .dta format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_names', keep(master match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,646,784  
    -----------------------------------------

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state county cases deaths 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/population_2020", keep(match) nogen  
(variable county_name was str35, now str46 to accommodate using data's values)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,643,408  
    -----------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned.dta saved

. 
. ** Keep one observation per month 
. keep year month fips state_name county_name cases_cum deaths_cum population

. collapse (sum) cases_cum cases_cum population, by(year month fips state_name county_name) 
error:
       cases_cum = (sum) cases_cum
       cases_cum = (sum) cases_cum
name conflict
r(198);

end of do-file

r(198);

. collapse (sum) cases_cum deaths_cum population, by(year month fips state_name county_name)

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002j.tmp"

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Generate per capita figures
. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. drop population 

. 
. ** Reshape wide 
. reshape wide cases_cum cases_cum, i(fips state_name county_name) j(date)
variable deaths_cum not constant within fips state_name county_name
    Your data are currently long. You are performing a reshape wide. You typed something like

        . reshape wide a b, i(fips state_name county_name) j(date)

    There are variables other than a, b, fips state_name county_name, date in your data. They must be constant within fips state_name county_name because that is the only way they can
    fit into wide data without loss of information.

    The variable or variables listed above are not constant within fips state_name county_name. Perhaps the values are in error. Type reshape error for a list of the problem
    observations.

    Either that, or the values vary because they should vary, in which case you must either add the variables to the list of xij variables to be reshaped, or drop them.
r(9);

end of do-file

r(9);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002k.tmp"

. reshape wide cases_cum deaths_cum, i(fips state_name county_name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations           90,828   ->   3,132       
Number of variables                   6   ->   61          
j variable (29 values)             date   ->   (dropped)
xij variables:
                              cases_cum   ->   cases_cum1 cases_cum2 ... cases_cum29
                             deaths_cum   ->   deaths_cum1 deaths_cum2 ... deaths_cum29
-----------------------------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002l.tmp"

. ** Save file 
. save ${data}working/covid_cleaned_wide.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned_wide.dta saved

. clear

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002m.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

.         
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002n.tmp"

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* 

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)
population not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002o.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

.         
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002p.tmp"

. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. 
. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002q.tmp"

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. 
end of do-file

. xtset kmean time

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum

. xtline deaths_cum

. use ${data}working/covid_cleaned.dta, clear

. graph dot (mean) cases_cum, over(date)

. collapse (mean) cases_cum deaths_cum, by(date)

. twoway line cases_cum deaths_cum date

. twoway line deaths_cum date

. clear

. 
. ** Keep one observation per month 

. 
. keep year month fips state_name county_name cases_cum deaths_cum population
no variables defined
r(111);

. 
. collapse (sum) cases_cum deaths_cum population, by(year month fips state_name county_name) 
no variables defined
(error in option by())
r(111);

. 
. sort year month fips 
no variables defined
r(111);

. 
. egen date = group(year month)
variable year not found
r(111);

. 
. drop year month 
no variables defined
r(111);

. 
. 
. 
. ** Generate per capita figures

. 
. replace cases_cum = 1000 * cases_cum / population
no variables defined
r(111);

. 
. replace cases_cum = 1000 * cases_cum / population
no variables defined
r(111);

. 
. drop population 
no variables defined
r(111);

. use ${data}working/covid_cleaned.dta, clear

. keep year month fips state_name county_name cases_cum deaths_cum population

. collapse (sum) cases_cum deaths_cum population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. drop population 

. collapse (mean) cases_cum deaths_cum, by(date)

. twoway line deaths_cum date

. clear

. use ${data}working/covid_cleaned.dta, clear

. keep year month fips state_name county_name cases_cum deaths_cum population

. collapse (sum) cases_cum deaths_cum population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. collapse (mean) cases_cum deaths_cum (n) ct, by(date)
(n) invalid statistic
r(198);

. help collapse

. collapse (mean) cases_cum deaths_cum (count) ct, by(date)
variable ct not found
r(111);

. collapse (mean) cases_cum deaths_cum (count) population , by(date)

. clear

. use ${data}working/covid_cleaned.dta, clear

. keep year month fips state_name county_name cases_cum deaths_cum population

. collapse (sum) cases_cum deaths_cum population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. xtset fips date

Panel variable: fips (strongly balanced)
 Time variable: date, 1 to 29
         Delta: 1 unit

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002r.tmp"

.  
. ** Import data 
. import delimited using "${data}covid/covid_nyt.csv", varnames(1) clear case(lower) 
(encoding automatically selected: ISO-8859-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832                  
    Variables:             6                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
date            str10   %10s                  
county          str35   %35s                  
state           str24   %24s                  
fips            long    %12.0g                
cases           long    %12.0g                
deaths          long    %8.0g                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to 13may2022, but with gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_name, force 

Duplicates in terms of fips state_name county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000003.tmp saved as .dta format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_names', keep(master match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,646,784  
    -----------------------------------------

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state county cases deaths 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/population_2020", keep(match) nogen  
(variable county_name was str35, now str46 to accommodate using data's values)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,643,408  
    -----------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned.dta saved

. 
. ** Keep one observation per month 
. keep year month fips state_name county_name cases_cum deaths_cum population

. collapse (sum) cases_cum deaths_cum (mean) population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Generate per capita figures
. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. drop population 

. 
. ** Reshape wide 
. reshape wide cases_cum deaths_cum, i(fips state_name county_name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations           90,828   ->   3,132       
Number of variables                   6   ->   61          
j variable (29 values)             date   ->   (dropped)
xij variables:
                              cases_cum   ->   cases_cum1 cases_cum2 ... cases_cum29
                             deaths_cum   ->   deaths_cum1 deaths_cum2 ... deaths_cum29
-----------------------------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002s.tmp"

. 
. ** Save file 
. save ${data}working/covid_cleaned_wide.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned_wide.dta saved

. clear

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002t.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002u.tmp"

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002v.tmp"

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. 
. 
end of do-file

. xtset fips time
variable fips not found
r(111);

. xtset kmean  time

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002w.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

.         
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00002x.tmp"

. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. 
end of do-file

. sort fips

. use ** Save file 
invalid 'Save' 
r(198);

. 
. use ${data}working/covid_cleaned.dta, clear 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000030.tmp"

. ** Import data 
. import delimited using "${data}covid/covid_nyt.csv", varnames(1) clear case(lower) 
(encoding automatically selected: ISO-8859-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832                  
    Variables:             6                  
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
date            str10   %10s                  
county          str35   %35s                  
state           str24   %24s                  
fips            long    %12.0g                
cases           long    %12.0g                
deaths          long    %8.0g                 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to 13may2022, but with gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_name, force 

Duplicates in terms of fips state_name county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000003.tmp saved as .dta format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_names', keep(master match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,646,784  
    -----------------------------------------

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state county cases deaths 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/population_2020", keep(match) nogen  
(variable county_name was str35, now str46 to accommodate using data's values)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,643,408  
    -----------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned.dta saved

. 
. ** Keep one observation per month 
. keep year month fips state_name county_name cases deaths population

. collapse (sum) cases deaths (mean) population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Generate per capita figures
. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. drop population cases deaths

. 
. ** Reshape wide 
. reshape wide cases_cum deaths_cum, i(fips state_name county_name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations           90,828   ->   3,132       
Number of variables                   6   ->   61          
j variable (29 values)             date   ->   (dropped)
xij variables:
                              cases_cum   ->   cases_cum1 cases_cum2 ... cases_cum29
                             deaths_cum   ->   deaths_cum1 deaths_cum2 ... deaths_cum29
-----------------------------------------------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned_wide.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned_wide.dta saved

. clear

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000031.tmp"

. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 13:10:10

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

.         
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum

. 
end of do-file

. tab kmean state_name if  sample_urban95 == 1 & year == 2020 & covid_merge == 3

           |                                  State name
Cluster ID |   Arizona   Colorado   Delaware  Distric..    Florida    Georgia      Idaho |     Total
-----------+-----------------------------------------------------------------------------+----------
         1 |         0          0          0          0          2          0          0 |        13 
         2 |         1          0          0          0          1          0          0 |         4 
         3 |         0          1          0          0          1          4          1 |        37 
         4 |         0          0          0          0          3          0          0 |        27 
         5 |         0          3          1          1          6          4          0 |        49 
-----------+-----------------------------------------------------------------------------+----------
     Total |         1          4          1          1         13          8          1 |       130 


           |                                  State name
Cluster ID |  Illinois    Indiana       Iowa     Kansas   Kentucky  Louisiana   Maryland |     Total
-----------+-----------------------------------------------------------------------------+----------
         1 |         0          0          0          0          0          0          0 |        13 
         2 |         1          0          0          0          0          0          0 |         4 
         3 |         0          1          0          1          1          1          0 |        37 
         4 |         0          1          0          0          0          0          2 |        27 
         5 |         4          1          1          1          1          2          1 |        49 
-----------+-----------------------------------------------------------------------------+----------
     Total |         5          3          1          2          2          3          3 |       130 


           |                                  State name
Cluster ID | Massach..   Michigan  Minnesota   Missouri   Nebraska     Nevada  New Jer.. |     Total
-----------+-----------------------------------------------------------------------------+----------
         1 |         1          1          0          0          0          1          2 |        13 
         2 |         0          0          0          0          0          0          0 |         4 
         3 |         1          0          1          3          1          1          0 |        37 
         4 |         3          2          1          1          0          0          6 |        27 
         5 |         0          0          1          0          1          1          2 |        49 
-----------+-----------------------------------------------------------------------------+----------
     Total |         5          3          3          4          2          3         10 |       130 


           |                                  State name
Cluster ID | New Mex..   New York  North C..       Ohio   Oklahoma     Oregon  Pennsyl.. |     Total
-----------+-----------------------------------------------------------------------------+----------
         1 |         0          2          0          0          0          0          1 |        13 
         2 |         0          0          0          0          0          0          0 |         4 
         3 |         1          0          2          0          0          1          0 |        37 
         4 |         0          1          0          1          0          0          3 |        27 
         5 |         1          1          2          5          1          0          0 |        49 
-----------+-----------------------------------------------------------------------------+----------
     Total |         2          4          4          6          1          1          4 |       130 


           |                            State name
Cluster ID | Rhode I..  Tennessee      Texas       Utah   Virginia  Wisconsin |     Total
-----------+------------------------------------------------------------------+----------
         1 |         0          0          3          0          0          0 |        13 
         2 |         0          0          1          0          0          0 |         4 
         3 |         1          0          1          3         10          0 |        37 
         4 |         1          1          1          0          0          0 |        27 
         5 |         0          1          5          1          0          1 |        49 
-----------+------------------------------------------------------------------+----------
     Total |         2          2         11          4         10          1 |       130 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000032.tmp"

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000033.tmp"

. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000034.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 13:16:03

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Sampe
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables 
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Label var 
. label var n1_rate "Net domestic migration rate, returns (%)"

. label var n2_rate "Net domestic migration rate, exemptions (%)"

. label var agi_rate "Net domestic migration rate, AGI (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2015 to 2021
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,916 |     2,916 
      2016 |     2,916          0 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over samples 
. foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  2.                 
.         ** Clear stored values 
.         eststo clear            
  3.                 
.         ** Loop over outcomes 
.         foreach out of varlist n1_rate n2_rate agi_rate {
  4.                 
.                 ** Store label 
.                 local label : variable label `out'
  5.                         
.                 ** Loop over inclusion of covariates
.                 forvalues c = 0/1 {
  6.                         
.                         if `c' == 0 local covars ""
  7.                         else if `c' == 1 local covars "covariates(`covariates', projected)"
  8.                         dis "`covars'"
  9.                         
.                         ** Run SDID
.                         eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                 if `samp' == 1,                         ///
>                                 vce(placebo)                            ///
>                                 `covar'                                         ///
>                                 reps(`reps')                            ///
>                                 graph graph_export("${results}fig_`out'_`c'_`samp'_", .pdf) 
 10.                                 
.                         ** Estadd counties  
.                         qui summ `out' if year == 2020 & `samp' == 1
 11.                         estadd scalar count = r(N)      
 12.                                 
.                         ** Estadd mean 
.                         qui summ `out' if multnomah == 1 & Treated == 0 
 13.                         estadd scalar mean = r(mean)
 14. 
.                         ** Run event-study 
.                         sdid_event `out' fips year Treated                      ///
>                                 if `samp' == 1,                                         ///
>                                 `covar'                                                         ///
>                                 vce(placebo)                                            ///
>                                 brep(`reps')                                            ///
>                                 placebo(all)
 15.                         
.                         ** Create Figure 
.                         
.                         ** Move results from matrix to data 
.                         matrix list e(H)
 16.                         mat res_att_`ct' = e(H)[1,1..4]
 17.                         mat res = e(H)[2..8,1..5]
 18.                         
.                         ** Move Matrix results to data 
.                         svmat res
 19.                         
.                         ** Generate ID variable
.                         gen id = 2021 - _n + 1 if !missing(res1)
 20.                         label var id "Tax year (origin)"
 21.                         
.                         ** Sort 
.                         sort id
 22.                         
.                         ** Plot
.                         twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                         (scatter res1 id, mc(black)),                           ///         
>     
>                                 legend(off) ytitle("`label'")                                   ///
>                                 yline(0, lc(red) lp(-))                                                 ///
>                                 xline(2019.5, lc(black) lp(solid))                              ///
>                                 ylabel(-10(2.5)10, format(%9.1f))
 23. 
.                         graph export "${results}fig_`out'_`c'_`samp'_eventstudy.jpg",   ///
>                                 as(jpg) name("Graph") quality(100) replace              
 24. 
.                         ** Clean up 
.                         drop res1 res2 res3 res4 res5 id 
 25. 
.                         ** Update Count
.                         local ct = `ct' + 1 
 26.                                                         
.                 } // END COVAR LOOP 
 27.         
.         } // END OUTCOME LOOP 
 28.         
.         
.         ** Table of results 
.         esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                         sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                         sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>         "${results}tab_sdid_irs_`samp'.tex",                    ///
>         starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>         b(%-9.3f) se(%-9.3f) replace                                    ///
>         mgroups("Returns" "Exemptions" "AGI",                   ///
>                 pattern(1 0 1 0 1 0) )                                          ///
>         mtitle( "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates")                   ///
>         stats(count mean,                                                               ///
>                 fmt(%9.0fc %9.3fc)                                                      ///
>                 labels("Number of Counties" "Pre-treatment mean"))
 29.         
.                         
. } // END SAMPLE LOOP 
command eststo is unrecognized
r(199);

end of do-file

r(199);

. ssc install eststo
ssc install: "eststo" not found at SSC, type search eststo
(To find all packages at SSC that start with e, type ssc describe e)
r(601);

. ssc install estout
checking estout consistency and verifying not already installed...
installing into C:\Users\ji252\ado\plus\...
installation complete.

. ssc install esttab
ssc install: "esttab" not found at SSC, type search esttab
(To find all packages at SSC that start with e, type ssc describe e)
r(601);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000035.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 13:16:34

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Sampe
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables 
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Label var 
. label var n1_rate "Net domestic migration rate, returns (%)"

. label var n2_rate "Net domestic migration rate, exemptions (%)"

. label var agi_rate "Net domestic migration rate, AGI (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2015 to 2021
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,916 |     2,916 
      2016 |     2,916          0 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over samples 
. foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  2.                 
.         ** Clear stored values 
.         eststo clear            
  3.                 
.         ** Loop over outcomes 
.         foreach out of varlist n1_rate n2_rate agi_rate {
  4.                 
.                 ** Store label 
.                 local label : variable label `out'
  5.                         
.                 ** Loop over inclusion of covariates
.                 forvalues c = 0/1 {
  6.                         
.                         if `c' == 0 local covars ""
  7.                         else if `c' == 1 local covars "covariates(`covariates', projected)"
  8.                         dis "`covars'"
  9.                         
.                         ** Run SDID
.                         eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                 if `samp' == 1,                         ///
>                                 vce(placebo)                            ///
>                                 `covar'                                         ///
>                                 reps(`reps')                            ///
>                                 graph graph_export("${results}fig_`out'_`c'_`samp'_", .pdf) 
 10.                                 
.                         ** Estadd counties  
.                         qui summ `out' if year == 2020 & `samp' == 1
 11.                         estadd scalar count = r(N)      
 12.                                 
.                         ** Estadd mean 
.                         qui summ `out' if multnomah == 1 & Treated == 0 
 13.                         estadd scalar mean = r(mean)
 14. 
.                         ** Run event-study 
.                         sdid_event `out' fips year Treated                      ///
>                                 if `samp' == 1,                                         ///
>                                 `covar'                                                         ///
>                                 vce(placebo)                                            ///
>                                 brep(`reps')                                            ///
>                                 placebo(all)
 15.                         
.                         ** Create Figure 
.                         
.                         ** Move results from matrix to data 
.                         matrix list e(H)
 16.                         mat res_att_`ct' = e(H)[1,1..4]
 17.                         mat res = e(H)[2..8,1..5]
 18.                         
.                         ** Move Matrix results to data 
.                         svmat res
 19.                         
.                         ** Generate ID variable
.                         gen id = 2021 - _n + 1 if !missing(res1)
 20.                         label var id "Tax year (origin)"
 21.                         
.                         ** Sort 
.                         sort id
 22.                         
.                         ** Plot
.                         twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                         (scatter res1 id, mc(black)),                           ///         
>     
>                                 legend(off) ytitle("`label'")                                   ///
>                                 yline(0, lc(red) lp(-))                                                 ///
>                                 xline(2019.5, lc(black) lp(solid))                              ///
>                                 ylabel(-10(2.5)10, format(%9.1f))
 23. 
.                         graph export "${results}fig_`out'_`c'_`samp'_eventstudy.jpg",   ///
>                                 as(jpg) name("Graph") quality(100) replace              
 24. 
.                         ** Clean up 
.                         drop res1 res2 res3 res4 res5 id 
 25. 
.                         ** Update Count
.                         local ct = `ct' + 1 
 26.                                                         
.                 } // END COVAR LOOP 
 27.         
.         } // END OUTCOME LOOP 
 28.         
.         
.         ** Table of results 
.         esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                         sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                         sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>         "${results}tab_sdid_irs_`samp'.tex",                    ///
>         starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>         b(%-9.3f) se(%-9.3f) replace                                    ///
>         mgroups("Returns" "Exemptions" "AGI",                   ///
>                 pattern(1 0 1 0 1 0) )                                          ///
>         mtitle( "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates")                   ///
>         stats(count mean,                                                               ///
>                 fmt(%9.0fc %9.3fc)                                                      ///
>                 labels("Number of Counties" "Pre-treatment mean"))
 29.         
.                         
. } // END SAMPLE LOOP 

command sdid is unrecognized
r(199);

end of do-file

r(199);

. ssc install sdid
checking sdid consistency and verifying not already installed...
installing into C:\Users\ji252\ado\plus\...
installation complete.

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000036.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 13:16:58

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Sampe
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables 
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Label var 
. label var n1_rate "Net domestic migration rate, returns (%)"

. label var n2_rate "Net domestic migration rate, exemptions (%)"

. label var agi_rate "Net domestic migration rate, AGI (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2015 to 2021
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,916 |     2,916 
      2016 |     2,916          0 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over samples 
. foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  2.                 
.         ** Clear stored values 
.         eststo clear            
  3.                 
.         ** Loop over outcomes 
.         foreach out of varlist n1_rate n2_rate agi_rate {
  4.                 
.                 ** Store label 
.                 local label : variable label `out'
  5.                         
.                 ** Loop over inclusion of covariates
.                 forvalues c = 0/1 {
  6.                         
.                         if `c' == 0 local covars ""
  7.                         else if `c' == 1 local covars "covariates(`covariates', projected)"
  8.                         dis "`covars'"
  9.                         
.                         ** Run SDID
.                         eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                 if `samp' == 1,                         ///
>                                 vce(placebo)                            ///
>                                 `covar'                                         ///
>                                 reps(`reps')                            ///
>                                 graph graph_export("${results}fig_`out'_`c'_`samp'_", .pdf) 
 10.                                 
.                         ** Estadd counties  
.                         qui summ `out' if year == 2020 & `samp' == 1
 11.                         estadd scalar count = r(N)      
 12.                                 
.                         ** Estadd mean 
.                         qui summ `out' if multnomah == 1 & Treated == 0 
 13.                         estadd scalar mean = r(mean)
 14. 
.                         ** Run event-study 
.                         sdid_event `out' fips year Treated                      ///
>                                 if `samp' == 1,                                         ///
>                                 `covar'                                                         ///
>                                 vce(placebo)                                            ///
>                                 brep(`reps')                                            ///
>                                 placebo(all)
 15.                         
.                         ** Create Figure 
.                         
.                         ** Move results from matrix to data 
.                         matrix list e(H)
 16.                         mat res_att_`ct' = e(H)[1,1..4]
 17.                         mat res = e(H)[2..8,1..5]
 18.                         
.                         ** Move Matrix results to data 
.                         svmat res
 19.                         
.                         ** Generate ID variable
.                         gen id = 2021 - _n + 1 if !missing(res1)
 20.                         label var id "Tax year (origin)"
 21.                         
.                         ** Sort 
.                         sort id
 22.                         
.                         ** Plot
.                         twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                         (scatter res1 id, mc(black)),                           ///         
>     
>                                 legend(off) ytitle("`label'")                                   ///
>                                 yline(0, lc(red) lp(-))                                                 ///
>                                 xline(2019.5, lc(black) lp(solid))                              ///
>                                 ylabel(-10(2.5)10, format(%9.1f))
 23. 
.                         graph export "${results}fig_`out'_`c'_`samp'_eventstudy.jpg",   ///
>                                 as(jpg) name("Graph") quality(100) replace              
 24. 
.                         ** Clean up 
.                         drop res1 res2 res3 res4 res5 id 
 25. 
.                         ** Update Count
.                         local ct = `ct' + 1 
 26.                                                         
.                 } // END COVAR LOOP 
 27.         
.         } // END OUTCOME LOOP 
 28.         
.         
.         ** Table of results 
.         esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                         sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                         sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>         "${results}tab_sdid_irs_`samp'.tex",                    ///
>         starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>         b(%-9.3f) se(%-9.3f) replace                                    ///
>         mgroups("Returns" "Exemptions" "AGI",                   ///
>                 pattern(1 0 1 0 1 0) )                                          ///
>         mtitle( "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates")                   ///
>         stats(count mean,                                                               ///
>                 fmt(%9.0fc %9.3fc)                                                      ///
>                 labels("Number of Counties" "Pre-treatment mean"))
 29.         
.                         
. } // END SAMPLE LOOP 

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.42893    1.02065    -1.40    0.162    -3.42935     0.57150
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  .1434552
command sdid_event is unrecognized
r(199);

end of do-file

r(199);

. ssc install sdid_event
checking sdid_event consistency and verifying not already installed...
installing into C:\Users\ji252\ado\plus\...
installation complete.

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000037.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 15:14:45

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Sampe
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables 
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Label var 
. label var n1_rate "Net domestic migration rate, returns (%)"

. label var n2_rate "Net domestic migration rate, exemptions (%)"

. label var agi_rate "Net domestic migration rate, AGI (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2015 to 2021
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,916 |     2,916 
      2016 |     2,916          0 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over samples 
. foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  2.                 
.         ** Clear stored values 
.         eststo clear            
  3.                 
.         ** Loop over outcomes 
.         foreach out of varlist n1_rate n2_rate agi_rate {
  4.                 
.                 ** Store label 
.                 local label : variable label `out'
  5.                         
.                 ** Loop over inclusion of covariates
.                 forvalues c = 0/1 {
  6.                         
.                         if `c' == 0 local covars ""
  7.                         else if `c' == 1 local covars "covariates(`covariates', projected)"
  8.                         dis "`covars'"
  9.                         
.                         ** Run SDID
.                         eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                 if `samp' == 1,                         ///
>                                 vce(placebo)                            ///
>                                 `covar'                                         ///
>                                 reps(`reps')                            ///
>                                 graph graph_export("${results}fig_`out'_`c'_`samp'_", .pdf) 
 10.                                 
.                         ** Estadd counties  
.                         qui summ `out' if year == 2020 & `samp' == 1
 11.                         estadd scalar count = r(N)      
 12.                                 
.                         ** Estadd mean 
.                         qui summ `out' if multnomah == 1 & Treated == 0 
 13.                         estadd scalar mean = r(mean)
 14. 
.                         ** Run event-study 
.                         sdid_event `out' fips year Treated                      ///
>                                 if `samp' == 1,                                         ///
>                                 `covar'                                                         ///
>                                 vce(placebo)                                            ///
>                                 brep(`reps')                                            ///
>                                 placebo(all)
 15.                         
.                         ** Create Figure 
.                         
.                         ** Move results from matrix to data 
.                         matrix list e(H)
 16.                         mat res_att_`ct' = e(H)[1,1..4]
 17.                         mat res = e(H)[2..8,1..5]
 18.                         
.                         ** Move Matrix results to data 
.                         svmat res
 19.                         
.                         ** Generate ID variable
.                         gen id = 2021 - _n + 1 if !missing(res1)
 20.                         label var id "Tax year (origin)"
 21.                         
.                         ** Sort 
.                         sort id
 22.                         
.                         ** Plot
.                         twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                         (scatter res1 id, mc(black)),                           ///         
>     
>                                 legend(off) ytitle("`label'")                                   ///
>                                 yline(0, lc(red) lp(-))                                                 ///
>                                 xline(2019.5, lc(black) lp(solid))                              ///
>                                 ylabel(-10(2.5)10, format(%9.1f))
 23. 
.                         graph export "${results}fig_`out'_`c'_`samp'_eventstudy.jpg",   ///
>                                 as(jpg) name("Graph") quality(100) replace              
 24. 
.                         ** Clean up 
.                         drop res1 res2 res3 res4 res5 id 
 25. 
.                         ** Update Count
.                         local ct = `ct' + 1 
 26.                                                         
.                 } // END COVAR LOOP 
 27.         
.         } // END OUTCOME LOOP 
 28.         
.         
.         ** Table of results 
.         esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                         sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                         sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>         "${results}tab_sdid_irs_`samp'.tex",                    ///
>         starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>         b(%-9.3f) se(%-9.3f) replace                                    ///
>         mgroups("Returns" "Exemptions" "AGI",                   ///
>                 pattern(1 0 1 0 1 0) )                                          ///
>         mtitle( "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates"                    ///
>                         "No Covariates" "Covariates")                   ///
>         stats(count mean,                                                               ///
>                 fmt(%9.0fc %9.3fc)                                                      ///
>                 labels("Number of Counties" "Pre-treatment mean"))
 29.         
.                         
. } // END SAMPLE LOOP 

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.42893    0.83323    -1.71    0.086    -3.06202     0.20417
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  .1434552
checking unique consistency and verifying not already installed...
installing into C:\Users\ji252\ado\plus\...
installation complete.
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.428925   .9547669  -3.300268    .442418          1 
    Effect_1 |  -1.83865   1.298539  -4.383787    .706487          1 
    Effect_2 |   -1.0192   1.138501  -3.250662   1.212262          1 
   Placebo_1 | -.0129703   .0274142  -.0667022   .0407615          1 
   Placebo_2 |  .0139657   .0147576  -.0149593   .0428906          1 
   Placebo_3 |  .0045226   .0509047  -.0952506   .1042958          1 
   Placebo_4 |  -.004614   .0263872  -.0563328   .0471049          1 
   Placebo_5 |  .0181625   .0833411  -.1451861   .1815111          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.4289251   .95476686  -3.3002681   .44241795           1
 Effect_1  -1.8386498   1.2985392  -4.3837866   .70648699           1
 Effect_2  -1.0192004   1.1385011  -3.2506625   1.2122617           1
Placebo_1  -.01297033    .0274142  -.06670217   .04076151           1
Placebo_2   .01396566   .01475761  -.01495925   .04289058           1
Placebo_3    .0045226   .05090472  -.09525065   .10429585           1
Placebo_4  -.00461397   .02638717  -.05633283   .04710488           1
Placebo_5   .01816248   .08334114  -.14518615   .18151111           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_all_eventstudy.jpg not
>  found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_all_eventstudy.jpg writ
> ten in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.42893    0.75862    -1.88    0.060    -2.91580     0.05795
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.428925   .9767074  -3.343272   .4854213          1 
    Effect_1 |  -1.83865   1.076983  -3.949536   .2722364          1 
    Effect_2 |   -1.0192   1.186412  -3.344568   1.306167          1 
   Placebo_1 | -.0129703   .0888568  -.1871296   .1611889          1 
   Placebo_2 |  .0139657   .0847959  -.1522343   .1801656          1 
   Placebo_3 |  .0045226   .0625127  -.1180023   .1270475          1 
   Placebo_4 |  -.004614   .1399127   -.278843    .269615          1 
   Placebo_5 |  .0181625   .2072977  -.3881411    .424466          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.4289251   .97670737  -3.3432715   .48542134           1
 Effect_1  -1.8386498   1.0769828   -3.949536   .27223643           1
 Effect_2  -1.0192004   1.1864122  -3.3445683   1.3061674           1
Placebo_1  -.01297033   .08885676  -.18712958   .16118891           1
Placebo_2   .01396566   .08479588  -.15223427   .18016559           1
Placebo_3    .0045226   .06251271  -.11800231   .12704751           1
Placebo_4  -.00461397   .13991275  -.27884296   .26961501           1
Placebo_5   .01816248   .20729772  -.38814105   .42446602           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_all_eventstudy.jpg not
>  found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_all_eventstudy.jpg writ
> ten in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.35556    0.90418    -1.50    0.134    -3.12772     0.41659
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.355564   1.031869  -3.378027   .6668992          1 
    Effect_1 | -1.744963   .9244442  -3.556874   .0669473          1 
    Effect_2 |  -.966164    1.42629  -3.761693   1.829365          1 
   Placebo_1 | -.0142295   .0525565  -.1172403   .0887812          1 
   Placebo_2 |  .0150267   .4318868  -.8314715   .8615249          1 
   Placebo_3 |  .0054525    .116578  -.2230405   .2339454          1 
   Placebo_4 | -.0089254   .1695874  -.3413167    .323466          1 
   Placebo_5 |  .0149209   .0882144  -.1579794   .1878211          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.3555637   1.0318688  -3.3780265   .66689922           1
 Effect_1  -1.7449634   .92444424  -3.5568741   .06694735           1
 Effect_2  -.96616397   1.4262904  -3.7616932   1.8293653           1
Placebo_1  -.01422954   .05255651   -.1172403   .08878122           1
Placebo_2   .01502674   .43188684  -.83147147   .86152495           1
Placebo_3   .00545246   .11657803  -.22304048   .23394541           1
Placebo_4  -.00892537   .16958742  -.34131672   .32346598           1
Placebo_5   .01492086    .0882144  -.15797937   .18782109           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_all_eventstudy.jpg not
>  found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_all_eventstudy.jpg writ
> ten in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.35556    0.69205    -1.96    0.050    -2.71197     0.00084
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.355564    .912543  -3.144148   .4330207          1 
    Effect_1 | -1.744963   1.254712  -4.204199   .7142726          1 
    Effect_2 |  -.966164   .9788668  -2.884743    .952415          1 
   Placebo_1 | -.0142295   .0367963  -.0863504   .0578913          1 
   Placebo_2 |  .0150267   .0474345  -.0779448   .1079983          1 
   Placebo_3 |  .0054525   .0218911  -.0374542   .0483591          1 
   Placebo_4 | -.0089254    .187238  -.3759119   .3580612          1 
   Placebo_5 |  .0149209   .1048054  -.1904977   .2203394          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.3555637   .91254303   -3.144148   .43302068           1
 Effect_1  -1.7449634   1.2547122  -4.2041993   .71427262           1
 Effect_2  -.96616397   .97886684   -2.884743   .95241503           1
Placebo_1  -.01422954   .03679635  -.08635038    .0578913           1
Placebo_2   .01502674   .04743446   -.0779448   .10799828           1
Placebo_3   .00545246   .02189113  -.03745416   .04835908           1
Placebo_4  -.00892537   .18723803   -.3759119   .35806117           1
Placebo_5   .01492086   .10480538  -.19049768   .22033941           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_all_eventstudy.jpg not
>  found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_all_eventstudy.jpg writ
> ten in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -3.16140    0.98844    -3.20    0.001    -5.09870    -1.22410
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -3.161398    1.05901  -5.237058  -1.085738          1 
    Effect_1 | -3.296967   1.442964  -6.125177  -.4687571          1 
    Effect_2 | -3.025829   1.316397  -5.605967  -.4456916          1 
   Placebo_1 | -.0210602   .0427348  -.1048204   .0626999          1 
   Placebo_2 |  .0157834   .0643164  -.1102767   .1418435          1 
   Placebo_3 |  .0083374   .0571784  -.1037323   .1204071          1 
   Placebo_4 |  .0053846   .0350311  -.0632764   .0740457          1 
   Placebo_5 |  .0049263   .0492044  -.0915144    .101367          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -3.1613982   1.0590102  -5.2370582  -1.0857382           1
 Effect_1  -3.2969672   1.4429644  -6.1251774  -.46875707           1
 Effect_2  -3.0258291   1.3163967  -5.6059667  -.44569155           1
Placebo_1  -.02106024   .04273478   -.1048204   .06269992           1
Placebo_2    .0157834    .0643164  -.11027674   .14184354           1
Placebo_3   .00833739    .0571784  -.10373227   .12040706           1
Placebo_4   .00538463   .03503115  -.06327642   .07404568           1
Placebo_5   .00492626   .04920444  -.09151444   .10136696           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_all_eventstudy.jpg no
> t found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_all_eventstudy.jpg wri
> tten in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -3.16140    1.08793    -2.91    0.004    -5.29370    -1.02909
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_all_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -3.161398   1.241505  -5.594748  -.7280486          1 
    Effect_1 | -3.296967   1.612004  -6.456495  -.1374391          1 
    Effect_2 | -3.025829   1.412964  -5.795239  -.2564192          1 
   Placebo_1 | -.0210602   .0210224  -.0622642   .0201437          1 
   Placebo_2 |  .0157834   .0292645   -.041575   .0731418          1 
   Placebo_3 |  .0083374   .0381185  -.0663749   .0830497          1 
   Placebo_4 |  .0053846    .029618  -.0526667    .063436          1 
   Placebo_5 |  .0049263   .0168689  -.0281369   .0379894          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -3.1613982   1.2415049  -5.5947478  -.72804859           1
 Effect_1  -3.2969672   1.6120042  -6.4564954  -.13743907           1
 Effect_2  -3.0258291   1.4129643  -5.7952391  -.25641916           1
Placebo_1  -.02106024   .02102241  -.06226416   .02014368           1
Placebo_2    .0157834    .0292645  -.04157503   .07314183           1
Placebo_3   .00833739   .03811852  -.06637491    .0830497           1
Placebo_4   .00538463   .02961804  -.05266673   .06343599           1
Placebo_5   .00492626   .01686894  -.02813686   .03798937           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_all_eventstudy.jpg no
> t found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_all_eventstudy.jpg wri
> tten in JPEG format
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_all.tex not found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_all.tex)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.02753    0.45413    -2.26    0.024    -1.91761    -0.13744
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban95_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  135

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.027528   .4070341  -1.825315  -.2297412          1 
    Effect_1 | -1.099209   .3990023  -1.881254  -.3171645          1 
    Effect_2 | -.9558469   .4724967   -1.88194  -.0297535          1 
   Placebo_1 | -.0317664   .0392725  -.1087405   .0452078          1 
   Placebo_2 | -.0030152   .1004849  -.1999655   .1939351          1 
   Placebo_3 |  -.105787   .1310685  -.3626813   .1511073          1 
   Placebo_4 | -.0616236   .1089375   -.275141   .1518939          1 
   Placebo_5 |  .1869085   .0852704   .0197786   .3540385          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   -1.027528   .40703408  -1.8253148  -.22974121           1
 Effect_1  -1.0992091   .39900235  -1.8812537  -.31716449           1
 Effect_2  -.95584693   .47249666  -1.8819404  -.02975347           1
Placebo_1  -.03176636   .03927254  -.10874053   .04520781           1
Placebo_2   -.0030152   .10048485  -.19996551   .19393512           1
Placebo_3  -.10578697   .13106852  -.36268127   .15110733           1
Placebo_4  -.06162357   .10893748  -.27514104   .15189389           1
Placebo_5   .18690851   .08527039   .01977855   .35403847           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban95_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban95_eventstudy.jpg 
> written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.02753    0.47945    -2.14    0.032    -1.96723    -0.08783
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban95_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  135

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.027528   .4979605  -2.003531  -.0515253          1 
    Effect_1 | -1.099209   .5326535   -2.14321  -.0552082          1 
    Effect_2 | -.9558469   .5962831  -2.124562   .2128679          1 
   Placebo_1 | -.0317664   .0472457  -.1243679   .0608352          1 
   Placebo_2 | -.0030152   .1573471  -.3114154    .305385          1 
   Placebo_3 |  -.105787    .173712  -.4462626   .2346886          1 
   Placebo_4 | -.0616236   .2041853  -.4618268   .3385797          1 
   Placebo_5 |  .1869085   .1830349  -.1718399   .5456569          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   -1.027528   .49796055  -2.0035307  -.05152534           1
 Effect_1  -1.0992091   .53265351    -2.14321  -.05520822           1
 Effect_2  -.95584693   .59628307  -2.1245618   .21286789           1
Placebo_1  -.03176636   .04724571  -.12436794   .06083523           1
Placebo_2   -.0030152   .15734706  -.31141543   .30538504           1
Placebo_3  -.10578697   .17371204  -.44626257   .23468863           1
Placebo_4  -.06162357   .20418533  -.46182683   .33857968           1
Placebo_5   .18690851    .1830349  -.17183989   .54565692           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban95_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban95_eventstudy.jpg 
> written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.91126    0.52588    -1.73    0.083    -1.94197     0.11944
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban95_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  135

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9112626   .4163185  -1.727247  -.0952783          1 
    Effect_1 | -1.022893   .4410975  -1.887444  -.1583421          1 
    Effect_2 | -.7996321   .4772837  -1.735108    .135844          1 
   Placebo_1 |  -.027774   .0530502  -.1317524   .0762044          1 
   Placebo_2 |  .0058348   .1729727  -.3331917   .3448612          1 
   Placebo_3 | -.0575165   .1782107  -.4068094   .2917764          1 
   Placebo_4 | -.0787714   .1645793  -.4013468   .2438039          1 
   Placebo_5 |  .1249803   .1464117  -.1619866   .4119471          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.91126262   .41631854   -1.727247  -.09527828           1
 Effect_1  -1.0228931   .44109745  -1.8874441  -.15834212           1
 Effect_2  -.79963212   .47728371  -1.7351082   .13584395           1
Placebo_1    -.027774   .05305023  -.13175244   .07620445           1
Placebo_2   .00583476   .17297269  -.33319172   .34486123           1
Placebo_3  -.05751647   .17821066  -.40680937   .29177643           1
Placebo_4  -.07877142   .16457926  -.40134676   .24380393           1
Placebo_5   .12498028   .14641166  -.16198658   .41194715           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban95_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban95_eventstudy.jpg 
> written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.91126    0.45636    -2.00    0.046    -1.80572    -0.01681
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban95_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  135

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9112626   .4023587  -1.699886  -.1226396          1 
    Effect_1 | -1.022893    .427974  -1.861722   -.184064          1 
    Effect_2 | -.7996321   .4356968  -1.653598   .0543335          1 
   Placebo_1 |  -.027774   .0466279  -.1191647   .0636167          1 
   Placebo_2 |  .0058348   .1041281  -.1982564   .2099259          1 
   Placebo_3 | -.0575165   .1286279  -.3096271   .1945942          1 
   Placebo_4 | -.0787714    .196008   -.462947   .3054042          1 
   Placebo_5 |  .1249803   .1201746   -.110562   .3605225          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.91126262   .40235871  -1.6998857  -.12263956           1
 Effect_1  -1.0228931   .42797403  -1.8617222  -.18406402           1
 Effect_2  -.79963212   .43569676  -1.6535978   .05433353           1
Placebo_1    -.027774    .0466279  -.11916468   .06361668           1
Placebo_2   .00583476   .10412812  -.19825637   .20992588           1
Placebo_3  -.05751647   .12862788  -.30962712   .19459418           1
Placebo_4  -.07877142   .19600798  -.46294705   .30540422           1
Placebo_5   .12498028   .12017462  -.11056198   .36052255           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban95_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban95_eventstudy.jpg 
> written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.88396    0.92298    -3.12    0.002    -4.69296    -1.07496
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban95_trends2020.pd
    > f saved as PDF format

added scalar:
              e(count) =  135

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.883959   .7784815  -4.409783  -1.358135          1 
    Effect_1 | -2.801384   .7881543  -4.346166  -1.256601          1 
    Effect_2 | -2.966534   .9430042  -4.814822  -1.118246          1 
   Placebo_1 | -.1274314   .0615218  -.2480141  -.0068487          1 
   Placebo_2 | -.0937712   .2331032  -.5506534    .363111          1 
   Placebo_3 | -.2804366   .1897902  -.6524253   .0915521          1 
   Placebo_4 | -.0886882   .1596508  -.4016038   .2242274          1 
   Placebo_5 |  .2747592   .1383134    .003665   .5458534          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.8839591   .77848149  -4.4097828  -1.3581354           1
 Effect_1  -2.8013839   .78815433  -4.3461664  -1.2566014           1
 Effect_2  -2.9665343   .94300418  -4.8148225  -1.1182461           1
Placebo_1   -.1274314    .0615218  -.24801414  -.00684867           1
Placebo_2  -.09377119   .23310316  -.55065337     .363111           1
Placebo_3  -.28043657   .18979016  -.65242528   .09155214           1
Placebo_4  -.08868821   .15965083  -.40160382   .22422741           1
Placebo_5   .27475921   .13831338   .00366499   .54585343           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban95_eventstudy.jp
> g not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban95_eventstudy.jpg
>  written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.88396    0.88498    -3.26    0.001    -4.61848    -1.14944
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban95_trends2020.pd
    > f saved as PDF format

added scalar:
              e(count) =  135

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.883959   .8692271  -4.587644  -1.180274          1 
    Effect_1 | -2.801384   .9951598  -4.751897  -.8508708          1 
    Effect_2 | -2.966534   1.009653  -4.945454  -.9876145          1 
   Placebo_1 | -.1274314   .0961289   -.315844   .0609811          1 
   Placebo_2 | -.0937712   .2566706  -.5968455   .4093031          1 
   Placebo_3 | -.2804366   .2608888  -.7917786   .2309054          1 
   Placebo_4 | -.0886882   .2070133  -.4944342   .3170578          1 
   Placebo_5 |  .2747592   .2011909  -.1195749   .6690933          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.8839591   .86922713  -4.5876443  -1.1802739           1
 Effect_1  -2.8013839   .99515976   -4.751897  -.85087077           1
 Effect_2  -2.9665343   1.0096529   -4.945454  -.98761454           1
Placebo_1   -.1274314   .09612885  -.31584396   .06098115           1
Placebo_2  -.09377119   .25667057  -.59684551   .40930314           1
Placebo_3  -.28043657   .26088877  -.79177856   .23090542           1
Placebo_4  -.08868821   .20701326  -.49443419   .31705778           1
Placebo_5   .27475921   .20119085  -.11957486   .66909328           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban95_eventstudy.jp
> g not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban95_eventstudy.jpg
>  written in JPEG format
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_urban95.tex not
    found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_urban95.te
> x)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.96004    0.58606    -1.64    0.101    -2.10868     0.18861
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban95_covid_trends20
    > 20.pdf saved as PDF format

added scalar:
              e(count) =  37

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9600356   .5834406  -2.103579   .1835081          1 
    Effect_1 | -1.116088   .6641632  -2.417848   .1856719          1 
    Effect_2 | -.8039832   .6039357  -1.987697   .3797308          1 
   Placebo_1 | -.0763331   .2039943  -.4761618   .3234956          1 
   Placebo_2 |  .1257697   .2834354  -.4297637    .681303          1 
   Placebo_3 |  -.016911   .2150208  -.4383518   .4045298          1 
   Placebo_4 | -.0030918   .3325922  -.6549725    .648789          1 
   Placebo_5 |  .3434118   .2485417  -.1437299   .8305535          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.96003557   .58344063  -2.1035792   .18350808           1
 Effect_1   -1.116088    .6641632  -2.4178478    .1856719           1
 Effect_2  -.80398316   .60393571  -1.9876972   .37973082           1
Placebo_1   -.0763331   .20399425  -.47616183   .32349563           1
Placebo_2   .12576965   .28343536  -.42976366   .68130297           1
Placebo_3  -.01691101   .21502082  -.43835181   .40452979           1
Placebo_4  -.00309176   .33259221  -.65497249   .64878897           1
Placebo_5   .34341179    .2485417  -.14372994   .83055351           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban95_covid_eventstu
> dy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban95_covid_eventstud
> y.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.96004    0.53384    -1.80    0.072    -2.00634     0.08627
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban95_covid_trends20
    > 20.pdf saved as PDF format

added scalar:
              e(count) =  37

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9600356   .5205052  -1.980226   .0601547          1 
    Effect_1 | -1.116088   .5872745  -2.267146     .03497          1 
    Effect_2 | -.8039832   .5549544  -1.891694   .2837275          1 
   Placebo_1 | -.0763331   .1920449  -.4527411   .3000749          1 
   Placebo_2 |  .1257697   .2796201  -.4222857    .673825          1 
   Placebo_3 |  -.016911   .2114487  -.4313504   .3975284          1 
   Placebo_4 | -.0030918   .3988663  -.7848696   .7786861          1 
   Placebo_5 |  .3434118   .3124998  -.2690878   .9559114          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.96003557   .52050524  -1.9802258   .06015471           1
 Effect_1   -1.116088   .58727448  -2.2671459   .03497002           1
 Effect_2  -.80398316   .55495444  -1.8916939   .28372754           1
Placebo_1   -.0763331   .19204488  -.45274107   .30007487           1
Placebo_2   .12576965   .27962009  -.42228571   .67382502           1
Placebo_3  -.01691101   .21144866  -.43135039   .39752836           1
Placebo_4  -.00309176   .39886626  -.78486964   .77868612           1
Placebo_5   .34341179   .31249979   -.2690878   .95591138           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban95_covid_eventstu
> dy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban95_covid_eventstud
> y.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.89066    0.49721    -1.79    0.073    -1.86517     0.08385
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban95_covid_trends20
    > 20.pdf saved as PDF format

added scalar:
              e(count) =  37

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.8906568   .4805329  -1.832501   .0511876          1 
    Effect_1 | -1.068757    .509722  -2.067812  -.0697015          1 
    Effect_2 | -.7125571   .5527045  -1.795858   .3707438          1 
   Placebo_1 | -.0812036    .169031  -.4125044   .2500972          1 
   Placebo_2 |   .110491   .3478432  -.5712818   .7922638          1 
   Placebo_3 |  .0288225   .2912739  -.5420744   .5997194          1 
   Placebo_4 | -.0548716   .3257261  -.6932947   .5835516          1 
   Placebo_5 |  .2691876   .3472182  -.4113601   .9497353          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.89065684   .48053287  -1.8325013    .0511876           1
 Effect_1  -1.0687566     .509722  -2.0678117  -.06970147           1
 Effect_2  -.71255709   .55270452   -1.795858   .37074377           1
Placebo_1  -.08120358   .16903103  -.41250439   .25009724           1
Placebo_2     .110491   .34784324  -.57128176   .79226375           1
Placebo_3   .02882251   .29127391  -.54207436   .59971939           1
Placebo_4  -.05487157   .32572609  -.69329471   .58355157           1
Placebo_5   .26918761    .3472182  -.41136007   .94973529           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban95_covid_eventstu
> dy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban95_covid_eventstud
> y.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.89066    0.57732    -1.54    0.123    -2.02219     0.24088
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban95_covid_trends20
    > 20.pdf saved as PDF format

added scalar:
              e(count) =  37

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.8906568   .4831869  -1.837703   .0563896          1 
    Effect_1 | -1.068757   .5283816  -2.104385  -.0331286          1 
    Effect_2 | -.7125571   .5199057  -1.731572   .3064582          1 
   Placebo_1 | -.0812036   .1788327  -.4317157   .2693086          1 
   Placebo_2 |   .110491   .2478046  -.3752061   .5961881          1 
   Placebo_3 |  .0288225   .2587256  -.4782796   .5359247          1 
   Placebo_4 | -.0548716    .318983  -.6800782    .570335          1 
   Placebo_5 |  .2691876   .3104073  -.3392107    .877586          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.89065684   .48318694  -1.8377032   .05638957           1
 Effect_1  -1.0687566   .52838164  -2.1043846  -.03312856           1
 Effect_2  -.71255709   .51990574  -1.7315723   .30645816           1
Placebo_1  -.08120358   .17883273  -.43171572   .26930857           1
Placebo_2     .110491   .24780464  -.37520609   .59618809           1
Placebo_3   .02882251   .25872558  -.47827963   .53592466           1
Placebo_4  -.05487157   .31898297  -.68007819   .57033505           1
Placebo_5   .26918761   .31040732  -.33921074   .87758596           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban95_covid_eventstu
> dy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban95_covid_eventstud
> y.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -3.07462    0.95170    -3.23    0.001    -4.93991    -1.20932
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban95_covid_trends2
    > 020.pdf saved as PDF format

added scalar:
              e(count) =  37

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -3.074615   .9869925   -5.00912  -1.140109          1 
    Effect_1 | -2.862969   1.024392  -4.870777  -.8551614          1 
    Effect_2 |  -3.28626   1.343872   -5.92025  -.6522699          1 
   Placebo_1 |  -.512405   .3991122  -1.294665    .269855          1 
   Placebo_2 | -.0756476    .534326  -1.122926   .9716313          1 
   Placebo_3 | -.3423139   .4317391  -1.188523   .5038947          1 
   Placebo_4 | -.1265441   .4356003  -.9803207   .7272326          1 
   Placebo_5 |   .484325   .3284026   -.159344   1.127994          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -3.0746145   .98699248  -5.0091198  -1.1401093           1
 Effect_1  -2.8629693   1.0243918  -4.8707771  -.85516144           1
 Effect_2  -3.2862598   1.3438724  -5.9202497  -.65226989           1
Placebo_1  -.51240499   .39911225   -1.294665   .26985502           1
Placebo_2  -.07564758   .53432596  -1.1229265    .9716313           1
Placebo_3  -.34231394   .43173908  -1.1885225   .50389467           1
Placebo_4  -.12654408   .43560032  -.98032072   .72723255           1
Placebo_5   .48432504   .32840257  -.15934398   1.1279941           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban95_covid_eventst
> udy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban95_covid_eventstu
> dy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -3.07462    1.19642    -2.57    0.010    -5.41955    -0.72968
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban95_covid_trends2
    > 020.pdf saved as PDF format

added scalar:
              e(count) =  37

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -3.074615   .8105125  -4.663219   -1.48601          1 
    Effect_1 | -2.862969   .7111241  -4.256773  -1.469166          1 
    Effect_2 |  -3.28626   1.159116  -5.558128  -1.014392          1 
   Placebo_1 |  -.512405   .2678919  -1.037473   .0126632          1 
   Placebo_2 | -.0756476   .3660422  -.7930902    .641795          1 
   Placebo_3 | -.3423139   .2779586  -.8871128    .202485          1 
   Placebo_4 | -.1265441   .3572317  -.8267182     .57363          1 
   Placebo_5 |   .484325   .3582145  -.2177754   1.186425          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -3.0746145    .8105125   -4.663219    -1.48601           1
 Effect_1  -2.8629693   .71112413  -4.2567726   -1.469166           1
 Effect_2  -3.2862598   1.1591165  -5.5581281  -1.0143915           1
Placebo_1  -.51240499   .26789194  -1.0374732   .01266321           1
Placebo_2  -.07564758   .36604216   -.7930902   .64179505           1
Placebo_3  -.34231394   .27795862  -.88711282   .20248495           1
Placebo_4  -.12654408    .3572317  -.82671821   .57363004           1
Placebo_5   .48432504   .35821451  -.21777539   1.1864255           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban95_covid_eventst
> udy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban95_covid_eventstu
> dy.jpg written in JPEG format
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_urban95_covid.tex not
    found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_urban95_co
> vid.tex)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.82123    0.44286    -1.85    0.064    -1.68921     0.04676
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban98_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  55

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.8212256    .445976  -1.695339   .0528875          1 
    Effect_1 | -.8660405   .4387068  -1.725906  -.0061751          1 
    Effect_2 | -.7764106    .512214   -1.78035   .2275289          1 
   Placebo_1 |   .020322   .1240532  -.2228222   .2634663          1 
   Placebo_2 |  .0232299   .1664941  -.3030985   .3495583          1 
   Placebo_3 | -.0901443    .174583  -.4323269   .2520382          1 
   Placebo_4 | -.0214276   .2853841  -.5807804   .5379252          1 
   Placebo_5 |  .2973557   .2529119  -.1983517    .793063          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.82122556   .44597605  -1.6953386   .05288749           1
 Effect_1  -.86604049   .43870682  -1.7259059  -.00617511           1
 Effect_2  -.77641064   .51221404  -1.7803502   .22752887           1
Placebo_1   .02032202   .12405318  -.22282221   .26346626           1
Placebo_2    .0232299   .16649406  -.30309847   .34955826           1
Placebo_3  -.09014434   .17458295  -.43232693   .25203825           1
Placebo_4  -.02142761   .28538408  -.58078041   .53792519           1
Placebo_5   .29735568   .25291192  -.19835168   .79306305           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban98_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_0_sample_urban98_eventstudy.jpg 
> written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n1_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.82123    0.44594    -1.84    0.066    -1.69525     0.05280
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban98_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  55

added scalar:
               e(mean) =  .1434552
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.8212256   .4867874  -1.775329   .1328777          1 
    Effect_1 | -.8660405   .4823608  -1.811468   .0793867          1 
    Effect_2 | -.7764106   .5470733  -1.848674    .295853          1 
   Placebo_1 |   .020322   .0869682  -.1501357   .1907798          1 
   Placebo_2 |  .0232299   .1413608  -.2538373   .3002971          1 
   Placebo_3 | -.0901443   .1495721  -.3833057    .203017          1 
   Placebo_4 | -.0214276   .2517182  -.5147953     .47194          1 
   Placebo_5 |  .2973557   .2352769  -.1637871   .7584985          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.82122556   .48678736  -1.7753288   .13287767           1
 Effect_1  -.86604049    .4823608  -1.8114677   .07938668           1
 Effect_2  -.77641064   .54707328  -1.8486743     .295853           1
Placebo_1   .02032202   .08696823  -.15013571   .19077976           1
Placebo_2    .0232299   .14136082   -.2538373   .30029709           1
Placebo_3  -.09014434   .14957214  -.38330573   .20301704           1
Placebo_4  -.02142761   .25171818  -.51479525   .47194003           1
Placebo_5   .29735568   .23527693  -.16378711   .75849847           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban98_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_1_sample_urban98_eventstudy.jpg 
> written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.77372    0.39472    -1.96    0.050    -1.54737    -0.00008
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban98_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  55

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.7737222   .3507683  -1.461228  -.0862163          1 
    Effect_1 | -.8941189   .3747134  -1.628557  -.1596807          1 
    Effect_2 | -.6533256   .4256624  -1.487624   .1809728          1 
   Placebo_1 |  .0009528   .1090982  -.2128797   .2147852          1 
   Placebo_2 |   .010807   .1975256  -.3763432   .3979573          1 
   Placebo_3 | -.0474812   .1680216  -.3768035   .2818412          1 
   Placebo_4 | -.0834814   .2512043  -.5758418   .4088791          1 
   Placebo_5 |  .1985285   .2637767  -.3184738   .7155307          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.77372222   .35076835  -1.4612282  -.08621626           1
 Effect_1  -.89411888   .37471338  -1.6285571  -.15968066           1
 Effect_2  -.65332556   .42566242  -1.4876239   .18097278           1
Placebo_1   .00095276   .10909821  -.21287972   .21478524           1
Placebo_2   .01080701   .19752564  -.37634324   .39795725           1
Placebo_3  -.04748116   .16802161  -.37680351    .2818412           1
Placebo_4  -.08348137   .25120431  -.57584181   .40887908           1
Placebo_5   .19852848   .26377666  -.31847378   .71553074           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban98_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_0_sample_urban98_eventstudy.jpg 
> written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
     n2_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.77372    0.41220    -1.88    0.061    -1.58162     0.03417
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban98_trends2020.pdf
    saved as PDF format

added scalar:
              e(count) =  55

added scalar:
               e(mean) =  -.73591077
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.7737222   .4128955  -1.582997   .0355529          1 
    Effect_1 | -.8941189   .4023095  -1.682645  -.1055923          1 
    Effect_2 | -.6533256   .4949401  -1.623408   .3167571          1 
   Placebo_1 |  .0009528   .0826822  -.1611044   .1630099          1 
   Placebo_2 |   .010807   .1448102  -.2730209    .294635          1 
   Placebo_3 | -.0474812   .2053033  -.4498756   .3549133          1 
   Placebo_4 | -.0834814   .2577328  -.5886376   .4216749          1 
   Placebo_5 |  .1985285   .2775576  -.3454845   .7425415          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.77372222   .41289546  -1.5829973   .03555289           1
 Effect_1  -.89411888   .40230946  -1.6826454  -.10559234           1
 Effect_2  -.65332556   .49494012  -1.6234082   .31675707           1
Placebo_1   .00095276   .08268223  -.16110441   .16300993           1
Placebo_2   .01080701   .14481018  -.27302094   .29463496           1
Placebo_3  -.04748116   .20530329  -.44987561    .3549133           1
Placebo_4  -.08348137   .25773279  -.58863763   .42167489           1
Placebo_5   .19852848   .27755765  -.34548451   .74254147           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban98_eventstudy.jpg
>  not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_1_sample_urban98_eventstudy.jpg 
> written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.90531    1.19318    -2.43    0.015    -5.24389    -0.56673
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban98_trends2020.pd
    > f saved as PDF format

added scalar:
              e(count) =  55

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.905309   .9304217  -4.728936  -1.081682          1 
    Effect_1 | -2.751319   1.096608   -4.90067   -.601968          1 
    Effect_2 | -3.059299   1.059186  -5.135302  -.9832951          1 
   Placebo_1 | -.2293173    .122085  -.4686038   .0099692          1 
   Placebo_2 | -.3432383    .288382  -.9084669   .2219903          1 
   Placebo_3 | -.5683463   .2878223  -1.132478  -.0042146          1 
   Placebo_4 |  .0082995   .3050367  -.5895724   .6061714          1 
   Placebo_5 |  .4105898   .2676612   -.114026   .9352057          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   -2.905309   .93042174  -4.7289356  -1.0816824           1
 Effect_1  -2.7513192   1.0966077  -4.9006703  -.60196802           1
 Effect_2  -3.0592988   1.0591855  -5.1353025  -.98329513           1
Placebo_1  -.22931729   .12208496  -.46860381   .00996924           1
Placebo_2   -.3432383   .28838195  -.90846692   .22199033           1
Placebo_3  -.56834625   .28782229  -1.1324779  -.00421457           1
Placebo_4    .0082995   .30503668  -.58957239   .60617139           1
Placebo_5   .41058985   .26766117  -.11402605   .93520574           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban98_eventstudy.jp
> g not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_0_sample_urban98_eventstudy.jpg
>  written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
    agi_rate |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.90531    1.15652    -2.51    0.012    -5.17204    -0.63857
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban98_trends2020.pd
    > f saved as PDF format

added scalar:
              e(count) =  55

added scalar:
               e(mean) =  -.29483641
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.905309   .8247898  -4.521897  -1.288721          1 
    Effect_1 | -2.751319   1.008661  -4.728295  -.7743433          1 
    Effect_2 | -3.059299    1.05192  -5.121063  -.9975351          1 
   Placebo_1 | -.2293173   .2744573  -.7672535    .308619          1 
   Placebo_2 | -.3432383    .398496   -1.12429   .4378139          1 
   Placebo_3 | -.5683463   .4558141  -1.461742   .3250495          1 
   Placebo_4 |  .0082995   .4161698  -.8073933   .8239923          1 
   Placebo_5 |  .4105898   .4005118  -.3744134   1.195593          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   -2.905309   .82478981   -4.521897   -1.288721           1
 Effect_1  -2.7513192   1.0086612   -4.728295  -.77434332           1
 Effect_2  -3.0592988   1.0519203  -5.1210625  -.99753508           1
Placebo_1  -.22931729   .27445728  -.76725355   .30861897           1
Placebo_2   -.3432383   .39849602  -1.1242905    .4378139           1
Placebo_3  -.56834625   .45581414   -1.461742   .32504947           1
Placebo_4    .0082995   .41616981  -.80739333   .82399233           1
Placebo_5   .41058985   .40051184  -.37441336   1.1955931           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban98_eventstudy.jp
> g not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_1_sample_urban98_eventstudy.jpg
>  written in JPEG format
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_urban98.tex not
    found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_irs_sample_urban98.te
> x)

.         
. 
. ** Close log
. clear 

. log close log_02
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 closed on:  18 Dec 2025, 16:37:13
--------------------------------------------------------------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000038.tmp"

.     saving("${data}working/acs_county_gross_18plus", replace)
command saving is unrecognized
r(199);

end of do-file

r(199);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000039.tmp"

. /*****************************************************************************
> * Program:                      01_clean_data.do 
> * Author(s):            John Iselin 
> * Date Updated:         October 19, 2025
> 
> *** Demographic data via IPUMS NHGIS 
> ** Via https://www.nhgis.org/
> ** Downloaded on October 19, 2025
> ** EXTRACT DETAILS in "nhgis0031_ts_nominal_county_codebook"
> 
> *** Economic data via BEA Regional Economic Accounts (CAINC1)
> ** Via https://apps.bea.gov/regional/downloadzip.htm
> 
> *** ACS individual data via IPUMS USA 
> ** Via https://usa.ipums.org/usa/index.shtml
> ** Downloaded via R program 
> 
> *** IRS SOI County-Level Migration Files
> ** Via https://www.irs.gov/statistics/soi-tax-stats-migration-data
> 
> *** IRS SOI County-Level Files
> ** Via https://www.irs.gov/statistics/soi-tax-stats-county-data
> 
> *** NYTimes COVID Cases and Deaths 
> ** Via https://github.com/nytimes/covid-19-data
> 
> *******************************************************************************/
. 
. ** Start log file 
. capture log close log_01

. log using "${logs}01_log_data_clean_${pr_name}_${date}", replace text name(log_01)
--------------------------------------------------------------------------------------------------------------
      name:  log_01
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/01_log_data_clean_multnomah_2025-1
> 2-16.log
  log type:  text
 opened on:  18 Dec 2025, 17:32:02

. 
. //--------------------------------------------------
. // STEP 0: Preliminary Set-Up 
. //--------------------------------------------------
. 
. ** Define labels 
. label define lb_move_type       0 "ERROR"                               ///
>                                                         1 "Non-movers"                  ///
>                                                         2 "All movers"                  ///
>                                                         3 "Domestic movers"             ///
>                                                         4 "Within-state movers" ///
>                                                         5 "Inter-state movers"  ///
>                                                         6 "Foreign movers", modify

.                                                         
. label define lb_agi             1 "Under $1"                    ///
>                                                         2 "$1 under $10K"               ///
>                                                         3 "$10K under $25K"             ///
>                                                         4 "$25K under $50K"             ///
>                                                         5 "$50K under $75K"             ///
>                                                         6 "$75K under $100K"    ///
>                                                         7 "$100K under $200K"   ///
>                                                         8 "$200K or more", modify                           
>                             

. 
. 
. ** Define Programs
. 
. ** Make FIPS code from state and county fips codes 
. capture program drop make_fips

. program define make_fips
  1.     syntax varlist(min=2 max=2 numeric), GEN(name)
  2. 
.     quietly {
  3.         tempvar s c
  4. 
.         local v1 : word 1 of `varlist'
  5.         local v2 : word 2 of `varlist'
  6. 
.         gen `s' = string(`v1', "%02.0f")
  7.         gen `c' = string(`v2', "%03.0f")
  8. 
.         gen `gen' = real(`s' + `c')
  9.     }
 10. end

. 
. ** Reclassify suppressed values as 0 
. 
. capture program drop unsuppress

. program define unsuppress
  1.     syntax varlist
  2. 
.     foreach v of varlist `varlist' {
  3.         replace `v' = 0 if `v' == -1
  4.     }
  5. end

. 
. 
. ** Create a gross-migration fiel via ACS 
. capture program drop acs_make_gross_migration

. program define acs_make_gross_migration
  1.     version 16.0
  2.     /*
>       Build county-year gross migration totals from ACS microdata with origin/destination counties.
> 
>       Outputs (wide):
>         persons_in_*, persons_out_*, persons_net_*
>         households_in_*, households_out_*, households_net_*
>         dollars_in_*, dollars_out_*, dollars_net_*
> 
>       Move-type indices (mirrors your IRS convention as closely as possible):
>         1 = Non-movers (same county)
>         2 = All movers (different county) = 4 + 5
>         3 = Domestic movers (same as 2 here; foreign already dropped upstream)
>         4 = Within-state movers (different county, same state)
>         5 = Inter-state movers (different state)
>     */
. 
.     syntax using/ [if] [in], SAVING(string) [REPLACE] ///
>         [ IDSFILE(string) ///
>           YEARVAR(name) ORIGFIPS(name) DESTFIPS(name) ///
>           PERSONWT(name) HHWT(name) HEADVAR(name) INCOME(name) ]
  3. 
.     // Defaults consistent with your 01_clean_data.do
.     if "`idsfile'"  == "" local idsfile  "${data}working/ids"
  4.     if "`yearvar'"  == "" local yearvar  year
  5.     if "`origfips'" == "" local origfips fips_o
  6.     if "`destfips'" == "" local destfips fips_d
  7.     if "`personwt'" == "" local personwt perwt
  8.     if "`hhwt'"     == "" local hhwt     hhwt
  9.     if "`headvar'"  == "" local headvar  hh_head
 10.     if "`income'"   == "" local income   inctot
 11. 
.     // Load microdata (optionally subset via if/in)
.     use "`using'" `if' `in', clear
 12. 
.     // Basic checks
.     foreach v in `yearvar' `origfips' `destfips' `personwt' `hhwt' `headvar' `income' {
 13.         capture confirm variable `v'
 14.         if _rc {
 15.             di as err "Required variable `v' not found in `using'."
 16.             exit 198
 17.         }
 18.     }
 19. 
.     // Keep only valid year/origin/destination
.     drop if missing(`yearvar') | missing(`origfips') | missing(`destfips')
 20. 
.     // Income: treat missing as 0 (keep negatives as reported)
.     replace `income' = 0 if missing(`income')
 21. 
.     // Build weighted components at the person level
.     gen double persons_wt = `personwt'
 22.     gen double dollars_wt = `income' * `personwt'
 23.     gen double households_wt = `hhwt' if `headvar' == 1
 24.     replace households_wt = 0 if missing(households_wt)
 25. 
.     // Collapse to origin-destination-year flow first
.     keep `yearvar' `origfips' `destfips' persons_wt dollars_wt households_wt
 26.     collapse (sum) persons=persons_wt dollars=dollars_wt households=households_wt, ///
>         by(`yearvar' `origfips' `destfips')
 27. 
.     // Derive state/county components for mover-type logic
.     gen int state_o  = floor(`origfips'/1000)
 28.     gen int state_d  = floor(`destfips'/1000)
 29. 
.     gen byte same_county = (`origfips' == `destfips')
 30.     gen byte same_state  = (state_o == state_d)
 31.     gen byte within_state_mover = same_state & !same_county
 32.     gen byte inter_state_mover  = !same_state
 33. 
.     // -----------------------
.     // IN-MIGRATION (by destination county)
.     // -----------------------
.     preserve
 34.         gen long fips = `destfips'
 35.         gen int state_fips  = floor(fips/1000)
 36.         gen int county_fips = mod(fips, 1000)
 37. 
.         // type 1/4/5 components
.         foreach m in persons households dollars {
 38.             gen double `m'_1 = `m' if same_county
 39.             gen double `m'_4 = `m' if within_state_mover
 40.             gen double `m'_5 = `m' if inter_state_mover
 41.         }
 42. 
.         collapse (sum) persons_1 persons_4 persons_5 ///
>                        households_1 households_4 households_5 ///
>                        dollars_1 dollars_4 dollars_5, ///
>                 by(`yearvar' fips state_fips county_fips)
 43. 
.         // build 2 and 3
.         gen double persons_2    = persons_4 + persons_5
 44.         gen double persons_3    = persons_2
 45.         gen double households_2 = households_4 + households_5
 46.         gen double households_3 = households_2
 47.         gen double dollars_2    = dollars_4 + dollars_5
 48.         gen double dollars_3    = dollars_2
 49. 
.         // rename to *_in_*
.         foreach t in 1 2 3 4 5 {
 50.             rename persons_`t'    persons_in_`t'
 51.             rename households_`t' households_in_`t'
 52.             rename dollars_`t'    dollars_in_`t'
 53.         }
 54. 
.         tempfile __in
 55.         save `__in', replace
 56.     restore
 57. 
.     // -----------------------
.     // OUT-MIGRATION (by origin county)
.     // -----------------------
.     preserve
 58.         gen long fips = `origfips'
 59.         gen int state_fips  = floor(fips/1000)
 60.         gen int county_fips = mod(fips, 1000)
 61. 
.         foreach m in persons households dollars {
 62.             gen double `m'_1 = `m' if same_county
 63.             gen double `m'_4 = `m' if within_state_mover
 64.             gen double `m'_5 = `m' if inter_state_mover
 65.         }
 66. 
.         collapse (sum) persons_1 persons_4 persons_5 ///
>                        households_1 households_4 households_5 ///
>                        dollars_1 dollars_4 dollars_5, ///
>                 by(`yearvar' fips state_fips county_fips)
 67. 
.         gen double persons_2    = persons_4 + persons_5
 68.         gen double persons_3    = persons_2
 69.         gen double households_2 = households_4 + households_5
 70.         gen double households_3 = households_2
 71.         gen double dollars_2    = dollars_4 + dollars_5
 72.         gen double dollars_3    = dollars_2
 73. 
.         foreach t in 1 2 3 4 5 {
 74.             rename persons_`t'    persons_out_`t'
 75.             rename households_`t' households_out_`t'
 76.             rename dollars_`t'    dollars_out_`t'
 77.         }
 78. 
.         tempfile __out
 79.         save `__out', replace
 80.     restore
 81. 
.     // -----------------------
.     // Merge in/out; compute net
.     // -----------------------
.     use `__in', clear
 82.     merge 1:1 `yearvar' fips state_fips county_fips using `__out', nogen
 83. 
.     // Replace missings with 0 prior to net calcs (counties can be only in or only out)
.     foreach m in persons households dollars {
 84.         foreach t in 1 2 3 4 5 {
 85.             replace `m'_in_`t'  = 0 if missing(`m'_in_`t')
 86.             replace `m'_out_`t' = 0 if missing(`m'_out_`t')
 87.         }
 88.     }
 89. 
.     // Net = in - out (types 2/3/4/5 are the meaningful migration nets; 1 will be ~0 by construction)
.     foreach m in persons households dollars {
 90.         foreach t in 2 3 4 5 {
 91.             gen double `m'_net_`t' = `m'_in_`t' - `m'_out_`t'
 92.         }
 93.     }
 94. 
.     // Merge names
.     merge m:1 state_fips county_fips using "`idsfile'", keep(master match) nogen
 95. 
.     // Labels
.     label var fips "County FIPS (state*1000 + county)"
 96.     label var state_fips "State FIPS"
 97.     label var county_fips "County FIPS"
 98. 
.     label var persons_in_2  "Persons, in-migration, all movers"
 99.     label var persons_out_2 "Persons, out-migration, all movers"
100.     label var persons_net_2 "Persons, net migration, all movers"
101. 
.     label var households_in_2  "Households, in-migration, all movers (HH heads)"
102.     label var households_out_2 "Households, out-migration, all movers (HH heads)"
103.     label var households_net_2 "Households, net migration, all movers (HH heads)"
104. 
.     label var dollars_in_2  "Dollars, in-migration, all movers (INCTOT*PERWT)"
105.     label var dollars_out_2 "Dollars, out-migration, all movers (INCTOT*PERWT)"
106.     label var dollars_net_2 "Dollars, net migration, all movers (INCTOT*PERWT)"
107. 
.     order `yearvar' fips state_fips county_fips state_name county_name, first
108.     sort `yearvar' state_fips county_fips
109.     compress
110. 
.     // Save
.     save "`saving'", `replace'
111.         clear
112.         
. end

. 
. 
. //--------------------------------------------------
. // STEP -1: Acquire raw data (automated where possible)
. //--------------------------------------------------
. /*
> This block downloads public-use source data directly from official URLs if not present locally.
> 
> Automated downloads included:
>   - IRS SOI county-to-county migration: countyinflowYYZZ.csv / countyoutflowYYZZ.csv
>   - IRS SOI county data: YYincyallagi.csv
>   - BEA Regional Economic Accounts (CAINC1): CAINC1.zip (unzips to CAINC1__ALL_AREAS_*.csv and related files
> )
> 
> */
. 
. * Ensure expected directory structure exists
. capture mkdir "${data}"

. capture mkdir "${data}working"

. capture mkdir "${data}demographic"

. capture mkdir "${data}demographic/CAINC1"

. capture mkdir "${data}demographic/nhgis0031_csv"

. capture mkdir "${data}irs"

. capture mkdir "${data}covid"

. 
. * ----------------------------
. * IRS SOI: migration files
. * ----------------------------
. local irs_base "https://www.irs.gov/pub/irs-soi"

. 
. forvalues yy = 15/21 {
  2.     local zz = `yy' + 1
  3.     local fn_out "countyoutflow`yy'`zz'.csv"
  4.     local fn_in  "countyinflow`yy'`zz'.csv"
  5. 
.     capture confirm file "${data}irs/`fn_out'"
  6.     if _rc {
  7.         di as txt "Downloading (IRS SOI) `fn_out' ..."
  8.         copy "`irs_base'/`fn_out'" "${data}irs/`fn_out'", replace
  9.     }
 10. 
.     capture confirm file "${data}irs/`fn_in'"
 11.     if _rc {
 12.         di as txt "Downloading (IRS SOI) `fn_in' ..."
 13.         copy "`irs_base'/`fn_in'" "${data}irs/`fn_in'", replace
 14.     }
 15. }

. 
. * ----------------------------
. * IRS SOI: county income (AGI) files
. * ----------------------------
. forvalues yy = 15/22 {
  2.     local fn_inc "`yy'incyallagi.csv"
  3. 
.     capture confirm file "${data}irs/`fn_inc'"
  4.     if _rc {
  5.         di as txt "Downloading (IRS SOI) `fn_inc' ..."
  6.         copy "`irs_base'/`fn_inc'" "${data}irs/`fn_inc'", replace
  7.     }
  8. }

. 
. * ----------------------------
. * BEA Regional: CAINC1.zip
. * ----------------------------
. local bea_dir "${data}demographic/CAINC1"

. local bea_url "https://apps.bea.gov/regional/zip/CAINC1.zip"

. local bea_zip "`bea_dir'/CAINC1.zip"

. 
. * If we don't already have a CAINC1 "_ALL_AREAS" file, download + unzip the ZIP.
. local bea_files : dir "`bea_dir'" files "CAINC1__ALL_AREAS_*.csv"

. if "`bea_files'"=="" {
.     local bea_files : dir "`bea_dir'" files "CAINC1__ALL_STATES_*.csv"
. }

. 
. if "`bea_files'"=="" {
.     di as txt "Downloading (BEA) CAINC1.zip ..."
Downloading (BEA) CAINC1.zip ...
.     copy "`bea_url'" "`bea_zip'", replace
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/demographic/CAINC1/CAINC1.zip not found)
. 
.     local curdir "`c(pwd)'"
.     cd "`bea_dir'"
C:\Users\ji252\Documents\GitHub\multnomah-county-tax\data\demographic\CAINC1
.     unzipfile "CAINC1.zip", replace
    inflating: CAINC1__ALL_AREAS_1969_2023.csv
    inflating: CAINC1__definition.xml
    inflating: CAINC1__Footnotes.html
    inflating: CAINC1_AK_1969_2023.csv
    inflating: CAINC1_AL_1969_2023.csv
    inflating: CAINC1_AR_1969_2023.csv
    inflating: CAINC1_AZ_1969_2023.csv
    inflating: CAINC1_CA_1969_2023.csv
    inflating: CAINC1_CO_1969_2023.csv
    inflating: CAINC1_CSA_1969_2023.csv
    inflating: CAINC1_CT_1969_2023.csv
    inflating: CAINC1_DC_1969_2023.csv
    inflating: CAINC1_DE_1969_2023.csv
    inflating: CAINC1_FL_1969_2023.csv
    inflating: CAINC1_GA_1969_2023.csv
    inflating: CAINC1_HI_1969_2023.csv
    inflating: CAINC1_IA_1969_2023.csv
    inflating: CAINC1_ID_1969_2023.csv
    inflating: CAINC1_IL_1969_2023.csv
    inflating: CAINC1_IN_1969_2023.csv
    inflating: CAINC1_KS_1969_2023.csv
    inflating: CAINC1_KY_1969_2023.csv
    inflating: CAINC1_LA_1969_2023.csv
    inflating: CAINC1_MA_1969_2023.csv
    inflating: CAINC1_MD_1969_2023.csv
    inflating: CAINC1_MDIV_1969_2023.csv
    inflating: CAINC1_ME_1969_2023.csv
    inflating: CAINC1_MI_1969_2023.csv
    inflating: CAINC1_MIC_1969_2023.csv
    inflating: CAINC1_MN_1969_2023.csv
    inflating: CAINC1_MO_1969_2023.csv
    inflating: CAINC1_MS_1969_2023.csv
    inflating: CAINC1_MSA_1969_2023.csv
    inflating: CAINC1_MT_1969_2023.csv
    inflating: CAINC1_NC_1969_2023.csv
    inflating: CAINC1_ND_1969_2023.csv
    inflating: CAINC1_NE_1969_2023.csv
    inflating: CAINC1_NH_1969_2023.csv
    inflating: CAINC1_NJ_1969_2023.csv
    inflating: CAINC1_NM_1969_2023.csv
    inflating: CAINC1_NV_1969_2023.csv
    inflating: CAINC1_NY_1969_2023.csv
    inflating: CAINC1_OH_1969_2023.csv
    inflating: CAINC1_OK_1969_2023.csv
    inflating: CAINC1_OR_1969_2023.csv
    inflating: CAINC1_PA_1969_2023.csv
    inflating: CAINC1_PORT_1969_2023.csv
    inflating: CAINC1_RI_1969_2023.csv
    inflating: CAINC1_SC_1969_2023.csv
    inflating: CAINC1_SD_1969_2023.csv
    inflating: CAINC1_TN_1969_2023.csv
    inflating: CAINC1_TX_1969_2023.csv
    inflating: CAINC1_US_1969_2023.csv
    inflating: CAINC1_UT_1969_2023.csv
    inflating: CAINC1_VA_1969_2023.csv
    inflating: CAINC1_VT_1969_2023.csv
    inflating: CAINC1_WA_1969_2023.csv
    inflating: CAINC1_WI_1969_2023.csv
    inflating: CAINC1_WV_1969_2023.csv
    inflating: CAINC1_WY_1969_2023.csv

successfully unzipped CAINC1.zip to current directory
total processed:  60
        skipped:  0
      extracted:  60
.     cd "`curdir'"
C:\Users\ji252\Documents\GitHub\multnomah-county-tax
. 
.     capture erase "`bea_zip'"
. }

. 
. * ----------------------------
. * NYTimes COVID Data 
. * ----------------------------
. local covid_dir "${data}covid"

. local covid_url "https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"

. 
. * If we don't already have a COVID file, download.
. local covid_file : dir "`covid_dir'" files "covid_nyt.csv"

. if "`covid_file'"=="" {
.     local covid_file : dir "`covid_dir'" files "covid_nyt.csv"
. }

. 
. if "`covid_file'"=="" {
.     di as txt "Downloading (COVID)  ..."
Downloading (COVID)  ...
.     copy "`covid_url'" "`covid_dir'/covid_nyt.csv", replace
. }

. 
. 
. 
. //-----------------------------------------------------------
. // STEP 1: Import and Clean Demographic Data via IPUMS + BEA  
. //-----------------------------------------------------------
. 
. ** Import data 
. import delimited        ///
>         "${data}demographic/nhgis0031_csv/nhgis0031_ts_nominal_county.csv", clear 
(encoding automatically selected: ISO-8859-1)
(15 vars, 54,673 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:        54,673                  
    Variables:            15                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
gisjoin         str8    %9s                   GISJOIN
year            str9    %9s                   YEAR
state           str20   %20s                  STATE
statefp         byte    %8.0g                 STATEFP
statenh         int     %8.0g                 STATENH
county          str46   %46s                  COUNTY
countyfp        int     %8.0g                 COUNTYFP
countynh        int     %8.0g                 COUNTYNH
name            str59   %59s                  NAME
av0aa           long    %12.0g                AV0AA
d15aa           long    %12.0g                D15AA
d15ab           long    %12.0g                D15AB
b79aa           long    %12.0g                B79AA
av0aam          long    %12.0g                AV0AAM
b79aam          long    %8.0g                 B79AAM
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Drop unnecc variables 
. drop gisjoin statenh countynh name 

. 
. ** Rename 
. rename state state_name 

. rename statefp state_fips 

. rename county county_name 

. rename countyfp county_fips 

. rename av0aa population 

. rename d15aa pop_urban 

. rename d15ab pop_rural 

. rename b79aa median_income 

. rename av0aam population_margin

. rename b79aam median_income_margin 

. 
. ** Create urban percent 
. gen percent_urban = pop_urban / population
(45,090 missing values generated)

. 
. ** Label variables 
. label var state_name "State name"

. label var state_fips "State FIPS code"

. label var county_name "County name"

. label var county_fips "County FIPS code"

. label var population "Population count"

. label var pop_rural "Rural population count"

. label var pop_urban "Urban population count"

. label var percent_urban "Percent of population in urban areas"

. label var median_income "Median household income (prior year)"

. label var population_margin "ACS margin for error: population"

. label var median_income_margin "ACS margin for error: median income"

. 
. ** Save as temporary file 
. tempfile demo

. save `demo'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000002.tmp saved as .dta format

. 
. ** Create three datasets 
. 
. ** (1) Basic state and county IDs 
. keep if year == "2020" 
(51,452 observations deleted)

. keep state* county* 

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save as state and county Ids 
. save "${data}working/ids", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/ids.dta saved

. clear  

. 
. ** (2) Population data 
. use `demo'

. keep if !missing(pop_urban) 
(45,090 observations deleted)

. tab year 

       YEAR |      Freq.     Percent        Cum.
------------+-----------------------------------
       2000 |      3,141       32.78       32.78
       2010 |      3,221       33.61       66.39
       2020 |      3,221       33.61      100.00
------------+-----------------------------------
      Total |      9,583      100.00

. 
. ** Keep 2020 
. keep if year == "2020"
(6,362 observations deleted)

. drop year median_income* population_margin

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save data
. save "${data}working/population_2020", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/population_2020.dta saved

. clear  

. 
. ** (3) 2015-2019 ACS data 
. use `demo'

. keep if !missing(median_income) 
(6,447 observations deleted)

. tab year 

       YEAR |      Freq.     Percent        Cum.
------------+-----------------------------------
       2000 |      3,141        6.51        6.51
  2006-2010 |      3,221        6.68       13.19
  2007-2011 |      3,221        6.68       19.87
  2008-2012 |      3,221        6.68       26.55
  2009-2013 |      3,221        6.68       33.23
  2010-2014 |      3,220        6.68       39.91
  2011-2015 |      3,219        6.67       46.58
  2012-2016 |      3,220        6.68       53.26
  2013-2017 |      3,220        6.68       59.93
  2014-2018 |      3,219        6.67       66.61
  2015-2019 |      3,220        6.68       73.29
  2016-2020 |      3,220        6.68       79.96
  2017-2021 |      3,220        6.68       86.64
  2018-2022 |      3,221        6.68       93.32
  2019-2023 |      3,222        6.68      100.00
------------+-----------------------------------
      Total |     48,226      100.00

. 
. ** Keep 2020 
. keep if year == "2015-2019"
(45,006 observations deleted)

. drop year pop_rural pop_urban percent_urban

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save data
. save "${data}working/acs_2015_2019_data", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_2015_2019_data.dta saved

. 
. ** Rename for merge 
. rename population population_acs

. 
. ** Merge with other data 
. merge 1:1 state_fips county_fips using "${data}working/population_2020",                ///
>         keep(match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                             3,219  
    -----------------------------------------

. 
. ** Save data
. save "${data}working/demographics_2020", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/demographics_2020.dta saved

. 
. ** Load BEA Data 
. import delimited "${data}demographic/CAINC1/CAINC1__ALL_AREAS_1969_2023.csv",   ///
>         clear 
(encoding automatically selected: ISO-8859-1)
(63 vars, 9,604 obs)

. 
. ** Drop unnecc variables 
. drop region tablename industryclassification unit geoname 

. 
. ** Drop empty cells 
. drop if missing(linecode)
(4 observations deleted)

. 
. ** Update names 
. rename geofips fips 

. replace fips = subinstr(fips, `"""', "", .)
(9,600 real changes made)

. destring fips, replace 
fips: all characters numeric; replaced as long

. 
. ** Keep population and per-capita income, dropping personal income (total)
. tab description linecode

                      |             LineCode
          Description |         1          2          3 |     Total
----------------------+---------------------------------+----------
Per capita personal.. |         0          0      3,200 |     3,200 
Personal income (th.. |     3,200          0          0 |     3,200 
Population (persons.. |         0      3,200          0 |     3,200 
----------------------+---------------------------------+----------
                Total |     3,200      3,200      3,200 |     9,600 

. drop if linecode == 1   
(3,200 observations deleted)

. drop description

.         
. ** Get V* to be in terms of years 
. ** V9 == 1969 
. forvalues i = 9/63 {
  2.         
.         local j = 1960 + `i'
  3.         rename v`i' value`j'
  4.         
. } // END I LOOP 

. 
. ** Reshape 
. reshape long value, i(fips linecode) j(year)
(j = 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 
> 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 201
> 1 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations            6,400   ->   352,000     
Number of variables                  57   ->   4           
j variable (55 values)                    ->   year
xij variables:
      value1969 value1970 ... value2023   ->   value
-----------------------------------------------------------------------------

. reshape wide value, i(fips year ) j(linecode)
(j = 2 3)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations          352,000   ->   176,000     
Number of variables                   4   ->   4           
j variable (2 values)          linecode   ->   (dropped)
xij variables:
                                  value   ->   value2 value3
-----------------------------------------------------------------------------

. 
. ** Keep years 
. keep if inrange(year, 2015, 2023)
(147,200 observations deleted)

. 
. ** Rename values 
. rename value2 population 

. rename value3 per_capita_income

. 
. ** Drop if missing values 
. drop if population == "(NA)"
(239 observations deleted)

. 
. ** Keep only counties with all observations 
. bysort fips: gen ct = _N 

. tab ct

         ct |      Freq.     Percent        Cum.
------------+-----------------------------------
          4 |          8        0.03        0.03
          5 |          5        0.02        0.05
          9 |     28,548       99.95      100.00
------------+-----------------------------------
      Total |     28,561      100.00

. keep if ct == 9
(13 observations deleted)

. drop ct

. 
. ** Destring 
. destring population, replace 
population: all characters numeric; replaced as long

. destring per_capita_income, replace 
per_capita_income: all characters numeric; replaced as long

. 
. ** Save data
. save "${data}working/bea_economics", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/bea_economics.dta saved

. 
. //----------------------------------------------------
. // STEP 2: Import and Clean NYTimes COVID-19 Data 
. //----------------------------------------------------
.  
. ** Import data 
. import delimited using "${data}covid/covid_nyt.csv", varnames(1) clear case(lower) 
(encoding automatically selected: ISO-8859-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832                  
    Variables:             6                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
date            str10   %10s                  
county          str35   %35s                  
state           str24   %24s                  
fips            long    %12.0g                
cases           long    %12.0g                
deaths          long    %8.0g                 
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to 13may2022, but with gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_name, force 

Duplicates in terms of fips state_name county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000004.tmp saved as .dta format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_names', keep(master match) nogen 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,646,784  
    -----------------------------------------

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state county cases deaths 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/population_2020", keep(match) nogen  
(variable county_name was str35, now str46 to accommodate using data's values)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                         2,643,408  
    -----------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned.dta saved

. 
. ** Keep one observation per month 
. keep year month fips state_name county_name cases deaths population

. collapse (sum) cases deaths (mean) population, by(year month fips state_name county_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Calculate cumulative cases and deaths 
. bysort fips (date): gen cases_cum = sum(cases)

. bysort fips (date): gen deaths_cum = sum(deaths)

. 
. ** Generate per capita figures
. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / population
(82,955 real changes made)

. drop population cases deaths

. 
. ** Reshape wide 
. reshape wide cases_cum deaths_cum, i(fips state_name county_name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations           90,828   ->   3,132       
Number of variables                   6   ->   61          
j variable (29 values)             date   ->   (dropped)
xij variables:
                              cases_cum   ->   cases_cum1 cases_cum2 ... cases_cum29
                             deaths_cum   ->   deaths_cum1 deaths_cum2 ... deaths_cum29
-----------------------------------------------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned_wide.dta, replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/covid_cleaned_wide.dta saved

. clear

. 
. //----------------------------------------------------
. // STEP 3: Import and Clean ACS Micro Data via IPUMS 
. //----------------------------------------------------
. 
. ** Load data 
. forvalues y = 2015(1)2023 {
  2.         
.         ** Import CSV
.         import delimited using "${data}acs/acs_`y'", varnames(1) clear case(lower)
  3.         
.         ** Save as temporary data 
.         tempfile acs_`y'
  4.         save `acs_`y''
  5.         clear 
  6.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-8859-1)
(57 vars, 2,997,503 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000005.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,007,847 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000006.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,038,696 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000007.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,060,442 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000008.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,087,291 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000009.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 2,454,160 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000a.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(57 vars, 3,092,079 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000b.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(55 vars, 3,190,848 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000c.tmp saved as .dta format
(encoding automatically selected: ISO-8859-1)
(55 vars, 3,228,659 obs)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000d.tmp saved as .dta format

. 
. ** Append data 
. forvalues y = 2015(1)2023 {
  2.         
.         append using `acs_`y''  
  3.         
. } // END YEAR LOOP 
(variable cbserial was long, now double to accommodate using data's values)

. 
. ** Des 
. tab year 

       year |      Freq.     Percent        Cum.
------------+-----------------------------------
       2015 |  2,997,503       11.04       11.04
       2016 |  3,007,847       11.08       22.11
       2017 |  3,038,696       11.19       33.30
       2018 |  3,060,442       11.27       44.57
       2019 |  3,087,291       11.37       55.94
       2020 |  2,454,160        9.04       64.98
       2021 |  3,092,079       11.39       76.36
       2022 |  3,190,848       11.75       88.11
       2023 |  3,228,659       11.89      100.00
------------+-----------------------------------
      Total | 27,157,525      100.00

. 
. ** Define # of adults and kids in HHs 
. gen adult = age >= 18 

. gen child = age < 18 

. bysort year serial: gen hh_size = _N 

. bysort year serial: egen hh_adult_ct = total(adult)

. bysort year serial: egen hh_child_ct = total(child)

. 
. ** Sample 18+
. drop if child == 1 
(5,629,869 observations deleted)

. drop child adult 

. 
. ** Sample not living abroad last year 
. drop if migplac1 > 56 
(108,862 observations deleted)

. drop if migrate1 == 4 
(0 observations deleted)

. 
. ** Rename variables 
. rename statefip state_fips_d

. rename countyfip county_fips_d 

. 
. ** Set up origin data 
. fre migrate1

migrate1
-----------------------------------------------------------
              |      Freq.    Percent      Valid       Cum.
--------------+--------------------------------------------
Valid   1     |   1.92e+07      89.51      89.51      89.51
        2     |    1809920       8.45       8.45      97.96
        3     |     436745       2.04       2.04     100.00
        Total |   2.14e+07     100.00     100.00           
-----------------------------------------------------------

. drop migrate1d

. tab migplac1

   migplac1 |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 | 19,172,129       89.51       89.51
          1 |     31,329        0.15       89.66
          2 |      5,825        0.03       89.68
          4 |     54,912        0.26       89.94
          5 |     21,714        0.10       90.04
          6 |    260,673        1.22       91.26
          8 |     52,539        0.25       91.50
          9 |     21,577        0.10       91.61
         10 |      5,369        0.03       91.63
         11 |      8,664        0.04       91.67
         12 |    152,989        0.71       92.38
         13 |     71,263        0.33       92.72
         15 |      9,845        0.05       92.76
         16 |     13,536        0.06       92.83
         17 |     86,306        0.40       93.23
         18 |     47,941        0.22       93.45
         19 |     21,469        0.10       93.55
         20 |     22,338        0.10       93.66
         21 |     31,888        0.15       93.81
         22 |     28,776        0.13       93.94
         23 |      7,911        0.04       93.98
         24 |     40,223        0.19       94.17
         25 |     48,684        0.23       94.39
         26 |     65,444        0.31       94.70
         27 |     35,177        0.16       94.86
         28 |     16,994        0.08       94.94
         29 |     45,200        0.21       95.15
         30 |      7,453        0.03       95.19
         31 |     13,567        0.06       95.25
         32 |     24,785        0.12       95.37
         33 |      8,787        0.04       95.41
         34 |     50,561        0.24       95.64
         35 |     12,299        0.06       95.70
         36 |    118,674        0.55       96.26
         37 |     70,555        0.33       96.59
         38 |      5,884        0.03       96.61
         39 |     81,541        0.38       96.99
         40 |     28,921        0.14       97.13
         41 |     36,246        0.17       97.30
         42 |     76,201        0.36       97.65
         44 |      6,551        0.03       97.68
         45 |     33,552        0.16       97.84
         46 |      6,067        0.03       97.87
         47 |     48,061        0.22       98.09
         48 |    197,912        0.92       99.02
         49 |     25,798        0.12       99.14
         50 |      4,106        0.02       99.16
         51 |     64,560        0.30       99.46
         53 |     64,790        0.30       99.76
         54 |     10,532        0.05       99.81
         55 |     35,653        0.17       99.98
         56 |      5,023        0.02      100.00
------------+-----------------------------------
      Total | 21,418,794      100.00

. rename migplac1 state_fips_o

. tab migcounty1

 migcounty1 |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 | 19,952,847       93.16       93.16
          1 |     35,752        0.17       93.32
          3 |     58,525        0.27       93.60
          5 |     21,286        0.10       93.70
          7 |     13,720        0.06       93.76
          9 |     11,958        0.06       93.82
         11 |     23,663        0.11       93.93
         13 |     53,927        0.25       94.18
         15 |      7,126        0.03       94.21
         17 |     21,840        0.10       94.31
         19 |     24,348        0.11       94.43
         20 |      2,061        0.01       94.44
         21 |     12,848        0.06       94.50
         23 |      7,725        0.04       94.53
         25 |     21,090        0.10       94.63
         27 |     15,274        0.07       94.70
         29 |     32,454        0.15       94.85
         31 |     57,529        0.27       95.12
         33 |     33,851        0.16       95.28
         35 |     24,912        0.12       95.40
         37 |     72,280        0.34       95.73
         39 |     10,381        0.05       95.78
         41 |      8,696        0.04       95.82
         43 |      8,893        0.04       95.86
         45 |      5,998        0.03       95.89
         47 |     22,821        0.11       96.00
         49 |     21,522        0.10       96.10
         51 |     17,488        0.08       96.18
         53 |     17,759        0.08       96.26
         55 |     12,676        0.06       96.32
         57 |     18,309        0.09       96.41
         59 |     30,944        0.14       96.55
         61 |     31,725        0.15       96.70
         63 |     12,421        0.06       96.76
         65 |     18,670        0.09       96.85
         67 |     29,982        0.14       96.99
         69 |      4,036        0.02       97.01
         71 |     27,649        0.13       97.13
         73 |     36,959        0.17       97.31
         75 |     11,968        0.06       97.36
         77 |      8,293        0.04       97.40
         79 |      7,681        0.04       97.44
         81 |     30,275        0.14       97.58
         83 |      9,053        0.04       97.62
         85 |     28,918        0.14       97.76
         87 |      6,680        0.03       97.79
         89 |     10,158        0.05       97.83
         91 |     15,565        0.07       97.91
         93 |      4,960        0.02       97.93
         95 |     19,883        0.09       98.02
         97 |     19,460        0.09       98.11
         99 |     19,554        0.09       98.21
        101 |     14,457        0.07       98.27
        103 |     18,351        0.09       98.36
        105 |      7,421        0.03       98.39
        107 |      5,600        0.03       98.42
        109 |     10,761        0.05       98.47
        111 |     14,844        0.07       98.54
        113 |     30,918        0.14       98.68
        115 |      4,818        0.02       98.71
        117 |      7,798        0.04       98.74
        119 |     14,739        0.07       98.81
        121 |     10,181        0.05       98.86
        123 |      3,671        0.02       98.88
        125 |      9,036        0.04       98.92
        127 |      2,348        0.01       98.93
        129 |      1,814        0.01       98.94
        133 |      5,313        0.02       98.96
        135 |      7,844        0.04       99.00
        139 |      5,952        0.03       99.03
        141 |      6,936        0.03       99.06
        143 |      4,286        0.02       99.08
        145 |      1,975        0.01       99.09
        147 |      2,327        0.01       99.10
        149 |      2,146        0.01       99.11
        151 |      1,900        0.01       99.12
        153 |      5,155        0.02       99.14
        157 |     11,532        0.05       99.20
        159 |        751        0.00       99.20
        160 |        149        0.00       99.20
        161 |      4,716        0.02       99.22
        163 |     13,817        0.06       99.29
        165 |      2,418        0.01       99.30
        167 |      5,023        0.02       99.32
        169 |        850        0.00       99.33
        171 |        529        0.00       99.33
        173 |        264        0.00       99.33
        179 |      1,879        0.01       99.34
        183 |     11,521        0.05       99.39
        185 |        871        0.00       99.40
        187 |      2,303        0.01       99.41
        189 |      6,599        0.03       99.44
        191 |        759        0.00       99.44
        197 |      3,401        0.02       99.46
        201 |     29,158        0.14       99.59
        209 |      2,664        0.01       99.60
        215 |      3,046        0.01       99.62
        223 |        758        0.00       99.62
        227 |        946        0.00       99.63
        245 |      3,068        0.01       99.64
        251 |      1,020        0.00       99.65
        257 |        850        0.00       99.65
        303 |      3,247        0.02       99.67
        309 |      2,351        0.01       99.68
        313 |        456        0.00       99.68
        329 |      1,177        0.01       99.68
        339 |      3,176        0.01       99.70
        355 |      2,646        0.01       99.71
        367 |        977        0.00       99.72
        375 |      1,001        0.00       99.72
        381 |      1,199        0.01       99.73
        423 |      1,497        0.01       99.73
        439 |     14,652        0.07       99.80
        441 |      1,419        0.01       99.81
        451 |        952        0.00       99.81
        453 |     12,549        0.06       99.87
        479 |      1,301        0.01       99.88
        485 |      1,288        0.01       99.88
        491 |      4,036        0.02       99.90
        510 |     10,140        0.05       99.95
        550 |      1,187        0.01       99.95
        650 |      1,031        0.00       99.96
        700 |      1,438        0.01       99.97
        710 |        466        0.00       99.97
        760 |      2,799        0.01       99.98
        810 |      3,933        0.02      100.00
------------+-----------------------------------
      Total | 21,418,794      100.00

. rename migcounty1 county_fips_o

. 
. ** Use migrate1 to update values 
. 
. ** Within same house 
. replace state_fips_o = state_fips_d if migrate1 == 1
(19,172,129 real changes made)

. replace county_fips_o = county_fips_d if migrate1 == 1 
(11,640,515 real changes made)

. 
. ** Within same state 
. replace state_fips_o = state_fips_d if migrate1 == 2
(0 real changes made)

. 
. ** Generate county IDS 
. foreach x in "o" "d" {
  2.         
.         make_fips state_fips_`x' county_fips_`x', gen(fips_`x')
  3. 
. }

. 
. ** Check for within-state migration 
. gen same_county = fips_o == fips_d 

. tab year same_county

           |      same_county
      year |         0          1 |     Total
-----------+----------------------+----------
      2015 |    89,492  2,245,481 | 2,334,973 
      2016 |    91,109  2,255,901 | 2,347,010 
      2017 |    93,553  2,278,348 | 2,371,901 
      2018 |    96,080  2,306,022 | 2,402,102 
      2019 |    96,088  2,344,171 | 2,440,259 
      2020 |    71,827  1,877,155 | 1,948,982 
      2021 |    97,600  2,361,518 | 2,459,118 
      2022 |   106,231  2,430,426 | 2,536,657 
      2023 |    98,226  2,479,566 | 2,577,792 
-----------+----------------------+----------
     Total |   840,206 20,578,588 |21,418,794 

. tab year same_county if migrate1 == 2

           |      same_county
      year |         0          1 |     Total
-----------+----------------------+----------
      2015 |    42,597    172,956 |   215,553 
      2016 |    43,823    172,091 |   215,914 
      2017 |    45,058    174,386 |   219,444 
      2018 |    46,477    173,182 |   219,659 
      2019 |    46,329    168,101 |   214,430 
      2020 |    34,625    119,307 |   153,932 
      2021 |    46,470    148,925 |   195,395 
      2022 |    50,584    141,717 |   192,301 
      2023 |    47,498    135,794 |   183,292 
-----------+----------------------+----------
     Total |   403,461  1,406,459 | 1,809,920 

. 
. ** Tag HH head 
. gen byte hh_head = (relate == 1)

. 
. ** Compress file 
. compress 
  variable state_fips_o was int now byte
  variable hh_size was float now byte
  variable hh_adult_ct was float now byte
  variable hh_child_ct was float now byte
  variable same_county was float now byte
  (278,444,322 bytes saved)

. 
. ** Save 
. save "${data}working/acs_migration_file", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_migration_file.dta saved

. 
. // Keep only observations with valid origin/destination counties and YEAR
. drop if missing(year) | missing(fips_o) | missing(fips_d)
(0 observations deleted)

. 
. // Clean income (treat missing as 0; keep negative values as reported)
. replace inctot = 0 if missing(inctot)
(0 real changes made)

. gen double income_wt = inctot * perwt

. label var income_wt "Person income (INCTOT) weighted by PERWT"

. 
. // --- Persons + income totals by origin/destination/year
. preserve

. keep year fips_o fips_d perwt income_wt

. collapse (sum) persons=perwt income_total=income_wt, by(year fips_o fips_d)

. tempfile acs_pi

. save `acs_pi'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000f.tmp saved as .dta format

. restore

. 
. // --- Households by origin/destination/year
. // Use HHWT among household heads (RELATE==1) if available; else PERNUM==1 fallback.
. 
. preserve

. keep if hh_head
(10,269,992 observations deleted)

. keep year fips_o fips_d hhwt

. collapse (sum) households=hhwt, by(year fips_o fips_d)

. tempfile acs_hh

. save `acs_hh'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000h.tmp saved as .dta format

. restore

. 
. // --- Merge persons/income with households
. use `acs_pi', clear

. merge 1:1 year fips_o fips_d using `acs_hh', nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                        45,163
        from master                    45,163  
        from using                          0  

    Matched                           162,899  
    -----------------------------------------

. 
. label var persons "Estimated number of persons (sum PERWT)"

. label var households "Estimated number of households (sum HHWT among heads)"

. label var income_total "Estimated total personal income (sum INCTOT*PERWT)"

. 
. // --- Derive state/county components for merges with name crosswalk
. gen int state_fips_o  = floor(fips_o/1000)

. gen int county_fips_o = mod(fips_o,1000)

. gen int state_fips_d  = floor(fips_d/1000)

. gen int county_fips_d = mod(fips_d,1000)

. 
. label var state_fips_o "State FIPS (origin)"

. label var county_fips_o "County FIPS (origin)"

. label var state_fips_d "State FIPS (destination)"

. label var county_fips_d "County FIPS (destination)"

. 
. // --- Merge in names (from NHGIS IDs snapshot)
. preserve

. use "${data}working/ids", clear

. rename (state_fips county_fips state_name county_name) (state_fips_o county_fips_o state_name_o county_name_
> o)

. tempfile ids_o

. save `ids_o'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000j.tmp saved as .dta format

. keep state_fips_o state_name_o 

. duplicates drop 

Duplicates in terms of all variables

(3,169 observations deleted)

. tempfile state_ids_o

. save `state_ids_o'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000k.tmp saved as .dta format

. restore

. merge m:1 state_fips_o county_fips_o using `ids_o', keep(master match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                        46,997
        from master                    46,997  
        from using                          0  

    Matched                           161,065  
    -----------------------------------------

. drop state_name_o 

. merge m:1 state_fips_o using `state_ids_o', keep(master match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           208,062  
    -----------------------------------------

. 
. preserve

. use "${data}working/ids", clear

. rename (state_fips county_fips state_name county_name) (state_fips_d county_fips_d state_name_d county_name_
> d)

. tempfile ids_d

. save `ids_d'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000m.tmp saved as .dta format

. keep state_fips_d state_name_d 

. duplicates drop 

Duplicates in terms of all variables

(3,169 observations deleted)

. tempfile state_ids_d

. save `state_ids_d'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000n.tmp saved as .dta format

. restore

. 
. merge m:1 state_fips_d county_fips_d using `ids_d', keep(master match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                        50,197
        from master                    50,197  
        from using                          0  

    Matched                           157,865  
    -----------------------------------------

. drop state_name_d

. merge m:1 state_fips_d using `state_ids_d', keep(master match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           208,062  
    -----------------------------------------

. order year ///
>     state_fips_o county_fips_o state_name_o county_name_o fips_o ///
>     state_fips_d county_fips_d state_name_d county_name_d fips_d ///
>     persons households income_total

. 
. sort year state_fips_o county_fips_o state_fips_d county_fips_d

. 
. replace county_name_o = "Other" if county_fips_o == 0 
(46,948 real changes made)

. replace county_name_d = "Other" if county_fips_d == 0 
(49,676 real changes made)

. 
. save "${data}working/acs_county_flow", replace
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_county_flow.dta saved

. 
. // Optional: Multnomah-focused flow extract (origin = Multnomah County, OR)
. // Multnomah County, OR = state 41, county 051
. preserve

. keep if state_fips_o == 41 & county_fips_o == 51
(207,316 observations deleted)

. save "${data}working/multnomah_acs_flow", replace
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/multnomah_acs_flow.dta saved

. clear

. 
. ** Create gross-migration files for ACS 
. 
. ** All (18+)
. acs_make_gross_migration using "${data}working/acs_migration_file", ///
>     saving("${data}working/acs_county_gross_18plus", replace)
(0 observations deleted)
(0 real changes made)
(10,269,992 missing values generated)
(10,269,992 real changes made)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000q.tmp not found)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000q.tmp saved as .dta format
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000s.tmp not found)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000s.tmp saved as .dta format

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                             4,332  
    -----------------------------------------
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           448
        from master                       448  
        from using                          0  

    Matched                             3,884  
    -----------------------------------------
  variable state_fips was int now byte
  variable fips was double now long
  variable persons_in_1 was double now long
  variable persons_in_4 was double now long
  variable persons_in_5 was double now long
  variable households_in_1 was double now long
  variable households_in_4 was double now long
  variable households_in_5 was double now long
  variable persons_in_2 was double now long
  variable persons_in_3 was double now long
  variable households_in_2 was double now long
  variable households_in_3 was double now long
  variable persons_out_1 was double now long
  variable persons_out_4 was double now long
  variable persons_out_5 was double now long
  variable households_out_1 was double now long
  variable households_out_4 was double now long
  variable households_out_5 was double now long
  variable persons_out_2 was double now long
  variable persons_out_3 was double now long
  variable households_out_2 was double now long
  variable households_out_3 was double now long
  variable persons_net_2 was double now long
  variable persons_net_3 was double now long
  variable persons_net_4 was double now long
  variable persons_net_5 was double now long
  variable households_net_2 was double now long
  variable households_net_3 was double now long
  variable households_net_4 was double now long
  variable households_net_5 was double now long
  variable county_name was str46 now str23
  (606,480 bytes saved)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_county_gross_18plus , replace.dta
    saved

.         
. 
. //----------------------------------------------------
. // STEP 4: Import and Clean IRS Migration Data 
. //----------------------------------------------------
. 
. ** Loop over years 
. forvalues y = 15(1)21 {
  2.         
.         local start = `y'
  3.         local end = `y' + 1 
  4.         
.         ** Import data (out)
.         import delimited "${data}irs/countyoutflow`start'`end'.csv", clear 
  5.         
.         ** Describe data 
.         des 
  6.         
.         ** Generate year 
.         gen year = 2000 + `y' 
  7.         
.         ** Drop Regional Values 
.         drop if y2_state == "DS"
  8.         
.         ** Drop Foreign Migration 
.         drop if y2_state == "FR"
  9.         
.         ** Drop observations without a county
.         drop if y1_countyfips == 0 
 10.         
.         ** Deal with suppressed values 
.         unsuppress n1 n2 agi
 11.         
.         ** Drop unnecc variables 
.         drop y2_state y2_countyname
 12.                 
.         ** Create two versions: gross and net 
.         tempfile tmp
 13.         save `tmp'
 14.         
.         ** Gross first 
.         
.         ** Keep gross categories 
.         keep if ///
>                 (y1_statefips == y2_statefips & y1_countyfips == y2_countyfips) |       ///
>                 inlist(y2_statefips, 96, 97, 98)
 15. 
.         ** Clean up 
.         gen move_type = 0 
 16.         
.         ** Stayers 
.         replace move_type = 1 if        (y1_statefips == y2_statefips) &        ///
>                                                                 (y1_countyfips == y2_countyfips) 
 17.         
.         ** Movers
.         replace move_type = 2 if        y2_statefips == 96              // ALL 
 18.         replace move_type = 3 if        y2_statefips == 97 &    ///
>                                                                 y2_countyfips == 0              // Domestic 
> Total
 19.         replace move_type = 4 if        y2_statefips == 97 &    ///
>                                                                 y2_countyfips == 1              // Within-st
> ate
 20.         replace move_type = 5 if        y2_statefips == 97 &    ///
>                                                                 y2_countyfips == 3              // Between-s
> tates 
 21.         replace move_type = 6 if        y2_statefips == 98              // Foreign 
 22.         
.         ** Label movers 
.         label values move_type lb_move_type 
 23.         
.         ** Generate total category 
.         foreach var of varlist n1 n2 agi {
 24.                 
.                 gen tmp = `var' if inlist(move_type, 1, 2)
 25.                 bysort y1_statefips y1_countyfips: egen `var'_total = total(tmp)
 26.                 drop tmp 
 27.                 
.         } // END VAR LOOP 
 28.         
.         ** Drop unnecc variables 
.         drop y2_* 
 29.         
.         ** Sort 
.         sort year y1_statefips y1_countyfips move_type 
 30. 
.         ** Order 
.         order year y1_statefips y1_countyfips move_type 
 31.         
.         ** Rename 
.         rename y1_countyfips county_fips 
 32.         rename y1_statefips state_fips 
 33.         
.         ** Label variables 
.         label var year "Tax year (year before move)"
 34.         label var state_fips "State FIPS code (origin state)"
 35.         label var county_fips "County FIPS code (origin county)"
 36.         label var move_type "Mover category"
 37.         label var n1 "Number of returns"
 38.         label var n2 "Number of exemptions"
 39.         label var agi "Adjusted Gross Income"
 40.         label var n1_total "Number of returns, county total (origin)"
 41.         label var n2_total "Number of exemptions, county total (origin)"
 42.         label var agi_total "Adjusted Gross Income, county total (origin)"
 43.         
.         ** Save 
.         save "${data}working/irs_county_gross_out_`y'", replace 
 44.         
.         ** Create version for merge with net 
.         keep if move_type == 3 
 45.         
.         ** Rename variables 
.         rename n1 n1_mover
 46.         rename n2 n2_mover 
 47.         rename agi agi_mover 
 48.         
.         label var n1_mover "Number of domestic mover returns"
 49.         label var n2_mover "Number of domestic mover exemptions"
 50.         label var agi_mover "Adjusted Gross Income, domestic movers"
 51.         
.         ** Save as temp file 
.         tempfile merge 
 52.         save `merge'
 53.         clear 
 54.         
.         ** Next, create flow file 
.         use `tmp', clear 
 55.         
.         ** Drop aggregate values 
.         drop if inlist(y2_statefips, 96, 97, 98)
 56.         drop if (y1_statefips == y2_statefips & y1_countyfips == y2_countyfips) 
 57.         
.         ** Sort 
.         sort year y1_statefips y1_countyfips y2_statefips y2_countyfips 
 58. 
.         ** Order 
.         order year y1_statefips y1_countyfips y2_statefips y2_countyfips
 59. 
.         
.         ** Rename 
.         rename y1_countyfips county_fips 
 60.         rename y1_statefips state_fips 
 61.         rename y2_countyfips y2_county_fips 
 62.         rename y2_statefips y2_state_fips       
 63.         
.         ** Label variables 
.         label var year "Tax year (year before move)"
 64.         label var state_fips "State FIPS code (origin state)"
 65.         label var county_fips "County FIPS code (origin county)"
 66.         label var y2_state_fips "State FIPS code (dest. state)"
 67.         label var y2_county_fips "County FIPS code (dest. county)"      
 68.         label var n1 "Number of returns"
 69.         label var n2 "Number of exemptions"
 70.         label var agi "Adjusted Gross Income"
 71.         
.         ** Merge with county of origin data 
.         merge m:1 state_fips county_fips using `merge', nogen keep(master match)
 72.         
.         ** Rename 
.         rename state_fips state_fips_o
 73.         rename county_fips county_fips_o
 74.         rename y2_* *_d 
 75.         
.         ** Dropo unnecc variable 
.         drop move_type 
 76.         
.         ** Save 
.         save "${data}working/irs_county_flow_`y'", replace 
 77.         clear
 78.         
.         ** Import data (in)
.         import delimited "${data}irs/countyinflow`start'`end'.csv", clear 
 79.         
.         ** Describe data 
.         des 
 80. 
.         ** Generate year 
.         gen year = 2000 + `y' 
 81.         
.         ** Drop Regional Values 
.         drop if y1_state == "DS"
 82.         
.         ** Drop Foreign Migration 
.         drop if y1_state == "FR"
 83.         
.         ** Drop observations with no county ID 
.         drop if y2_countyfips == 0 
 84.         
.         ** Keep gross categories 
.         keep if ///
>                 (y1_statefips == y2_statefips & y1_countyfips == y2_countyfips) |       ///
>                 inlist(y1_statefips, 96, 97, 98)
 85. 
.         ** Clean up 
.         gen move_type = 0 
 86.         
.         ** Deal with suppressed values 
.         unsuppress n1 n2 agi
 87.         
.         ** Stayers 
.         replace move_type = 1 if        (y1_statefips == y2_statefips) &        ///
>                                                                 (y1_countyfips == y2_countyfips) 
 88.         
.         ** Movers
.         replace move_type = 2 if        y1_statefips == 96              // ALL 
 89.         replace move_type = 3 if        y1_statefips == 97 &    ///
>                                                                 y1_countyfips == 0              // Domestic 
> Total
 90.         replace move_type = 4 if        y1_statefips == 97 &    ///
>                                                                 y1_countyfips == 1              // Within-st
> ate
 91.         replace move_type = 5 if        y1_statefips == 97 &    ///
>                                                                 y1_countyfips == 3              // Between-s
> tates 
 92.         replace move_type = 6 if        y1_statefips == 98              // Foreign 
 93.         
.         ** Label move variable  
.         label values move_type lb_move_type 
 94.         
.         ** Generate total category 
.         foreach var of varlist n1 n2 agi {
 95.                 
.                 gen tmp = `var' if inlist(move_type, 1, 2)
 96.                 bysort y2_statefips y2_countyfips: egen `var'_total = total(tmp)
 97.                 drop tmp 
 98.                 
.         } // END VAR LOOP 
 99.         
.         ** Drop unnecc variables 
.         drop y1_*
100.         
.         ** Sort 
.         sort year y2_statefips y2_countyfips move_type 
101. 
.         ** Order 
.         order year y2_statefips y2_countyfips move_type 
102.         
.         ** Rename 
.         rename y2_countyfips county_fips 
103.         rename y2_statefips state_fips 
104.         
.         ** Label variables 
.         label var year "Tax year (year before move)"
105.         label var state_fips "State FIPS code (dest. state)"
106.         label var county_fips "County FIPS code (dest. county)"
107.         label var move_type "Mover category"
108.         label var n1 "Number of returns"
109.         label var n2 "Number of exemptions"
110.         label var agi "Adjusted Gross Income"
111.         label var n1_total "Number of returns, county total (dest.)"
112.         label var n2_total "Number of exemptions, county total (dest.)"
113.         label var agi_total "Adjusted Gross Income, county total (dest.)"
114.         
.         ** Save 
.         save "${data}working/irs_county_gross_in_`y'", replace 
115.         clear 
116.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-8859-1)
(9 vars, 86,481 obs)

Contains data
 Observations:        86,481                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,289 observations deleted)
(2,937 observations deleted)
(254 observations deleted)
(2,056 real changes made)
(2,056 real changes made)
(2,056 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000p.tmp saved as .dta format
(50,007 observations deleted)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,291 real changes made)
(11,712 missing values generated)
(11,712 missing values generated)
(11,712 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_15.dta saved
(14,853 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000q.tmp saved as .dta format
(14,853 observations deleted)
(3,141 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            50,007  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_15.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 86,330 obs)

Contains data
 Observations:        86,330                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,315 observations deleted)
(2,814 observations deleted)
(254 observations deleted)
(50,005 observations deleted)
(2,041 real changes made)
(2,041 real changes made)
(2,041 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,239 real changes made)
(11,660 missing values generated)
(11,660 missing values generated)
(11,660 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_15.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 98,948 obs)

Contains data
 Observations:        98,948                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,372 observations deleted)
(2,360 observations deleted)
(254 observations deleted)
(1,877 real changes made)
(1,877 real changes made)
(1,877 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000r.tmp saved as .dta format
(63,249 observations deleted)
(3,140 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,141 real changes made)
(2,010 real changes made)
(11,432 missing values generated)
(11,432 missing values generated)
(11,432 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_16.dta saved
(14,572 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000s.tmp saved as .dta format
(14,573 observations deleted)
(3,140 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            63,249  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_16.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 98,874 obs)

Contains data
 Observations:        98,874                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,432 observations deleted)
(2,282 observations deleted)
(254 observations deleted)
(63,249 observations deleted)
(1,788 real changes made)
(1,788 real changes made)
(1,788 real changes made)
(3,140 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(1,955 real changes made)
(11,376 missing values generated)
(11,376 missing values generated)
(11,376 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_16.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,820 obs)

Contains data
 Observations:        87,820                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,300 observations deleted)
(2,364 observations deleted)
(254 observations deleted)
(1,942 real changes made)
(1,942 real changes made)
(1,942 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000t.tmp saved as .dta format
(52,173 observations deleted)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,026 real changes made)
(11,447 missing values generated)
(11,447 missing values generated)
(11,447 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_17.dta saved
(14,588 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000u.tmp saved as .dta format
(14,588 observations deleted)
(3,141 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            52,173  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_17.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,932 obs)

Contains data
 Observations:        87,932                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,368 observations deleted)
(2,403 observations deleted)
(254 observations deleted)
(52,174 observations deleted)
(1,919 real changes made)
(1,919 real changes made)
(1,919 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,030 real changes made)
(11,451 missing values generated)
(11,451 missing values generated)
(11,451 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_17.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 83,878 obs)

Contains data
 Observations:        83,878                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,919 observations deleted)
(2,298 observations deleted)
(0 observations deleted)
(53 real changes made)
(53 real changes made)
(53 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000v.tmp saved as .dta format
(51,090 observations deleted)
(3,141 real changes made)
(3,107 real changes made)
(3,107 real changes made)
(3,103 real changes made)
(2,778 real changes made)
(335 real changes made)
(9,323 missing values generated)
(9,323 missing values generated)
(9,323 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_18.dta saved
(12,464 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000w.tmp saved as .dta format
(12,430 observations deleted)
(3,141 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            34
        from master                        34  
        from using                          0  

    Matched                            51,056  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_18.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 83,762 obs)

Contains data
 Observations:        83,762                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,890 observations deleted)
(2,290 observations deleted)
(0 observations deleted)
(51,090 observations deleted)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3,141 real changes made)
(3,086 real changes made)
(3,086 real changes made)
(3,082 real changes made)
(2,729 real changes made)
(368 real changes made)
(9,265 missing values generated)
(9,265 missing values generated)
(9,265 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_18.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,325 obs)

Contains data
 Observations:        87,325                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,937 observations deleted)
(2,272 observations deleted)
(0 observations deleted)
(62 real changes made)
(62 real changes made)
(62 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_00000x.tmp saved as .dta format
(54,560 observations deleted)
(3,142 real changes made)
(3,104 real changes made)
(3,104 real changes made)
(3,101 real changes made)
(2,773 real changes made)
(332 real changes made)
(9,310 missing values generated)
(9,310 missing values generated)
(9,310 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_19.dta saved
(12,452 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000010.tmp saved as .dta format
(12,414 observations deleted)
(3,142 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            38
        from master                        38  
        from using                          0  

    Matched                            54,522  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_19.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 87,552 obs)

Contains data
 Observations:        87,552                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,060 observations deleted)
(2,323 observations deleted)
(0 observations deleted)
(54,560 observations deleted)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3,142 real changes made)
(3,102 real changes made)
(3,102 real changes made)
(3,097 real changes made)
(2,805 real changes made)
(361 real changes made)
(9,365 missing values generated)
(9,365 missing values generated)
(9,365 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_19.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 89,511 obs)

Contains data
 Observations:        89,511                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,963 observations deleted)
(2,175 observations deleted)
(0 observations deleted)
(79 real changes made)
(79 real changes made)
(79 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000011.tmp saved as .dta format
(56,831 observations deleted)
(3,143 real changes made)
(3,097 real changes made)
(3,097 real changes made)
(3,094 real changes made)
(2,787 real changes made)
(324 real changes made)
(9,302 missing values generated)
(9,302 missing values generated)
(9,302 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_20.dta saved
(12,445 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000012.tmp saved as .dta format
(12,399 observations deleted)
(3,143 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            46
        from master                        46  
        from using                          0  

    Matched                            56,785  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_20.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 89,850 obs)

Contains data
 Observations:        89,850                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,132 observations deleted)
(2,263 observations deleted)
(0 observations deleted)
(56,835 observations deleted)
(1 real change made)
(1 real change made)
(1 real change made)
(3,143 real changes made)
(3,101 real changes made)
(3,101 real changes made)
(3,098 real changes made)
(2,838 real changes made)
(339 real changes made)
(9,376 missing values generated)
(9,376 missing values generated)
(9,376 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_20.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 90,409 obs)

Contains data
 Observations:        90,409                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y2_state        str2    %9s                   
y2_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(14,962 observations deleted)
(2,223 observations deleted)
(0 observations deleted)
(64 real changes made)
(64 real changes made)
(64 real changes made)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000013.tmp saved as .dta format
(57,644 observations deleted)
(3,144 real changes made)
(3,107 real changes made)
(3,107 real changes made)
(3,103 real changes made)
(2,790 real changes made)
(329 real changes made)
(9,329 missing values generated)
(9,329 missing values generated)
(9,329 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out_21.dta saved
(12,473 observations deleted)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000014.tmp saved as .dta format
(12,436 observations deleted)
(3,144 observations deleted)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            37
        from master                        37  
        from using                          0  

    Matched                            57,607  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow_21.dta saved
(encoding automatically selected: ISO-8859-1)
(9 vars, 90,498 obs)

Contains data
 Observations:        90,498                  
    Variables:             9                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
y2_statefips    byte    %8.0g                 
y2_countyfips   int     %8.0g                 
y1_statefips    byte    %8.0g                 
y1_countyfips   int     %8.0g                 
y1_state        str2    %9s                   
y1_countyname   str60   %60s                  
n1              long    %12.0g                
n2              long    %12.0g                
agi             long    %12.0g                
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
(15,093 observations deleted)
(2,179 observations deleted)
(0 observations deleted)
(57,640 observations deleted)
(1 real change made)
(1 real change made)
(1 real change made)
(3,144 real changes made)
(3,098 real changes made)
(3,098 real changes made)
(3,094 real changes made)
(2,822 real changes made)
(330 real changes made)
(9,344 missing values generated)
(9,344 missing values generated)
(9,344 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in_21.dta saved

. 
. ** Append data 
. 
. ** Loop over datasets 
. foreach file in "irs_county_gross_in" "irs_county_gross_out" "irs_county_flow"{
  2.         
.                 
.         ** Loop over years 
.         forvalues y = 15(1)21 {
  3. 
.                 ** Append 
.                 append using "${data}working/`file'_`y'"
  4.                 
.         } // END YEAR LOOP 
  5.         
.         
.         ** Order and sort flow file 
.         if "`file'" == "irs_county_flow" {
  6.                 
.                 ** Loop over orgin and destination state 
.                 foreach x in "o" "d" {
  7.                         
.                         ** Rename 
.                         rename *_fips_`x' *_fips 
  8.                         
.                         ** Merge with county and state names 
.                         merge m:1 state_fips county_fips using "${data}working/ids",    ///
>                                 keep(match) nogen 
  9.                                 
.                         ** Rename 
.                         rename *_fips *_fips_`x' 
 10.                         rename *_name *_name_`x' 
 11.                         
.                         ** Generate county IDS 
.                         make_fips state_fips_`x' county_fips_`x', gen(fips_`x')
 12.                         
.                 } // END ORIGIN / DESTINATION LOOP 
 13.                 
.                 ** Order file 
.                 order year state_*_o county_*_o state_*_d county_*_d  
 14.                 sort year state_*_o county_*_o state_*_d county_*_d  
 15. 
.         } // END MIGRATION FLOW IF-STATEMENT 
 16.         
.         else {
 17.                 
.                 ** Merge with county and state names 
.                 merge m:1 state_fips county_fips using "${data}working/ids",    ///
>                                 keep(match) nogen 
 18.                                 
.                 ** Order 
.                 order year state_* county* move_type
 19.                 
.         } 
 20.         
.         ** Save file 
.         save "${data}working/`file'", replace 
 21.         clear 
 22.         
. } // END FILE LOOP 

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           115,567  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_in.dta saved

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           115,611  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross_out.dta saved

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           384,896  
    -----------------------------------------

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                           362,678  
    -----------------------------------------
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_flow.dta saved

. 
. ** Create gross file with in and out migration 
. use "${data}working/irs_county_gross_in", clear 

. 
. ** Rename 
. rename n1 n1_in_

. rename n2 n2_in_

. rename agi agi_in_

. rename *_total *_total_in

. 
. ** Reshape 
. reshape wide n1_in_ n2_in_ agi_in_, i(year state_fips county_fips) j(move_type)
(j = 1 2 3 4 5 6)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations          115,567   ->   21,980      
Number of variables                  13   ->   27          
j variable (6 values)         move_type   ->   (dropped)
xij variables:
                                 n1_in_   ->   n1_in_1 n1_in_2 ... n1_in_6
                                 n2_in_   ->   n2_in_1 n2_in_2 ... n2_in_6
                                agi_in_   ->   agi_in_1 agi_in_2 ... agi_in_6
-----------------------------------------------------------------------------

. 
. ** Define locals 
. local txt1 "Non-movers"

. local txt2 "All movers"                 

. local txt3 "Domestic movers"            

. local txt4 "Within-state movers"        

. local txt5 "Inter-state movers" 

. local txt6 "Foreign movers"

. 
. ** Label variables, in loop 
. foreach n of numlist 1(1)6 {
  2.         
.         label var n1_in_`n' "Returns, in-migration, `txt`n''"
  3.         label var n2_in_`n' "Exemptions, in-migration, `txt`n''"
  4.         label var agi_in_`n' "AGI, in-migration, `txt`n''"
  5. 
. } // END NUMLIST LOOP 

. 
. ** Preserve 
. tempfile gross_in

. save `gross_in'
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000015.tmp saved as .dta format

. clear

. 
. ** Create gross file with in and out migration 
. use "${data}working/irs_county_gross_out", clear 

. 
. ** Rename 
. rename n1 n1_out_

. rename n2 n2_out_

. rename agi agi_out_

. rename *_total *_total_out

. 
. ** Reshape 
. reshape wide n1_out_ n2_out_ agi_out_, i(year state_fips county_fips) j(move_type)
(j = 1 2 3 4 5 6)

Data                               Long   ->   Wide
-----------------------------------------------------------------------------
Number of observations          115,611   ->   21,980      
Number of variables                  13   ->   27          
j variable (6 values)         move_type   ->   (dropped)
xij variables:
                                n1_out_   ->   n1_out_1 n1_out_2 ... n1_out_6
                                n2_out_   ->   n2_out_1 n2_out_2 ... n2_out_6
                               agi_out_   ->   agi_out_1 agi_out_2 ... agi_out_6
-----------------------------------------------------------------------------

. 
. ** Define locals 
. local txt1 "Non-movers"

. local txt2 "All movers"                 

. local txt3 "Domestic movers"            

. local txt4 "Within-state movers"        

. local txt5 "Inter-state movers" 

. local txt6 "Foreign movers"

. 
. ** Label variables, in loop 
. foreach n of numlist 1(1)6 {
  2.         
.         label var n1_out_`n' "Returns, out-migration, `txt`n''"
  3.         label var n2_out_`n' "Exemptions, out-migration, `txt`n''"
  4.         label var agi_out_`n' "AGI, out-migration, `txt`n''"
  5. 
. } // END NUMLIST LOOP 

. 
. ** Merge data 
. merge 1:1 year state_fips county_fips using `gross_in', keep(match) nogen

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                            21,980  
    -----------------------------------------

. 
. ** Text for correct matching (non-movers should match perfectly)
. summ n*_*_1 agi_*_1

    Variable |        Obs        Mean    Std. dev.       Min        Max
-------------+---------------------------------------------------------
    n1_out_1 |     21,979    37461.71    123155.4          0    3944880
    n2_out_1 |     21,979    78000.79    252081.2          0    7841705
     n1_in_1 |     21,979    37461.71    123155.4          0    3944880
     n2_in_1 |     21,979    78000.79    252081.2          0    7841705
   agi_out_1 |     21,979     3214755    1.23e+07      -8051   4.30e+08
-------------+---------------------------------------------------------
    agi_in_1 |     21,979     3214755    1.23e+07      -8051   4.30e+08

. 
. ** Define net migration variables 
. 
. ** Loop over variable
. foreach a in "n1" "n2" "agi" {
  2. 
.         if "`a'" == "n1" local txt "Returns"
  3.         else if "`a'" == "n2" local txt "Exemptions"
  4.         else if "`a'" == "agi" local txt "AGI"
  5. 
.         ** Loop over type of movers 
.         forvalues n = 2/6 {
  6.                 
.                 ** Clean up missing values 
.                 replace `a'_in_`n' = 0 if missing(`a'_in_`n')
  7.                 replace `a'_out_`n' = 0 if missing(`a'_out_`n')
  8. 
.                 ** Generate net 
.                 gen `a'_net_`n' = `a'_in_`n' - `a'_out_`n'
  9.                 label var `a'_net_`n' "`txt', net-migration, `txt`n''"
 10. 
.         } // END MOVER TYPE LOOP 
 11. 
. } // END VARIABLE LOOP 
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)

. 
. ** Generate fips variable
. *make_fips state_fips county_fips, gen(fips)
. 
. ** Save file 
. save "${data}working/irs_county_gross", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_gross.dta saved

. clear

. 
. //-----------------------------------------------------
. // STEP 4: Import and Clean IRS County-Level Aggr. Data 
. //-----------------------------------------------------
. 
. ** Loop over years 
. forvalues y = 15(1)22 {
  2.         
.         
.         ** Import data (out)
.         import delimited "${data}irs/`y'incyallagi.csv", clear 
  3. 
.         ** Describe data 
.         des 
  4.         
.         ** Generate year 
.         gen year = 2000 + `y' 
  5.         
.         ** Define AGI groups 
.         label var agi_stub "AGI Brackets"
  6.         label values agi_stub lb_agi 
  7.         
.         ** Define set of variables to keep 
.         keep state* county* agi_stub year n1 mars1 mars2 mars4 n2 elderly       ///
>                 a00100 n02650 a02650 n00200 a00200 
  8.                 
.         ** Rename variables 
.         rename a00100 agi 
  9.         rename n02650 n_total_inc
 10.         rename a02650 a_total_inc
 11.         rename n00200 n_wage
 12.         rename a00200 a_wage 
 13.         rename statefips state_fips
 14.         rename state state_abb 
 15.         rename countyfips county_fips 
 16.         rename countyname county_name 
 17.         
.         ** Rescale 
.         replace agi = 1000 * agi 
 18.         replace a_total_inc = 1000 * a_total_inc
 19.         replace a_wage = 1000 * a_wage 
 20.         
.         ** Label 
.         label var n1 "Number of returns"
 21.         label var mars1 "Number of single returns"
 22.         label var mars1 "Number of MFJ returns"
 23.         label var mars1 "Number of HoH returns"
 24.         label var n2 "Number of individuals"
 25.         label var elderly "Number of returns with one individual over 60"
 26.         label var agi "Adjusted Gross Income (AGI)"
 27.         label var n_total_inc "Number of returns with total income"
 28.         label var a_total_inc "Total income amount"
 29.         label var n_wage "Number of returns with wage income"
 30.         label var a_wage "Wage income amount"
 31.         
.         ** Sort 
.         sort year state_fips county_fips agi_stub 
 32.         
.         ** Order 
.         order year state* county* agi_stub 
 33.         
.         ** Save 
.         save "${data}working/irs_county_all_`y'", replace 
 34.         
.         clear 
 35.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-8859-1)
(132 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           132                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
prep            long    %12.0g                PREP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %12.0g                TOTAL_VITA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
ral             long    %8.0g                 RAL
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n03230          long    %8.0g                 N03230
a03230          long    %12.0g                A03230
n03240          int     %8.0g                 N03240
a03240          long    %12.0g                A03240
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %12.0g                N18450
a18450          long    %12.0g                A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %12.0g                N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %12.0g                N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07220          long    %12.0g                N07220
a07220          long    %12.0g                A07220
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %12.0g                N09750
a09750          long    %8.0g                 A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,283 real changes made)
variable a_total_inc was long now double
(25,283 real changes made)
variable a_wage was long now double
(24,576 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_15.dta saved
(encoding automatically selected: ISO-8859-1)
(148 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           148                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
prep            long    %12.0g                PREP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %8.0g                 TOTAL_VITA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
ral             long    %8.0g                 RAL
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %8.0g                 N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n03230          long    %8.0g                 N03230
a03230          long    %8.0g                 A03230
n03240          int     %8.0g                 N03240
a03240          long    %12.0g                A03240
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %12.0g                N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %12.0g                N18450
a18450          long    %12.0g                A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %12.0g                A18800
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %12.0g                N19550
a19550          long    %12.0g                A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20800          long    %12.0g                N20800
a20800          long    %12.0g                A20800
n21020          long    %8.0g                 N21020
a21020          long    %12.0g                A21020
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %12.0g                N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07220          long    %12.0g                N07220
a07220          long    %12.0g                A07220
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %12.0g                N09750
a09750          long    %12.0g                A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,267 real changes made)
variable a_total_inc was long now double
(25,267 real changes made)
variable a_wage was long now double
(24,662 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_16.dta saved
(encoding automatically selected: ISO-8859-1)
(154 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           154                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %12.0g                CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %12.0g                TOTAL_VITA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n03230          long    %8.0g                 N03230
a03230          long    %8.0g                 A03230
n03240          long    %8.0g                 N03240
a03240          long    %12.0g                A03240
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %12.0g                N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %12.0g                N18450
a18450          long    %12.0g                A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %12.0g                A18800
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %8.0g                 N19550
a19550          long    %8.0g                 A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20800          long    %12.0g                N20800
a20800          long    %12.0g                A20800
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %12.0g                N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %12.0g                N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07220          long    %12.0g                N07220
a07220          long    %12.0g                A07220
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %12.0g                N09750
a09750          long    %12.0g                A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %12.0g                N12000
a12000          long    %12.0g                A12000
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,280 real changes made)
variable a_total_inc was long now double
(25,280 real changes made)
variable a_wage was long now double
(24,634 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_17.dta saved
(encoding automatically selected: ISO-8859-1)
(154 vars, 25,536 obs)

Contains data
 Observations:        25,536                  
    Variables:           154                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %12.0g                CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
n2              long    %12.0g                N2
numdep          long    %12.0g                NUMDEP
total_vita      long    %12.0g                TOTAL_VITA
vita            long    %8.0g                 VITA
tce             long    %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01750          long    %12.0g                N01750
a01750          long    %12.0g                A01750
schf            long    %8.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %8.0g                 N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          long    %12.0g                N07180
a07180          long    %12.0g                A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n09750          long    %12.0g                N09750
a09750          long    %8.0g                 A09750
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %12.0g                N12000
a12000          long    %12.0g                A12000
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,325 real changes made)
variable a_total_inc was long now double
(25,325 real changes made)
variable a_wage was long now double
(24,672 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_18.dta saved
(encoding automatically selected: ISO-8859-1)
(153 vars, 25,544 obs)

Contains data
 Observations:        25,544                  
    Variables:           153                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str24   %24s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %8.0g                 CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VITA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          float   %9.0g                 A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %8.0g                 N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %8.0g                 N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          long    %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          int     %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %8.0g                 A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %8.0g                 N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %8.0g                 N12000
a12000          long    %12.0g                A12000
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,363 real changes made)
(25,363 real changes made)
variable a_wage was long now double
(24,724 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_19.dta saved
(encoding automatically selected: ISO-8859-1)
(166 vars, 25,545 obs)

Contains data
 Observations:        25,545                  
    Variables:           166                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %8.0g                 CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
vrtcrind        long    %8.0g                 VRTCRIND
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VITA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          float   %9.0g                 A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %8.0g                 N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            float   %9.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %8.0g                 N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %8.0g                 N03210
a03210          long    %8.0g                 A03210
n02910          long    %12.0g                N02910
a02910          long    %12.0g                A02910
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          int     %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %8.0g                 N19550
a19550          long    %8.0g                 A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          int     %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %8.0g                 N85770
a85770          long    %12.0g                A85770
n85775          long    %8.0g                 N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %8.0g                 N10960
a10960          long    %8.0g                 A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n11450          long    %8.0g                 N11450
a11450          long    %8.0g                 A11450
n10970          long    %12.0g                N10970
a10970          long    %12.0g                A10970
n10971          long    %12.0g                N10971
a10971          long    %12.0g                A10971
n10973          long    %12.0g                N10973
a10973          long    %12.0g                A10973
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %8.0g                 N12000
a12000          long    %12.0g                A12000
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,410 real changes made)
(25,410 real changes made)
variable a_wage was long now double
(24,896 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_20.dta saved
(encoding automatically selected: ISO-8859-1)
(168 vars, 25,552 obs)

Contains data
 Observations:        25,552                  
    Variables:           168                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %12.0g                CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
vrtcrind        long    %12.0g                VRTCRIND
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VITA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          float   %9.0g                 A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %12.0g                N00700
a00700          long    %12.0g                A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            float   %9.0g                 SCHF
n02300          long    %12.0g                N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %12.0g                N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %12.0g                N03210
a03210          long    %12.0g                A03210
n02910          long    %12.0g                N02910
a02910          long    %12.0g                A02910
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %8.0g                 N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          int     %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19550          long    %8.0g                 N19550
a19550          long    %8.0g                 A19550
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          long    %8.0g                 N09600
a09600          long    %12.0g                A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %12.0g                N07300
a07300          long    %12.0g                A07300
n07180          int     %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %12.0g                A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %12.0g                N10960
a10960          long    %12.0g                A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n11450          long    %8.0g                 N11450
a11450          long    %12.0g                A11450
n11520          long    %12.0g                N11520
a11520          long    %12.0g                A11520
n11530          long    %8.0g                 N11530
a11530          long    %12.0g                A11530
n10970          long    %12.0g                N10970
a10970          long    %12.0g                A10970
n10971          long    %12.0g                N10971
a10971          long    %12.0g                A10971
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %12.0g                N12000
a12000          long    %12.0g                A12000
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,456 real changes made)
(25,456 real changes made)
variable a_wage was long now double
(24,659 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_21.dta saved
(encoding automatically selected: ISO-8859-1)
(166 vars, 25,552 obs)

Contains data
 Observations:        25,552                  
    Variables:           166                  
--------------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
--------------------------------------------------------------------------------------------------------------
statefips       byte    %8.0g                 STATEFIPS
state           str2    %9s                   STATE
countyfips      int     %8.0g                 COUNTYFIPS
countyname      str20   %20s                  COUNTYNAME
agi_stub        byte    %8.0g                 
n1              long    %12.0g                N1
mars1           long    %12.0g                
mars2           long    %12.0g                MARS2
mars4           long    %12.0g                MARS4
elf             long    %12.0g                ELF
cprep           long    %8.0g                 CPREP
prep            long    %12.0g                PREP
dir_dep         long    %12.0g                DIR_DEP
vrtcrind        long    %8.0g                 VRTCRIND
n2              long    %12.0g                N2
total_vita      long    %8.0g                 TOTAL_VITA
vita            long    %8.0g                 VITA
tce             int     %8.0g                 TCE
vita_eic        int     %8.0g                 VITA_EIC
rac             long    %12.0g                RAC
elderly         long    %12.0g                ELDERLY
a00100          long    %12.0g                A00100
n02650          long    %12.0g                N02650
a02650          long    %12.0g                A02650
n00200          long    %12.0g                N00200
a00200          long    %12.0g                A00200
n00300          long    %12.0g                N00300
a00300          long    %12.0g                A00300
n00400          long    %8.0g                 N00400
a00400          long    %12.0g                A00400
n00600          long    %12.0g                N00600
a00600          long    %12.0g                A00600
n00650          long    %12.0g                N00650
a00650          long    %12.0g                A00650
n00700          long    %8.0g                 N00700
a00700          long    %8.0g                 A00700
n00900          long    %12.0g                N00900
a00900          long    %12.0g                A00900
n01000          long    %12.0g                N01000
a01000          long    %12.0g                A01000
n01400          long    %12.0g                N01400
a01400          long    %12.0g                A01400
n01700          long    %12.0g                N01700
a01700          long    %12.0g                A01700
schf            long    %8.0g                 SCHF
n02300          long    %8.0g                 N02300
a02300          long    %12.0g                A02300
n02500          long    %12.0g                N02500
a02500          long    %12.0g                A02500
n26270          long    %12.0g                N26270
a26270          long    %12.0g                A26270
n25870          long    %8.0g                 N25870
a25870          long    %12.0g                A25870
n02900          long    %12.0g                N02900
a02900          long    %12.0g                A02900
n03220          long    %8.0g                 N03220
a03220          long    %8.0g                 A03220
n03300          long    %8.0g                 N03300
a03300          long    %12.0g                A03300
n03270          long    %8.0g                 N03270
a03270          long    %12.0g                A03270
n03150          long    %8.0g                 N03150
a03150          long    %12.0g                A03150
n03210          long    %8.0g                 N03210
a03210          long    %8.0g                 A03210
n04450          long    %12.0g                N04450
a04450          long    %12.0g                A04450
n04100          long    %12.0g                N04100
a04100          long    %12.0g                A04100
n04200          long    %12.0g                N04200
a04200          long    %12.0g                A04200
n04470          long    %12.0g                N04470
a04470          long    %12.0g                A04470
a00101          long    %12.0g                A00101
n17000          long    %8.0g                 N17000
a17000          long    %12.0g                A17000
n18425          long    %12.0g                N18425
a18425          long    %12.0g                A18425
n18450          long    %8.0g                 N18450
a18450          long    %8.0g                 A18450
n18500          long    %12.0g                N18500
a18500          long    %12.0g                A18500
n18800          long    %12.0g                N18800
a18800          long    %8.0g                 A18800
n18460          long    %12.0g                N18460
a18460          long    %12.0g                A18460
n18300          long    %12.0g                N18300
a18300          long    %12.0g                A18300
n19300          long    %12.0g                N19300
a19300          long    %12.0g                A19300
n19500          int     %8.0g                 N19500
a19500          long    %8.0g                 A19500
n19530          long    %8.0g                 N19530
a19530          long    %8.0g                 A19530
n19570          long    %8.0g                 N19570
a19570          long    %12.0g                A19570
n19700          long    %12.0g                N19700
a19700          long    %12.0g                A19700
n20950          long    %8.0g                 N20950
a20950          long    %12.0g                A20950
n04475          long    %12.0g                N04475
a04475          long    %12.0g                A04475
n04800          long    %12.0g                N04800
a04800          long    %12.0g                A04800
n05800          long    %12.0g                N05800
a05800          long    %12.0g                A05800
n09600          int     %8.0g                 N09600
a09600          long    %8.0g                 A09600
n05780          long    %8.0g                 N05780
a05780          long    %8.0g                 A05780
n07100          long    %12.0g                N07100
a07100          long    %12.0g                A07100
n07300          long    %8.0g                 N07300
a07300          long    %12.0g                A07300
n07180          long    %8.0g                 N07180
a07180          long    %8.0g                 A07180
n07230          long    %12.0g                N07230
a07230          long    %12.0g                A07230
n07240          long    %12.0g                N07240
a07240          long    %8.0g                 A07240
n07225          long    %12.0g                N07225
a07225          long    %12.0g                A07225
n07260          long    %8.0g                 N07260
a07260          long    %8.0g                 A07260
n09400          long    %12.0g                N09400
a09400          long    %12.0g                A09400
n85770          long    %12.0g                N85770
a85770          long    %12.0g                A85770
n85775          long    %12.0g                N85775
a85775          long    %12.0g                A85775
n10600          long    %12.0g                N10600
a10600          long    %12.0g                A10600
n59660          long    %12.0g                N59660
a59660          long    %12.0g                A59660
n59661          long    %12.0g                N59661
a59661          long    %8.0g                 A59661
n59662          long    %12.0g                N59662
a59662          long    %12.0g                A59662
n59663          long    %12.0g                N59663
a59663          long    %12.0g                A59663
n59664          long    %8.0g                 N59664
a59664          long    %12.0g                A59664
n59720          long    %12.0g                N59720
a59720          long    %12.0g                A59720
n11070          long    %12.0g                N11070
a11070          long    %12.0g                A11070
n10960          long    %8.0g                 N10960
a10960          long    %8.0g                 A10960
n11560          long    %8.0g                 N11560
a11560          long    %8.0g                 A11560
n06500          long    %12.0g                N06500
a06500          long    %12.0g                A06500
n10300          long    %12.0g                N10300
a10300          long    %12.0g                A10300
n85530          long    %12.0g                N85530
a85530          long    %12.0g                A85530
n85300          long    %12.0g                N85300
a85300          long    %12.0g                A85300
n11901          long    %12.0g                N11901
a11901          long    %12.0g                A11901
n11900          long    %12.0g                N11900
a11900          long    %12.0g                A11900
n11902          long    %12.0g                N11902
a11902          long    %12.0g                A11902
n12000          long    %8.0g                 N12000
a12000          long    %12.0g                A12000
--------------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
variable agi was long now double
(25,400 real changes made)
variable a_total_inc was long now double
(25,400 real changes made)
variable a_wage was long now double
(24,693 real changes made)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all_22.dta saved

. 
. ** Append data 
. 
. ** Loop over years 
. forvalues y = 15(1)22 {
  2. 
.         ** Append 
.         append using "${data}working/irs_county_all_`y'"
  3.                 
.         } // END YEAR LOOP 
(variable county_name was str20, now str24 to accommodate using data's values)

.         
. ** Save file 
. save "${data}working/irs_county_all", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all.dta saved

.         
. ** Generate fips variable
. make_fips state_fips county_fips, gen(fips)

. 
. ** Save file 
. save "${data}working/irs_county_all", replace 
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/irs_county_all.dta saved

. 
. ** Close log
. log close log_01
      name:  log_01
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/01_log_data_clean_multnomah_2025-1
> 2-16.log
  log type:  text
 closed on:  18 Dec 2025, 17:43:47
--------------------------------------------------------------------------------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003a.tmp"

. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus, gen(merge_acs)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_county_gross_18plus,
    gen(merge_acs).dta not found
r(601);

end of do-file

r(601);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003b.tmp"

. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_county_gross_18plus.dta not found
r(601);

end of do-file

r(601);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003c.tmp"

. 
. ** All (18+)
. acs_make_gross_migration using "${data}working/acs_migration_file", ///
>     saving("${data}working/acs_county_gross_18plus") replace 
(0 observations deleted)
(0 real changes made)
(10,269,992 missing values generated)
(10,269,992 real changes made)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000003.tmp not found)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000003.tmp saved as .dta format
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000005.tmp not found)
file C:\Users\ji252\AppData\Local\Temp\ST_91a0_000005.tmp saved as .dta format

    Result                      Number of obs
    -----------------------------------------
    Not matched                             0
    Matched                             4,332  
    -----------------------------------------
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(variable fips was long, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           448
        from master                       448  
        from using                          0  

    Matched                             3,884  
    -----------------------------------------
  variable state_fips was int now byte
  variable fips was double now long
  variable persons_in_1 was double now long
  variable persons_in_4 was double now long
  variable persons_in_5 was double now long
  variable households_in_1 was double now long
  variable households_in_4 was double now long
  variable households_in_5 was double now long
  variable persons_in_2 was double now long
  variable persons_in_3 was double now long
  variable households_in_2 was double now long
  variable households_in_3 was double now long
  variable persons_out_1 was double now long
  variable persons_out_4 was double now long
  variable persons_out_5 was double now long
  variable households_out_1 was double now long
  variable households_out_4 was double now long
  variable households_out_5 was double now long
  variable persons_out_2 was double now long
  variable persons_out_3 was double now long
  variable households_out_2 was double now long
  variable households_out_3 was double now long
  variable persons_net_2 was double now long
  variable persons_net_3 was double now long
  variable persons_net_4 was double now long
  variable persons_net_5 was double now long
  variable households_net_2 was double now long
  variable households_net_3 was double now long
  variable households_net_4 was double now long
  variable households_net_5 was double now long
  variable county_name was str46 now str23
  (606,480 bytes saved)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_county_gross_18plus.dta not
    found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/data/working/acs_county_gross_18plus.dta saved

.         
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003d.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,578
        from master                    17,829  (merge_acs==1)
        from using                      1,749  (merge_acs==2)

    Matched                             2,583  (merge_acs==3)
    -----------------------------------------

. 
end of do-file

. use ${data}working/acs_county_gross_18plus, clear

. tab year

       year |      Freq.     Percent        Cum.
------------+-----------------------------------
       2015 |        478       11.03       11.03
       2016 |        478       11.03       22.07
       2017 |        478       11.03       33.10
       2018 |        478       11.03       44.14
       2019 |        478       11.03       55.17
       2020 |        478       11.03       66.20
       2021 |        478       11.03       77.24
       2022 |        493       11.38       88.62
       2023 |        493       11.38      100.00
------------+-----------------------------------
      Total |      4,332      100.00

. tab fips

County FIPS |
(state*1000 |
  + county) |      Freq.     Percent        Cum.
------------+-----------------------------------
       1000 |          9        0.21        0.21
       1003 |          9        0.21        0.42
       1015 |          9        0.21        0.62
       1055 |          7        0.16        0.78
       1073 |          7        0.16        0.95
       1081 |          7        0.16        1.11
       1083 |          2        0.05        1.15
       1097 |          9        0.21        1.36
       1117 |          7        0.16        1.52
       1125 |          2        0.05        1.57
       2000 |          9        0.21        1.78
       2020 |          9        0.21        1.99
       4000 |          9        0.21        2.19
       4005 |          9        0.21        2.40
       4013 |          9        0.21        2.61
       4015 |          2        0.05        2.65
       4019 |          7        0.16        2.82
       4025 |          9        0.21        3.02
       4027 |          7        0.16        3.19
       5000 |          9        0.21        3.39
       5007 |          9        0.21        3.60
       5119 |          9        0.21        3.81
       5125 |          7        0.16        3.97
       5143 |          9        0.21        4.18
       6000 |          9        0.21        4.39
       6001 |          9        0.21        4.59
       6007 |          9        0.21        4.80
       6013 |          9        0.21        5.01
       6017 |          9        0.21        5.22
       6019 |          9        0.21        5.42
       6023 |          9        0.21        5.63
       6025 |          9        0.21        5.84
       6029 |          9        0.21        6.05
       6031 |          9        0.21        6.26
       6037 |          9        0.21        6.46
       6039 |          9        0.21        6.67
       6041 |          9        0.21        6.88
       6047 |          9        0.21        7.09
       6055 |          9        0.21        7.29
       6059 |          9        0.21        7.50
       6061 |          9        0.21        7.71
       6065 |          9        0.21        7.92
       6067 |          9        0.21        8.13
       6071 |          9        0.21        8.33
       6073 |          9        0.21        8.54
       6075 |          9        0.21        8.75
       6077 |          9        0.21        8.96
       6079 |          9        0.21        9.16
       6081 |          9        0.21        9.37
       6083 |          9        0.21        9.58
       6085 |          9        0.21        9.79
       6087 |          9        0.21       10.00
       6089 |          9        0.21       10.20
       6095 |          9        0.21       10.41
       6097 |          9        0.21       10.62
       6099 |          9        0.21       10.83
       6107 |          9        0.21       11.03
       6111 |          9        0.21       11.24
       6113 |          9        0.21       11.45
       8000 |          9        0.21       11.66
       8069 |          9        0.21       11.87
       8123 |          2        0.05       11.91
       9000 |          2        0.05       11.96
       9001 |          7        0.16       12.12
       9003 |          7        0.16       12.28
       9005 |          7        0.16       12.44
       9007 |          7        0.16       12.60
       9009 |          7        0.16       12.77
       9011 |          7        0.16       12.93
       9013 |          7        0.16       13.09
       9015 |          7        0.16       13.25
       9120 |          2        0.05       13.30
       9130 |          2        0.05       13.34
       9140 |          2        0.05       13.39
       9160 |          2        0.05       13.43
       9170 |          2        0.05       13.48
       9180 |          2        0.05       13.53
       9190 |          2        0.05       13.57
      10001 |          9        0.21       13.78
      10003 |          9        0.21       13.99
      10005 |          9        0.21       14.20
      11001 |          9        0.21       14.40
      12000 |          9        0.21       14.61
      12001 |          9        0.21       14.82
      12005 |          2        0.05       14.87
      12009 |          9        0.21       15.07
      12011 |          9        0.21       15.28
      12015 |          9        0.21       15.49
      12017 |          9        0.21       15.70
      12019 |          9        0.21       15.90
      12021 |          9        0.21       16.11
      12031 |          9        0.21       16.32
      12033 |          9        0.21       16.53
      12035 |          2        0.05       16.57
      12053 |          9        0.21       16.78
      12057 |          9        0.21       16.99
      12061 |          9        0.21       17.20
      12069 |          2        0.05       17.24
      12071 |          9        0.21       17.45
      12073 |          9        0.21       17.66
      12081 |          9        0.21       17.87
      12083 |          9        0.21       18.07
      12085 |          9        0.21       18.28
      12091 |          9        0.21       18.49
      12095 |          9        0.21       18.70
      12097 |          9        0.21       18.91
      12099 |          9        0.21       19.11
      12101 |          9        0.21       19.32
      12103 |          9        0.21       19.53
      12105 |          9        0.21       19.74
      12111 |          9        0.21       19.94
      12113 |          9        0.21       20.15
      12115 |          9        0.21       20.36
      12117 |          9        0.21       20.57
      12119 |          2        0.05       20.61
      12127 |          2        0.05       20.66
      13000 |          9        0.21       20.87
      13015 |          9        0.21       21.08
      13021 |          9        0.21       21.28
      13045 |          9        0.21       21.49
      13051 |          9        0.21       21.70
      13057 |          9        0.21       21.91
      13059 |          9        0.21       22.11
      13063 |          9        0.21       22.32
      13067 |          9        0.21       22.53
      13073 |          9        0.21       22.74
      13077 |          9        0.21       22.95
      13089 |          2        0.05       22.99
      13097 |          9        0.21       23.20
      13113 |          9        0.21       23.41
      13117 |          9        0.21       23.61
      13121 |          2        0.05       23.66
      13135 |          9        0.21       23.87
      13139 |          9        0.21       24.08
      13151 |          9        0.21       24.28
      13185 |          9        0.21       24.49
      13223 |          9        0.21       24.70
      13245 |          9        0.21       24.91
      13313 |          9        0.21       25.12
      15000 |          9        0.21       25.32
      15001 |          9        0.21       25.53
      15003 |          9        0.21       25.74
      16000 |          9        0.21       25.95
      16019 |          9        0.21       26.15
      17000 |          9        0.21       26.36
      17019 |          7        0.16       26.52
      17031 |          9        0.21       26.73
      17037 |          7        0.16       26.89
      17043 |          9        0.21       27.10
      17089 |          9        0.21       27.31
      17091 |          7        0.16       27.47
      17093 |          2        0.05       27.52
      17097 |          9        0.21       27.72
      17099 |          7        0.16       27.89
      17111 |          9        0.21       28.09
      17113 |          9        0.21       28.30
      17115 |          7        0.16       28.46
      17119 |          9        0.21       28.67
      17143 |          9        0.21       28.88
      17161 |          9        0.21       29.09
      17163 |          7        0.16       29.25
      17167 |          9        0.21       29.46
      17179 |          9        0.21       29.66
      17197 |          9        0.21       29.87
      18000 |          9        0.21       30.08
      18003 |          9        0.21       30.29
      18019 |          9        0.21       30.49
      18035 |          9        0.21       30.70
      18039 |          9        0.21       30.91
      18063 |          9        0.21       31.12
      18081 |          9        0.21       31.33
      18089 |          9        0.21       31.53
      18091 |          9        0.21       31.74
      18095 |          9        0.21       31.95
      18097 |          9        0.21       32.16
      18105 |          9        0.21       32.36
      18127 |          9        0.21       32.57
      18141 |          9        0.21       32.78
      18157 |          9        0.21       32.99
      18163 |          9        0.21       33.19
      18167 |          9        0.21       33.40
      19000 |          9        0.21       33.61
      19013 |          9        0.21       33.82
      19103 |          9        0.21       34.03
      19113 |          9        0.21       34.23
      19153 |          2        0.05       34.28
      19163 |          9        0.21       34.49
      20000 |          9        0.21       34.70
      20045 |          9        0.21       34.90
      20091 |          9        0.21       35.11
      20209 |          9        0.21       35.32
      21000 |          9        0.21       35.53
      21015 |          9        0.21       35.73
      21059 |          2        0.05       35.78
      21067 |          9        0.21       35.99
      21093 |          2        0.05       36.03
      21111 |          9        0.21       36.24
      21117 |          9        0.21       36.45
      21227 |          9        0.21       36.66
      22000 |          9        0.21       36.87
      22005 |          9        0.21       37.07
      22017 |          9        0.21       37.28
      22033 |          9        0.21       37.49
      22055 |          9        0.21       37.70
      22071 |          9        0.21       37.90
      22073 |          9        0.21       38.11
      22103 |          9        0.21       38.32
      22109 |          7        0.16       38.48
      23000 |          9        0.21       38.69
      23001 |          9        0.21       38.90
      23011 |          9        0.21       39.10
      23019 |          7        0.16       39.27
      24000 |          9        0.21       39.47
      24003 |          9        0.21       39.68
      24005 |          9        0.21       39.89
      24013 |          9        0.21       40.10
      24015 |          9        0.21       40.30
      24017 |          9        0.21       40.51
      24021 |          9        0.21       40.72
      24025 |          9        0.21       40.93
      24027 |          9        0.21       41.14
      24031 |          9        0.21       41.34
      24033 |          9        0.21       41.55
      24043 |          7        0.16       41.71
      24510 |          9        0.21       41.92
      25000 |          9        0.21       42.13
      25003 |          9        0.21       42.34
      25005 |          2        0.05       42.38
      25009 |          2        0.05       42.43
      25013 |          2        0.05       42.47
      25017 |          2        0.05       42.52
      25021 |          2        0.05       42.57
      25023 |          2        0.05       42.61
      25025 |          9        0.21       42.82
      25027 |          2        0.05       42.87
      26000 |          9        0.21       43.07
      26005 |          9        0.21       43.28
      26021 |          9        0.21       43.49
      26065 |          9        0.21       43.70
      26075 |          9        0.21       43.91
      26077 |          9        0.21       44.11
      26081 |          9        0.21       44.32
      26093 |          9        0.21       44.53
      26099 |          9        0.21       44.74
      26115 |          9        0.21       44.94
      26121 |          9        0.21       45.15
      26125 |          9        0.21       45.36
      26139 |          9        0.21       45.57
      26145 |          9        0.21       45.78
      26147 |          9        0.21       45.98
      26161 |          9        0.21       46.19
      26163 |          9        0.21       46.40
      27000 |          9        0.21       46.61
      27003 |          9        0.21       46.81
      27019 |          2        0.05       46.86
      27037 |          9        0.21       47.07
      27053 |          9        0.21       47.28
      27109 |          9        0.21       47.48
      27123 |          9        0.21       47.69
      27139 |          2        0.05       47.74
      27145 |          7        0.16       47.90
      27163 |          9        0.21       48.11
      27171 |          7        0.16       48.27
      28000 |          9        0.21       48.48
      28033 |          9        0.21       48.68
      28047 |          9        0.21       48.89
      28059 |          9        0.21       49.10
      29000 |          9        0.21       49.31
      29019 |          7        0.16       49.47
      29047 |          2        0.05       49.52
      29071 |          7        0.16       49.68
      29095 |          9        0.21       49.88
      29099 |          9        0.21       50.09
      29165 |          2        0.05       50.14
      29183 |          9        0.21       50.35
      29189 |          9        0.21       50.55
      29510 |          9        0.21       50.76
      30000 |          9        0.21       50.97
      30031 |          2        0.05       51.02
      31000 |          9        0.21       51.22
      31055 |          9        0.21       51.43
      31109 |          9        0.21       51.64
      31153 |          9        0.21       51.85
      32000 |          9        0.21       52.05
      32003 |          9        0.21       52.26
      32031 |          9        0.21       52.47
      33000 |          9        0.21       52.68
      34000 |          9        0.21       52.89
      34003 |          9        0.21       53.09
      34005 |          9        0.21       53.30
      34007 |          9        0.21       53.51
      34013 |          9        0.21       53.72
      34015 |          9        0.21       53.92
      34017 |          9        0.21       54.13
      34019 |          9        0.21       54.34
      34021 |          9        0.21       54.55
      34023 |          9        0.21       54.76
      34025 |          9        0.21       54.96
      34027 |          9        0.21       55.17
      34029 |          9        0.21       55.38
      34031 |          9        0.21       55.59
      34035 |          9        0.21       55.79
      34037 |          9        0.21       56.00
      34039 |          9        0.21       56.21
      34041 |          9        0.21       56.42
      35000 |          9        0.21       56.63
      35013 |          9        0.21       56.83
      35043 |          9        0.21       57.04
      35049 |          7        0.16       57.20
      36000 |          9        0.21       57.41
      36001 |          9        0.21       57.62
      36005 |          9        0.21       57.83
      36013 |          9        0.21       58.03
      36027 |          7        0.16       58.19
      36029 |          9        0.21       58.40
      36047 |          9        0.21       58.61
      36055 |          9        0.21       58.82
      36059 |          9        0.21       59.03
      36061 |          9        0.21       59.23
      36063 |          9        0.21       59.44
      36071 |          9        0.21       59.65
      36075 |          9        0.21       59.86
      36081 |          9        0.21       60.06
      36083 |          9        0.21       60.27
      36085 |          9        0.21       60.48
      36087 |          9        0.21       60.69
      36089 |          9        0.21       60.90
      36091 |          9        0.21       61.10
      36093 |          9        0.21       61.31
      36103 |          9        0.21       61.52
      36109 |          9        0.21       61.73
      36119 |          2        0.05       61.77
      37000 |          9        0.21       61.98
      37001 |          9        0.21       62.19
      37019 |          9        0.21       62.40
      37021 |          9        0.21       62.60
      37035 |          9        0.21       62.81
      37049 |          7        0.16       62.97
      37051 |          9        0.21       63.18
      37057 |          9        0.21       63.39
      37063 |          9        0.21       63.60
      37067 |          9        0.21       63.80
      37071 |          9        0.21       64.01
      37081 |          9        0.21       64.22
      37085 |          9        0.21       64.43
      37101 |          7        0.16       64.59
      37119 |          9        0.21       64.80
      37135 |          9        0.21       65.00
      37147 |          9        0.21       65.21
      37151 |          9        0.21       65.42
      37159 |          9        0.21       65.63
      37183 |          9        0.21       65.84
      37191 |          9        0.21       66.04
      38000 |          9        0.21       66.25
      38017 |          9        0.21       66.46
      39000 |          9        0.21       66.67
      39003 |          9        0.21       66.87
      39007 |          7        0.16       67.04
      39017 |          9        0.21       67.24
      39023 |          9        0.21       67.45
      39029 |          7        0.16       67.61
      39035 |          9        0.21       67.82
      39041 |          9        0.21       68.03
      39045 |          9        0.21       68.24
      39049 |          9        0.21       68.44
      39057 |          9        0.21       68.65
      39061 |          9        0.21       68.86
      39085 |          2        0.05       68.91
      39089 |          9        0.21       69.11
      39093 |          9        0.21       69.32
      39103 |          9        0.21       69.53
      39109 |          9        0.21       69.74
      39113 |          9        0.21       69.94
      39133 |          9        0.21       70.15
      39139 |          9        0.21       70.36
      39153 |          9        0.21       70.57
      39165 |          9        0.21       70.78
      39169 |          9        0.21       70.98
      39173 |          2        0.05       71.03
      40000 |          9        0.21       71.24
      40017 |          9        0.21       71.45
      40027 |          9        0.21       71.65
      40109 |          9        0.21       71.86
      40143 |          2        0.05       71.91
      41000 |          9        0.21       72.11
      41005 |          9        0.21       72.32
      41017 |          7        0.16       72.48
      41019 |          9        0.21       72.69
      41029 |          9        0.21       72.90
      41039 |          9        0.21       73.11
      41047 |          9        0.21       73.31
      41051 |          9        0.21       73.52
      41067 |          9        0.21       73.73
      41071 |          2        0.05       73.78
      42000 |          9        0.21       73.98
      42003 |          9        0.21       74.19
      42011 |          9        0.21       74.40
      42017 |          9        0.21       74.61
      42019 |          9        0.21       74.82
      42021 |          9        0.21       75.02
      42027 |          9        0.21       75.23
      42029 |          9        0.21       75.44
      42043 |          9        0.21       75.65
      42045 |          9        0.21       75.85
      42049 |          9        0.21       76.06
      42051 |          9        0.21       76.27
      42071 |          9        0.21       76.48
      42075 |          9        0.21       76.69
      42085 |          9        0.21       76.89
      42089 |          9        0.21       77.10
      42091 |          9        0.21       77.31
      42101 |          9        0.21       77.52
      42107 |          9        0.21       77.72
      42129 |          9        0.21       77.93
      42133 |          9        0.21       78.14
      44000 |          9        0.21       78.35
      44003 |          9        0.21       78.55
      44007 |          9        0.21       78.76
      44009 |          9        0.21       78.97
      45000 |          9        0.21       79.18
      45003 |          2        0.05       79.22
      45007 |          7        0.16       79.39
      45015 |          2        0.05       79.43
      45019 |          2        0.05       79.48
      45035 |          2        0.05       79.52
      45041 |          2        0.05       79.57
      45045 |          2        0.05       79.62
      45051 |          7        0.16       79.78
      45063 |          2        0.05       79.82
      45083 |          9        0.21       80.03
      45091 |          7        0.16       80.19
      46000 |          9        0.21       80.40
      47000 |          9        0.21       80.61
      47009 |          9        0.21       80.82
      47037 |          9        0.21       81.02
      47065 |          9        0.21       81.23
      47093 |          2        0.05       81.28
      47119 |          2        0.05       81.33
      47125 |          2        0.05       81.37
      47149 |          9        0.21       81.58
      47157 |          9        0.21       81.79
      47163 |          2        0.05       81.83
      47165 |          7        0.16       81.99
      47179 |          7        0.16       82.16
      47187 |          9        0.21       82.36
      47189 |          9        0.21       82.57
      48000 |          9        0.21       82.78
      48027 |          9        0.21       82.99
      48029 |          9        0.21       83.19
      48039 |          9        0.21       83.40
      48041 |          9        0.21       83.61
      48061 |          9        0.21       83.82
      48085 |          9        0.21       84.03
      48091 |          9        0.21       84.23
      48113 |          9        0.21       84.44
      48121 |          9        0.21       84.65
      48135 |          9        0.21       84.86
      48139 |          9        0.21       85.06
      48141 |          9        0.21       85.27
      48157 |          9        0.21       85.48
      48167 |          9        0.21       85.69
      48183 |          9        0.21       85.90
      48187 |          9        0.21       86.10
      48201 |          9        0.21       86.31
      48209 |          9        0.21       86.52
      48215 |          9        0.21       86.73
      48245 |          9        0.21       86.93
      48251 |          9        0.21       87.14
      48257 |          9        0.21       87.35
      48303 |          9        0.21       87.56
      48309 |          9        0.21       87.77
      48329 |          9        0.21       87.97
      48339 |          9        0.21       88.18
      48355 |          9        0.21       88.39
      48367 |          9        0.21       88.60
      48375 |          9        0.21       88.80
      48381 |          9        0.21       89.01
      48423 |          9        0.21       89.22
      48439 |          9        0.21       89.43
      48441 |          9        0.21       89.64
      48451 |          9        0.21       89.84
      48453 |          9        0.21       90.05
      48479 |          9        0.21       90.26
      48485 |          9        0.21       90.47
      48491 |          9        0.21       90.67
      49000 |          9        0.21       90.88
      49011 |          9        0.21       91.09
      49035 |          9        0.21       91.30
      49049 |          9        0.21       91.51
      49053 |          9        0.21       91.71
      49057 |          9        0.21       91.92
      50000 |          9        0.21       92.13
      50007 |          2        0.05       92.17
      51000 |          9        0.21       92.38
      51013 |          9        0.21       92.59
      51041 |          9        0.21       92.80
      51087 |          9        0.21       93.01
      51107 |          9        0.21       93.21
      51510 |          9        0.21       93.42
      51550 |          7        0.16       93.58
      51650 |          9        0.21       93.79
      51700 |          9        0.21       94.00
      51710 |          2        0.05       94.04
      51760 |          9        0.21       94.25
      51810 |          9        0.21       94.46
      53000 |          9        0.21       94.67
      53011 |          9        0.21       94.88
      53033 |          9        0.21       95.08
      53035 |          9        0.21       95.29
      53053 |          9        0.21       95.50
      53057 |          2        0.05       95.54
      53061 |          9        0.21       95.75
      53063 |          9        0.21       95.96
      53067 |          9        0.21       96.17
      53073 |          9        0.21       96.38
      53077 |          9        0.21       96.58
      54000 |          9        0.21       96.79
      54039 |          2        0.05       96.84
      55000 |          9        0.21       97.05
      55009 |          9        0.21       97.25
      55025 |          9        0.21       97.46
      55059 |          9        0.21       97.67
      55063 |          9        0.21       97.88
      55073 |          9        0.21       98.08
      55079 |          9        0.21       98.29
      55087 |          9        0.21       98.50
      55101 |          9        0.21       98.71
      55105 |          9        0.21       98.92
      55117 |          9        0.21       99.12
      55127 |          9        0.21       99.33
      55133 |          9        0.21       99.54
      55139 |          9        0.21       99.75
      56000 |          9        0.21       99.95
      56021 |          2        0.05      100.00
------------+-----------------------------------
      Total |      4,332      100.00

. tab state_name

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         59        1.52        1.52
              Alaska |          9        0.23        1.75
             Arizona |         43        1.11        2.86
            Arkansas |         34        0.88        3.73
          California |        306        7.88       11.61
            Colorado |         11        0.28       11.89
         Connecticut |         56        1.44       13.34
            Delaware |         27        0.70       14.03
District of Columbia |          9        0.23       14.26
             Florida |        262        6.75       21.01
             Georgia |        184        4.74       25.75
              Hawaii |         18        0.46       26.21
               Idaho |          9        0.23       26.44
            Illinois |        152        3.91       30.36
             Indiana |        144        3.71       34.06
                Iowa |         38        0.98       35.04
              Kansas |         27        0.70       35.74
            Kentucky |         49        1.26       37.00
           Louisiana |         70        1.80       38.80
               Maine |         25        0.64       39.44
            Maryland |        106        2.73       42.17
       Massachusetts |         32        0.82       43.00
            Michigan |        144        3.71       46.70
           Minnesota |         72        1.85       48.56
         Mississippi |         27        0.70       49.25
            Missouri |         63        1.62       50.88
             Montana |          2        0.05       50.93
            Nebraska |         27        0.70       51.62
              Nevada |         18        0.46       52.09
          New Jersey |        153        3.94       56.02
          New Mexico |         25        0.64       56.67
            New York |        189        4.87       61.53
      North Carolina |        176        4.53       66.07
        North Dakota |          9        0.23       66.30
                Ohio |        189        4.87       71.16
            Oklahoma |         29        0.75       71.91
              Oregon |         72        1.85       73.76
        Pennsylvania |        180        4.63       78.40
        Rhode Island |         27        0.70       79.09
      South Carolina |         44        1.13       80.23
           Tennessee |         85        2.19       82.42
               Texas |        342        8.81       91.22
                Utah |         45        1.16       92.38
             Vermont |          2        0.05       92.43
            Virginia |         90        2.32       94.75
          Washington |         83        2.14       96.88
       West Virginia |          2        0.05       96.94
           Wisconsin |        117        3.01       99.95
             Wyoming |          2        0.05      100.00
---------------------+-----------------------------------
               Total |      3,884      100.00

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003e.tmp"

. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,836       97.26       97.26
          1 |         80        2.74      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,578
        from master                    17,829  (merge_acs==1)
        from using                      1,749  (merge_acs==2)

    Matched                             2,583  (merge_acs==3)
    -----------------------------------------

. 
end of do-file

. tab county_fips if merge_acs == 2

County FIPS |
       code |
    (origin |
    county) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        434       24.81       24.81
          1 |         37        2.12       26.93
          3 |         40        2.29       29.22
          5 |         34        1.94       31.16
          7 |         24        1.37       32.53
          9 |         17        0.97       33.50
         11 |         24        1.37       34.88
         13 |         32        1.83       36.71
         15 |         23        1.32       38.02
         17 |         34        1.94       39.97
         19 |         34        1.94       41.91
         20 |          9        0.51       42.42
         21 |         18        1.03       43.45
         23 |         15        0.86       44.31
         25 |         19        1.09       45.40
         27 |         12        0.69       46.08
         29 |         26        1.49       47.57
         31 |         21        1.20       48.77
         33 |         17        0.97       49.74
         35 |         23        1.32       51.06
         37 |         15        0.86       51.92
         39 |         26        1.49       53.40
         41 |         19        1.09       54.49
         43 |          6        0.34       54.83
         45 |         10        0.57       55.40
         47 |         24        1.37       56.78
         49 |          6        0.34       57.12
         51 |          8        0.46       57.58
         53 |         15        0.86       58.43
         55 |         15        0.86       59.29
         57 |         12        0.69       59.98
         59 |         19        1.09       61.06
         61 |         26        1.49       62.55
         63 |         21        1.20       63.75
         65 |         13        0.74       64.49
         67 |         33        1.89       66.38
         69 |          4        0.23       66.61
         71 |         21        1.20       67.81
         73 |         26        1.49       69.30
         75 |         15        0.86       70.15
         77 |         22        1.26       71.41
         79 |         11        0.63       72.04
         81 |         19        1.09       73.13
         83 |         17        0.97       74.10
         85 |         21        1.20       75.30
         87 |         15        0.86       76.16
         89 |         21        1.20       77.36
         91 |         12        0.69       78.04
         93 |         12        0.69       78.73
         95 |         15        0.86       79.59
         97 |         19        1.09       80.67
         99 |         15        0.86       81.53
        101 |          6        0.34       81.88
        103 |         10        0.57       82.45
        105 |          6        0.34       82.79
        107 |         13        0.74       83.53
        109 |         10        0.57       84.11
        111 |         15        0.86       84.96
        113 |         21        1.20       86.16
        115 |          4        0.23       86.39
        117 |          8        0.46       86.85
        119 |         12        0.69       87.54
        120 |          2        0.11       87.65
        121 |          6        0.34       87.99
        123 |          4        0.23       88.22
        125 |          6        0.34       88.56
        127 |          6        0.34       88.91
        129 |          2        0.11       89.02
        130 |          2        0.11       89.14
        133 |          6        0.34       89.48
        135 |          6        0.34       89.82
        139 |         12        0.69       90.51
        140 |          2        0.11       90.62
        141 |          4        0.23       90.85
        143 |          6        0.34       91.19
        145 |          2        0.11       91.31
        147 |          4        0.23       91.54
        149 |          2        0.11       91.65
        151 |          4        0.23       91.88
        153 |          6        0.34       92.22
        157 |          6        0.34       92.57
        159 |          2        0.11       92.68
        160 |          2        0.11       92.80
        161 |          4        0.23       93.02
        163 |         10        0.57       93.60
        165 |          4        0.23       93.83
        167 |          6        0.34       94.17
        169 |          2        0.11       94.28
        170 |          2        0.11       94.40
        173 |          2        0.11       94.51
        179 |          2        0.11       94.63
        180 |          2        0.11       94.74
        183 |          6        0.34       95.08
        185 |          2        0.11       95.20
        187 |          4        0.23       95.43
        189 |          4        0.23       95.65
        190 |          2        0.11       95.77
        191 |          2        0.11       95.88
        197 |          2        0.11       96.00
        201 |          2        0.11       96.11
        209 |          4        0.23       96.34
        215 |          2        0.11       96.46
        223 |          2        0.11       96.57
        227 |          2        0.11       96.68
        245 |          4        0.23       96.91
        251 |          2        0.11       97.03
        257 |          2        0.11       97.14
        303 |          2        0.11       97.26
        309 |          2        0.11       97.37
        313 |          2        0.11       97.48
        329 |          2        0.11       97.60
        339 |          2        0.11       97.71
        355 |          2        0.11       97.83
        367 |          2        0.11       97.94
        375 |          2        0.11       98.06
        381 |          2        0.11       98.17
        423 |          2        0.11       98.28
        439 |          2        0.11       98.40
        441 |          2        0.11       98.51
        451 |          2        0.11       98.63
        453 |          2        0.11       98.74
        479 |          2        0.11       98.86
        485 |          2        0.11       98.97
        491 |          2        0.11       99.09
        510 |          6        0.34       99.43
        650 |          2        0.11       99.54
        700 |          2        0.11       99.66
        710 |          2        0.11       99.77
        760 |          2        0.11       99.89
        810 |          2        0.11      100.00
------------+-----------------------------------
      Total |      1,749      100.00

. tab merge_acs multnomah

                      |     Indicator for
                      |   Multnomah County,
 Matching result from |        Oregon
                merge |         0          1 |     Total
----------------------+----------------------+----------
      Master only (1) |    17,829          0 |    17,829 
          Matched (3) |     2,576          7 |     2,583 
----------------------+----------------------+----------
                Total |    20,405          7 |    20,412 

. tab merge_acs yera
variable yera not found
r(111);

. tab merge_acs year

 Matching result from |                    Tax year (year before move)
                merge |      2015       2016       2017       2018       2019       2020 |     Total
----------------------+------------------------------------------------------------------+----------
      Master only (1) |     2,547      2,547      2,547      2,547      2,547      2,547 |    17,829 
       Using only (2) |       109        109        109        109        109        109 |     1,749 
          Matched (3) |       369        369        369        369        369        369 |     2,583 
----------------------+------------------------------------------------------------------+----------
                Total |     3,025      3,025      3,025      3,025      3,025      3,025 |    22,161 


 Matching result from |   Tax year (year before move)
                merge |      2021       2022       2023 |     Total
----------------------+---------------------------------+----------
      Master only (1) |     2,547          0          0 |    17,829 
       Using only (2) |       109        493        493 |     1,749 
          Matched (3) |       369          0          0 |     2,583 
----------------------+---------------------------------+----------
                Total |     3,025        493        493 |    22,161 

. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,547        109        369 |     3,025 
      2016 |     2,547        109        369 |     3,025 
      2017 |     2,547        109        369 |     3,025 
      2018 |     2,547        109        369 |     3,025 
      2019 |     2,547        109        369 |     3,025 
      2020 |     2,547        109        369 |     3,025 
      2021 |     2,547        109        369 |     3,025 
      2022 |         0        493          0 |       493 
      2023 |         0        493          0 |       493 
-----------+---------------------------------+----------
     Total |    17,829      1,749      2,583 |    22,161 

. drop if county_fips == 0
(434 observations deleted)

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003f.tmp"

.  tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,547         61        369 |     2,977 
      2016 |     2,547         61        369 |     2,977 
      2017 |     2,547         61        369 |     2,977 
      2018 |     2,547         61        369 |     2,977 
      2019 |     2,547         61        369 |     2,977 
      2020 |     2,547         61        369 |     2,977 
      2021 |     2,547         61        369 |     2,977 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    17,829      1,315      2,583 |    21,727 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003g.tmp"

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                  Alaska |          1        1.64        1.64
              California |         34       55.74       57.38
             Connecticut |          8       13.11       70.49
                  Hawaii |          2        3.28       73.77
                  Oregon |          7       11.48       85.25
              Washington |          9       14.75      100.00
-------------------------+-----------------------------------
                   Total |         61      100.00

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003h.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. 
. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. 
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003i.tmp"

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003j.tmp"

. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,887       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003k.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-1
> 6.log
  log type:  text
 opened on:  18 Dec 2025, 18:22:47

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA
> , HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,887       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace            
>  
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG 
> format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(850 missing values generated)
variable population was long now double
(20,412 real changes made)
(850 missing values generated)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(850 missing values generated)
(850 missing values generated)
(850 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2)
too few ')' or ']'
r(132);

end of do-file

r(132);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003l.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-1
> 6.log
  log type:  text
 opened on:  18 Dec 2025, 18:23:12

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA
> , HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,887       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace            
>  
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG 
> format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(850 missing values generated)
variable population was long now double
(20,412 real changes made)
(850 missing values generated)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(850 missing values generated)
(850 missing values generated)
(850 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (person_net_3 / (person_out_1 + person_out_2))
person_net_3 not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003m.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-1
> 6.log
  log type:  text
 opened on:  18 Dec 2025, 18:23:43

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA
> , HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,887       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace            
>  
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG 
> format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(850 missing values generated)
variable population was long now double
(20,412 real changes made)
(850 missing values generated)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(850 missing values generated)
(850 missing values generated)
(850 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,829 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,829 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (unbalanced)
 Time variable: year, 2015 to 2023
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,924 |     2,924 
      2016 |     2,924          0 |     2,924 
      2017 |     2,924          0 |     2,924 
      2018 |     2,924          0 |     2,924 
      2019 |     2,924          0 |     2,924 
      2020 |     2,924          0 |     2,924 
      2021 |     2,924          0 |     2,924 
      2022 |       383         14 |       397 
      2023 |       397          0 |       397 
-----------+----------------------+----------
     Total |    18,324      2,938 |    21,262 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 {
>  
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if merge_acs != 3       
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate n2_rate agi_rate {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', proj
> ected)"
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`data'_`out'_`c'_`sam
> p'_", .pdf) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out' fips year Treated                      ///
>                                         if sample == 1,                                        
>  ///
>                                         `covar'                                                
>          ///
>                                         vce(placebo)                                           
>  ///
>                                         brep(`reps')                                           
>  ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                  
>          ///             
>                                         legend(off) ytitle("`label'")                          
>          ///
>                                         yline(0, lc(red) lp(-))                                
>                  ///
>                                         xline(2019.5, lc(black) lp(solid))                     
>          ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`data'_`out'_`c'_sample_eventstudy.
> jpg",    ///
>                                         as(jpg) name("Graph") quality(100) replace             
>  
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                                 sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                                 sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                              
>  ///
>                         fmt(%9.0fc %9.3fc)                                                     
>  ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,829 real changes made)
n1_rate ambiguous abbreviation
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003n.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-1
> 6.log
  log type:  text
 opened on:  18 Dec 2025, 18:24:25

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA
> , HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,887       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace            
>  
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG 
> format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(850 missing values generated)
variable population was long now double
(20,412 real changes made)
(850 missing values generated)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(850 missing values generated)
(850 missing values generated)
(850 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,829 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,829 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (unbalanced)
 Time variable: year, 2015 to 2023
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,924 |     2,924 
      2016 |     2,924          0 |     2,924 
      2017 |     2,924          0 |     2,924 
      2018 |     2,924          0 |     2,924 
      2019 |     2,924          0 |     2,924 
      2020 |     2,924          0 |     2,924 
      2021 |     2,924          0 |     2,924 
      2022 |       383         14 |       397 
      2023 |       397          0 |       397 
-----------+----------------------+----------
     Total |    18,324      2,938 |    21,262 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 {
>  
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if merge_acs != 3       
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate n2_rate agi_rate {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', proj
> ected)"
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out'_`data' fips year Treated     
>  ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`data'_`out'_`c'_`sam
> p'_", .pdf) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out'_`data' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out'_`data' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out'_`data' fips year Treated                      
>  ///
>                                         if sample == 1,                                        
>  ///
>                                         `covar'                                                
>          ///
>                                         vce(placebo)                                           
>  ///
>                                         brep(`reps')                                           
>  ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                  
>          ///             
>                                         legend(off) ytitle("`label'")                          
>          ///
>                                         yline(0, lc(red) lp(-))                                
>                  ///
>                                         xline(2019.5, lc(black) lp(solid))                     
>          ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`data'_`out'_`c'_sample_eventstudy.
> jpg",    ///
>                                         as(jpg) name("Graph") quality(100) replace             
>  
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                                 sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                                 sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                              
>  ///
>                         fmt(%9.0fc %9.3fc)                                                     
>  ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,829 real changes made)
n1_rate ambiguous abbreviation
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003o.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-1
> 6.log
  log type:  text
 opened on:  18 Dec 2025, 18:25:17

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA
> , HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,887       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace            
>  
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG 
> format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(850 missing values generated)
variable population was long now double
(20,412 real changes made)
(850 missing values generated)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(850 missing values generated)
(850 missing values generated)
(850 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,829 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,829 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (unbalanced)
 Time variable: year, 2015 to 2023
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,924 |     2,924 
      2016 |     2,924          0 |     2,924 
      2017 |     2,924          0 |     2,924 
      2018 |     2,924          0 |     2,924 
      2019 |     2,924          0 |     2,924 
      2020 |     2,924          0 |     2,924 
      2021 |     2,924          0 |     2,924 
      2022 |       383         14 |       397 
      2023 |       397          0 |       397 
-----------+----------------------+----------
     Total |    18,324      2,938 |    21,262 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 {
>  
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if merge_acs != 3       
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate_`data' n2_rate_`data' agi_rate_`data' {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', proj
> ected)"
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`out'_`c'_`samp'_", .
> pdf) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out' fips year Treated                      ///
>                                         if sample == 1,                                        
>  ///
>                                         `covar'                                                
>          ///
>                                         vce(placebo)                                           
>  ///
>                                         brep(`reps')                                           
>  ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                  
>          ///             
>                                         legend(off) ytitle("`label'")                          
>          ///
>                                         yline(0, lc(red) lp(-))                                
>                  ///
>                                         xline(2019.5, lc(black) lp(solid))                     
>          ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`out'_`c'_sample_eventstudy.jpg",  
>  ///
>                                         as(jpg) name("Graph") quality(100) replace             
>  
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_0 sdid_n1_rate_1                   ///
>                                 sdid_n2_rate_0 sdid_n2_rate_1                   ///
>                                 sdid_agi_rate_0 sdid_agi_rate_1 using   ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                              
>  ///
>                         fmt(%9.0fc %9.3fc)                                                     
>  ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,829 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.30856    1.73454     0.18    0.859    -3.09106     3.70819
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .3085641   1.691776  -3.007316   3.624444          1 
    Effect_1 |  .9490793   2.039835  -3.048998   4.947157          1 
    Effect_2 | -.3319511   1.845077  -3.948302     3.2844          1 
   Placebo_1 |  .0660487   .3296082  -.5799833   .7120807          1 
   Placebo_2 |  .0054543   .4040894  -.7865609   .7974695          1 
   Placebo_3 |  .0427832   .3274383  -.5989959   .6845623          1 
   Placebo_4 |  .0051022    .350923   -.682707   .6929113          1 
   Placebo_5 | -.1120318   .2286449  -.5601758   .3361122          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .30856409   1.6917756  -3.0073162   3.6244444           1
 Effect_1   .94907928   2.0398355  -3.0489982   4.9471568           1
 Effect_2   -.3319511    1.845077   -3.948302   3.2843998           1
Placebo_1   .06604869   .32960817  -.57998333   .71208071           1
Placebo_2   .00545431   .40408938  -.78656088    .7974695           1
Placebo_3   .04278319    .3274383  -.59899588   .68456226           1
Placebo_4   .00510217   .35092302  -.68270696   .69291129           1
Placebo_5  -.11203184    .2286449  -.56017585   .33611218           1
(21,255 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_event
> study.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.30856    1.58675     0.19    0.846    -2.80141     3.41854
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .3085641   1.639635   -2.90512   3.522248          1 
    Effect_1 |  .9490793    2.19904  -3.361038   5.259197          1 
    Effect_2 | -.3319511   1.645345  -3.556827   2.892925          1 
   Placebo_1 |  .0660487    .218927  -.3630483   .4951457          1 
   Placebo_2 |  .0054543   .2607381  -.5055923    .516501          1 
   Placebo_3 |  .0427832   .3811805  -.7043305   .7898969          1 
   Placebo_4 |  .0051022   .3206645  -.6234002   .6336045          1 
   Placebo_5 | -.1120318   .3958919    -.88798   .6639163          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .30856409   1.6396348  -2.9051201   3.5222483           1
 Effect_1   .94907928   2.1990395  -3.3610382   5.2591967           1
 Effect_2   -.3319511    1.645345  -3.5568273    2.892925           1
Placebo_1   .06604869   .21892705  -.36304832   .49514571           1
Placebo_2   .00545431   .26073808  -.50559233   .51650095           1
Placebo_3   .04278319   .38118048  -.70433055   .78989693           1
Placebo_4   .00510217   .32066448  -.62340021   .63360454           1
Placebo_5  -.11203184    .3958919  -.88797997    .6639163           1
(21,255 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_event
> study.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.94344    1.46824    -0.64    0.521    -3.82114     1.93427
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9434363   1.494163  -3.871995   1.985123          1 
    Effect_1 | -.5698533   1.969369  -4.429816    3.29011          1 
    Effect_2 | -1.317019     1.8869  -5.015343   2.381305          1 
   Placebo_1 |   .038203   .3449193  -.6378388   .7142449          1 
   Placebo_2 |  .0074584   .4401791  -.8552927   .8702095          1 
   Placebo_3 |  .0479863   .3316799  -.6021062   .6980789          1 
   Placebo_4 | -.0323308   .3147026  -.6491478   .5844862          1 
   Placebo_5 | -.0736683   .2755764   -.613798   .4664615          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.94343627   1.4941627  -3.8719951   1.9851225           1
 Effect_1  -.56985334    1.969369  -4.4298165   3.2901098           1
 Effect_2  -1.3170192      1.8869  -5.0153431   2.3813047           1
Placebo_1   .03820304   .34491932  -.63783883   .71424491           1
Placebo_2   .00745838   .44017914  -.85529274    .8702095           1
Placebo_3    .0479863   .33167987  -.60210625   .69807885           1
Placebo_4  -.03233075   .31470255  -.64914776   .58448625           1
Placebo_5  -.07366825   .27557642  -.61379804   .46646153           1
(21,255 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_event
> study.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.94344    1.59202    -0.59    0.553    -4.06374     2.17687
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9434363   1.499742  -3.882931   1.996059          1 
    Effect_1 | -.5698533   2.106952  -4.699479   3.559772          1 
    Effect_2 | -1.317019   1.623933  -4.499928    1.86589          1 
   Placebo_1 |   .038203    .307309  -.5641225   .6405286          1 
   Placebo_2 |  .0074584   .3282609  -.6359331   .6508498          1 
   Placebo_3 |  .0479863   .3447709  -.6277647   .7237373          1 
   Placebo_4 | -.0323308   .2637822  -.5493439   .4846824          1 
   Placebo_5 | -.0736683   .3019323  -.6654556   .5181191          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.94343627   1.4997422  -3.8829311   1.9960585           1
 Effect_1  -.56985334   2.1069519   -4.699479   3.5597723           1
 Effect_2  -1.3170192    1.623933  -4.4999279   1.8658896           1
Placebo_1   .03820304   .30730895   -.5641225   .64052859           1
Placebo_2   .00745838   .32826094  -.63593307   .65084983           1
Placebo_3    .0479863    .3447709  -.62776467   .72373727           1
Placebo_4  -.03233075   .26378221  -.54934389   .48468238           1
Placebo_5  -.07366825    .3019323  -.66545557   .51811906           1
(21,255 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_event
> study.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.15131    1.68769    -0.09    0.929    -3.45911     3.15649
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_all_
    > trends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.1513129   1.944377  -3.962293   3.659667          1 
    Effect_1 |  .3034976   2.725898  -5.039262   5.646257          1 
    Effect_2 | -.6061234   1.958395  -4.444578   3.232331          1 
   Placebo_1 |   .100418   .4027557  -.6889832   .8898192          1 
   Placebo_2 | -.0308459   .2613917  -.5431736   .4814818          1 
   Placebo_3 |  .0329575      .3234  -.6009064   .6668214          1 
   Placebo_4 |  .0912491      .3895  -.6721708   .8546691          1 
   Placebo_5 | -.1506934   .4904696  -1.112014    .810627          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.15131291   1.9443775  -3.9622928    3.659667           1
 Effect_1   .30349763   2.7258976  -5.0392616   5.6462568           1
 Effect_2  -.60612344   1.9583953  -4.4445782   3.2323313           1
Placebo_1   .10041797   .40275571  -.68898323   .88981916           1
Placebo_2  -.03084588   .26139167  -.54317355   .48148179           1
Placebo_3    .0329575   .32339996  -.60090642   .66682142           1
Placebo_4   .09124913   .38949998  -.67217084    .8546691           1
Placebo_5  -.15069339   .49046961  -1.1120138   .81062705           1
(21,255 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_even
> tstudy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_event
> study.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.15131    1.99978    -0.08    0.940    -4.07081     3.76818
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_all_
    > trends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.1513129   1.810669  -3.700225   3.397599          1 
    Effect_1 |  .3034976   2.520569  -4.636817   5.243812          1 
    Effect_2 | -.6061234   1.936636  -4.401929   3.189682          1 
   Placebo_1 |   .100418   .4619695  -.8050423   1.005878          1 
   Placebo_2 | -.0308459   .4758781  -.9635669   .9018752          1 
   Placebo_3 |  .0329575   .4418053  -.8329808   .8988958          1 
   Placebo_4 |  .0912491   .4267639  -.7452082   .9277064          1 
   Placebo_5 | -.1506934   .3427248  -.8224341   .5210473          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.15131291   1.8106693  -3.7002248    3.397599           1
 Effect_1   .30349763   2.5205686  -4.6368168   5.2438121           1
 Effect_2  -.60612344   1.9366357  -4.4019293   3.1896825           1
Placebo_1   .10041797    .4619695  -.80504226   1.0058782           1
Placebo_2  -.03084588   .47587808  -.96356692   .90187515           1
Placebo_3    .0329575   .44180527  -.83298083   .89889583           1
Placebo_4   .09124913   .42676392  -.74520815   .92770641           1
Placebo_5  -.15069339   .34272485  -.82243409   .52104731           1
(21,255 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_even
> tstudy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_event
> study.jpg written in JPEG format
estimation result sdid_n1_rate_0 not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003p.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-1
> 6.log
  log type:  text
 opened on:  18 Dec 2025, 18:32:56

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

.         
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 0
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,977
        from master                    18,599  (merge_acs==1)
        from using                      1,378  (merge_acs==2)

    Matched                             2,954  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year |
    before |    Matching result from merge
     move) | Master on  Using onl  Matched ( |     Total
-----------+---------------------------------+----------
      2015 |     2,657          8        422 |     3,087 
      2016 |     2,657          8        422 |     3,087 
      2017 |     2,657          8        422 |     3,087 
      2018 |     2,657          8        422 |     3,087 
      2019 |     2,657          8        422 |     3,087 
      2020 |     2,657          8        422 |     3,087 
      2021 |     2,657          8        422 |     3,087 
      2022 |         0        444          0 |       444 
      2023 |         0        444          0 |       444 
-----------+---------------------------------+----------
     Total |    18,599        944      2,954 |    22,497 

. tab state_name if merge_acs == 2 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
             Connecticut |          8      100.00      100.00
-------------------------+-----------------------------------
                   Total |          8      100.00

. tab state_name if merge_acs == 1 & year == 2021

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         60        2.26        2.26
                  Alaska |         27        1.02        3.27
                 Arizona |         10        0.38        3.65
                Arkansas |         71        2.67        6.32
              California |         24        0.90        7.23
                Colorado |         63        2.37        9.60
                 Florida |         39        1.47       11.07
                 Georgia |        139        5.23       16.30
                  Hawaii |          1        0.04       16.33
                   Idaho |         43        1.62       17.95
                Illinois |         84        3.16       21.11
                 Indiana |         76        2.86       23.97
                    Iowa |         95        3.58       27.55
                  Kansas |        102        3.84       31.39
                Kentucky |        115        4.33       35.72
               Louisiana |         56        2.11       37.82
                   Maine |         13        0.49       38.31
                Maryland |         12        0.45       38.77
           Massachusetts |         12        0.45       39.22
                Michigan |         67        2.52       41.74
               Minnesota |         79        2.97       44.71
             Mississippi |         79        2.97       47.69
                Missouri |        108        4.06       51.75
                 Montana |         56        2.11       53.86
                Nebraska |         90        3.39       57.25
                  Nevada |         15        0.56       57.81
           New Hampshire |         10        0.38       58.19
              New Jersey |          4        0.15       58.34
              New Mexico |         30        1.13       59.47
                New York |         41        1.54       61.01
          North Carolina |         80        3.01       64.02
            North Dakota |         52        1.96       65.98
                    Ohio |         67        2.52       68.50
                Oklahoma |         74        2.79       71.28
                  Oregon |         28        1.05       72.34
            Pennsylvania |         47        1.77       74.11
            Rhode Island |          2        0.08       74.18
          South Carolina |         42        1.58       75.76
            South Dakota |         66        2.48       78.25
               Tennessee |         86        3.24       81.48
                   Texas |        215        8.09       89.57
                    Utah |         24        0.90       90.48
                 Vermont |         14        0.53       91.00
                Virginia |         72        2.71       93.71
              Washington |         30        1.13       94.84
           West Virginia |         55        2.07       96.91
               Wisconsin |         59        2.22       99.13
                 Wyoming |         23        0.87      100.00
-------------------------+-----------------------------------
                   Total |      2,657      100.00

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       94.75       94.75
          1 |        162        5.25      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       97.76       97.76
          1 |         69        2.24      100.00
------------+-----------------------------------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(20,130 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(21,261 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA
> , HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,880       98.50       98.50
          1 |         44        1.50      100.00
------------+-----------------------------------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(21,132 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace            
>  
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG 
> format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(850 missing values generated)
variable population was long now double
(20,412 real changes made)
(850 missing values generated)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(850 missing values generated)
(850 missing values generated)
(850 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,829 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,829 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (unbalanced)
 Time variable: year, 2015 to 2023
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,924 |     2,924 
      2016 |     2,924          0 |     2,924 
      2017 |     2,924          0 |     2,924 
      2018 |     2,924          0 |     2,924 
      2019 |     2,924          0 |     2,924 
      2020 |     2,924          0 |     2,924 
      2021 |     2,924          0 |     2,924 
      2022 |       383         14 |       397 
      2023 |       397          0 |       397 
-----------+----------------------+----------
     Total |    18,324      2,938 |    21,262 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 {
>  
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if merge_acs != 3       
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate_`data' n2_rate_`data' agi_rate_`data' {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', proj
> ected)"
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`out'_`c'_`samp'_", .
> pdf) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out' fips year Treated                      ///
>                                         if sample == 1,                                        
>  ///
>                                         `covar'                                                
>          ///
>                                         vce(placebo)                                           
>  ///
>                                         brep(`reps')                                           
>  ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                  
>          ///             
>                                         legend(off) ytitle("`label'")                          
>          ///
>                                         yline(0, lc(red) lp(-))                                
>                  ///
>                                         xline(2019.5, lc(black) lp(solid))                     
>          ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`out'_`c'_sample_eventstudy.jpg",  
>  ///
>                                         as(jpg) name("Graph") quality(100) replace             
>  
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_`data'_0 sdid_n1_rate_`data'_1                     ///
>                                 sdid_n2_rate_`data'_0 sdid_n2_rate_`data'_1                    
>  ///
>                                 sdid_agi_rate_`data'_0 sdid_agi_rate_`data'_1 using     ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                              
>  ///
>                         fmt(%9.0fc %9.3fc)                                                     
>  ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,829 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.30856    1.82331     0.17    0.866    -3.26506     3.88218
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .3085641   1.744912  -3.111463   3.728591          1 
    Effect_1 |  .9490793   2.475665  -3.903224   5.801382          1 
    Effect_2 | -.3319511   1.811053  -3.881614   3.217712          1 
   Placebo_1 |  .0660487   .2673763  -.4580089   .5901063          1 
   Placebo_2 |  .0054543   .3490675  -.6787181   .6896267          1 
   Placebo_3 |  .0427832   .3782851  -.6986556    .784222          1 
   Placebo_4 |  .0051022   .3036036  -.5899609   .6001653          1 
   Placebo_5 | -.1120318   .3217928  -.7427456    .518682          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .30856409   1.7449117  -3.1114628    3.728591           1
 Effect_1   .94907928   2.4756648  -3.9032237   5.8013823           1
 Effect_2   -.3319511   1.8110527  -3.8816144   3.2177122           1
Placebo_1   .06604869   .26737631  -.45800888   .59010626           1
Placebo_2   .00545431   .34906754  -.67871807    .6896267           1
Placebo_3   .04278319    .3782851  -.69865561   .78422199           1
Placebo_4   .00510217   .30360362  -.58996093   .60016527           1
Placebo_5  -.11203184   .32179275  -.74274563   .51868196           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.30856    1.86716     0.17    0.869    -3.35100     3.96813
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .3085641   1.601891  -2.831142    3.44827          1 
    Effect_1 |  .9490793   2.016849  -3.003945   4.902104          1 
    Effect_2 | -.3319511   1.789359  -3.839095   3.175193          1 
   Placebo_1 |  .0660487   .2717057  -.4664944   .5985918          1 
   Placebo_2 |  .0054543    .320441    -.62261   .6335186          1 
   Placebo_3 |  .0427832   .2951075  -.5356275   .6211939          1 
   Placebo_4 |  .0051022   .2751236  -.5341401   .5443444          1 
   Placebo_5 | -.1120318   .1987317   -.501546   .2774823          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .30856409   1.6018907  -2.8311417   3.4482699           1
 Effect_1   .94907928   2.0168492  -3.0039452   4.9021037           1
 Effect_2   -.3319511   1.7893594  -3.8390955   3.1751932           1
Placebo_1   .06604869   .27170567  -.46649441    .5985918           1
Placebo_2   .00545431   .32044097  -.62260998    .6335186           1
Placebo_3   .04278319    .2951075   -.5356275   .62119388           1
Placebo_4   .00510217   .27512359  -.53414007   .54434441           1
Placebo_5  -.11203184    .1987317  -.50154596   .27748229           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.94344    1.35876    -0.69    0.487    -3.60656     1.71969
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9434363   1.733321  -4.340744   2.453872          1 
    Effect_1 | -.5698533   2.358727  -5.192957   4.053251          1 
    Effect_2 | -1.317019   2.025464  -5.286929   2.652891          1 
   Placebo_1 |   .038203   .2873355  -.5249745   .6013806          1 
   Placebo_2 |  .0074584   .2624928  -.5070275   .5219443          1 
   Placebo_3 |  .0479863   .3584812  -.6546369   .7506095          1 
   Placebo_4 | -.0323308   .3038684  -.6279129   .5632514          1 
   Placebo_5 | -.0736683   .3464036  -.7526193   .6052828          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.94343627   1.7333205  -4.3407445   2.4538719           1
 Effect_1  -.56985334   2.3587265  -5.1929574   4.0532507           1
 Effect_2  -1.3170192   2.0254641  -5.2869289   2.6528905           1
Placebo_1   .03820304   .28733547  -.52497447   .60138055           1
Placebo_2   .00745838   .26249282  -.50702755   .52194431           1
Placebo_3    .0479863   .35848123  -.65463691   .75060952           1
Placebo_4  -.03233075   .30386844   -.6279129   .56325139           1
Placebo_5  -.07366825   .34640361  -.75261933   .60528282           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.94344    1.38969    -0.68    0.497    -3.66718     1.78031
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.9434363   1.538424  -3.958747   2.071875          1 
    Effect_1 | -.5698533   1.965256  -4.421756   3.282049          1 
    Effect_2 | -1.317019   1.838359  -4.920203   2.286165          1 
   Placebo_1 |   .038203   .3634063  -.6740733   .7504794          1 
   Placebo_2 |  .0074584   .3733538  -.7243152   .7392319          1 
   Placebo_3 |  .0479863   .3759782  -.6889309   .7849035          1 
   Placebo_4 | -.0323308   .3352159  -.6893538   .6246923          1 
   Placebo_5 | -.0736683   .3387688  -.7376552   .5903187          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.94343627   1.5384239  -3.9587471   2.0718746           1
 Effect_1  -.56985334   1.9652564  -4.4217559   3.2820492           1
 Effect_2  -1.3170192   1.8383593  -4.9202035   2.2861651           1
Placebo_1   .03820304   .36340631  -.67407334   .75047942           1
Placebo_2   .00745838   .37335385  -.72431516   .73923193           1
Placebo_3    .0479863   .37597815  -.68893087   .78490348           1
Placebo_4  -.03233075   .33521586  -.68935385   .62469234           1
Placebo_5  -.07366825   .33876884  -.73765518   .59031868           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.15131    1.97346    -0.08    0.939    -4.01923     3.71661
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_all_
    > trends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.1513129   1.714042  -3.510836    3.20821          1 
    Effect_1 |  .3034976   1.983795  -3.584741   4.191736          1 
    Effect_2 | -.6061234   2.247825   -5.01186   3.799614          1 
   Placebo_1 |   .100418    .296706  -.4811258   .6819617          1 
   Placebo_2 | -.0308459   .3781342  -.7719889   .7102971          1 
   Placebo_3 |  .0329575   .4237841  -.7976593   .8635743          1 
   Placebo_4 |  .0912491   .3913022  -.6757032   .8582015          1 
   Placebo_5 | -.1506934   .3204073  -.7786916   .4773049          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.15131291   1.7140422  -3.5108357   3.2082098           1
 Effect_1   .30349763   1.9837952  -3.5847409   4.1917361           1
 Effect_2  -.60612344    2.247825  -5.0118605   3.7996136           1
Placebo_1   .10041797     .296706  -.48112579   .68196173           1
Placebo_2  -.03084588   .37813419  -.77198889   .71029712           1
Placebo_3    .0329575   .42378408   -.7976593    .8635743           1
Placebo_4   .09124913   .39130221   -.6757032   .85820145           1
Placebo_5  -.15069339   .32040727  -.77869163   .47730485           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_event
> study.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.15131    1.84058    -0.08    0.934    -3.75878     3.45616
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_all_
    > trends2020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.1513129   1.859486  -3.795905   3.493279          1 
    Effect_1 |  .3034976   2.681011  -4.951284   5.558279          1 
    Effect_2 | -.6061234   1.853781  -4.239535   3.027288          1 
   Placebo_1 |   .100418   .3125982  -.5122744   .7131104          1 
   Placebo_2 | -.0308459   .3481117  -.7131448   .6514531          1 
   Placebo_3 |  .0329575   .4080716  -.7668628   .8327778          1 
   Placebo_4 |  .0912491   .3161585  -.5284216   .7109198          1 
   Placebo_5 | -.1506934   .3445948  -.8260992   .5247124          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.15131291   1.8594856  -3.7959047   3.4932788           1
 Effect_1   .30349763   2.6810111  -4.9512841   5.5582794           1
 Effect_2  -.60612344   1.8537813  -4.2395348   3.0272879           1
Placebo_1   .10041797   .31259817  -.51227444   .71311038           1
Placebo_2  -.03084588   .34811171  -.71314483   .65145306           1
Placebo_3    .0329575    .4080716  -.76686284   .83277784           1
Placebo_4   .09124913   .31615853  -.52842159   .71091984           1
Placebo_5  -.15069339   .34459478  -.82609916   .52471238           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_event
> study.jpg written in JPEG format
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sample_all.tex
    not found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_samp
> le_all.tex)
(1,046 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.04988    1.04834    -0.05    0.962    -2.10460     2.00483
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_urban
    > 95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.0498834   1.331534   -2.65969   2.559923          1 
    Effect_1 |  .1430958   1.926566  -3.632974   3.919166          1 
    Effect_2 | -.2428627   1.200143  -2.595142   2.109417          1 
   Placebo_1 |  .3026772   .4358013  -.5514934   1.156848          1 
   Placebo_2 | -.0360174   .4659029  -.9491871   .8771524          1 
   Placebo_3 |  .2022049   .3868651  -.5560507   .9604604          1 
   Placebo_4 |  -.106479   .3001952  -.6948616   .4819036          1 
   Placebo_5 | -.2107308   .2613317  -.7229409   .3014793          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.04988344    1.331534  -2.6596902   2.5599233           1
 Effect_1   .14309582   1.9265664  -3.6329744    3.919166           1
 Effect_2   -.2428627   1.2001427  -2.5951423   2.1094169           1
Placebo_1   .30267721   .43580132  -.55149337   1.1568478           1
Placebo_2  -.03601737   .46590293   -.9491871   .87715237           1
Placebo_3   .20220486   .38686508   -.5560507   .96046043           1
Placebo_4  -.10647899   .30019519  -.69486156   .48190358           1
Placebo_5  -.21073083   .26133168  -.72294093   .30147926           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.04988    1.14621    -0.04    0.965    -2.29642     2.19666
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_urban
    > 95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.0498834   1.101129  -2.208096   2.108329          1 
    Effect_1 |  .1430958   1.514688  -2.825692   3.111884          1 
    Effect_2 | -.2428627   1.220473   -2.63499   2.149265          1 
   Placebo_1 |  .3026772   .3366533  -.3571633   .9625177          1 
   Placebo_2 | -.0360174   .4132912  -.8460682   .7740335          1 
   Placebo_3 |  .2022049   .3209594  -.4268755   .8312853          1 
   Placebo_4 |  -.106479   .3675722  -.8269205   .6139626          1 
   Placebo_5 | -.2107308   .5447895  -1.278518   .8570566          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.04988344   1.1011287  -2.2080957   2.1083288           1
 Effect_1   .14309582   1.5146877  -2.8256921   3.1118838           1
 Effect_2   -.2428627   1.2204734  -2.6349905   2.1492651           1
Placebo_1   .30267721   .33665333  -.35716332   .96251775           1
Placebo_2  -.03601737   .41329125  -.84606821   .77403348           1
Placebo_3   .20220486   .32095939  -.42687554   .83128526           1
Placebo_4  -.10647899   .36757222  -.82692055   .61396256           1
Placebo_5  -.21073083   .54478949  -1.2785182   .85705656           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.31245    1.23902    -1.06    0.289    -3.74089     1.11598
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_urban
    > 95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.312451   .9905142  -3.253859   .6289566          1 
    Effect_1 | -1.326346   1.340836  -3.954384   1.301692          1 
    Effect_2 | -1.298557   1.215766  -3.681458   1.084345          1 
   Placebo_1 |  .1883361   .3314712  -.4613474   .8380195          1 
   Placebo_2 | -.0195514   .3393169  -.6846126   .6455097          1 
   Placebo_3 |  .1855187   .3527826  -.5059352   .8769726          1 
   Placebo_4 | -.2236574   .3669538  -.9428868    .495572          1 
   Placebo_5 | -.2760077   .3965822  -1.053309   .5012934          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.3124513   .99051423  -3.2538592   .62895661           1
 Effect_1  -1.3263459   1.3408357  -3.9543839   1.3016921           1
 Effect_2  -1.2985567   1.2157661  -3.6814582   1.0843449           1
Placebo_1   .18833605   .33147116  -.46134742   .83801953           1
Placebo_2  -.01955144   .33931692   -.6846126   .64550973           1
Placebo_3    .1855187   .35278258  -.50593515   .87697255           1
Placebo_4  -.22365742   .36695378  -.94288683   .49557198           1
Placebo_5  -.27600769   .39658219  -1.0533088   .50129341           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.31245    1.23704    -1.06    0.289    -3.73700     1.11210
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_urban
    > 95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.312451   1.172573  -3.610694   .9857915          1 
    Effect_1 | -1.326346   1.395217  -4.060971   1.408279          1 
    Effect_2 | -1.298557   1.444508  -4.129792   1.532678          1 
   Placebo_1 |  .1883361   .3274738  -.4535127   .8301848          1 
   Placebo_2 | -.0195514   .4029907  -.8094132   .7703104          1 
   Placebo_3 |  .1855187   .2730609  -.3496807   .7207181          1 
   Placebo_4 | -.2236574   .3337445  -.8777967   .4304818          1 
   Placebo_5 | -.2760077   .3596409  -.9809039   .4288885          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.3124513   1.1725728  -3.6106941   .98579149           1
 Effect_1  -1.3263459   1.3952169   -4.060971   1.4082792           1
 Effect_2  -1.2985567   1.4445077  -4.1297918   1.5326785           1
Placebo_1   .18833605   .32747384  -.45351268   .83018478           1
Placebo_2  -.01955144   .40299072  -.80941325   .77031037           1
Placebo_3    .1855187   .27306091  -.34968068   .72071808           1
Placebo_4  -.22365742   .33374451  -.87779666   .43048181           1
Placebo_5  -.27600769    .3596409  -.98090386   .42888848           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.43478    1.67059    -0.26    0.795    -3.70908     2.83951
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_urba
    > n95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.4347848   1.452654  -3.281986   2.412416          1 
    Effect_1 | -.4628026   1.970517  -4.325015    3.39941          1 
    Effect_2 | -.4067669   1.542114  -3.429311   2.615777          1 
   Placebo_1 |  .3219735   .3678737  -.3990591   1.043006          1 
   Placebo_2 | -.1408936   .4771116  -1.076032   .7942451          1 
   Placebo_3 |  .0330072   .5144433  -.9753017   1.041316          1 
   Placebo_4 |  .0452849    .456061  -.8485947   .9391644          1 
   Placebo_5 | -.3740984   .4205082  -1.198294   .4500976          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.43478478   1.4526535  -3.2819857   2.4124161           1
 Effect_1  -.46280261   1.9705167  -4.3250154   3.3994101           1
 Effect_2  -.40676694   1.5421142  -3.4293108   2.6157769           1
Placebo_1   .32197347   .36787374  -.39905906    1.043006           1
Placebo_2  -.14089363   .47711162  -1.0760324   .79424515           1
Placebo_3   .03300721   .51444331  -.97530168   1.0413161           1
Placebo_4   .04528488     .456061  -.84859469   .93916444           1
Placebo_5  -.37409836   .42050817  -1.1982944   .45009765           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_event
> study.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.43478    1.71737    -0.25    0.800    -3.80077     2.93120
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_urba
    > n95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.4347848   1.187764  -2.762802   1.893233          1 
    Effect_1 | -.4628026   1.245268  -2.903528   1.977923          1 
    Effect_2 | -.4067669   1.672259  -3.684394    2.87086          1 
   Placebo_1 |  .3219735   .4659047  -.5911998   1.235147          1 
   Placebo_2 | -.1408936   .4730611  -1.068093   .7863061          1 
   Placebo_3 |  .0330072   .4980416  -.9431544   1.009169          1 
   Placebo_4 |  .0452849   .4323807  -.8021812    .892751          1 
   Placebo_5 | -.3740984   .4633834   -1.28233    .534133          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.43478478    1.187764  -2.7628021   1.8932326           1
 Effect_1  -.46280261   1.2452682  -2.9035283   1.9779231           1
 Effect_2  -.40676694   1.6722589  -3.6843943   2.8708604           1
Placebo_1   .32197347   .46590472  -.59119978   1.2351467           1
Placebo_2  -.14089363   .47306108  -1.0680933   .78630608           1
Placebo_3   .03300721   .49804161  -.94315435   1.0091688           1
Placebo_4   .04528488   .43238066  -.80218122   .89275098           1
Placebo_5  -.37409836   .46338335  -1.2823297   .53413301           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_event
> study.jpg written in JPEG format
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sample_urban95.te
    > x not found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_samp
> le_urban95.tex)
(162 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.13466    2.10161    -0.06    0.949    -4.25374     3.98441
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_urban
    > 95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  30

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.1346611   1.686692  -3.440578   3.171256          1 
    Effect_1 |  .3195058   2.660241  -4.894567   5.533579          1 
    Effect_2 |  -.588828   1.822916  -4.161743   2.984087          1 
   Placebo_1 |  .5029253   .8973594  -1.255899    2.26175          1 
   Placebo_2 | -.4558924   .9126187  -2.244625    1.33284          1 
   Placebo_3 |  .5687205   .7974573  -.9942957   2.131737          1 
   Placebo_4 | -.5170842   .6664932  -1.823411   .7892425          1 
   Placebo_5 | -.4687179   1.186745  -2.794738   1.857302          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.13466113   1.6866922  -3.4405778   3.1712555           1
 Effect_1   .31950576   2.6602414  -4.8945675    5.533579           1
 Effect_2  -.58882802   1.8229159  -4.1617432   2.9840872           1
Placebo_1   .50292535   .89735944  -1.2558992   2.2617499           1
Placebo_2  -.45589243   .91261867   -2.244625   1.3328402           1
Placebo_3   .56872048   .79745726  -.99429574   2.1317367           1
Placebo_4  -.51708423   .66649324   -1.823411   .78924252           1
Placebo_5  -.46871789   1.1867447  -2.7947375   1.8573017           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.13466    2.01226    -0.07    0.947    -4.07861     3.80929
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_urban
    > 95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  30

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -.1346611   2.000941  -4.056506   3.787184          1 
    Effect_1 |  .3195058   2.954418  -5.471154   6.110165          1 
    Effect_2 |  -.588828   1.856102  -4.226788   3.049132          1 
   Placebo_1 |  .5029253   .8723592  -1.206899   2.212749          1 
   Placebo_2 | -.4558924   .8628768  -2.147131   1.235346          1 
   Placebo_3 |  .5687205   .7987962  -.9969202   2.134361          1 
   Placebo_4 | -.5170842   .7297094  -1.947315   .9131461          1 
   Placebo_5 | -.4687179   .9353378   -2.30198   1.364544          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.13466113   2.0009412  -4.0565059   3.7871836           1
 Effect_1   .31950576   2.9544181  -5.4711537   6.1101653           1
 Effect_2  -.58882802    1.856102  -4.2267879   3.0491318           1
Placebo_1   .50292535   .87235921  -1.2068987   2.2127494           1
Placebo_2  -.45589243   .86287685   -2.147131   1.2353462           1
Placebo_3   .56872048   .79879624  -.99692015   2.1343611           1
Placebo_4  -.51708423   .72970938  -1.9473146   .91314614           1
Placebo_5  -.46871789   .93533776  -2.3019799   1.3645441           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.36805    1.63399    -0.84    0.402    -4.57061     1.83451
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_urban
    > 95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  30

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.368051   1.696304  -4.692807   1.956705          1 
    Effect_1 | -1.209896    1.96426  -5.059846   2.640053          1 
    Effect_2 | -1.526206   1.955916  -5.359802    2.30739          1 
   Placebo_1 |  .1626256   .6933928  -1.196424   1.521676          1 
   Placebo_2 | -.4102298   .7967261  -1.971813   1.151353          1 
   Placebo_3 |  .3855492   .5124641  -.6188805   1.389979          1 
   Placebo_4 | -.6929698   .7963753  -2.253865   .8679258          1 
   Placebo_5 | -.6451582    .764414   -2.14341   .8530931          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.3680512   1.6963041  -4.6928072   1.9567047           1
 Effect_1  -1.2098962     1.96426  -5.0598458   2.6400533           1
 Effect_2  -1.5262062   1.9559162  -5.3598019   2.3073896           1
Placebo_1    .1626256   .69339281  -1.1964243   1.5216755           1
Placebo_2  -.41022982   .79672612   -1.971813   1.1513534           1
Placebo_3   .38554925   .51246415  -.61888048    1.389979           1
Placebo_4  -.69296975   .79637526  -2.2538653   .86792575           1
Placebo_5  -.64515824   .76441397  -2.1434096   .85309313           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.36805    1.72669    -0.79    0.428    -4.75231     2.01620
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_urban
    > 95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  30

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.368051   1.439121  -4.188729   1.452627          1 
    Effect_1 | -1.209896   1.755663  -4.650995   2.231203          1 
    Effect_2 | -1.526206   1.748395   -4.95306   1.900648          1 
   Placebo_1 |  .1626256   .6397498  -1.091284   1.416535          1 
   Placebo_2 | -.4102298   .7862442  -1.951269   1.130809          1 
   Placebo_3 |  .3855492   .5218936  -.6373622   1.408461          1 
   Placebo_4 | -.6929698   .8218273  -2.303751   .9178118          1 
   Placebo_5 | -.6451582   .5822603  -1.786388    .496072          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.3680512   1.4391215  -4.1887293   1.4526269           1
 Effect_1  -1.2098962   1.7556627  -4.6509951   2.2312026           1
 Effect_2  -1.5262062   1.7483948  -4.9530601   1.9006477           1
Placebo_1    .1626256   .63974982  -1.0912841   1.4165352           1
Placebo_2  -.41022982   .78624425  -1.9512685   1.1308089           1
Placebo_3   .38554925   .52189359  -.63736218   1.4084607           1
Placebo_4  -.69296975   .82182731  -2.3037513   .91781178           1
Placebo_5  -.64515824   .58226031  -1.7863884   .49607196           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.51543    1.65410    -0.31    0.755    -3.75740     2.72653
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_urba
    > n95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  30

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  -.515434   1.915218  -4.269262   3.238394          1 
    Effect_1 | -.4835625   2.505627  -5.394592   4.427467          1 
    Effect_2 | -.5473054   2.063531  -4.591827   3.497216          1 
   Placebo_1 |  .4273238   .8180989   -1.17615   2.030798          1 
   Placebo_2 | -.3498915    .945535   -2.20314   1.503357          1 
   Placebo_3 |  .2527577   .7745324  -1.265326   1.770841          1 
   Placebo_4 | -.0192986   .7517134  -1.492657    1.45406          1 
   Placebo_5 | -.5520937   1.092361  -2.693121   1.588934          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.51543396   1.9152185  -4.2692622   3.2383943           1
 Effect_1  -.48356252   2.5056271  -5.3945916   4.4274665           1
 Effect_2   -.5473054   2.0635313  -4.5918268    3.497216           1
Placebo_1   .42732379    .8180989  -1.1761501   2.0307976           1
Placebo_2  -.34989151   .94553496    -2.20314    1.503357           1
Placebo_3   .25275768   .77453244  -1.2653259   1.7708413           1
Placebo_4  -.01929862   .75171337  -1.4926568   1.4540596           1
Placebo_5  -.55209372   1.0923609   -2.693121   1.5889336           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_event
> study.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -0.51543    2.07079    -0.25    0.803    -4.57411     3.54324
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_urba
    > n95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  30

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  -.515434   1.785835  -4.015671   2.984803          1 
    Effect_1 | -.4835625   2.592454  -5.564771   4.597646          1 
    Effect_2 | -.5473054   1.720124  -3.918749   2.824138          1 
   Placebo_1 |  .4273238   .8864227  -1.310065   2.164712          1 
   Placebo_2 | -.3498915   .8510406  -2.017931   1.318148          1 
   Placebo_3 |  .2527577   .7610994  -1.238997   1.744512          1 
   Placebo_4 | -.0192986   .8839186  -1.751779   1.713182          1 
   Placebo_5 | -.5520937   1.029734  -2.570373   1.466186          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -.51543396   1.7858353  -4.0156712   2.9848033           1
 Effect_1  -.48356252   2.5924535  -5.5647714   4.5976464           1
 Effect_2   -.5473054   1.7201244  -3.9187492   2.8241384           1
Placebo_1   .42732379    .8864227  -1.3100647   2.1647123           1
Placebo_2  -.34989151   .85104058   -2.017931    1.318148           1
Placebo_3   .25275768   .76109937  -1.2389971   1.7445125           1
Placebo_4  -.01929862   .88391863  -1.7517791   1.7131819           1
Placebo_5  -.55209372   1.0297343   -2.570373   1.4661856           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_event
> study.jpg written in JPEG format
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sample_urban95_co
    > vid.tex not found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_samp
> le_urban95_covid.tex)
(913 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.01776    1.63190     0.01    0.991    -3.18071     3.21623
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_urban
    > 98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .0177585   1.244042  -2.420565   2.456082          1 
    Effect_1 |  .2340215   1.657458  -3.014595   3.482638          1 
    Effect_2 | -.1985046   1.230592  -2.610464   2.213455          1 
   Placebo_1 |  .6948368   .4697726  -.2259175   1.615591          1 
   Placebo_2 | -.0874582   .4479934  -.9655253   .7906089          1 
   Placebo_3 |  .6450595   .4729491  -.2819207    1.57204          1 
   Placebo_4 | -.0430069   .5105469  -1.043679   .9576651          1 
   Placebo_5 | -.8486601   .5402341  -1.907519   .2101988          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .01775846   1.2440425  -2.4205648   2.4560817           1
 Effect_1   .23402153   1.6574575  -3.0145952   3.4826383           1
 Effect_2  -.19850462   1.2305916  -2.6104642    2.213455           1
Placebo_1    .6948368   .46977259  -.22591747   1.6155911           1
Placebo_2  -.08745823   .44799343  -.96552535   .79060888           1
Placebo_3   .64505953    .4729491   -.2819207   1.5720398           1
Placebo_4  -.04300693   .51054694  -1.0436789   .95766507           1
Placebo_5  -.84866011   .54023413   -1.907519   .21019879           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.01776    1.56389     0.01    0.991    -3.04741     3.08292
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_urban
    > 98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .0177585   1.088776  -2.116242   2.151759          1 
    Effect_1 |  .2340215   1.737394   -3.17127   3.639313          1 
    Effect_2 | -.1985046   1.024129  -2.205797   1.808788          1 
   Placebo_1 |  .6948368   .5091105  -.3030198   1.692693          1 
   Placebo_2 | -.0874582   .3738165  -.8201386   .6452221          1 
   Placebo_3 |  .6450595   .3698357  -.0798185   1.369938          1 
   Placebo_4 | -.0430069   .3130289  -.6565435   .5705296          1 
   Placebo_5 | -.8486601   .5555636  -1.937565   .2402445          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .01775846    1.088776  -2.1162424   2.1517593           1
 Effect_1   .23402153   1.7373935  -3.1712698   3.6393129           1
 Effect_2  -.19850462   1.0241288  -2.2057971   1.8087879           1
Placebo_1    .6948368   .50911051   -.3030198   1.6926934           1
Placebo_2  -.08745823   .37381652  -.82013861   .64522214           1
Placebo_3   .64505953   .36983573   -.0798185   1.3699376           1
Placebo_4  -.04300693   .31302885  -.65654348   .57052963           1
Placebo_5  -.84866011   .55556358  -1.9375647   .24024451           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.01848    1.42628    -0.71    0.475    -3.81393     1.77697
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_urban
    > 98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.018481   1.307055  -3.580308   1.543346          1 
    Effect_1 | -1.181583   1.549716  -4.219026    1.85586          1 
    Effect_2 | -.8553789   1.425223  -3.648816   1.938058          1 
   Placebo_1 |  .3990419   .6740639  -.9221234   1.720207          1 
   Placebo_2 |  .1551682   .5419259  -.9070066   1.217343          1 
   Placebo_3 |  .5533498   .4688003  -.3654989   1.472198          1 
   Placebo_4 | -.4310342   .8048749  -2.008589   1.146521          1 
   Placebo_5 | -.5558816   .6297665  -1.790224   .6784608          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.0184809   1.3070546  -3.5803079   1.5433461           1
 Effect_1  -1.1815829   1.5497159   -4.219026   1.8558602           1
 Effect_2  -.85537889   1.4252228  -3.6488156   1.9380578           1
Placebo_1   .39904186   .67406388  -.92212335   1.7202071           1
Placebo_2   .15516817   .54192589  -.90700657   1.2173429           1
Placebo_3   .55334981   .46880034  -.36549886   1.4721985           1
Placebo_4   -.4310342   .80487489   -2.008589   1.1465206           1
Placebo_5   -.5558816   .62976651   -1.790224   .67846075           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.01848    1.57131    -0.65    0.517    -4.09820     2.06124
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_urban
    > 98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .29903995
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.018481   1.402712  -3.767796   1.730835          1 
    Effect_1 | -1.181583   1.657753  -4.430779   2.067613          1 
    Effect_2 | -.8553789   1.451267  -3.699863   1.989105          1 
   Placebo_1 |  .3990419   .5067832  -.5942531   1.392337          1 
   Placebo_2 |  .1551682   .4746072  -.7750619   1.085398          1 
   Placebo_3 |  .5533498   .4047511  -.2399624   1.346662          1 
   Placebo_4 | -.4310342   .6467248  -1.698615   .8365464          1 
   Placebo_5 | -.5558816   .4255941  -1.390046   .2782828          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.0184809    1.402712  -3.7677964   1.7308346           1
 Effect_1  -1.1815829   1.6577529  -4.4307786   2.0676128           1
 Effect_2  -.85537889   1.4512672  -3.6998625   1.9891047           1
Placebo_1   .39904186   .50678315  -.59425312   1.3923368           1
Placebo_2   .15516817   .47460717  -.77506189   1.0853982           1
Placebo_3   .55334981   .40475111  -.23996237    1.346662           1
Placebo_4   -.4310342   .64672482  -1.6986148   .83654644           1
Placebo_5   -.5558816   .42559408   -1.390046   .27828279           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_events
> tudy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.05672    1.86458     0.03    0.976    -3.59779     3.71122
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_urba
    > n98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .0567185    1.49258  -2.868738   2.982175          1 
    Effect_1 |  .0453857    1.42452  -2.746673   2.837445          1 
    Effect_2 |  .0680513   1.928224  -3.711267    3.84737          1 
   Placebo_1 |  .2645655   .6568579  -1.022876   1.552007          1 
   Placebo_2 | -.2288683    .597985  -1.400919   .9431823          1 
   Placebo_3 |  .2282187    .467064  -.6872268   1.143664          1 
   Placebo_4 |  .1278778    .551278  -.9526269   1.208383          1 
   Placebo_5 | -.8005655     .59632  -1.969353   .3682217          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT    .0567185     1.49258  -2.8687382   2.9821752           1
 Effect_1   .04538571   1.4245198  -2.7466732   2.8374446           1
 Effect_2   .06805129   1.9282237  -3.7112672   3.8473698           1
Placebo_1   .26456551   .65685794   -1.022876   1.5520071           1
Placebo_2  -.22886833   .59798499  -1.4009189   .94318226           1
Placebo_3   .22821873   .46706404  -.68722678   1.1436642           1
Placebo_4   .12787785   .55127795  -.95262694   1.2083826           1
Placebo_5  -.80056554      .59632  -1.9693527   .36822166           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_event
> study.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.05672    1.84694     0.03    0.976    -3.56322     3.67665
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_urba
    > n98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .19020519
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .0567185   1.572025  -3.024451   3.137888          1 
    Effect_1 |  .0453857   1.455307  -2.807017   2.897788          1 
    Effect_2 |  .0680513   1.993909   -3.84001   3.976112          1 
   Placebo_1 |  .2645655   .5935791  -.8988496   1.427981          1 
   Placebo_2 | -.2288683   .5768694  -1.359532   .9017957          1 
   Placebo_3 |  .2282187   .6074804  -.9624428    1.41888          1 
   Placebo_4 |  .1278778   .5747239   -.998581   1.254337          1 
   Placebo_5 | -.8005655   .6743622  -2.122316   .5211845          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT    .0567185   1.5720251  -3.0244507   3.1378877           1
 Effect_1   .04538571   1.4553074  -2.8070168   2.8977882           1
 Effect_2   .06805129   1.9939086  -3.8400096   3.9761122           1
Placebo_1   .26456551   .59357913  -.89884958   1.4279806           1
Placebo_2  -.22886833   .57686941  -1.3595324   .90179572           1
Placebo_3   .22821873   .60748038  -.96244281   1.4188803           1
Placebo_4   .12787785    .5747239    -.998581   1.2543367           1
Placebo_5  -.80056554   .67436225  -2.1223155   .52118447           1
(21,255 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_event
> study.jpg written in JPEG format
(file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sample_urban98.te
    > x not found)
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_samp
> le_urban98.tex)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
.................--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_
> 00003q.tmp"

. /*********************************************
> **********************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-diffe
> rence estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale
> .edu
> 
> **********************************************
> *********************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replac
> e text name(log_02)
------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/mul
> tnomah-county-tax/code/logs/02_log_sdid_2025-1
> 2-16.log
  log type:  text
 opened on:  18 Dec 2025, 18:45:35

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace
>  

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demograph
> ics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (
> demo_merge==1)
        from using                          0  (
> demo_merge==2)

    Matched                            21,974  (
> demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         6 |       202 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         0 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |         0 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |         6 |    21,980 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       202 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        30 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       931 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_
> economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (
> econ_merge==1)
        from using                          0  (
> econ_merge==2)

    Matched                            21,608  (
> econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         0 |       196 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         9 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |       357 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |       366 |    21,974 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       196 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        21 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       574 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_clea
> ned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (
> covid_merge==1)
        from using                          0  (
> covid_merge==2)

    Matched                            21,545  (
> covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     Total
----------------------+-----------+----------
              Alabama |         0 |       469 
               Alaska |        28 |       196 
              Arizona |         0 |       105 
             Arkansas |         0 |       525 
           California |         0 |       406 
             Colorado |         0 |       448 
          Connecticut |         0 |        48 
             Delaware |         0 |        21 
 District of Columbia |         0 |         7 
              Florida |         0 |       469 
              Georgia |         0 |     1,113 
               Hawaii |         0 |        21 
                Idaho |         0 |       308 
             Illinois |         0 |       714 
              Indiana |         0 |       644 
                 Iowa |         0 |       693 
               Kansas |         0 |       735 
             Kentucky |         0 |       840 
            Louisiana |         0 |       448 
                Maine |         0 |       112 
             Maryland |         0 |       168 
        Massachusetts |         0 |        98 
             Michigan |         0 |       581 
            Minnesota |         0 |       609 
          Mississippi |         0 |       574 
             Missouri |         0 |       805 
              Montana |         0 |       392 
             Nebraska |         0 |       651 
               Nevada |         0 |       119 
        New Hampshire |         0 |        70 
           New Jersey |         0 |       147 
           New Mexico |         0 |       231 
             New York |        35 |       434 
       North Carolina |         0 |       700 
         North Dakota |         0 |       371 
                 Ohio |         0 |       616 
             Oklahoma |         0 |       539 
               Oregon |         0 |       252 
         Pennsylvania |         0 |       469 
         Rhode Island |         0 |        35 
       South Carolina |         0 |       322 
         South Dakota |         0 |       462 
            Tennessee |         0 |       665 
                Texas |         0 |     1,778 
                 Utah |         0 |       203 
              Vermont |         0 |        98 
             Virginia |         0 |       574 
           Washington |         0 |       273 
        West Virginia |         0 |       385 
            Wisconsin |         0 |       504 
              Wyoming |         0 |       161 
----------------------+-----------+----------
                Total |        63 |    21,608 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     Total
----------------------+-----------+----------
              Alabama |       469 |       469 
               Alaska |       168 |       196 
              Arizona |       105 |       105 
             Arkansas |       525 |       525 
           California |       406 |       406 
             Colorado |       448 |       448 
          Connecticut |        48 |        48 
             Delaware |        21 |        21 
 District of Columbia |         7 |         7 
              Florida |       469 |       469 
              Georgia |     1,113 |     1,113 
               Hawaii |        21 |        21 
                Idaho |       308 |       308 
             Illinois |       714 |       714 
              Indiana |       644 |       644 
                 Iowa |       693 |       693 
               Kansas |       735 |       735 
             Kentucky |       840 |       840 
            Louisiana |       448 |       448 
                Maine |       112 |       112 
             Maryland |       168 |       168 
        Massachusetts |        98 |        98 
             Michigan |       581 |       581 
            Minnesota |       609 |       609 
          Mississippi |       574 |       574 
             Missouri |       805 |       805 
              Montana |       392 |       392 
             Nebraska |       651 |       651 
               Nevada |       119 |       119 
        New Hampshire |        70 |        70 
           New Jersey |       147 |       147 
           New Mexico |       231 |       231 
             New York |       399 |       434 
       North Carolina |       700 |       700 
         North Dakota |       371 |       371 
                 Ohio |       616 |       616 
             Oklahoma |       539 |       539 
               Oregon |       252 |       252 
         Pennsylvania |       469 |       469 
         Rhode Island |        35 |        35 
       South Carolina |       322 |       322 
         South Dakota |       462 |       462 
            Tennessee |       665 |       665 
                Texas |     1,778 |     1,778 
                 Utah |       203 |       203 
              Vermont |        98 |        98 
             Virginia |       574 |       574 
           Washington |       273 |       273 
        West Virginia |       385 |       385 
            Wisconsin |       504 |       504 
              Wyoming |       161 |       161 
----------------------+-----------+----------
                Total |    21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_
> county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,936
        from master                    18,606  (
> merge_acs==1)
        from using                      1,330  (
> merge_acs==2)

    Matched                             3,002  (
> merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Using onl |     Total
-----------+----------------------+----------
      2015 |     2,658          0 |     3,088 
      2016 |     2,658          0 |     3,088 
      2017 |     2,658          0 |     3,088 
      2018 |     2,658          0 |     3,088 
      2019 |     2,658          0 |     3,088 
      2020 |     2,658          0 |     3,088 
      2021 |     2,658          8 |     3,088 
      2022 |         0        444 |       444 
      2023 |         0        444 |       444 
-----------+----------------------+----------
     Total |    18,606        896 |    22,504 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |       430 |     3,088 
      2016 |       430 |     3,088 
      2017 |       430 |     3,088 
      2018 |       430 |     3,088 
      2019 |       430 |     3,088 
      2020 |       430 |     3,088 
      2021 |       422 |     3,088 
      2022 |         0 |       444 
      2023 |         0 |       444 
-----------+-----------+----------
     Total |     3,002 |    22,504 

. tab state_name if merge_acs == 2 & year == 202
> 1

              State name |      Freq.     Percen
> t        Cum.
-------------------------+----------------------
> -------------
             Connecticut |          8      100.0
> 0      100.00
-------------------------+----------------------
> -------------
                   Total |          8      100.0
> 0

. tab state_name if merge_acs == 1 & year == 202
> 1

              State name |      Freq.     Percen
> t        Cum.
-------------------------+----------------------
> -------------
                 Alabama |         60        2.2
> 6        2.26
                  Alaska |         27        1.0
> 2        3.27
                 Arizona |         10        0.3
> 8        3.65
                Arkansas |         71        2.6
> 7        6.32
              California |         24        0.9
> 0        7.22
                Colorado |         63        2.3
> 7        9.59
                 Florida |         39        1.4
> 7       11.06
                 Georgia |        139        5.2
> 3       16.29
                  Hawaii |          1        0.0
> 4       16.33
                   Idaho |         43        1.6
> 2       17.95
                Illinois |         84        3.1
> 6       21.11
                 Indiana |         76        2.8
> 6       23.97
                    Iowa |         95        3.5
> 7       27.54
                  Kansas |        102        3.8
> 4       31.38
                Kentucky |        115        4.3
> 3       35.70
               Louisiana |         56        2.1
> 1       37.81
                   Maine |         13        0.4
> 9       38.30
                Maryland |         12        0.4
> 5       38.75
           Massachusetts |         12        0.4
> 5       39.20
                Michigan |         67        2.5
> 2       41.72
               Minnesota |         79        2.9
> 7       44.70
             Mississippi |         79        2.9
> 7       47.67
                Missouri |        108        4.0
> 6       51.73
                 Montana |         56        2.1
> 1       53.84
                Nebraska |         90        3.3
> 9       57.22
                  Nevada |         15        0.5
> 6       57.79
           New Hampshire |         10        0.3
> 8       58.16
              New Jersey |          4        0.1
> 5       58.31
              New Mexico |         30        1.1
> 3       59.44
                New York |         41        1.5
> 4       60.99
          North Carolina |         80        3.0
> 1       64.00
            North Dakota |         52        1.9
> 6       65.95
                    Ohio |         67        2.5
> 2       68.47
                Oklahoma |         74        2.7
> 8       71.26
                  Oregon |         28        1.0
> 5       72.31
            Pennsylvania |         47        1.7
> 7       74.08
            Rhode Island |          2        0.0
> 8       74.15
          South Carolina |         42        1.5
> 8       75.73
            South Dakota |         66        2.4
> 8       78.22
               Tennessee |         86        3.2
> 4       81.45
                   Texas |        216        8.1
> 3       89.58
                    Utah |         24        0.9
> 0       90.48
                 Vermont |         14        0.5
> 3       91.01
                Virginia |         72        2.7
> 1       93.72
              Washington |         30        1.1
> 3       94.85
           West Virginia |         55        2.0
> 7       96.91
               Wisconsin |         59        2.2
> 2       99.13
                 Wyoming |         23        0.8
> 7      100.00
-------------------------+----------------------
> -------------
                   Total |      2,658      100.0
> 0

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips
>  == 51

. label var multnomah "Indicator for Multnomah C
> ounty, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Mul
> tnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base popu
> lations
. tab year county_name if missing(n1_in_1 ) | n1
> _in_1 == 0
too many values
r(134);

end of do-file

r(134);

. do "C:\Users\ji252\Documents\GitHub\multnomah-
> county-tax\code\02_sdid_analysis.do"

. /*********************************************
> **********************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-diffe
> rence estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale
> .edu
> 
> **********************************************
> *********************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replac
> e text name(log_02)
------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/mul
> tnomah-county-tax/code/logs/02_log_sdid_2025-1
> 2-16.log
  log type:  text
 opened on:  18 Dec 2025, 18:45:39

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace
>  

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demograph
> ics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (
> demo_merge==1)
        from using                          0  (
> demo_merge==2)

    Matched                            21,974  (
> demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         6 |       202 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         0 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |         0 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |         6 |    21,980 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       202 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        30 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       931 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_
> economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (
> econ_merge==1)
        from using                          0  (
> econ_merge==2)

    Matched                            21,608  (
> econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       469 
              Alaska |         0 |       196 
             Arizona |         0 |       105 
            Arkansas |         0 |       525 
          California |         0 |       406 
            Colorado |         0 |       448 
         Connecticut |         0 |        48 
            Delaware |         0 |        21 
District of Columbia |         0 |         7 
             Florida |         0 |       469 
             Georgia |         0 |     1,113 
              Hawaii |         9 |        30 
               Idaho |         0 |       308 
            Illinois |         0 |       714 
             Indiana |         0 |       644 
                Iowa |         0 |       693 
              Kansas |         0 |       735 
            Kentucky |         0 |       840 
           Louisiana |         0 |       448 
               Maine |         0 |       112 
            Maryland |         0 |       168 
       Massachusetts |         0 |        98 
            Michigan |         0 |       581 
           Minnesota |         0 |       609 
         Mississippi |         0 |       574 
            Missouri |         0 |       805 
             Montana |         0 |       392 
            Nebraska |         0 |       651 
              Nevada |         0 |       119 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       147 
          New Mexico |         0 |       231 
            New York |         0 |       434 
      North Carolina |         0 |       700 
        North Dakota |         0 |       371 
                Ohio |         0 |       616 
            Oklahoma |         0 |       539 
              Oregon |         0 |       252 
        Pennsylvania |         0 |       469 
        Rhode Island |         0 |        35 
      South Carolina |         0 |       322 
        South Dakota |         0 |       462 
           Tennessee |         0 |       665 
               Texas |         0 |     1,778 
                Utah |         0 |       203 
             Vermont |         0 |        98 
            Virginia |       357 |       931 
          Washington |         0 |       273 
       West Virginia |         0 |       385 
           Wisconsin |         0 |       504 
             Wyoming |         0 |       161 
---------------------+-----------+----------
               Total |       366 |    21,974 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       469 |       469 
              Alaska |       196 |       196 
             Arizona |       105 |       105 
            Arkansas |       525 |       525 
          California |       406 |       406 
            Colorado |       448 |       448 
         Connecticut |        48 |        48 
            Delaware |        21 |        21 
District of Columbia |         7 |         7 
             Florida |       469 |       469 
             Georgia |     1,113 |     1,113 
              Hawaii |        21 |        30 
               Idaho |       308 |       308 
            Illinois |       714 |       714 
             Indiana |       644 |       644 
                Iowa |       693 |       693 
              Kansas |       735 |       735 
            Kentucky |       840 |       840 
           Louisiana |       448 |       448 
               Maine |       112 |       112 
            Maryland |       168 |       168 
       Massachusetts |        98 |        98 
            Michigan |       581 |       581 
           Minnesota |       609 |       609 
         Mississippi |       574 |       574 
            Missouri |       805 |       805 
             Montana |       392 |       392 
            Nebraska |       651 |       651 
              Nevada |       119 |       119 
       New Hampshire |        70 |        70 
          New Jersey |       147 |       147 
          New Mexico |       231 |       231 
            New York |       434 |       434 
      North Carolina |       700 |       700 
        North Dakota |       371 |       371 
                Ohio |       616 |       616 
            Oklahoma |       539 |       539 
              Oregon |       252 |       252 
        Pennsylvania |       469 |       469 
        Rhode Island |        35 |        35 
      South Carolina |       322 |       322 
        South Dakota |       462 |       462 
           Tennessee |       665 |       665 
               Texas |     1,778 |     1,778 
                Utah |       203 |       203 
             Vermont |        98 |        98 
            Virginia |       574 |       931 
          Washington |       273 |       273 
       West Virginia |       385 |       385 
           Wisconsin |       504 |       504 
             Wyoming |       161 |       161 
---------------------+-----------+----------
               Total |    21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_clea
> ned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (
> covid_merge==1)
        from using                          0  (
> covid_merge==2)

    Matched                            21,545  (
> covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     Total
----------------------+-----------+----------
              Alabama |         0 |       469 
               Alaska |        28 |       196 
              Arizona |         0 |       105 
             Arkansas |         0 |       525 
           California |         0 |       406 
             Colorado |         0 |       448 
          Connecticut |         0 |        48 
             Delaware |         0 |        21 
 District of Columbia |         0 |         7 
              Florida |         0 |       469 
              Georgia |         0 |     1,113 
               Hawaii |         0 |        21 
                Idaho |         0 |       308 
             Illinois |         0 |       714 
              Indiana |         0 |       644 
                 Iowa |         0 |       693 
               Kansas |         0 |       735 
             Kentucky |         0 |       840 
            Louisiana |         0 |       448 
                Maine |         0 |       112 
             Maryland |         0 |       168 
        Massachusetts |         0 |        98 
             Michigan |         0 |       581 
            Minnesota |         0 |       609 
          Mississippi |         0 |       574 
             Missouri |         0 |       805 
              Montana |         0 |       392 
             Nebraska |         0 |       651 
               Nevada |         0 |       119 
        New Hampshire |         0 |        70 
           New Jersey |         0 |       147 
           New Mexico |         0 |       231 
             New York |        35 |       434 
       North Carolina |         0 |       700 
         North Dakota |         0 |       371 
                 Ohio |         0 |       616 
             Oklahoma |         0 |       539 
               Oregon |         0 |       252 
         Pennsylvania |         0 |       469 
         Rhode Island |         0 |        35 
       South Carolina |         0 |       322 
         South Dakota |         0 |       462 
            Tennessee |         0 |       665 
                Texas |         0 |     1,778 
                 Utah |         0 |       203 
              Vermont |         0 |        98 
             Virginia |         0 |       574 
           Washington |         0 |       273 
        West Virginia |         0 |       385 
            Wisconsin |         0 |       504 
              Wyoming |         0 |       161 
----------------------+-----------+----------
                Total |        63 |    21,608 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     Total
----------------------+-----------+----------
              Alabama |       469 |       469 
               Alaska |       168 |       196 
              Arizona |       105 |       105 
             Arkansas |       525 |       525 
           California |       406 |       406 
             Colorado |       448 |       448 
          Connecticut |        48 |        48 
             Delaware |        21 |        21 
 District of Columbia |         7 |         7 
              Florida |       469 |       469 
              Georgia |     1,113 |     1,113 
               Hawaii |        21 |        21 
                Idaho |       308 |       308 
             Illinois |       714 |       714 
              Indiana |       644 |       644 
                 Iowa |       693 |       693 
               Kansas |       735 |       735 
             Kentucky |       840 |       840 
            Louisiana |       448 |       448 
                Maine |       112 |       112 
             Maryland |       168 |       168 
        Massachusetts |        98 |        98 
             Michigan |       581 |       581 
            Minnesota |       609 |       609 
          Mississippi |       574 |       574 
             Missouri |       805 |       805 
              Montana |       392 |       392 
             Nebraska |       651 |       651 
               Nevada |       119 |       119 
        New Hampshire |        70 |        70 
           New Jersey |       147 |       147 
           New Mexico |       231 |       231 
             New York |       399 |       434 
       North Carolina |       700 |       700 
         North Dakota |       371 |       371 
                 Ohio |       616 |       616 
             Oklahoma |       539 |       539 
               Oregon |       252 |       252 
         Pennsylvania |       469 |       469 
         Rhode Island |        35 |        35 
       South Carolina |       322 |       322 
         South Dakota |       462 |       462 
            Tennessee |       665 |       665 
                Texas |     1,778 |     1,778 
                 Utah |       203 |       203 
              Vermont |        98 |        98 
             Virginia |       574 |       574 
           Washington |       273 |       273 
        West Virginia |       385 |       385 
            Wisconsin |       504 |       504 
              Wyoming |       161 |       161 
----------------------+-----------+----------
                Total |    21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_
> county_gross_18plus", gen(merge_acs)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        19,936
        from master                    18,606  (
> merge_acs==1)
        from using                      1,330  (
> merge_acs==2)

    Matched                             3,002  (
> merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Using onl |     Total
-----------+----------------------+----------
      2015 |     2,658          0 |     3,088 
      2016 |     2,658          0 |     3,088 
      2017 |     2,658          0 |     3,088 
      2018 |     2,658          0 |     3,088 
      2019 |     2,658          0 |     3,088 
      2020 |     2,658          0 |     3,088 
      2021 |     2,658          8 |     3,088 
      2022 |         0        444 |       444 
      2023 |         0        444 |       444 
-----------+----------------------+----------
     Total |    18,606        896 |    22,504 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |       430 |     3,088 
      2016 |       430 |     3,088 
      2017 |       430 |     3,088 
      2018 |       430 |     3,088 
      2019 |       430 |     3,088 
      2020 |       430 |     3,088 
      2021 |       422 |     3,088 
      2022 |         0 |       444 
      2023 |         0 |       444 
-----------+-----------+----------
     Total |     3,002 |    22,504 

. tab state_name if merge_acs == 2 & year == 202
> 1

              State name |      Freq.     Percen
> t        Cum.
-------------------------+----------------------
> -------------
             Connecticut |          8      100.0
> 0      100.00
-------------------------+----------------------
> -------------
                   Total |          8      100.0
> 0

. tab state_name if merge_acs == 1 & year == 202
> 1

              State name |      Freq.     Percen
> t        Cum.
-------------------------+----------------------
> -------------
                 Alabama |         60        2.2
> 6        2.26
                  Alaska |         27        1.0
> 2        3.27
                 Arizona |         10        0.3
> 8        3.65
                Arkansas |         71        2.6
> 7        6.32
              California |         24        0.9
> 0        7.22
                Colorado |         63        2.3
> 7        9.59
                 Florida |         39        1.4
> 7       11.06
                 Georgia |        139        5.2
> 3       16.29
                  Hawaii |          1        0.0
> 4       16.33
                   Idaho |         43        1.6
> 2       17.95
                Illinois |         84        3.1
> 6       21.11
                 Indiana |         76        2.8
> 6       23.97
                    Iowa |         95        3.5
> 7       27.54
                  Kansas |        102        3.8
> 4       31.38
                Kentucky |        115        4.3
> 3       35.70
               Louisiana |         56        2.1
> 1       37.81
                   Maine |         13        0.4
> 9       38.30
                Maryland |         12        0.4
> 5       38.75
           Massachusetts |         12        0.4
> 5       39.20
                Michigan |         67        2.5
> 2       41.72
               Minnesota |         79        2.9
> 7       44.70
             Mississippi |         79        2.9
> 7       47.67
                Missouri |        108        4.0
> 6       51.73
                 Montana |         56        2.1
> 1       53.84
                Nebraska |         90        3.3
> 9       57.22
                  Nevada |         15        0.5
> 6       57.79
           New Hampshire |         10        0.3
> 8       58.16
              New Jersey |          4        0.1
> 5       58.31
              New Mexico |         30        1.1
> 3       59.44
                New York |         41        1.5
> 4       60.99
          North Carolina |         80        3.0
> 1       64.00
            North Dakota |         52        1.9
> 6       65.95
                    Ohio |         67        2.5
> 2       68.47
                Oklahoma |         74        2.7
> 8       71.26
                  Oregon |         28        1.0
> 5       72.31
            Pennsylvania |         47        1.7
> 7       74.08
            Rhode Island |          2        0.0
> 8       74.15
          South Carolina |         42        1.5
> 8       75.73
            South Dakota |         66        2.4
> 8       78.22
               Tennessee |         86        3.2
> 4       81.45
                   Texas |        216        8.1
> 3       89.58
                    Utah |         24        0.9
> 0       90.48
                 Vermont |         14        0.5
> 3       91.01
                Virginia |         72        2.7
> 1       93.72
              Washington |         30        1.1
> 3       94.85
           West Virginia |         55        2.0
> 7       96.91
               Wisconsin |         59        2.2
> 2       99.13
                 Wyoming |         23        0.8
> 7      100.00
-------------------------+----------------------
> -------------
                   Total |      2,658      100.0
> 0

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips
>  == 51

. label var multnomah "Indicator for Multnomah C
> ounty, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Mul
> tnomah County, Oregon"    

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base popu
> lations
. tab year county_name if missing(n1_in_1 ) | n1
> _in_1 == 0
too many values
r(134);

end of do-file

r(134);

. tab year if missing(n1_in_1) | n1_in_1

   Tax year |
      (year |
     before |
      move) |      Freq.     Percent        Cum.
------------+-----------------------------------
       2015 |      3,088       13.72       13.72
       2016 |      3,088       13.72       27.44
       2017 |      3,088       13.72       41.17
       2018 |      3,088       13.72       54.89
       2019 |      3,088       13.72       68.61
       2020 |      3,088       13.72       82.33
       2021 |      3,088       13.72       96.05
       2022 |        444        1.97       98.03
       2023 |        444        1.97      100.00
------------+-----------------------------------
      Total |     22,504      100.00

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003r.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 18:47:17

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab year county_name if missing(n1_in_1 ) | n1_in_1 == 0 & acs_m
acs_m not found
r(111);

end of do-file

r(111);

. do "C:\Users\ji252\AppData\Local\Temp\S
> TD91a0_00003s.tmp"

. tab year county_name if missing(n1_in_1
>  ) | n1_in_1 == 0 

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 
> 0
(1 observation deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\S
> TD91a0_00003t.tmp"

. 
. ** Keep only sample with observations i
> n each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      | State name
          County name | Connect.. |     T
> otal
----------------------+-----------+------
> ----
     Fairfield County |         6 |      
>    6 
      Hartford County |         6 |      
>    6 
    Litchfield County |         6 |      
>    6 
        Loving County |         0 |      
>    6 
     Middlesex County |         6 |      
>    6 
     New Haven County |         6 |      
>    6 
    New London County |         6 |      
>    6 
       Tolland County |         6 |      
>    6 
       Windham County |         6 |      
>    6 
----------------------+-----------+------
> ----
                Total |        48 |      
>   54 


                      | State name
          County name |     Texas |     T
> otal
----------------------+-----------+------
> ----
     Fairfield County |         0 |      
>    6 
      Hartford County |         0 |      
>    6 
    Litchfield County |         0 |      
>    6 
        Loving County |         6 |      
>    6 
     Middlesex County |         0 |      
>    6 
     New Haven County |         0 |      
>    6 
    New London County |         0 |      
>    6 
       Tolland County |         0 |      
>    6 
       Windham County |         0 |      
>    6 
----------------------+-----------+------
> ----
                Total |         6 |      
>   54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\S
> TD91a0_00003u.tmp"

. /**************************************
> ***************************************
> **
> File Name:              02_sdid_analysi
> s.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-i
> n-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.isel
> in@yale.edu
> 
> ***************************************
> ***************************************
> */
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}",
>  replace text name(log_02)
-----------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/Git
> Hub/multnomah-county-tax/code/logs/02_l
> og_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 18:47:45

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", 
> replace 

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/de
> mographics_2020",        ///
>         gen(demo_merge) keep(master mat
> ch)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    6
        from master                      
>    6  (demo_merge==1)
        from using                       
>    0  (demo_merge==2)

    Matched                            21
> ,974  (demo_merge==3)
    -------------------------------------
> ----

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |         0 |       
> 469 
              Alaska |         6 |       
> 202 
             Arizona |         0 |       
> 105 
            Arkansas |         0 |       
> 525 
          California |         0 |       
> 406 
            Colorado |         0 |       
> 448 
         Connecticut |         0 |       
>  48 
            Delaware |         0 |       
>  21 
District of Columbia |         0 |       
>   7 
             Florida |         0 |       
> 469 
             Georgia |         0 |     1,
> 113 
              Hawaii |         0 |       
>  30 
               Idaho |         0 |       
> 308 
            Illinois |         0 |       
> 714 
             Indiana |         0 |       
> 644 
                Iowa |         0 |       
> 693 
              Kansas |         0 |       
> 735 
            Kentucky |         0 |       
> 840 
           Louisiana |         0 |       
> 448 
               Maine |         0 |       
> 112 
            Maryland |         0 |       
> 168 
       Massachusetts |         0 |       
>  98 
            Michigan |         0 |       
> 581 
           Minnesota |         0 |       
> 609 
         Mississippi |         0 |       
> 574 
            Missouri |         0 |       
> 805 
             Montana |         0 |       
> 392 
            Nebraska |         0 |       
> 651 
              Nevada |         0 |       
> 119 
       New Hampshire |         0 |       
>  70 
          New Jersey |         0 |       
> 147 
          New Mexico |         0 |       
> 231 
            New York |         0 |       
> 434 
      North Carolina |         0 |       
> 700 
        North Dakota |         0 |       
> 371 
                Ohio |         0 |       
> 616 
            Oklahoma |         0 |       
> 539 
              Oregon |         0 |       
> 252 
        Pennsylvania |         0 |       
> 469 
        Rhode Island |         0 |       
>  35 
      South Carolina |         0 |       
> 322 
        South Dakota |         0 |       
> 462 
           Tennessee |         0 |       
> 665 
               Texas |         0 |     1,
> 778 
                Utah |         0 |       
> 203 
             Vermont |         0 |       
>  98 
            Virginia |         0 |       
> 931 
          Washington |         0 |       
> 273 
       West Virginia |         0 |       
> 385 
           Wisconsin |         0 |       
> 504 
             Wyoming |         0 |       
> 161 
---------------------+-----------+-------
> ---
               Total |         6 |    21,
> 980 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |       469 |       
> 469 
              Alaska |       196 |       
> 202 
             Arizona |       105 |       
> 105 
            Arkansas |       525 |       
> 525 
          California |       406 |       
> 406 
            Colorado |       448 |       
> 448 
         Connecticut |        48 |       
>  48 
            Delaware |        21 |       
>  21 
District of Columbia |         7 |       
>   7 
             Florida |       469 |       
> 469 
             Georgia |     1,113 |     1,
> 113 
              Hawaii |        30 |       
>  30 
               Idaho |       308 |       
> 308 
            Illinois |       714 |       
> 714 
             Indiana |       644 |       
> 644 
                Iowa |       693 |       
> 693 
              Kansas |       735 |       
> 735 
            Kentucky |       840 |       
> 840 
           Louisiana |       448 |       
> 448 
               Maine |       112 |       
> 112 
            Maryland |       168 |       
> 168 
       Massachusetts |        98 |       
>  98 
            Michigan |       581 |       
> 581 
           Minnesota |       609 |       
> 609 
         Mississippi |       574 |       
> 574 
            Missouri |       805 |       
> 805 
             Montana |       392 |       
> 392 
            Nebraska |       651 |       
> 651 
              Nevada |       119 |       
> 119 
       New Hampshire |        70 |       
>  70 
          New Jersey |       147 |       
> 147 
          New Mexico |       231 |       
> 231 
            New York |       434 |       
> 434 
      North Carolina |       700 |       
> 700 
        North Dakota |       371 |       
> 371 
                Ohio |       616 |       
> 616 
            Oklahoma |       539 |       
> 539 
              Oregon |       252 |       
> 252 
        Pennsylvania |       469 |       
> 469 
        Rhode Island |        35 |       
>  35 
      South Carolina |       322 |       
> 322 
        South Dakota |       462 |       
> 462 
           Tennessee |       665 |       
> 665 
               Texas |     1,778 |     1,
> 778 
                Utah |       203 |       
> 203 
             Vermont |        98 |       
>  98 
            Virginia |       931 |       
> 931 
          Washington |       273 |       
> 273 
       West Virginia |       385 |       
> 385 
           Wisconsin |       504 |       
> 504 
             Wyoming |       161 |       
> 161 
---------------------+-----------+-------
> ---
               Total |    21,974 |    21,
> 980 

. tab year demo_merge, m

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2015 |         0 |     3,140 
      2016 |         0 |     3,140 
      2017 |         0 |     3,140 
      2018 |         0 |     3,140 
      2019 |         2 |     3,142 
      2020 |         2 |     3,143 
      2021 |         2 |     3,135 
-----------+-----------+----------
     Total |         6 |    21,980 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |     3,140 |     3,140 
      2016 |     3,140 |     3,140 
      2017 |     3,140 |     3,140 
      2018 |     3,140 |     3,140 
      2019 |     3,140 |     3,142 
      2020 |     3,141 |     3,143 
      2021 |     3,133 |     3,135 
-----------+-----------+----------
     Total |    21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}worki
> ng/bea_economics",       ///
>         gen(econ_merge) keep(master mat
> ch) 
(variable fips was float, now double to
       accommodate using data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>  366
        from master                      
>  366  (econ_merge==1)
        from using                       
>    0  (econ_merge==2)

    Matched                            21
> ,608  (econ_merge==3)
    -------------------------------------
> ----

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |         0 |       
> 469 
              Alaska |         0 |       
> 196 
             Arizona |         0 |       
> 105 
            Arkansas |         0 |       
> 525 
          California |         0 |       
> 406 
            Colorado |         0 |       
> 448 
         Connecticut |         0 |       
>  48 
            Delaware |         0 |       
>  21 
District of Columbia |         0 |       
>   7 
             Florida |         0 |       
> 469 
             Georgia |         0 |     1,
> 113 
              Hawaii |         9 |       
>  30 
               Idaho |         0 |       
> 308 
            Illinois |         0 |       
> 714 
             Indiana |         0 |       
> 644 
                Iowa |         0 |       
> 693 
              Kansas |         0 |       
> 735 
            Kentucky |         0 |       
> 840 
           Louisiana |         0 |       
> 448 
               Maine |         0 |       
> 112 
            Maryland |         0 |       
> 168 
       Massachusetts |         0 |       
>  98 
            Michigan |         0 |       
> 581 
           Minnesota |         0 |       
> 609 
         Mississippi |         0 |       
> 574 
            Missouri |         0 |       
> 805 
             Montana |         0 |       
> 392 
            Nebraska |         0 |       
> 651 
              Nevada |         0 |       
> 119 
       New Hampshire |         0 |       
>  70 
          New Jersey |         0 |       
> 147 
          New Mexico |         0 |       
> 231 
            New York |         0 |       
> 434 
      North Carolina |         0 |       
> 700 
        North Dakota |         0 |       
> 371 
                Ohio |         0 |       
> 616 
            Oklahoma |         0 |       
> 539 
              Oregon |         0 |       
> 252 
        Pennsylvania |         0 |       
> 469 
        Rhode Island |         0 |       
>  35 
      South Carolina |         0 |       
> 322 
        South Dakota |         0 |       
> 462 
           Tennessee |         0 |       
> 665 
               Texas |         0 |     1,
> 778 
                Utah |         0 |       
> 203 
             Vermont |         0 |       
>  98 
            Virginia |       357 |       
> 931 
          Washington |         0 |       
> 273 
       West Virginia |         0 |       
> 385 
           Wisconsin |         0 |       
> 504 
             Wyoming |         0 |       
> 161 
---------------------+-----------+-------
> ---
               Total |       366 |    21,
> 974 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |       469 |       
> 469 
              Alaska |       196 |       
> 196 
             Arizona |       105 |       
> 105 
            Arkansas |       525 |       
> 525 
          California |       406 |       
> 406 
            Colorado |       448 |       
> 448 
         Connecticut |        48 |       
>  48 
            Delaware |        21 |       
>  21 
District of Columbia |         7 |       
>   7 
             Florida |       469 |       
> 469 
             Georgia |     1,113 |     1,
> 113 
              Hawaii |        21 |       
>  30 
               Idaho |       308 |       
> 308 
            Illinois |       714 |       
> 714 
             Indiana |       644 |       
> 644 
                Iowa |       693 |       
> 693 
              Kansas |       735 |       
> 735 
            Kentucky |       840 |       
> 840 
           Louisiana |       448 |       
> 448 
               Maine |       112 |       
> 112 
            Maryland |       168 |       
> 168 
       Massachusetts |        98 |       
>  98 
            Michigan |       581 |       
> 581 
           Minnesota |       609 |       
> 609 
         Mississippi |       574 |       
> 574 
            Missouri |       805 |       
> 805 
             Montana |       392 |       
> 392 
            Nebraska |       651 |       
> 651 
              Nevada |       119 |       
> 119 
       New Hampshire |        70 |       
>  70 
          New Jersey |       147 |       
> 147 
          New Mexico |       231 |       
> 231 
            New York |       434 |       
> 434 
      North Carolina |       700 |       
> 700 
        North Dakota |       371 |       
> 371 
                Ohio |       616 |       
> 616 
            Oklahoma |       539 |       
> 539 
              Oregon |       252 |       
> 252 
        Pennsylvania |       469 |       
> 469 
        Rhode Island |        35 |       
>  35 
      South Carolina |       322 |       
> 322 
        South Dakota |       462 |       
> 462 
           Tennessee |       665 |       
> 665 
               Texas |     1,778 |     1,
> 778 
                Utah |       203 |       
> 203 
             Vermont |        98 |       
>  98 
            Virginia |       574 |       
> 931 
          Washington |       273 |       
> 273 
       West Virginia |       385 |       
> 385 
           Wisconsin |       504 |       
> 504 
             Wyoming |       161 |       
> 161 
---------------------+-----------+-------
> ---
               Total |    21,608 |    21,
> 974 

. tab year econ_merge, m

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2015 |        52 |     3,140 
      2016 |        52 |     3,140 
      2017 |        52 |     3,140 
      2018 |        52 |     3,140 
      2019 |        52 |     3,140 
      2020 |        53 |     3,141 
      2021 |        53 |     3,133 
-----------+-----------+----------
     Total |       366 |    21,974 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |     3,088 |     3,140 
      2016 |     3,088 |     3,140 
      2017 |     3,088 |     3,140 
      2018 |     3,088 |     3,140 
      2019 |     3,088 |     3,140 
      2020 |     3,088 |     3,141 
      2021 |     3,080 |     3,133 
-----------+-----------+----------
     Total |    21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/cov
> id_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master ma
> tch )
(variable state_name was str20, now
       str24 to accommodate using
       data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   63
        from master                      
>   63  (covid_merge==1)
        from using                       
>    0  (covid_merge==2)

    Matched                            21
> ,545  (covid_merge==3)
    -------------------------------------
> ----

. 
. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     T
> otal
----------------------+-----------+------
> ----
              Alabama |         0 |      
>  469 
               Alaska |        28 |      
>  196 
              Arizona |         0 |      
>  105 
             Arkansas |         0 |      
>  525 
           California |         0 |      
>  406 
             Colorado |         0 |      
>  448 
          Connecticut |         0 |      
>   48 
             Delaware |         0 |      
>   21 
 District of Columbia |         0 |      
>    7 
              Florida |         0 |      
>  469 
              Georgia |         0 |     1
> ,113 
               Hawaii |         0 |      
>   21 
                Idaho |         0 |      
>  308 
             Illinois |         0 |      
>  714 
              Indiana |         0 |      
>  644 
                 Iowa |         0 |      
>  693 
               Kansas |         0 |      
>  735 
             Kentucky |         0 |      
>  840 
            Louisiana |         0 |      
>  448 
                Maine |         0 |      
>  112 
             Maryland |         0 |      
>  168 
        Massachusetts |         0 |      
>   98 
             Michigan |         0 |      
>  581 
            Minnesota |         0 |      
>  609 
          Mississippi |         0 |      
>  574 
             Missouri |         0 |      
>  805 
              Montana |         0 |      
>  392 
             Nebraska |         0 |      
>  651 
               Nevada |         0 |      
>  119 
        New Hampshire |         0 |      
>   70 
           New Jersey |         0 |      
>  147 
           New Mexico |         0 |      
>  231 
             New York |        35 |      
>  434 
       North Carolina |         0 |      
>  700 
         North Dakota |         0 |      
>  371 
                 Ohio |         0 |      
>  616 
             Oklahoma |         0 |      
>  539 
               Oregon |         0 |      
>  252 
         Pennsylvania |         0 |      
>  469 
         Rhode Island |         0 |      
>   35 
       South Carolina |         0 |      
>  322 
         South Dakota |         0 |      
>  462 
            Tennessee |         0 |      
>  665 
                Texas |         0 |     1
> ,778 
                 Utah |         0 |      
>  203 
              Vermont |         0 |      
>   98 
             Virginia |         0 |      
>  574 
           Washington |         0 |      
>  273 
        West Virginia |         0 |      
>  385 
            Wisconsin |         0 |      
>  504 
              Wyoming |         0 |      
>  161 
----------------------+-----------+------
> ----
                Total |        63 |    21
> ,608 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     T
> otal
----------------------+-----------+------
> ----
              Alabama |       469 |      
>  469 
               Alaska |       168 |      
>  196 
              Arizona |       105 |      
>  105 
             Arkansas |       525 |      
>  525 
           California |       406 |      
>  406 
             Colorado |       448 |      
>  448 
          Connecticut |        48 |      
>   48 
             Delaware |        21 |      
>   21 
 District of Columbia |         7 |      
>    7 
              Florida |       469 |      
>  469 
              Georgia |     1,113 |     1
> ,113 
               Hawaii |        21 |      
>   21 
                Idaho |       308 |      
>  308 
             Illinois |       714 |      
>  714 
              Indiana |       644 |      
>  644 
                 Iowa |       693 |      
>  693 
               Kansas |       735 |      
>  735 
             Kentucky |       840 |      
>  840 
            Louisiana |       448 |      
>  448 
                Maine |       112 |      
>  112 
             Maryland |       168 |      
>  168 
        Massachusetts |        98 |      
>   98 
             Michigan |       581 |      
>  581 
            Minnesota |       609 |      
>  609 
          Mississippi |       574 |      
>  574 
             Missouri |       805 |      
>  805 
              Montana |       392 |      
>  392 
             Nebraska |       651 |      
>  651 
               Nevada |       119 |      
>  119 
        New Hampshire |        70 |      
>   70 
           New Jersey |       147 |      
>  147 
           New Mexico |       231 |      
>  231 
             New York |       399 |      
>  434 
       North Carolina |       700 |      
>  700 
         North Dakota |       371 |      
>  371 
                 Ohio |       616 |      
>  616 
             Oklahoma |       539 |      
>  539 
               Oregon |       252 |      
>  252 
         Pennsylvania |       469 |      
>  469 
         Rhode Island |        35 |      
>   35 
       South Carolina |       322 |      
>  322 
         South Dakota |       462 |      
>  462 
            Tennessee |       665 |      
>  665 
                Texas |     1,778 |     1
> ,778 
                 Utah |       203 |      
>  203 
              Vermont |        98 |      
>   98 
             Virginia |       574 |      
>  574 
           Washington |       273 |      
>  273 
        West Virginia |       385 |      
>  385 
            Wisconsin |       504 |      
>  504 
              Wyoming |       161 |      
>  161 
----------------------+-----------+------
> ----
                Total |    21,545 |    21
> ,608 

. tab year covid_merge, m

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2015 |         9 |     3,088 
      2016 |         9 |     3,088 
      2017 |         9 |     3,088 
      2018 |         9 |     3,088 
      2019 |         9 |     3,088 
      2020 |         9 |     3,088 
      2021 |         9 |     3,080 
-----------+-----------+----------
     Total |        63 |    21,608 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |     3,079 |     3,088 
      2016 |     3,079 |     3,088 
      2017 |     3,079 |     3,088 
      2018 |     3,079 |     3,088 
      2019 |     3,079 |     3,088 
      2020 |     3,079 |     3,088 
      2021 |     3,071 |     3,080 
-----------+-----------+----------
     Total |    21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing ba
> se populations
. tab year county_name if missing(n1_in_1
>  ) | n1_in_1 == 0 

  Tax year |
     (year |   County
    before |    name
     move) | Loving .. |     Total
-----------+-----------+----------
      2016 |         1 |         1 
-----------+-----------+----------
     Total |         1 |         1 

. drop if missing(n1_in_1 ) | n1_in_1 == 
> 0
(1 observation deleted)

. 
. ** Keep only sample with observations i
> n each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      | State name
          County name | Connect.. |     T
> otal
----------------------+-----------+------
> ----
     Fairfield County |         6 |      
>    6 
      Hartford County |         6 |      
>    6 
    Litchfield County |         6 |      
>    6 
        Loving County |         0 |      
>    6 
     Middlesex County |         6 |      
>    6 
     New Haven County |         6 |      
>    6 
    New London County |         6 |      
>    6 
       Tolland County |         6 |      
>    6 
       Windham County |         6 |      
>    6 
----------------------+-----------+------
> ----
                Total |        48 |      
>   54 


                      | State name
          County name |     Texas |     T
> otal
----------------------+-----------+------
> ----
     Fairfield County |         0 |      
>    6 
      Hartford County |         0 |      
>    6 
    Litchfield County |         0 |      
>    6 
        Loving County |         6 |      
>    6 
     Middlesex County |         0 |      
>    6 
     New Haven County |         0 |      
>    6 
    New London County |         0 |      
>    6 
       Tolland County |         0 |      
>    6 
       Windham County |         0 |      
>    6 
----------------------+-----------+------
> ----
                Total |         6 |      
>   54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}worki
> ng/acs_county_gross_18plus", gen(merge_
> acs)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        19
> ,977
        from master                    18
> ,599  (merge_acs==1)
        from using                      1
> ,378  (merge_acs==2)

    Matched                             2
> ,954  (merge_acs==3)
    -------------------------------------
> ----

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2015 |     2,657 |     3,087 
      2016 |     2,657 |     3,087 
      2017 |     2,657 |     3,087 
      2018 |     2,657 |     3,087 
      2019 |     2,657 |     3,087 
      2020 |     2,657 |     3,087 
      2021 |     2,657 |     3,087 
      2022 |         0 |       444 
      2023 |         0 |       444 
-----------+-----------+----------
     Total |    18,599 |    22,497 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Using onl |     Total
-----------+-----------+----------
      2015 |         8 |     3,087 
      2016 |         8 |     3,087 
      2017 |         8 |     3,087 
      2018 |         8 |     3,087 
      2019 |         8 |     3,087 
      2020 |         8 |     3,087 
      2021 |         8 |     3,087 
      2022 |       444 |       444 
      2023 |       444 |       444 
-----------+-----------+----------
     Total |       944 |    22,497 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |       422 |     3,087 
      2016 |       422 |     3,087 
      2017 |       422 |     3,087 
      2018 |       422 |     3,087 
      2019 |       422 |     3,087 
      2020 |       422 |     3,087 
      2021 |       422 |     3,087 
      2022 |         0 |       444 
      2023 |         0 |       444 
-----------+-----------+----------
     Total |     2,954 |    22,497 

. tab state_name if merge_acs == 2 & year
>  == 2021

              State name |      Freq.    
>  Percent        Cum.
-------------------------+---------------
> --------------------
             Connecticut |          8    
>   100.00      100.00
-------------------------+---------------
> --------------------
                   Total |          8    
>   100.00

. tab state_name if merge_acs == 1 & year
>  == 2021

              State name |      Freq.    
>  Percent        Cum.
-------------------------+---------------
> --------------------
                 Alabama |         60    
>     2.26        2.26
                  Alaska |         27    
>     1.02        3.27
                 Arizona |         10    
>     0.38        3.65
                Arkansas |         71    
>     2.67        6.32
              California |         24    
>     0.90        7.23
                Colorado |         63    
>     2.37        9.60
                 Florida |         39    
>     1.47       11.07
                 Georgia |        139    
>     5.23       16.30
                  Hawaii |          1    
>     0.04       16.33
                   Idaho |         43    
>     1.62       17.95
                Illinois |         84    
>     3.16       21.11
                 Indiana |         76    
>     2.86       23.97
                    Iowa |         95    
>     3.58       27.55
                  Kansas |        102    
>     3.84       31.39
                Kentucky |        115    
>     4.33       35.72
               Louisiana |         56    
>     2.11       37.82
                   Maine |         13    
>     0.49       38.31
                Maryland |         12    
>     0.45       38.77
           Massachusetts |         12    
>     0.45       39.22
                Michigan |         67    
>     2.52       41.74
               Minnesota |         79    
>     2.97       44.71
             Mississippi |         79    
>     2.97       47.69
                Missouri |        108    
>     4.06       51.75
                 Montana |         56    
>     2.11       53.86
                Nebraska |         90    
>     3.39       57.25
                  Nevada |         15    
>     0.56       57.81
           New Hampshire |         10    
>     0.38       58.19
              New Jersey |          4    
>     0.15       58.34
              New Mexico |         30    
>     1.13       59.47
                New York |         41    
>     1.54       61.01
          North Carolina |         80    
>     3.01       64.02
            North Dakota |         52    
>     1.96       65.98
                    Ohio |         67    
>     2.52       68.50
                Oklahoma |         74    
>     2.79       71.28
                  Oregon |         28    
>     1.05       72.34
            Pennsylvania |         47    
>     1.77       74.11
            Rhode Island |          2    
>     0.08       74.18
          South Carolina |         42    
>     1.58       75.76
            South Dakota |         66    
>     2.48       78.25
               Tennessee |         86    
>     3.24       81.48
                   Texas |        215    
>     8.09       89.57
                    Utah |         24    
>     0.90       90.48
                 Vermont |         14    
>     0.53       91.00
                Virginia |         72    
>     2.71       93.71
              Washington |         30    
>     1.13       94.84
           West Virginia |         55    
>     2.07       96.91
               Wisconsin |         59    
>     2.22       99.13
                 Wyoming |         23    
>     0.87      100.00
-------------------------+---------------
> --------------------
                   Total |      2,657    
>   100.00

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & coun
> ty_fips == 51

. label var multnomah "Indicator for Mult
> nomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 
> 2020

. label var Treated "Treatment indicator 
> for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (exc
> luding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 
> percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urba
> n areas
-----------------------------------------
> --------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs
>                3,079
25%            0              0       Sum
>  of wgt.       3,079

50%     .3256337                      Mea
> n           .3521437
                        Largest       Std
> . dev.       .332065
75%     .6326353              1
90%      .847923              1       Var
> iance       .1102672
95%     .9372299              1       Ske
> wness       .3661052
99%     .9972304              1       Kur
> tosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urb
> an >= `cutoff' & year == 2020

                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         0 |     T
> otal
----------------------+-----------+------
> ----
               Alaska |         1 |      
>    1 
              Arizona |         1 |      
>    1 
           California |        15 |      
>   15 
             Colorado |         4 |      
>    4 
          Connecticut |         8 |      
>    8 
             Delaware |         1 |      
>    1 
 District of Columbia |         1 |      
>    1 
              Florida |        13 |      
>   13 
              Georgia |         8 |      
>    8 
               Hawaii |         1 |      
>    1 
                Idaho |         1 |      
>    1 
             Illinois |         5 |      
>    5 
              Indiana |         3 |      
>    3 
                 Iowa |         1 |      
>    1 
               Kansas |         2 |      
>    2 
             Kentucky |         2 |      
>    2 
            Louisiana |         3 |      
>    3 
             Maryland |         3 |      
>    3 
        Massachusetts |         5 |      
>    5 
             Michigan |         3 |      
>    3 
            Minnesota |         3 |      
>    3 
             Missouri |         4 |      
>    4 
             Nebraska |         2 |      
>    2 
               Nevada |         3 |      
>    3 
           New Jersey |        10 |      
>   10 
           New Mexico |         2 |      
>    2 
             New York |         9 |      
>    9 
       North Carolina |         4 |      
>    4 
                 Ohio |         6 |      
>    6 
             Oklahoma |         1 |      
>    1 
               Oregon |         1 |      
>    2 
         Pennsylvania |         4 |      
>    4 
         Rhode Island |         2 |      
>    2 
            Tennessee |         2 |      
>    2 
                Texas |        11 |      
>   11 
                 Utah |         4 |      
>    4 
             Virginia |        10 |      
>   10 
           Washington |         1 |      
>    1 
            Wisconsin |         1 |      
>    1 
----------------------+-----------+------
> ----
                Total |       161 |      
>  162 


                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         1 |     T
> otal
----------------------+-----------+------
> ----
               Alaska |         0 |      
>    1 
              Arizona |         0 |      
>    1 
           California |         0 |      
>   15 
             Colorado |         0 |      
>    4 
          Connecticut |         0 |      
>    8 
             Delaware |         0 |      
>    1 
 District of Columbia |         0 |      
>    1 
              Florida |         0 |      
>   13 
              Georgia |         0 |      
>    8 
               Hawaii |         0 |      
>    1 
                Idaho |         0 |      
>    1 
             Illinois |         0 |      
>    5 
              Indiana |         0 |      
>    3 
                 Iowa |         0 |      
>    1 
               Kansas |         0 |      
>    2 
             Kentucky |         0 |      
>    2 
            Louisiana |         0 |      
>    3 
             Maryland |         0 |      
>    3 
        Massachusetts |         0 |      
>    5 
             Michigan |         0 |      
>    3 
            Minnesota |         0 |      
>    3 
             Missouri |         0 |      
>    4 
             Nebraska |         0 |      
>    2 
               Nevada |         0 |      
>    3 
           New Jersey |         0 |      
>   10 
           New Mexico |         0 |      
>    2 
             New York |         0 |      
>    9 
       North Carolina |         0 |      
>    4 
                 Ohio |         0 |      
>    6 
             Oklahoma |         0 |      
>    1 
               Oregon |         1 |      
>    2 
         Pennsylvania |         0 |      
>    4 
         Rhode Island |         0 |      
>    2 
            Tennessee |         0 |      
>    2 
                Texas |         0 |      
>   11 
                 Utah |         0 |      
>    4 
             Virginia |         0 |      
>   10 
           Washington |         0 |      
>    1 
            Wisconsin |         0 |      
>    1 
----------------------+-----------+------
> ----
                Total |         1 |      
>  162 

. gen sample_urban95 = percent_urban >= `
> cutoff' // All counties 

. label var sample_urban95 "Urban countie
> s (top 5%) (excluding AK, CA, HI OR, WA
> )"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 |      2,925       94.75     
>   94.75
          1 |        162        5.25     
>  100.00
------------+----------------------------
> -------
      Total |      3,087      100.00

. 
. ** Define sample 3: Counties in top 98 
> percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urb
> an >= `cutoff' & year == 2020

                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         0 |     T
> otal
----------------------+-----------+------
> ----
           California |         6 |      
>    6 
             Colorado |         2 |      
>    2 
          Connecticut |         8 |      
>    8 
 District of Columbia |         1 |      
>    1 
              Florida |         4 |      
>    4 
              Georgia |         5 |      
>    5 
             Illinois |         2 |      
>    2 
              Indiana |         1 |      
>    1 
            Louisiana |         1 |      
>    1 
             Maryland |         1 |      
>    1 
        Massachusetts |         1 |      
>    1 
             Michigan |         1 |      
>    1 
            Minnesota |         1 |      
>    1 
             Missouri |         1 |      
>    1 
               Nevada |         1 |      
>    1 
           New Jersey |         6 |      
>    6 
             New York |         7 |      
>    7 
       North Carolina |         1 |      
>    1 
                 Ohio |         1 |      
>    1 
               Oregon |         0 |      
>    1 
         Pennsylvania |         2 |      
>    2 
         Rhode Island |         1 |      
>    1 
                Texas |         3 |      
>    3 
                 Utah |         2 |      
>    2 
             Virginia |         8 |      
>    8 
            Wisconsin |         1 |      
>    1 
----------------------+-----------+------
> ----
                Total |        68 |      
>   69 


                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         1 |     T
> otal
----------------------+-----------+------
> ----
           California |         0 |      
>    6 
             Colorado |         0 |      
>    2 
          Connecticut |         0 |      
>    8 
 District of Columbia |         0 |      
>    1 
              Florida |         0 |      
>    4 
              Georgia |         0 |      
>    5 
             Illinois |         0 |      
>    2 
              Indiana |         0 |      
>    1 
            Louisiana |         0 |      
>    1 
             Maryland |         0 |      
>    1 
        Massachusetts |         0 |      
>    1 
             Michigan |         0 |      
>    1 
            Minnesota |         0 |      
>    1 
             Missouri |         0 |      
>    1 
               Nevada |         0 |      
>    1 
           New Jersey |         0 |      
>    6 
             New York |         0 |      
>    7 
       North Carolina |         0 |      
>    1 
                 Ohio |         0 |      
>    1 
               Oregon |         1 |      
>    1 
         Pennsylvania |         0 |      
>    2 
         Rhode Island |         0 |      
>    1 
                Texas |         0 |      
>    3 
                 Utah |         0 |      
>    2 
             Virginia |         0 |      
>    8 
            Wisconsin |         0 |      
>    1 
----------------------+-----------+------
> ----
                Total |         1 |      
>   69 

. gen sample_urban98 = percent_urban >= `
> cutoff' // All counties 

. label var sample_urban98 "Urban countie
> s (top 1%) (excluding AK, CA, HI OR, WA
> )"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 |      3,018       97.76     
>   97.76
          1 |         69        2.24     
>  100.00
------------+----------------------------
> -------
      Total |      3,087      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(198 observations deleted)

. drop if state_name == "Hawaii"
(25 observations deleted)

. drop if state_name == "California"
(474 observations deleted)

. drop if state_name == "Washington"
(293 observations deleted)

. drop if state_name == "Oregon" & multno
> mah == 0
(259 observations deleted)

. 
. ** Define sample 4: Counties in top 95 
> + covid 
. cluster kmeans cases_cum* deaths_cum* i
> f        ///
>         sample_urban95 == 1 & year == 2
> 020 & covid_merge == 3 , k(5) gen(kmean
> )
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(km
> ean)
(20,116 missing values generated)

. 
. ** Pull out kmeans cluster with Multnom
> a
. gen tmp1 = kmean if sample_urban95 == 1
>  & year == 2020 & covid_merge == 3 & mu
> ltnomah == 1 
(21,247 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban
> 95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban c
> ounties (top 5%) w. Kmean Covid Match  
> (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 202
> 0

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 |      2,887       98.73     
>   98.73
          1 |         37        1.27     
>  100.00
------------+----------------------------
> -------
      Total |      2,924      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2
> 020 & covid_merge == 3
(21,118 observations deleted)

. keep kmean cases_cum* deaths_cum* popul
> ation

. collapse (mean) cases_cum* deaths_cum* 
> [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(km
> ean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
> 16 17 18 19 20 21 22 23 24 25 26 27 28 
> 29)

Data                               Wide  
>  ->                                    
>       Long
-----------------------------------------
> ------------------------------------
Number of observations                5  
>  ->   145         
Number of variables                  59  
>  ->   4           
j variable (29 values)                   
>  ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29  
>  ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29 
>  ->   deaths_cum
-----------------------------------------
> ------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg"
> , as(jpg) name("Graph") quality(100) re
> place             
file C:/Users/ji252/Documents/GitHub/mult
> nomah-county-tax/results/fig_kmeans.jpg
>  written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita
> _income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
(836 missing values generated)
variable population was long now double
(20,412 real changes made)
(836 missing values generated)
variable per_capita_income was long now d
> ouble
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x
> '_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 
(836 missing values generated)
(836 missing values generated)
(836 missing values generated)

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net
> _3 / (households_out_1 + households_out
> _2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 
> / (persons_out_1 + persons_out_2))
(17,829 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3
>  / (dollars_out_1 + dollars_out_2))
(17,829 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic m
> igration rate, returns (%)"

. label var n2_rate_irs   "Net domestic m
> igration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic m
> igration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic m
> igration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic m
> igration rate, persons (%)"

. label var agi_rate_acs  "Net domestic m
> igration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (unbalanced)
 Time variable: year, 2015 to 2023
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before | tag(fips)
     move) |         0 |     Total
-----------+-----------+----------
      2015 |         0 |     2,924 
      2016 |     2,924 |     2,924 
      2017 |     2,924 |     2,924 
      2018 |     2,924 |     2,924 
      2019 |     2,924 |     2,924 
      2020 |     2,924 |     2,924 
      2021 |     2,924 |     2,924 
      2022 |       383 |       390 
      2023 |       390 |       390 
-----------+-----------+----------
     Total |    18,317 |    21,248 


  Tax year |
     (year |
    before | tag(fips)
     move) |         1 |     Total
-----------+-----------+----------
      2015 |     2,924 |     2,924 
      2016 |         0 |     2,924 
      2017 |         0 |     2,924 
      2018 |         0 |     2,924 
      2019 |         0 |     2,924 
      2020 |         0 |     2,924 
      2021 |         0 |     2,924 
      2022 |         7 |       390 
      2023 |         0 |       390 
-----------+-----------+----------
     Total |     2,931 |    21,248 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_
> all sample_urban95 sample_urban95_covid
>  sample_urban98 { 
  3.                         
.                 gen sample = `samp' == 
> 1        
  4.                 if "`data'" == "acs"
>  replace sample = 0 if merge_acs != 3  
>      
  5.                         
.                 ** Clear stored values 
.                 eststo clear           
>  
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist 
> n1_rate_`data' n2_rate_`data' agi_rate_
> `data' {
  7.                         
.                         ** Store label 
.                         local label : v
> ariable label `out'
  8.                                 
.                         ** Loop over in
> clusion of covariates
.                         forvalues c = 0
> /1 {
  9.                                 
.                                 if `c' 
> == 0 local covars ""
 10.                                 else
>  if `c' == 1 local covars "covariates(`
> covariates', projected)"
 11.                                 dis 
> "`covars'"
 12.                                 
.                                 ** Run 
> SDID
.                                 eststo 
> sdid_`out'_`c': sdid `out' fips year Tr
> eated     ///
>                                        
>  if sample == 1,                       
>   ///
>                                        
>  vce(placebo)                          
>   ///
>                                        
>  `covar'                               
>           ///
>                                        
>  reps(`reps')                          
>   ///
>                                        
>  graph graph_export("${results}fig_`out
> '_`c'_`samp'_", .pdf) 
 13.                                     
>     
.                                 ** Esta
> dd counties  
.                                 qui sum
> m `out' if year == 2020 & sample == 1
 14.                                 esta
> dd scalar count = r(N)      
 15.                                     
>     
.                                 ** Esta
> dd mean 
.                                 qui sum
> m `out' if multnomah == 1 & Treated == 
> 0 
 16.                                 esta
> dd scalar mean = r(mean)
 17. 
.                                 ** Run 
> event-study 
.                                 sdid_ev
> ent `out' fips year Treated            
>           ///
>                                        
>  if sample == 1,                       
>                   ///
>                                        
>  `covar'                               
>                           ///
>                                        
>  vce(placebo)                          
>                   ///
>                                        
>  brep(`reps')                          
>                   ///
>                                        
>  placebo(all)
 18.                                 
.                                 ** Crea
> te Figure 
.                                 
.                                 ** Move
>  results from matrix to data 
.                                 matrix 
> list e(H)
 19.                                 mat 
> res_att_`ct' = e(H)[1,1..4]
 20.                                 mat 
> res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move
>  Matrix results to data 
.                                 svmat r
> es
 22.                                 
.                                 ** Gene
> rate ID variable
.                                 gen id 
> = 2021 - _n + 1 if !missing(res1)
 23.                                 labe
> l var id "Tax year (origin)"
 24.                                 
.                                 ** Sort
>  
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway 
>  (rcap res3 res4 id, lc(gs10) fc(gs11%5
> 0))       ///
>                                        
>          (scatter res1 id, mc(black)), 
>                           ///          
>    
>                                        
>  legend(off) ytitle("`label'")         
>                           ///
>                                        
>  yline(0, lc(red) lp(-))               
>                                   ///
>                                        
>  xline(2019.5, lc(black) lp(solid))    
>                           ///
>                                        
>  ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph e
> xport "${results}fig_`out'_`c'_sample_e
> ventstudy.jpg",   ///
>                                        
>  as(jpg) name("Graph") quality(100) rep
> lace              
 27. 
.                                 ** Clea
> n up 
.                                 drop re
> s1 res2 res3 res4 res5 id 
 28. 
.                                 ** Upda
> te Count
.                                 local c
> t = `ct' + 1 
 29.                                     
>                             
.                         } // END COVAR 
> LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_`d
> ata'_0 sdid_n1_rate_`data'_1           
>           ///
>                                 sdid_n2
> _rate_`data'_0 sdid_n2_rate_`data'_1   
>                   ///
>                                 sdid_ag
> i_rate_`data'_0 sdid_agi_rate_`data'_1 
> using     ///
>                 "${results}tab_sdid_`da
> ta'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**"
>  0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) re
> place                                  
>   ///
>                 mgroups("Returns" "Exem
> ptions" "AGI",                   ///
>                         pattern(1 0 1 0
>  1 0) )                                
>           ///
>                 mtitle( "No Covariates"
>  "Covariates"                    ///
>                                 "No Cov
> ariates" "Covariates"                  
>   ///
>                                 "No Cov
> ariates" "Covariates")                 
>   ///
>                 stats(count mean,      
>                                        
>                   ///
>                         fmt(%9.0fc %9.3
> fc)                                    
>                   ///
>                         labels("Number 
> of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(18,665 real changes made)

Placebo replications (100). This may take
>  some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 
> ---+--- 5
.........................................
> .........     50
.........................................
> .........     100


Synthetic Difference-in-Differences Estim
> ator

-----------------------------------------
> ------------------------------------
 n1_rate_acs |     ATT     Std. Err.     
> t      P>|t|    [95% Conf. Interval]
-------------+---------------------------
> ------------------------------------
     Treated |   0.30856    1.54841     0
> .20    0.842    -2.72627     3.34340
-----------------------------------------
> ------------------------------------
95% CIs and p-values are based on large-s
> ample approximations.
Refer to Arkhangelsky et al., (2021) for 
> theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/results/fig_n1_
    > rate_acs_0_sample_all_trends2020.
    > pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode
> .
|0% -------------------------------------
> ---- 100%|
|........................................
> .........|


             |  Estimate         SE 
-------------+----------------------
         ATT |  .3085641    1.51486 
    Effect_1 |  .9490793   2.209653 
    Effect_2 | -.3319511   1.611078 
   Placebo_1 |  .0660487   .3482228 
   Placebo_2 |  .0054543   .3462583 
   Placebo_3 |  .0427832   .2590419 
   Placebo_4 |  .0051022   .3142293 
   Placebo_5 | -.1120318   .2485135 

             |     LB CI      UB CI 
-------------+----------------------
         ATT | -2.660561   3.277689 
    Effect_1 |  -3.38184   5.279998 
    Effect_2 | -3.489663   2.825761 
   Placebo_1 |  -.616468   .7485654 
   Placebo_2 | -.6732119   .6841205 
   Placebo_3 | -.4649389   .5505053 
   Placebo_4 | -.6107872   .6209915 
   Placebo_5 | -.5991184   .3750547 

             | Switchers 
-------------+----------
         ATT |         1 
    Effect_1 |         1 
    Effect_2 |         1 
   Placebo_1 |         1 
   Placebo_2 |         1 
   Placebo_3 |         1 
   Placebo_4 |         1 
   Placebo_5 |         1 

WARNING: Restarted 3 bootstrap run(s) wit
> h no treated or control groups.

e(H)[8,5]
             Estimate          SE
      ATT   .30856409   1.5148598
 Effect_1   .94907928   2.2096526
 Effect_2   -.3319511   1.6110777
Placebo_1   .06604869   .34822282
Placebo_2   .00545431   .34625828
Placebo_3   .04278319   .25904187
Placebo_4   .00510217   .31422927
Placebo_5  -.11203184   .24851355

                LB CI       UB CI
      ATT   -2.660561   3.2776892
 Effect_1  -3.3818398   5.2799984
 Effect_2  -3.4896634   2.8257612
Placebo_1  -.61646804   .74856543
Placebo_2  -.67321191   .68412053
Placebo_3  -.46493887   .55050525
Placebo_4   -.6107872   .62099153
Placebo_5  -.59911839   .37505472

            Switchers
      ATT           1
 Effect_1           1
 Effect_2           1
Placebo_1           1
Placebo_2           1
Placebo_3           1
Placebo_4           1
Placebo_5           1
(21,241 missing values generated)
file C:/Users/ji252/Documents/GitHub/mult
> nomah-county-tax/results/fig_n1_rate_ac
> s_0_sample_eventstudy.jpg written in JP
> EG format
covariates(population per_capita_income, 
> projected)
Placebo replications (100). This may take
>  some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 
> ---+--- 5
..................--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\S
> TD91a0_00003v.tmp"

. 
. ** Load data 
. use "${data}working/irs_county_gross", 
> replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}worki
> ng/acs_county_gross_18plus", gen(merge_
> acs)
(variable fips was float, now double to
       accommodate using data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        20
> ,308
        from master                    18
> ,978  (merge_acs==1)
        from using                      1
> ,330  (merge_acs==2)

    Matched                             3
> ,002  (merge_acs==3)
    -------------------------------------
> ----

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2015 |     2,710 |     3,140 
      2016 |     2,710 |     3,140 
      2017 |     2,710 |     3,140 
      2018 |     2,710 |     3,140 
      2019 |     2,712 |     3,142 
      2020 |     2,713 |     3,143 
      2021 |     2,713 |     3,143 
      2022 |         0 |       444 
      2023 |         0 |       444 
-----------+-----------+----------
     Total |    18,978 |    22,876 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Using onl |     Total
-----------+-----------+----------
      2015 |         0 |     3,140 
      2016 |         0 |     3,140 
      2017 |         0 |     3,140 
      2018 |         0 |     3,140 
      2019 |         0 |     3,142 
      2020 |         0 |     3,143 
      2021 |         8 |     3,143 
      2022 |       444 |       444 
      2023 |       444 |       444 
-----------+-----------+----------
     Total |       896 |    22,876 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2015 |       430 |     3,140 
      2016 |       430 |     3,140 
      2017 |       430 |     3,140 
      2018 |       430 |     3,140 
      2019 |       430 |     3,142 
      2020 |       430 |     3,143 
      2021 |       422 |     3,143 
      2022 |         0 |       444 
      2023 |         0 |       444 
-----------+-----------+----------
     Total |     3,002 |    22,876 

. tab state_name if merge_acs == 2 & year
>  == 2021

          State name |      Freq.     Per
> cent        Cum.
---------------------+-------------------
> ----------------
         Connecticut |          8      10
> 0.00      100.00
---------------------+-------------------
> ----------------
               Total |          8      10
> 0.00

. tab state_name if merge_acs == 1 & year
>  == 2021

          State name |      Freq.     Per
> cent        Cum.
---------------------+-------------------
> ----------------
             Alabama |         60        
> 2.21        2.21
              Alaska |         29        
> 1.07        3.28
             Arizona |         10        
> 0.37        3.65
            Arkansas |         71        
> 2.62        6.27
          California |         24        
> 0.88        7.15
            Colorado |         63        
> 2.32        9.47
             Florida |         39        
> 1.44       10.91
             Georgia |        139        
> 5.12       16.03
              Hawaii |          3        
> 0.11       16.14
               Idaho |         43        
> 1.58       17.73
            Illinois |         84        
> 3.10       20.83
             Indiana |         76        
> 2.80       23.63
                Iowa |         95        
> 3.50       27.13
              Kansas |        102        
> 3.76       30.89
            Kentucky |        115        
> 4.24       35.13
           Louisiana |         56        
> 2.06       37.19
               Maine |         13        
> 0.48       37.67
            Maryland |         12        
> 0.44       38.11
       Massachusetts |         12        
> 0.44       38.56
            Michigan |         67        
> 2.47       41.02
           Minnesota |         79        
> 2.91       43.94
         Mississippi |         79        
> 2.91       46.85
            Missouri |        108        
> 3.98       50.83
             Montana |         56        
> 2.06       52.89
            Nebraska |         90        
> 3.32       56.21
              Nevada |         15        
> 0.55       56.76
       New Hampshire |         10        
> 0.37       57.13
          New Jersey |          4        
> 0.15       57.28
          New Mexico |         30        
> 1.11       58.39
            New York |         41        
> 1.51       59.90
      North Carolina |         80        
> 2.95       62.85
        North Dakota |         52        
> 1.92       64.76
                Ohio |         67        
> 2.47       67.23
            Oklahoma |         74        
> 2.73       69.96
              Oregon |         28        
> 1.03       70.99
        Pennsylvania |         47        
> 1.73       72.72
        Rhode Island |          2        
> 0.07       72.80
      South Carolina |         42        
> 1.55       74.35
        South Dakota |         66        
> 2.43       76.78
           Tennessee |         86        
> 3.17       79.95
               Texas |        216        
> 7.96       87.91
                Utah |         24        
> 0.88       88.79
             Vermont |         14        
> 0.52       89.31
            Virginia |        123        
> 4.53       93.84
          Washington |         30        
> 1.11       94.95
       West Virginia |         55        
> 2.03       96.98
           Wisconsin |         59        
> 2.17       99.15
             Wyoming |         23        
> 0.85      100.00
---------------------+-------------------
> ----------------
               Total |      2,713      10
> 0.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/de
> mographics_2020",        ///
>         gen(demo_merge) keep(master mat
> ch)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   20
        from master                      
>   20  (demo_merge==1)
        from using                       
>    0  (demo_merge==2)

    Matched                            22
> ,856  (demo_merge==3)
    -------------------------------------
> ----

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003w
> .tmp"

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
                     |        14 |        14 
             Alabama |         0 |       479 
              Alaska |         6 |       204 
             Arizona |         0 |       113 
            Arkansas |         0 |       531 
          California |         0 |       474 
            Colorado |         0 |       452 
         Connecticut |         0 |        56 
            Delaware |         0 |        27 
District of Columbia |         0 |         9 
             Florida |         0 |       535 
             Georgia |         0 |     1,157 
              Hawaii |         0 |        34 
               Idaho |         0 |       310 
            Illinois |         0 |       740 
             Indiana |         0 |       676 
                Iowa |         0 |       703 
              Kansas |         0 |       741 
            Kentucky |         0 |       854 
           Louisiana |         0 |       462 
               Maine |         0 |       116 
            Maryland |         0 |       190 
       Massachusetts |         0 |       116 
            Michigan |         0 |       613 
           Minnesota |         0 |       625 
         Mississippi |         0 |       580 
            Missouri |         0 |       819 
             Montana |         0 |       394 
            Nebraska |         0 |       657 
              Nevada |         0 |       123 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       181 
          New Mexico |         0 |       235 
            New York |         0 |       476 
      North Carolina |         0 |       736 
        North Dakota |         0 |       373 
                Ohio |         0 |       658 
            Oklahoma |         0 |       547 
              Oregon |         0 |       268 
        Pennsylvania |         0 |       509 
        Rhode Island |         0 |        41 
      South Carolina |         0 |       338 
        South Dakota |         0 |       462 
           Tennessee |         0 |       687 
               Texas |         0 |     1,854 
                Utah |         0 |       213 
             Vermont |         0 |       100 
            Virginia |         0 |       951 
          Washington |         0 |       293 
       West Virginia |         0 |       387 
           Wisconsin |         0 |       530 
             Wyoming |         0 |       163 
---------------------+-----------+----------
               Total |        20 |    22,876 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
                     |         0 |        14 
             Alabama |       479 |       479 
              Alaska |       198 |       204 
             Arizona |       113 |       113 
            Arkansas |       531 |       531 
          California |       474 |       474 
            Colorado |       452 |       452 
         Connecticut |        56 |        56 
            Delaware |        27 |        27 
District of Columbia |         9 |         9 
             Florida |       535 |       535 
             Georgia |     1,157 |     1,157 
              Hawaii |        34 |        34 
               Idaho |       310 |       310 
            Illinois |       740 |       740 
             Indiana |       676 |       676 
                Iowa |       703 |       703 
              Kansas |       741 |       741 
            Kentucky |       854 |       854 
           Louisiana |       462 |       462 
               Maine |       116 |       116 
            Maryland |       190 |       190 
       Massachusetts |       116 |       116 
            Michigan |       613 |       613 
           Minnesota |       625 |       625 
         Mississippi |       580 |       580 
            Missouri |       819 |       819 
             Montana |       394 |       394 
            Nebraska |       657 |       657 
              Nevada |       123 |       123 
       New Hampshire |        70 |        70 
          New Jersey |       181 |       181 
          New Mexico |       235 |       235 
            New York |       476 |       476 
      North Carolina |       736 |       736 
        North Dakota |       373 |       373 
                Ohio |       658 |       658 
            Oklahoma |       547 |       547 
              Oregon |       268 |       268 
        Pennsylvania |       509 |       509 
        Rhode Island |        41 |        41 
      South Carolina |       338 |       338 
        South Dakota |       462 |       462 
           Tennessee |       687 |       687 
               Texas |     1,854 |     1,854 
                Utah |       213 |       213 
             Vermont |       100 |       100 
            Virginia |       951 |       951 
          Washington |       293 |       293 
       West Virginia |       387 |       387 
           Wisconsin |       530 |       530 
             Wyoming |       163 |       163 
---------------------+-----------+----------
               Total |    22,856 |    22,876 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,141 |     3,143 
      2022 |         7        437 |       444 
      2023 |         7        437 |       444 
-----------+----------------------+----------
     Total |        20     22,856 |    22,876 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(20 observations deleted)

. drop demo_merge

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00003x
> .tmp"

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_econom
> ics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_m
> erge==1)
        from using                          0  (econ_m
> erge==2)

    Matched                            22,490  (econ_m
> erge==3)
    -----------------------------------------

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000040
> .tmp"

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     Total
---------------------+-----------+----------
             Alabama |         0 |       479 
              Alaska |         0 |       198 
             Arizona |         0 |       113 
            Arkansas |         0 |       531 
          California |         0 |       474 
            Colorado |         0 |       452 
         Connecticut |         0 |        56 
            Delaware |         0 |        27 
District of Columbia |         0 |         9 
             Florida |         0 |       535 
             Georgia |         0 |     1,157 
              Hawaii |         9 |        34 
               Idaho |         0 |       310 
            Illinois |         0 |       740 
             Indiana |         0 |       676 
                Iowa |         0 |       703 
              Kansas |         0 |       741 
            Kentucky |         0 |       854 
           Louisiana |         0 |       462 
               Maine |         0 |       116 
            Maryland |         0 |       190 
       Massachusetts |         0 |       116 
            Michigan |         0 |       613 
           Minnesota |         0 |       625 
         Mississippi |         0 |       580 
            Missouri |         0 |       819 
             Montana |         0 |       394 
            Nebraska |         0 |       657 
              Nevada |         0 |       123 
       New Hampshire |         0 |        70 
          New Jersey |         0 |       181 
          New Mexico |         0 |       235 
            New York |         0 |       476 
      North Carolina |         0 |       736 
        North Dakota |         0 |       373 
                Ohio |         0 |       658 
            Oklahoma |         0 |       547 
              Oregon |         0 |       268 
        Pennsylvania |         0 |       509 
        Rhode Island |         0 |        41 
      South Carolina |         0 |       338 
        South Dakota |         0 |       462 
           Tennessee |         0 |       687 
               Texas |         0 |     1,854 
                Utah |         0 |       213 
             Vermont |         0 |       100 
            Virginia |       357 |       951 
          Washington |         0 |       293 
       West Virginia |         0 |       387 
           Wisconsin |         0 |       530 
             Wyoming |         0 |       163 
---------------------+-----------+----------
               Total |       366 |    22,856 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     Total
---------------------+-----------+----------
             Alabama |       479 |       479 
              Alaska |       198 |       198 
             Arizona |       113 |       113 
            Arkansas |       531 |       531 
          California |       474 |       474 
            Colorado |       452 |       452 
         Connecticut |        56 |        56 
            Delaware |        27 |        27 
District of Columbia |         9 |         9 
             Florida |       535 |       535 
             Georgia |     1,157 |     1,157 
              Hawaii |        25 |        34 
               Idaho |       310 |       310 
            Illinois |       740 |       740 
             Indiana |       676 |       676 
                Iowa |       703 |       703 
              Kansas |       741 |       741 
            Kentucky |       854 |       854 
           Louisiana |       462 |       462 
               Maine |       116 |       116 
            Maryland |       190 |       190 
       Massachusetts |       116 |       116 
            Michigan |       613 |       613 
           Minnesota |       625 |       625 
         Mississippi |       580 |       580 
            Missouri |       819 |       819 
             Montana |       394 |       394 
            Nebraska |       657 |       657 
              Nevada |       123 |       123 
       New Hampshire |        70 |        70 
          New Jersey |       181 |       181 
          New Mexico |       235 |       235 
            New York |       476 |       476 
      North Carolina |       736 |       736 
        North Dakota |       373 |       373 
                Ohio |       658 |       658 
            Oklahoma |       547 |       547 
              Oregon |       268 |       268 
        Pennsylvania |       509 |       509 
        Rhode Island |        41 |        41 
      South Carolina |       338 |       338 
        South Dakota |       462 |       462 
           Tennessee |       687 |       687 
               Texas |     1,854 |     1,854 
                Utah |       213 |       213 
             Vermont |       100 |       100 
            Virginia |       594 |       951 
          Washington |       293 |       293 
       West Virginia |       387 |       387 
           Wisconsin |       530 |       530 
             Wyoming |       163 |       163 
---------------------+-----------+----------
               Total |    22,490 |    22,856 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,088 |     3,141 
      2022 |         0        437 |       437 
      2023 |         0        437 |       437 
-----------+----------------------+----------
     Total |       366     22,490 |    22,856 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000041
> .tmp"

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wi
> de.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to
       accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            73
        from master                        73  (covid_
> merge==1)
        from using                          0  (covid_
> merge==2)

    Matched                            22,417  (covid_
> merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     Total
----------------------+-----------+----------
              Alabama |         0 |       479 
               Alaska |        28 |       198 
              Arizona |         0 |       113 
             Arkansas |         0 |       531 
           California |         0 |       474 
             Colorado |         0 |       452 
          Connecticut |         0 |        56 
             Delaware |         0 |        27 
 District of Columbia |         0 |         9 
              Florida |         0 |       535 
              Georgia |         0 |     1,157 
               Hawaii |         0 |        25 
                Idaho |         0 |       310 
             Illinois |         0 |       740 
              Indiana |         0 |       676 
                 Iowa |         0 |       703 
               Kansas |         0 |       741 
             Kentucky |         0 |       854 
            Louisiana |         0 |       462 
                Maine |         0 |       116 
             Maryland |         0 |       190 
        Massachusetts |         0 |       116 
             Michigan |         0 |       613 
            Minnesota |         0 |       625 
          Mississippi |         0 |       580 
             Missouri |         0 |       819 
              Montana |         0 |       394 
             Nebraska |         0 |       657 
               Nevada |         0 |       123 
        New Hampshire |         0 |        70 
           New Jersey |         0 |       181 
           New Mexico |         0 |       235 
             New York |        45 |       476 
       North Carolina |         0 |       736 
         North Dakota |         0 |       373 
                 Ohio |         0 |       658 
             Oklahoma |         0 |       547 
               Oregon |         0 |       268 
         Pennsylvania |         0 |       509 
         Rhode Island |         0 |        41 
       South Carolina |         0 |       338 
         South Dakota |         0 |       462 
            Tennessee |         0 |       687 
                Texas |         0 |     1,854 
                 Utah |         0 |       213 
              Vermont |         0 |       100 
             Virginia |         0 |       594 
           Washington |         0 |       293 
        West Virginia |         0 |       387 
            Wisconsin |         0 |       530 
              Wyoming |         0 |       163 
----------------------+-----------+----------
                Total |        73 |    22,490 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     Total
----------------------+-----------+----------
              Alabama |       479 |       479 
               Alaska |       170 |       198 
              Arizona |       113 |       113 
             Arkansas |       531 |       531 
           California |       474 |       474 
             Colorado |       452 |       452 
          Connecticut |        56 |        56 
             Delaware |        27 |        27 
 District of Columbia |         9 |         9 
              Florida |       535 |       535 
              Georgia |     1,157 |     1,157 
               Hawaii |        25 |        25 
                Idaho |       310 |       310 
             Illinois |       740 |       740 
              Indiana |       676 |       676 
                 Iowa |       703 |       703 
               Kansas |       741 |       741 
             Kentucky |       854 |       854 
            Louisiana |       462 |       462 
                Maine |       116 |       116 
             Maryland |       190 |       190 
        Massachusetts |       116 |       116 
             Michigan |       613 |       613 
            Minnesota |       625 |       625 
          Mississippi |       580 |       580 
             Missouri |       819 |       819 
              Montana |       394 |       394 
             Nebraska |       657 |       657 
               Nevada |       123 |       123 
        New Hampshire |        70 |        70 
           New Jersey |       181 |       181 
           New Mexico |       235 |       235 
             New York |       431 |       476 
       North Carolina |       736 |       736 
         North Dakota |       373 |       373 
                 Ohio |       658 |       658 
             Oklahoma |       547 |       547 
               Oregon |       268 |       268 
         Pennsylvania |       509 |       509 
         Rhode Island |        41 |        41 
       South Carolina |       338 |       338 
         South Dakota |       462 |       462 
            Tennessee |       687 |       687 
                Texas |     1,854 |     1,854 
                 Utah |       213 |       213 
              Vermont |       100 |       100 
             Virginia |       594 |       594 
           Washington |       293 |       293 
        West Virginia |       387 |       387 
            Wisconsin |       530 |       530 
              Wyoming |       163 |       163 
----------------------+-----------+----------
                Total |    22,417 |    22,490 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000042
> .tmp"

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,079 |     3,088 
      2022 |         5        432 |       437 
      2023 |         5        432 |       437 
-----------+----------------------+----------
     Total |        73     22,417 |    22,490 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000043
> .tmp"

. ** Keep only sample with non-missing base population
> s
. tab year county_name if (missing(n1_in_1 ) | n1_in_1
>  == 0 ) & merge_acs == 3
no observations

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) & merge_
> acs == 3
(0 observations deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000044
> .tmp"

. tab year county_name if (missing(n1_in_1 ) | n1_in_1
>  == 0 ) & merge_acs != 3
too many values
r(134);

end of do-file

r(134);

. tab merge_acs

   Matching result from |
                  merge |      Freq.     Percent      
>   Cum.
------------------------+-----------------------------
> ------
        Master only (1) |     18,606       82.73      
>  82.73
         Using only (2) |        882        3.92      
>  86.65
            Matched (3) |      3,002       13.35      
> 100.00
------------------------+-----------------------------
> ------
                  Total |     22,490      100.00

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000045
> .tmp"

. tab year county_name if (missing(n1_in_1 ) | n1_in_1
>  == 0 ) & year <= 2021

  Tax year |
     (year |
    before |      County name
     move) | Fairfie..  Hartfor.. |     Total
-----------+----------------------+----------
      2016 |         0          0 |         1 
      2021 |         1          1 |         8 
-----------+----------------------+----------
     Total |         1          1 |         9 


  Tax year |
     (year |
    before |      County name
     move) | Litchfi..  Loving .. |     Total
-----------+----------------------+----------
      2016 |         0          1 |         1 
      2021 |         1          0 |         8 
-----------+----------------------+----------
     Total |         1          1 |         9 


  Tax year |
     (year |
    before |      County name
     move) | Middles..  New Hav.. |     Total
-----------+----------------------+----------
      2016 |         0          0 |         1 
      2021 |         1          1 |         8 
-----------+----------------------+----------
     Total |         1          1 |         9 


  Tax year |
     (year |
    before |      County name
     move) | New Lon..  Tolland.. |     Total
-----------+----------------------+----------
      2016 |         0          0 |         1 
      2021 |         1          1 |         8 
-----------+----------------------+----------
     Total |         1          1 |         9 


  Tax year |
     (year |   County
    before |    name
     move) | Windham.. |     Total
-----------+-----------+----------
      2016 |         0 |         1 
      2021 |         1 |         8 
-----------+-----------+----------
     Total |         1 |         9 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000046.tmp"

. tab year county_name if (missing(n1_in_1 ) | n1_in_1 == 0 ) & year <= 2021

  Tax year |
     (year |
    before |                                 County name
     move) | Fairfie..  Hartfor..  Litchfi..  Loving ..  Middles..  New Hav..  New Lon.. |     Total
-----------+-----------------------------------------------------------------------------+----------
      2016 |         0          0          0          1          0          0          0 |         1 
      2021 |         1          1          1          0          1          1          1 |         8 
-----------+-----------------------------------------------------------------------------+----------
     Total |         1          1          1          1          1          1          1 |         9 


  Tax year |
     (year |
    before |      County name
     move) | Tolland..  Windham.. |     Total
-----------+----------------------+----------
      2016 |         0          0 |         1 
      2021 |         1          1 |         8 
-----------+----------------------+----------
     Total |         1          1 |         9 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000047.tmp"

. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) & year <= 2021

                      | Tax year (year before
                      |         move)
          County name |      2016       2021 |     Total
----------------------+----------------------+----------
     Fairfield County |         0          1 |         1 
      Hartford County |         0          1 |         1 
    Litchfield County |         0          1 |         1 
        Loving County |         1          0 |         1 
     Middlesex County |         0          1 |         1 
     New Haven County |         0          1 |         1 
    New London County |         0          1 |         1 
       Tolland County |         0          1 |         1 
       Windham County |         0          1 |         1 
----------------------+----------------------+----------
                Total |         1          8 |         9 

. 
end of do-file

. tab merge_acs  year if (missing(n1_in_1 ) | n1_in_1 == 0 ) & year <= 2021

                      | Tax year (year before
 Matching result from |         move)
                merge |      2016       2021 |     Total
----------------------+----------------------+----------
      Master only (1) |         1          0 |         1 
       Using only (2) |         0          8 |         8 
----------------------+----------------------+----------
                Total |         1          8 |         9 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000048.tmp"

. drop if merge_acs == 3 & year <= 2021
(3,002 observations deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_000049.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 19:10:05

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,308
        from master                    18,978  (merge_acs==1)
        from using                      1,330  (merge_acs==2)

    Matched                             3,002  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2022
(888 observations deleted)

. drop if merge_acs == 
invalid syntax
r(198);

end of do-file

r(198);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004a.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 19:10:17

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,308
        from master                    18,978  (merge_acs==1)
        from using                      1,330  (merge_acs==2)

    Matched                             3,002  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2022
(888 observations deleted)

. drop if merge_acs == 2
(8 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |     2,710        430 |     3,140 
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,712        430 |     3,142 
      2020 |     2,713        430 |     3,143 
      2021 |     2,713        422 |     3,135 
-----------+----------------------+----------
     Total |    18,978      3,002 |    21,980 

. tab state_name if merge_acs == 2 & year == 2021
no observations

. tab state_name if merge_acs == 1 & year == 2021

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         60        2.21        2.21
              Alaska |         29        1.07        3.28
             Arizona |         10        0.37        3.65
            Arkansas |         71        2.62        6.27
          California |         24        0.88        7.15
            Colorado |         63        2.32        9.47
             Florida |         39        1.44       10.91
             Georgia |        139        5.12       16.03
              Hawaii |          3        0.11       16.14
               Idaho |         43        1.58       17.73
            Illinois |         84        3.10       20.83
             Indiana |         76        2.80       23.63
                Iowa |         95        3.50       27.13
              Kansas |        102        3.76       30.89
            Kentucky |        115        4.24       35.13
           Louisiana |         56        2.06       37.19
               Maine |         13        0.48       37.67
            Maryland |         12        0.44       38.11
       Massachusetts |         12        0.44       38.56
            Michigan |         67        2.47       41.02
           Minnesota |         79        2.91       43.94
         Mississippi |         79        2.91       46.85
            Missouri |        108        3.98       50.83
             Montana |         56        2.06       52.89
            Nebraska |         90        3.32       56.21
              Nevada |         15        0.55       56.76
       New Hampshire |         10        0.37       57.13
          New Jersey |          4        0.15       57.28
          New Mexico |         30        1.11       58.39
            New York |         41        1.51       59.90
      North Carolina |         80        2.95       62.85
        North Dakota |         52        1.92       64.76
                Ohio |         67        2.47       67.23
            Oklahoma |         74        2.73       69.96
              Oregon |         28        1.03       70.99
        Pennsylvania |         47        1.73       72.72
        Rhode Island |          2        0.07       72.80
      South Carolina |         42        1.55       74.35
        South Dakota |         66        2.43       76.78
           Tennessee |         86        3.17       79.95
               Texas |        216        7.96       87.91
                Utah |         24        0.88       88.79
             Vermont |         14        0.52       89.31
            Virginia |        123        4.53       93.84
          Washington |         30        1.11       94.95
       West Virginia |         55        2.03       96.98
           Wisconsin |         59        2.17       99.15
             Wyoming |         23        0.85      100.00
---------------------+-----------------------------------
               Total |      2,713      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) & year <= 2021

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2016 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) & merge_acs == 3
(0 observations deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      | State name
          County name | Connect.. |     Total
----------------------+-----------+----------
     Fairfield County |         6 |         6 
      Hartford County |         6 |         6 
    Litchfield County |         6 |         6 
     Middlesex County |         6 |         6 
     New Haven County |         6 |         6 
    New London County |         6 |         6 
       Tolland County |         6 |         6 
       Windham County |         6 |         6 
----------------------+-----------+----------
                Total |        48 |        48 

. drop if ct <= 7 
(21,608 observations deleted)

. drop ct 

. 
.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
no observations

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020
no observations

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020
no observations

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020
no observations

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020
no observations

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(0 observations deleted)

. drop if state_name == "Hawaii"
(0 observations deleted)

. drop if state_name == "California"
(0 observations deleted)

. drop if state_name == "Washington"
(0 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(0 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
insufficient observations
r(2001);

end of do-file

r(2001);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004b.tmp"

. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,308
        from master                    18,978  (merge_acs==1)
        from using                      1,330  (merge_acs==2)

    Matched                             3,002  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2022
(888 observations deleted)

. drop if merge_acs == 2
(8 observations deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004c.tmp"

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |     2,710        430 |     3,140 
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,712        430 |     3,142 
      2020 |     2,713        430 |     3,143 
      2021 |     2,713        422 |     3,135 
-----------+----------------------+----------
     Total |    18,978      3,002 |    21,980 

. tab state_name if merge_acs == 2 & year == 2021
no observations

. tab state_name if merge_acs == 1 & year == 2021

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         60        2.21        2.21
              Alaska |         29        1.07        3.28
             Arizona |         10        0.37        3.65
            Arkansas |         71        2.62        6.27
          California |         24        0.88        7.15
            Colorado |         63        2.32        9.47
             Florida |         39        1.44       10.91
             Georgia |        139        5.12       16.03
              Hawaii |          3        0.11       16.14
               Idaho |         43        1.58       17.73
            Illinois |         84        3.10       20.83
             Indiana |         76        2.80       23.63
                Iowa |         95        3.50       27.13
              Kansas |        102        3.76       30.89
            Kentucky |        115        4.24       35.13
           Louisiana |         56        2.06       37.19
               Maine |         13        0.48       37.67
            Maryland |         12        0.44       38.11
       Massachusetts |         12        0.44       38.56
            Michigan |         67        2.47       41.02
           Minnesota |         79        2.91       43.94
         Mississippi |         79        2.91       46.85
            Missouri |        108        3.98       50.83
             Montana |         56        2.06       52.89
            Nebraska |         90        3.32       56.21
              Nevada |         15        0.55       56.76
       New Hampshire |         10        0.37       57.13
          New Jersey |          4        0.15       57.28
          New Mexico |         30        1.11       58.39
            New York |         41        1.51       59.90
      North Carolina |         80        2.95       62.85
        North Dakota |         52        1.92       64.76
                Ohio |         67        2.47       67.23
            Oklahoma |         74        2.73       69.96
              Oregon |         28        1.03       70.99
        Pennsylvania |         47        1.73       72.72
        Rhode Island |          2        0.07       72.80
      South Carolina |         42        1.55       74.35
        South Dakota |         66        2.43       76.78
           Tennessee |         86        3.17       79.95
               Texas |        216        7.96       87.91
                Utah |         24        0.88       88.79
             Vermont |         14        0.52       89.31
            Virginia |        123        4.53       93.84
          Washington |         30        1.11       94.95
       West Virginia |         55        2.03       96.98
           Wisconsin |         59        2.17       99.15
             Wyoming |         23        0.85      100.00
---------------------+-----------------------------------
               Total |      2,713      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004d.tmp"

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) & year <= 2021

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2016 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) & merge_acs == 3
(0 observations deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      | State name
          County name | Connect.. |     Total
----------------------+-----------+----------
     Fairfield County |         6 |         6 
      Hartford County |         6 |         6 
    Litchfield County |         6 |         6 
     Middlesex County |         6 |         6 
     New Haven County |         6 |         6 
    New London County |         6 |         6 
       Tolland County |         6 |         6 
       Windham County |         6 |         6 
----------------------+-----------+----------
                Total |        48 |        48 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004e.tmp"

. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2016 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004f.tmp"

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004g.tmp"

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N
variable ct already defined
r(110);

end of do-file

r(110);

. drop ct

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004h.tmp"

. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct <= 7 
(21,607 observations deleted)

. drop ct 

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004i.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
-------------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 19:11:32

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,308
        from master                    18,978  (merge_acs==1)
        from using                      1,330  (merge_acs==2)

    Matched                             3,002  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2022
(888 observations deleted)

. drop if merge_acs == 2
(8 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |     2,710        430 |     3,140 
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,712        430 |     3,142 
      2020 |     2,713        430 |     3,143 
      2021 |     2,713        422 |     3,135 
-----------+----------------------+----------
     Total |    18,978      3,002 |    21,980 

. tab state_name if merge_acs == 2 & year == 2021
no observations

. tab state_name if merge_acs == 1 & year == 2021

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         60        2.21        2.21
              Alaska |         29        1.07        3.28
             Arizona |         10        0.37        3.65
            Arkansas |         71        2.62        6.27
          California |         24        0.88        7.15
            Colorado |         63        2.32        9.47
             Florida |         39        1.44       10.91
             Georgia |        139        5.12       16.03
              Hawaii |          3        0.11       16.14
               Idaho |         43        1.58       17.73
            Illinois |         84        3.10       20.83
             Indiana |         76        2.80       23.63
                Iowa |         95        3.50       27.13
              Kansas |        102        3.76       30.89
            Kentucky |        115        4.24       35.13
           Louisiana |         56        2.06       37.19
               Maine |         13        0.48       37.67
            Maryland |         12        0.44       38.11
       Massachusetts |         12        0.44       38.56
            Michigan |         67        2.47       41.02
           Minnesota |         79        2.91       43.94
         Mississippi |         79        2.91       46.85
            Missouri |        108        3.98       50.83
             Montana |         56        2.06       52.89
            Nebraska |         90        3.32       56.21
              Nevada |         15        0.55       56.76
       New Hampshire |         10        0.37       57.13
          New Jersey |          4        0.15       57.28
          New Mexico |         30        1.11       58.39
            New York |         41        1.51       59.90
      North Carolina |         80        2.95       62.85
        North Dakota |         52        1.92       64.76
                Ohio |         67        2.47       67.23
            Oklahoma |         74        2.73       69.96
              Oregon |         28        1.03       70.99
        Pennsylvania |         47        1.73       72.72
        Rhode Island |          2        0.07       72.80
      South Carolina |         42        1.55       74.35
        South Dakota |         66        2.43       76.78
           Tennessee |         86        3.17       79.95
               Texas |        216        7.96       87.91
                Utah |         24        0.88       88.79
             Vermont |         14        0.52       89.31
            Virginia |        123        4.53       93.84
          Washington |         30        1.11       94.95
       West Virginia |         55        2.03       96.98
           Wisconsin |         59        2.17       99.15
             Wyoming |         23        0.85      100.00
---------------------+-----------------------------------
               Total |      2,713      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         0      3,140 |     3,140 
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         2      3,140 |     3,142 
      2020 |         2      3,141 |     3,143 
      2021 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |        52      3,088 |     3,140 
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        53      3,088 |     3,141 
      2021 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2015 |         9      3,079 |     3,088 
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2016 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA, HI O
> R, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. 
. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,829 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,829 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,829 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2015 to 2021
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2015 |         0      2,916 |     2,916 
      2016 |     2,916          0 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if merge_acs != 3       
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate_`data' n2_rate_`data' agi_rate_`data' {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', projected)
> "
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`out'_`c'_`samp'_", .pdf) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out' fips year Treated                      ///
>                                         if sample == 1,                                         ///
>                                         `covar'                                                      
>    ///
>                                         vce(placebo)                                            ///
>                                         brep(`reps')                                            ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                        
>    ///             
>                                         legend(off) ytitle("`label'")                                
>    ///
>                                         yline(0, lc(red) lp(-))                                      
>            ///
>                                         xline(2019.5, lc(black) lp(solid))                           
>    ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`out'_`c'_sample_eventstudy.jpg",   ///
>                                         as(jpg) name("Graph") quality(100) replace              
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_`data'_0 sdid_n1_rate_`data'_1                     ///
>                                 sdid_n2_rate_`data'_0 sdid_n2_rate_`data'_1                     ///
>                                 sdid_agi_rate_`data'_0 sdid_agi_rate_`data'_1 using     ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                               ///
>                         fmt(%9.0fc %9.3fc)                                                      ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,829 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |   0.30856    1.84673     0.17    0.867    -3.31095     3.92808
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_all_trends2
    > 020.pdf saved as PDF format

added scalar:
              e(count) =  369

added scalar:
               e(mean) =  .31922523
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  .3085641   1.515389  -2.661599   3.278727          1 
    Effect_1 |  .9490793   1.989948  -2.951218   4.849377          1 
    Effect_2 | -.3319511   1.633652  -3.533909   2.870007          1 
   Placebo_1 |  .0660487   .2010193  -.3279492   .4600466          1 
   Placebo_2 |  .0054543   .2069993  -.4002644    .411173          1 
   Placebo_3 |  .0427832   .4310202  -.8020163   .8875827          1 
   Placebo_4 |  .0051022   .2296837  -.4450779   .4552823          1 
   Placebo_5 | -.1120318   .2249951  -.5530222   .3289586          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   .30856409   1.5153891  -2.6615986   3.2787267           1
 Effect_1   .94907928   1.9899476  -2.9512179   4.8493765           1
 Effect_2   -.3319511   1.6336521  -3.5339093   2.8700071           1
Placebo_1   .06604869   .20101933   -.3279492   .46004658           1
Placebo_2   .00545431   .20699932  -.40026435   .41117297           1
Placebo_3   .04278319   .43102017  -.80201635   .88758273           1
Placebo_4   .00510217   .22968373  -.44507794   .45528227           1
Placebo_5  -.11203184    .2249951  -.55302223   .32895856           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_eventstudy.j
> pg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
....................--Break--
r(1);

end of do-file

--Break--
r(1);

. do "C:\Users\ji252\AppData\Local\Temp\S
> TD91a0_00004j.tmp"

. /**************************************
> ***************************************
> * Program:                      01_clea
> n_data.do 
> * Author(s):            John Iselin 
> * Date Updated:         October 19, 202
> 5
> 
> *** Demographic data via IPUMS NHGIS 
> ** Via https://www.nhgis.org/
> ** Downloaded on October 19, 2025
> ** EXTRACT DETAILS in "nhgis0031_ts_nom
> inal_county_codebook"
> 
> *** Economic data via BEA Regional Econ
> omic Accounts (CAINC1)
> ** Via https://apps.bea.gov/regional/do
> wnloadzip.htm
> 
> *** ACS individual data via IPUMS USA 
> ** Via https://usa.ipums.org/usa/index.
> shtml
> ** Downloaded via R program 
> 
> *** IRS SOI County-Level Migration File
> s
> ** Via https://www.irs.gov/statistics/s
> oi-tax-stats-migration-data
> 
> *** IRS SOI County-Level Files
> ** Via https://www.irs.gov/statistics/s
> oi-tax-stats-county-data
> 
> *** NYTimes COVID Cases and Deaths 
> ** Via https://github.com/nytimes/covid
> -19-data
> 
> ***************************************
> ***************************************
> */
. 
. ** Start log file 
. capture log close log_01

. log using "${logs}01_log_data_clean_${p
> r_name}_${date}", replace text name(log
> _01)
-----------------------------------------
      name:  log_01
       log:  C:/Users/ji252/Documents/Git
> Hub/multnomah-county-tax/code/logs/01_l
> og_data_clean_multnomah_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 19:17:14

. 
. //-------------------------------------
> -------------
. // STEP 0: Preliminary Set-Up 
. //-------------------------------------
> -------------
. 
. ** Define labels 
. label define lb_move_type       0 "ERRO
> R"                               ///
>                                        
>                  1 "Non-movers"        
>           ///
>                                        
>                  2 "All movers"        
>           ///
>                                        
>                  3 "Domestic movers"   
>           ///
>                                        
>                  4 "Within-state movers
> " ///
>                                        
>                  5 "Inter-state movers"
>   ///
>                                        
>                  6 "Foreign movers", mo
> dify

.                                        
>                  
. label define lb_agi             1 "Unde
> r $1"                    ///
>                                        
>                  2 "$1 under $10K"     
>           ///
>                                        
>                  3 "$10K under $25K"   
>           ///
>                                        
>                  4 "$25K under $50K"   
>           ///
>                                        
>                  5 "$50K under $75K"   
>           ///
>                                        
>                  6 "$75K under $100K"  
>   ///
>                                        
>                  7 "$100K under $200K" 
>   ///
>                                        
>                  8 "$200K or more", mod
> ify                                    
>                    

. 
. 
. ** Define Programs
. 
. ** Make FIPS code from state and county
>  fips codes 
. capture program drop make_fips

. program define make_fips
  1.     syntax varlist(min=2 max=2 numer
> ic), GEN(name)
  2. 
.     quietly {
  3.         tempvar s c
  4. 
.         local v1 : word 1 of `varlist'
  5.         local v2 : word 2 of `varlis
> t'
  6. 
.         gen `s' = string(`v1', "%02.0f"
> )
  7.         gen `c' = string(`v2', "%03.
> 0f")
  8. 
.         gen `gen' = real(`s' + `c')
  9.     }
 10. end

. 
. ** Reclassify suppressed values as 0 
. 
. capture program drop unsuppress

. program define unsuppress
  1.     syntax varlist
  2. 
.     foreach v of varlist `varlist' {
  3.         replace `v' = 0 if `v' == -1
  4.     }
  5. end

. 
. 
. ** Create a gross-migration fiel via AC
> S 
. capture program drop acs_make_gross_mig
> ration

. program define acs_make_gross_migration
  1.     version 16.0
  2.     /*
>       Build county-year gross migration
>  totals from ACS microdata with origin/
> destination counties.
> 
>       Outputs (wide):
>         persons_in_*, persons_out_*, pe
> rsons_net_*
>         households_in_*, households_out
> _*, households_net_*
>         dollars_in_*, dollars_out_*, do
> llars_net_*
> 
>       Move-type indices (mirrors your I
> RS convention as closely as possible):
>         1 = Non-movers (same county)
>         2 = All movers (different count
> y) = 4 + 5
>         3 = Domestic movers (same as 2 
> here; foreign already dropped upstream)
>         4 = Within-state movers (differ
> ent county, same state)
>         5 = Inter-state movers (differe
> nt state)
>     */
. 
.     syntax using/ [if] [in], SAVING(str
> ing) [REPLACE] ///
>         [ IDSFILE(string) ///
>           YEARVAR(name) ORIGFIPS(name) 
> DESTFIPS(name) ///
>           PERSONWT(name) HHWT(name) HEA
> DVAR(name) INCOME(name) ]
  3. 
.     // Defaults consistent with your 01
> _clean_data.do
.     if "`idsfile'"  == "" local idsfile
>   "${data}working/ids"
  4.     if "`yearvar'"  == "" local year
> var  year
  5.     if "`origfips'" == "" local orig
> fips fips_o
  6.     if "`destfips'" == "" local dest
> fips fips_d
  7.     if "`personwt'" == "" local pers
> onwt perwt
  8.     if "`hhwt'"     == "" local hhwt
>      hhwt
  9.     if "`headvar'"  == "" local head
> var  hh_head
 10.     if "`income'"   == "" local inco
> me   inctot
 11. 
.     // Load microdata (optionally subse
> t via if/in)
.     use "`using'" `if' `in', clear
 12. 
.     // Basic checks
.     foreach v in `yearvar' `origfips' `
> destfips' `personwt' `hhwt' `headvar' `
> income' {
 13.         capture confirm variable `v'
 14.         if _rc {
 15.             di as err "Required vari
> able `v' not found in `using'."
 16.             exit 198
 17.         }
 18.     }
 19. 
.     // Keep only valid year/origin/dest
> ination
.     drop if missing(`yearvar') | missin
> g(`origfips') | missing(`destfips')
 20. 
.     // Income: treat missing as 0 (keep
>  negatives as reported)
.     replace `income' = 0 if missing(`in
> come')
 21. 
.     // Build weighted components at the
>  person level
.     gen double persons_wt = `personwt'
 22.     gen double dollars_wt = `income'
>  * `personwt'
 23.     gen double households_wt = `hhwt
> ' if `headvar' == 1
 24.     replace households_wt = 0 if mis
> sing(households_wt)
 25. 
.     // Collapse to origin-destination-y
> ear flow first
.     keep `yearvar' `origfips' `destfips
> ' persons_wt dollars_wt households_wt
 26.     collapse (sum) persons=persons_w
> t dollars=dollars_wt households=househo
> lds_wt, ///
>         by(`yearvar' `origfips' `destfi
> ps')
 27. 
.     // Derive state/county components f
> or mover-type logic
.     gen int state_o  = floor(`origfips'
> /1000)
 28.     gen int state_d  = floor(`destfi
> ps'/1000)
 29. 
.     gen byte same_county = (`origfips' 
> == `destfips')
 30.     gen byte same_state  = (state_o 
> == state_d)
 31.     gen byte within_state_mover = sa
> me_state & !same_county
 32.     gen byte inter_state_mover  = !s
> ame_state
 33. 
.     // -----------------------
.     // IN-MIGRATION (by destination cou
> nty)
.     // -----------------------
.     preserve
 34.         gen long fips = `destfips'
 35.         gen int state_fips  = floor(
> fips/1000)
 36.         gen int county_fips = mod(fi
> ps, 1000)
 37. 
.         // type 1/4/5 components
.         foreach m in persons households
>  dollars {
 38.             gen double `m'_1 = `m' i
> f same_county
 39.             gen double `m'_4 = `m' i
> f within_state_mover
 40.             gen double `m'_5 = `m' i
> f inter_state_mover
 41.         }
 42. 
.         collapse (sum) persons_1 person
> s_4 persons_5 ///
>                        households_1 hou
> seholds_4 households_5 ///
>                        dollars_1 dollar
> s_4 dollars_5, ///
>                 by(`yearvar' fips state
> _fips county_fips)
 43. 
.         // build 2 and 3
.         gen double persons_2    = perso
> ns_4 + persons_5
 44.         gen double persons_3    = pe
> rsons_2
 45.         gen double households_2 = ho
> useholds_4 + households_5
 46.         gen double households_3 = ho
> useholds_2
 47.         gen double dollars_2    = do
> llars_4 + dollars_5
 48.         gen double dollars_3    = do
> llars_2
 49. 
.         // rename to *_in_*
.         foreach t in 1 2 3 4 5 {
 50.             rename persons_`t'    pe
> rsons_in_`t'
 51.             rename households_`t' ho
> useholds_in_`t'
 52.             rename dollars_`t'    do
> llars_in_`t'
 53.         }
 54. 
.         tempfile __in
 55.         save `__in', replace
 56.     restore
 57. 
.     // -----------------------
.     // OUT-MIGRATION (by origin county)
.     // -----------------------
.     preserve
 58.         gen long fips = `origfips'
 59.         gen int state_fips  = floor(
> fips/1000)
 60.         gen int county_fips = mod(fi
> ps, 1000)
 61. 
.         foreach m in persons households
>  dollars {
 62.             gen double `m'_1 = `m' i
> f same_county
 63.             gen double `m'_4 = `m' i
> f within_state_mover
 64.             gen double `m'_5 = `m' i
> f inter_state_mover
 65.         }
 66. 
.         collapse (sum) persons_1 person
> s_4 persons_5 ///
>                        households_1 hou
> seholds_4 households_5 ///
>                        dollars_1 dollar
> s_4 dollars_5, ///
>                 by(`yearvar' fips state
> _fips county_fips)
 67. 
.         gen double persons_2    = perso
> ns_4 + persons_5
 68.         gen double persons_3    = pe
> rsons_2
 69.         gen double households_2 = ho
> useholds_4 + households_5
 70.         gen double households_3 = ho
> useholds_2
 71.         gen double dollars_2    = do
> llars_4 + dollars_5
 72.         gen double dollars_3    = do
> llars_2
 73. 
.         foreach t in 1 2 3 4 5 {
 74.             rename persons_`t'    pe
> rsons_out_`t'
 75.             rename households_`t' ho
> useholds_out_`t'
 76.             rename dollars_`t'    do
> llars_out_`t'
 77.         }
 78. 
.         tempfile __out
 79.         save `__out', replace
 80.     restore
 81. 
.     // -----------------------
.     // Merge in/out; compute net
.     // -----------------------
.     use `__in', clear
 82.     merge 1:1 `yearvar' fips state_f
> ips county_fips using `__out', nogen
 83. 
.     // Replace missings with 0 prior to
>  net calcs (counties can be only in or 
> only out)
.     foreach m in persons households dol
> lars {
 84.         foreach t in 1 2 3 4 5 {
 85.             replace `m'_in_`t'  = 0 
> if missing(`m'_in_`t')
 86.             replace `m'_out_`t' = 0 
> if missing(`m'_out_`t')
 87.         }
 88.     }
 89. 
.     // Net = in - out (types 2/3/4/5 ar
> e the meaningful migration nets; 1 will
>  be ~0 by construction)
.     foreach m in persons households dol
> lars {
 90.         foreach t in 2 3 4 5 {
 91.             gen double `m'_net_`t' =
>  `m'_in_`t' - `m'_out_`t'
 92.         }
 93.     }
 94. 
.     // Merge names
.     merge m:1 state_fips county_fips us
> ing "`idsfile'", keep(master match) nog
> en
 95. 
.     // Labels
.     label var fips "County FIPS (state*
> 1000 + county)"
 96.     label var state_fips "State FIPS
> "
 97.     label var county_fips "County FI
> PS"
 98. 
.     label var persons_in_2  "Persons, i
> n-migration, all movers"
 99.     label var persons_out_2 "Persons
> , out-migration, all movers"
100.     label var persons_net_2 "Persons
> , net migration, all movers"
101. 
.     label var households_in_2  "Househo
> lds, in-migration, all movers (HH heads
> )"
102.     label var households_out_2 "Hous
> eholds, out-migration, all movers (HH h
> eads)"
103.     label var households_net_2 "Hous
> eholds, net migration, all movers (HH h
> eads)"
104. 
.     label var dollars_in_2  "Dollars, i
> n-migration, all movers (INCTOT*PERWT)"
105.     label var dollars_out_2 "Dollars
> , out-migration, all movers (INCTOT*PER
> WT)"
106.     label var dollars_net_2 "Dollars
> , net migration, all movers (INCTOT*PER
> WT)"
107. 
.     order `yearvar' fips state_fips cou
> nty_fips state_name county_name, first
108.     sort `yearvar' state_fips county
> _fips
109.     compress
110. 
.     // Save
.     save "`saving'", `replace'
111.         clear
112.         
. end

. 
. 
. //-------------------------------------
> -------------
. // STEP -1: Acquire raw data (automated
>  where possible)
. //-------------------------------------
> -------------
. /*
> This block downloads public-use source 
> data directly from official URLs if not
>  present locally.
> 
> Automated downloads included:
>   - IRS SOI county-to-county migration:
>  countyinflowYYZZ.csv / countyoutflowYY
> ZZ.csv
>   - IRS SOI county data: YYincyallagi.c
> sv
>   - BEA Regional Economic Accounts (CAI
> NC1): CAINC1.zip (unzips to CAINC1__ALL
> _AREAS_*.csv and related files)
> 
> */
. 
. * Ensure expected directory structure e
> xists
. capture mkdir "${data}"

. capture mkdir "${data}working"

. capture mkdir "${data}demographic"

. capture mkdir "${data}demographic/CAINC
> 1"

. capture mkdir "${data}demographic/nhgis
> 0031_csv"

. capture mkdir "${data}irs"

. capture mkdir "${data}covid"

. 
. * ----------------------------
. * IRS SOI: migration files
. * ----------------------------
. local irs_base "https://www.irs.gov/pub
> /irs-soi"

. 
. forvalues yy = 15/21 {
  2.     local zz = `yy' + 1
  3.     local fn_out "countyoutflow`yy'`
> zz'.csv"
  4.     local fn_in  "countyinflow`yy'`z
> z'.csv"
  5. 
.     capture confirm file "${data}irs/`f
> n_out'"
  6.     if _rc {
  7.         di as txt "Downloading (IRS 
> SOI) `fn_out' ..."
  8.         copy "`irs_base'/`fn_out'" "
> ${data}irs/`fn_out'", replace
  9.     }
 10. 
.     capture confirm file "${data}irs/`f
> n_in'"
 11.     if _rc {
 12.         di as txt "Downloading (IRS 
> SOI) `fn_in' ..."
 13.         copy "`irs_base'/`fn_in'" "$
> {data}irs/`fn_in'", replace
 14.     }
 15. }

. 
. * ----------------------------
. * IRS SOI: county income (AGI) files
. * ----------------------------
. forvalues yy = 15/22 {
  2.     local fn_inc "`yy'incyallagi.csv
> "
  3. 
.     capture confirm file "${data}irs/`f
> n_inc'"
  4.     if _rc {
  5.         di as txt "Downloading (IRS 
> SOI) `fn_inc' ..."
  6.         copy "`irs_base'/`fn_inc'" "
> ${data}irs/`fn_inc'", replace
  7.     }
  8. }

. 
. * ----------------------------
. * BEA Regional: CAINC1.zip
. * ----------------------------
. local bea_dir "${data}demographic/CAINC
> 1"

. local bea_url "https://apps.bea.gov/reg
> ional/zip/CAINC1.zip"

. local bea_zip "`bea_dir'/CAINC1.zip"

. 
. * If we don't already have a CAINC1 "_A
> LL_AREAS" file, download + unzip the ZI
> P.
. local bea_files : dir "`bea_dir'" files
>  "CAINC1__ALL_AREAS_*.csv"

. if "`bea_files'"=="" {
.     local bea_files : dir "`bea_dir'" f
> iles "CAINC1__ALL_STATES_*.csv"
. }

. 
. if "`bea_files'"=="" {
.     di as txt "Downloading (BEA) CAINC1
> .zip ..."
Downloading (BEA) CAINC1.zip ...
.     copy "`bea_url'" "`bea_zip'", repla
> ce
(file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/demographi
    > c/CAINC1/CAINC1.zip not found)
. 
.     local curdir "`c(pwd)'"
.     cd "`bea_dir'"
C:\Users\ji252\Documents\GitHub\multnomah
> -county-tax\data\demographic\CAINC1
.     unzipfile "CAINC1.zip", replace
    inflating: CAINC1__ALL_AREAS_1969_202
> 3.csv
    inflating: CAINC1__definition.xml
    inflating: CAINC1__Footnotes.html
    inflating: CAINC1_AK_1969_2023.csv
    inflating: CAINC1_AL_1969_2023.csv
    inflating: CAINC1_AR_1969_2023.csv
    inflating: CAINC1_AZ_1969_2023.csv
    inflating: CAINC1_CA_1969_2023.csv
    inflating: CAINC1_CO_1969_2023.csv
    inflating: CAINC1_CSA_1969_2023.csv
    inflating: CAINC1_CT_1969_2023.csv
    inflating: CAINC1_DC_1969_2023.csv
    inflating: CAINC1_DE_1969_2023.csv
    inflating: CAINC1_FL_1969_2023.csv
    inflating: CAINC1_GA_1969_2023.csv
    inflating: CAINC1_HI_1969_2023.csv
    inflating: CAINC1_IA_1969_2023.csv
    inflating: CAINC1_ID_1969_2023.csv
    inflating: CAINC1_IL_1969_2023.csv
    inflating: CAINC1_IN_1969_2023.csv
    inflating: CAINC1_KS_1969_2023.csv
    inflating: CAINC1_KY_1969_2023.csv
    inflating: CAINC1_LA_1969_2023.csv
    inflating: CAINC1_MA_1969_2023.csv
    inflating: CAINC1_MD_1969_2023.csv
    inflating: CAINC1_MDIV_1969_2023.csv
    inflating: CAINC1_ME_1969_2023.csv
    inflating: CAINC1_MI_1969_2023.csv
    inflating: CAINC1_MIC_1969_2023.csv
    inflating: CAINC1_MN_1969_2023.csv
    inflating: CAINC1_MO_1969_2023.csv
    inflating: CAINC1_MS_1969_2023.csv
    inflating: CAINC1_MSA_1969_2023.csv
    inflating: CAINC1_MT_1969_2023.csv
    inflating: CAINC1_NC_1969_2023.csv
    inflating: CAINC1_ND_1969_2023.csv
    inflating: CAINC1_NE_1969_2023.csv
    inflating: CAINC1_NH_1969_2023.csv
    inflating: CAINC1_NJ_1969_2023.csv
    inflating: CAINC1_NM_1969_2023.csv
    inflating: CAINC1_NV_1969_2023.csv
    inflating: CAINC1_NY_1969_2023.csv
    inflating: CAINC1_OH_1969_2023.csv
    inflating: CAINC1_OK_1969_2023.csv
    inflating: CAINC1_OR_1969_2023.csv
    inflating: CAINC1_PA_1969_2023.csv
    inflating: CAINC1_PORT_1969_2023.csv
    inflating: CAINC1_RI_1969_2023.csv
    inflating: CAINC1_SC_1969_2023.csv
    inflating: CAINC1_SD_1969_2023.csv
    inflating: CAINC1_TN_1969_2023.csv
    inflating: CAINC1_TX_1969_2023.csv
    inflating: CAINC1_US_1969_2023.csv
    inflating: CAINC1_UT_1969_2023.csv
    inflating: CAINC1_VA_1969_2023.csv
    inflating: CAINC1_VT_1969_2023.csv
    inflating: CAINC1_WA_1969_2023.csv
    inflating: CAINC1_WI_1969_2023.csv
    inflating: CAINC1_WV_1969_2023.csv
    inflating: CAINC1_WY_1969_2023.csv

successfully unzipped CAINC1.zip to curre
> nt directory
total processed:  60
        skipped:  0
      extracted:  60
.     cd "`curdir'"
C:\Users\ji252\Documents\GitHub\multnomah
> -county-tax
. 
.     capture erase "`bea_zip'"
. }

. 
. * ----------------------------
. * NYTimes COVID Data 
. * ----------------------------
. local covid_dir "${data}covid"

. local covid_url "https://raw.githubuser
> content.com/nytimes/covid-19-data/maste
> r/us-counties.csv"

. 
. * If we don't already have a COVID file
> , download.
. local covid_file : dir "`covid_dir'" fi
> les "covid_nyt.csv"

. if "`covid_file'"=="" {
.     local covid_file : dir "`covid_dir'
> " files "covid_nyt.csv"
. }

. 
. if "`covid_file'"=="" {
.     di as txt "Downloading (COVID)  ...
> "
Downloading (COVID)  ...
.     copy "`covid_url'" "`covid_dir'/cov
> id_nyt.csv", replace
. }

. 
. 
. 
. //-------------------------------------
> ----------------------
. // STEP 1: Import and Clean Demographic
>  Data via IPUMS + BEA  
. //-------------------------------------
> ----------------------
. 
. ** Import data 
. import delimited        ///
>         "${data}demographic/nhgis0031_c
> sv/nhgis0031_ts_nominal_county.csv", cl
> ear 
(encoding automatically selected: ISO-885
> 9-1)
(15 vars, 54,673 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:        54,673             
>      
    Variables:            15             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
gisjoin         str8    %9s              
                     >      GISJOIN
year            str9    %9s              
                     >      YEAR
state           str20   %20s             
                     >      STATE
statefp         byte    %8.0g            
                     >      STATEFP
statenh         int     %8.0g            
                     >      STATENH
county          str46   %46s             
                     >      COUNTY
countyfp        int     %8.0g            
                     >      COUNTYFP
countynh        int     %8.0g            
                     >      COUNTYNH
name            str59   %59s             
                     >      NAME
av0aa           long    %12.0g           
                     >      AV0AA
d15aa           long    %12.0g           
                     >      D15AA
d15ab           long    %12.0g           
                     >      D15AB
b79aa           long    %12.0g           
                     >      B79AA
av0aam          long    %12.0g           
                     >      AV0AAM
b79aam          long    %12.0g           
                     >      B79AAM
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.

. 
. ** Drop unnecc variables 
. drop gisjoin statenh countynh name 

. 
. ** Rename 
. rename state state_name 

. rename statefp state_fips 

. rename county county_name 

. rename countyfp county_fips 

. rename av0aa population 

. rename d15aa pop_urban 

. rename d15ab pop_rural 

. rename b79aa median_income 

. rename av0aam population_margin

. rename b79aam median_income_margin 

. 
. ** Create urban percent 
. gen percent_urban = pop_urban / populat
> ion
(45,090 missing values generated)

. 
. ** Label variables 
. label var state_name "State name"

. label var state_fips "State FIPS code"

. label var county_name "County name"

. label var county_fips "County FIPS code
> "

. label var population "Population count"

. label var pop_rural "Rural population c
> ount"

. label var pop_urban "Urban population c
> ount"

. label var percent_urban "Percent of pop
> ulation in urban areas"

. label var median_income "Median househo
> ld income (prior year)"

. label var population_margin "ACS margin
>  for error: population"

. label var median_income_margin "ACS mar
> gin for error: median income"

. 
. ** Save as temporary file 
. tempfile demo

. save `demo'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000002.tmp saved as .dta
    format

. 
. ** Create three datasets 
. 
. ** (1) Basic state and county IDs 
. keep if year == "2020" 
(51,452 observations deleted)

. keep state* county* 

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(f
> ips)

. 
. ** Save as state and county Ids 
. save "${data}working/ids", replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/id
    > s.dta saved

. clear  

. 
. ** (2) Population data 
. use `demo'

. keep if !missing(pop_urban) 
(45,090 observations deleted)

. tab year 

       YEAR |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
       2000 |      3,141       32.78     
>   32.78
       2010 |      3,221       33.61     
>   66.39
       2020 |      3,221       33.61     
>  100.00
------------+----------------------------
> -------
      Total |      9,583      100.00

. 
. ** Keep 2020 
. keep if year == "2020"
(6,362 observations deleted)

. drop year median_income* population_mar
> gin

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(f
> ips)

. 
. ** Save data
. save "${data}working/population_2020", 
> replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/po
    > pulation_2020.dta saved

. clear  

. 
. ** (3) 2015-2019 ACS data 
. use `demo'

. keep if !missing(median_income) 
(6,447 observations deleted)

. tab year 

       YEAR |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
       2000 |      3,141        6.51     
>    6.51
  2006-2010 |      3,221        6.68     
>   13.19
  2007-2011 |      3,221        6.68     
>   19.87
  2008-2012 |      3,221        6.68     
>   26.55
  2009-2013 |      3,221        6.68     
>   33.23
  2010-2014 |      3,220        6.68     
>   39.91
  2011-2015 |      3,219        6.67     
>   46.58
  2012-2016 |      3,220        6.68     
>   53.26
  2013-2017 |      3,220        6.68     
>   59.93
  2014-2018 |      3,219        6.67     
>   66.61
  2015-2019 |      3,220        6.68     
>   73.29
  2016-2020 |      3,220        6.68     
>   79.96
  2017-2021 |      3,220        6.68     
>   86.64
  2018-2022 |      3,221        6.68     
>   93.32
  2019-2023 |      3,222        6.68     
>  100.00
------------+----------------------------
> -------
      Total |     48,226      100.00

. 
. ** Keep 2020 
. keep if year == "2015-2019"
(45,006 observations deleted)

. drop year pop_rural pop_urban percent_u
> rban

. 
. ** Make FIPS 
. make_fips state_fips county_fips, gen(f
> ips)

. 
. ** Save data
. save "${data}working/acs_2015_2019_data
> ", replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ac
    > s_2015_2019_data.dta saved

. 
. ** Rename for merge 
. rename population population_acs

. 
. ** Merge with other data 
. merge 1:1 state_fips county_fips using 
> "${data}working/population_2020",      
>           ///
>         keep(match) nogen 

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                             3
> ,219  
    -------------------------------------
> ----

. 
. ** Save data
. save "${data}working/demographics_2020"
> , replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/de
    > mographics_2020.dta saved

. 
. ** Load BEA Data 
. import delimited "${data}demographic/CA
> INC1/CAINC1__ALL_AREAS_1969_2023.csv", 
>   ///
>         clear 
(encoding automatically selected: ISO-885
> 9-1)
(63 vars, 9,604 obs)

. 
. ** Drop unnecc variables 
. drop region tablename industryclassific
> ation unit geoname 

. 
. ** Drop empty cells 
. drop if missing(linecode)
(4 observations deleted)

. 
. ** Update names 
. rename geofips fips 

. replace fips = subinstr(fips, `"""', ""
> , .)
(9,600 real changes made)

. destring fips, replace 
fips: all characters numeric; replaced as
>  long

. 
. ** Keep population and per-capita incom
> e, dropping personal income (total)
. tab description linecode

                      |  LineCode
          Description |         1 |     T
> otal
----------------------+-----------+------
> ----
Per capita personal.. |         0 |     3
> ,200 
Personal income (th.. |     3,200 |     3
> ,200 
Population (persons.. |         0 |     3
> ,200 
----------------------+-----------+------
> ----
                Total |     3,200 |     9
> ,600 


                      |  LineCode
          Description |         2 |     T
> otal
----------------------+-----------+------
> ----
Per capita personal.. |         0 |     3
> ,200 
Personal income (th.. |         0 |     3
> ,200 
Population (persons.. |     3,200 |     3
> ,200 
----------------------+-----------+------
> ----
                Total |     3,200 |     9
> ,600 


                      |  LineCode
          Description |         3 |     T
> otal
----------------------+-----------+------
> ----
Per capita personal.. |     3,200 |     3
> ,200 
Personal income (th.. |         0 |     3
> ,200 
Population (persons.. |         0 |     3
> ,200 
----------------------+-----------+------
> ----
                Total |     3,200 |     9
> ,600 

. drop if linecode == 1   
(3,200 observations deleted)

. drop description

.         
. ** Get V* to be in terms of years 
. ** V9 == 1969 
. forvalues i = 9/63 {
  2.         
.         local j = 1960 + `i'
  3.         rename v`i' value`j'
  4.         
. } // END I LOOP 

. 
. ** Reshape 
. reshape long value, i(fips linecode) j(
> year)
(j = 1969 1970 1971 1972 1973 1974 1975 1
> 976 1977 1978 1979 1980 1981 1982 1983 
> 1984 1985 1986 1987 1988 1989 1990 1991
>  1992 1993 1994 1995 1996 1997 1998 199
> 9 2000 2001 2002 2003 2004 2005 2006 20
> 07 2008 2009 2010 2011 2012 2013 2014 2
> 015 2016 2017 2018 2019 2020 2021 2022 
> 2023)

Data                               Wide  
>  ->                                    
>       Long
-----------------------------------------
> ------------------------------------
Number of observations            6,400  
>  ->   352,000     
Number of variables                  57  
>  ->   4           
j variable (55 values)                   
>  ->   year
xij variables:
      value1969 value1970 ... value2023  
>  ->   value
-----------------------------------------
> ------------------------------------

. reshape wide value, i(fips year ) j(lin
> ecode)
(j = 2 3)

Data                               Long  
>  ->                                    
>       Wide
-----------------------------------------
> ------------------------------------
Number of observations          352,000  
>  ->   176,000     
Number of variables                   4  
>  ->   4           
j variable (2 values)          linecode  
>  ->   (dropped)
xij variables:
                                  value  
>  ->   value2 value3
-----------------------------------------
> ------------------------------------

. 
. ** Keep years 
. keep if inrange(year, 2015, 2023)
(147,200 observations deleted)

. 
. ** Rename values 
. rename value2 population 

. rename value3 per_capita_income

. 
. ** Drop if missing values 
. drop if population == "(NA)"
(239 observations deleted)

. 
. ** Keep only counties with all observat
> ions 
. bysort fips: gen ct = _N 

. tab ct

         ct |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          4 |          8        0.03     
>    0.03
          5 |          5        0.02     
>    0.05
          9 |     28,548       99.95     
>  100.00
------------+----------------------------
> -------
      Total |     28,561      100.00

. keep if ct == 9
(13 observations deleted)

. drop ct

. 
. ** Destring 
. destring population, replace 
population: all characters numeric; repla
> ced as long

. destring per_capita_income, replace 
per_capita_income: all characters numeric
> ; replaced as long

. 
. ** Save data
. save "${data}working/bea_economics", re
> place 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/be
    > a_economics.dta saved

. 
. //-------------------------------------
> ---------------
. // STEP 2: Import and Clean NYTimes COV
> ID-19 Data 
. //-------------------------------------
> ---------------
.  
. ** Import data 
. import delimited using "${data}covid/co
> vid_nyt.csv", varnames(1) clear case(lo
> wer) 
(encoding automatically selected: ISO-885
> 9-1)
(6 vars, 2,502,832 obs)

. 
. ** Describe data 
. des 

Contains data
 Observations:     2,502,832             
>      
    Variables:             6             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
date            str10   %10s             
                     >      
county          str35   %35s             
                     >      
state           str24   %24s             
                     >      
fips            long    %12.0g           
                     >      
cases           long    %12.0g           
                     >      
deaths          long    %8.0g            
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.

. 
. ** Set up date information 
. generate num_date = date(date, "YMD")

. format num_date %td

. drop date 

. 
. ** Rename 
. rename state state_name 

. rename county county_name 

. rename num_date date 

. 
. ** keep only counties 
. keep if !missing(fips)
(23,678 observations deleted)

. 
. ** Keep in 50 states 
. drop if state_name == "Puerto Rico"
(57,605 observations deleted)

. drop if state_name == "Virgin Islands"
(2,304 observations deleted)

. drop if state_name == "Northern Mariana
>  Islands"
(1,452 observations deleted)

. 
. ** Sort 
. sort date fips 

. 
. ** Create panel 
. xtset fips date

Panel variable: fips (unbalanced)
 Time variable: date, 21jan2020 to
                13may2022, but with
                gaps
         Delta: 1 day

. 
. ** Fill in panel 
. tsfill, full 

. 
. ** Fill in missing values 
. replace cases = 0 if missing(cases)
(228,991 real changes made)

. replace deaths = 0 if missing(deaths)
(228,991 real changes made)

. 
. ** Preserve data 
. preserve 

. 
. ** Preserve fips codes and names 
. keep if !missing(state_name)
(228,991 observations deleted)

. keep if !missing(county_name)
(0 observations deleted)

. duplicates drop fips state_name county_
> name, force 

Duplicates in terms of fips state_name
    county_name

(2,414,657 observations deleted)

. 
. ** Save as temporary data 
. tempfile state_county_names 

. save `state_county_names'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000004.tmp saved as .dta
    format

. clear 

. 
. ** Restore 
. restore 

. 
. ** Drop and merge in names 
. drop state_name county_name

. merge m:1 fips using `state_county_name
> s', keep(master match) nogen 

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                         2,646
> ,784  
    -------------------------------------
> ----

. 
. ** Get year, month, day 
. gen year = year(date)

. gen month = month(date)

. gen day = day(date)

. 
. ** Order data 
. order date year month day fips state co
> unty cases deaths 

. 
. ** Calculate cumulative cases and death
> s 
. bysort fips (date): gen cases_cum = sum
> (cases)

. bysort fips (date): gen deaths_cum = su
> m(deaths)

. 
. ** Merge population data (2020)
. merge m:1 fips using "${data}working/po
> pulation_2020", keep(match) nogen  
(variable county_name was str35, now
       str46 to accommodate using
       data's values)
(variable fips was long, now double to
       accommodate using data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                         2,643
> ,408  
    -------------------------------------
> ----

. 
. ** Save file 
. save ${data}working/covid_cleaned.dta, 
> replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/co
    > vid_cleaned.dta saved

. 
. ** Keep one observation per month 
. keep year month fips state_name county_
> name cases deaths population

. collapse (sum) cases deaths (mean) popu
> lation, by(year month fips state_name c
> ounty_name) 

. sort year month fips 

. egen date = group(year month)

. drop year month 

. 
. ** Calculate cumulative cases and death
> s 
. bysort fips (date): gen cases_cum = sum
> (cases)

. bysort fips (date): gen deaths_cum = su
> m(deaths)

. 
. ** Generate per capita figures
. replace cases_cum = 1000 * cases_cum / 
> population
(82,955 real changes made)

. replace cases_cum = 1000 * cases_cum / 
> population
(82,955 real changes made)

. drop population cases deaths

. 
. ** Reshape wide 
. reshape wide cases_cum deaths_cum, i(fi
> ps state_name county_name) j(date)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
> 16 17 18 19 20 21 22 23 24 25 26 27 28 
> 29)

Data                               Long  
>  ->                                    
>       Wide
-----------------------------------------
> ------------------------------------
Number of observations           90,828  
>  ->   3,132       
Number of variables                   6  
>  ->   61          
j variable (29 values)             date  
>  ->   (dropped)
xij variables:
                              cases_cum  
>  ->   cases_cum1 cases_cum2 ... cases_c
> um29
                             deaths_cum  
>  ->   deaths_cum1 deaths_cum2 ... death
> s_cum29
-----------------------------------------
> ------------------------------------

. 
. ** Save file 
. save ${data}working/covid_cleaned_wide.
> dta, replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/co
    > vid_cleaned_wide.dta saved

. clear

. 
. //-------------------------------------
> ---------------
. // STEP 3: Import and Clean ACS Micro D
> ata via IPUMS 
. //-------------------------------------
> ---------------
. 
. ** Load data 
. forvalues y = 2015(1)2023 {
  2.         
.         ** Import CSV
.         import delimited using "${data}
> acs/acs_`y'", varnames(1) clear case(lo
> wer)
  3.         
.         ** Save as temporary data 
.         tempfile acs_`y'
  4.         save `acs_`y''
  5.         clear 
  6.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 2,997,503 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000005.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 3,007,847 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000006.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 3,038,696 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000007.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 3,060,442 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000008.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 3,087,291 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000009.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 2,454,160 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000a.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(57 vars, 3,092,079 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000b.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(55 vars, 3,190,848 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000c.tmp saved as .dta
    format
(encoding automatically selected: ISO-885
> 9-1)
(55 vars, 3,228,659 obs)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000d.tmp saved as .dta
    format

. 
. ** Append data 
. forvalues y = 2015(1)2023 {
  2.         
.         append using `acs_`y''  
  3.         
. } // END YEAR LOOP 
(variable cbserial was long, now double
       to accommodate using data's
       values)

. 
. ** Des 
. tab year 

       year |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
       2015 |  2,997,503       11.04     
>   11.04
       2016 |  3,007,847       11.08     
>   22.11
       2017 |  3,038,696       11.19     
>   33.30
       2018 |  3,060,442       11.27     
>   44.57
       2019 |  3,087,291       11.37     
>   55.94
       2020 |  2,454,160        9.04     
>   64.98
       2021 |  3,092,079       11.39     
>   76.36
       2022 |  3,190,848       11.75     
>   88.11
       2023 |  3,228,659       11.89     
>  100.00
------------+----------------------------
> -------
      Total | 27,157,525      100.00

. 
. ** Define # of adults and kids in HHs 
. gen adult = age >= 18 

. gen child = age < 18 

. bysort year serial: gen hh_size = _N 

. bysort year serial: egen hh_adult_ct = 
> total(adult)

. bysort year serial: egen hh_child_ct = 
> total(child)

. 
. ** Sample 18+
. drop if child == 1 
(5,629,869 observations deleted)

. drop child adult 

. 
. ** Sample not living abroad last year 
. drop if migplac1 > 56 
(108,862 observations deleted)

. drop if migrate1 == 4 
(0 observations deleted)

. 
. ** Rename variables 
. rename statefip state_fips_d

. rename countyfip county_fips_d 

. 
. ** Set up origin data 
. fre migrate1

migrate1
-----------------------------------------
> ------------------
              |      Freq.    Percent    
>   Valid       Cum.
--------------+--------------------------
> ------------------
Valid   1     |   1.92e+07      89.51    
>   89.51      89.51
        2     |    1809920       8.45    
>    8.45      97.96
        3     |     436745       2.04    
>    2.04     100.00
        Total |   2.14e+07     100.00    
>  100.00           
-----------------------------------------
> ------------------

. drop migrate1d

. tab migplac1

   migplac1 |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 | 19,172,129       89.51     
>   89.51
          1 |     31,329        0.15     
>   89.66
          2 |      5,825        0.03     
>   89.68
          4 |     54,912        0.26     
>   89.94
          5 |     21,714        0.10     
>   90.04
          6 |    260,673        1.22     
>   91.26
          8 |     52,539        0.25     
>   91.50
          9 |     21,577        0.10     
>   91.61
         10 |      5,369        0.03     
>   91.63
         11 |      8,664        0.04     
>   91.67
         12 |    152,989        0.71     
>   92.38
         13 |     71,263        0.33     
>   92.72
         15 |      9,845        0.05     
>   92.76
         16 |     13,536        0.06     
>   92.83
         17 |     86,306        0.40     
>   93.23
         18 |     47,941        0.22     
>   93.45
         19 |     21,469        0.10     
>   93.55
         20 |     22,338        0.10     
>   93.66
         21 |     31,888        0.15     
>   93.81
         22 |     28,776        0.13     
>   93.94
         23 |      7,911        0.04     
>   93.98
         24 |     40,223        0.19     
>   94.17
         25 |     48,684        0.23     
>   94.39
         26 |     65,444        0.31     
>   94.70
         27 |     35,177        0.16     
>   94.86
         28 |     16,994        0.08     
>   94.94
         29 |     45,200        0.21     
>   95.15
         30 |      7,453        0.03     
>   95.19
         31 |     13,567        0.06     
>   95.25
         32 |     24,785        0.12     
>   95.37
         33 |      8,787        0.04     
>   95.41
         34 |     50,561        0.24     
>   95.64
         35 |     12,299        0.06     
>   95.70
         36 |    118,674        0.55     
>   96.26
         37 |     70,555        0.33     
>   96.59
         38 |      5,884        0.03     
>   96.61
         39 |     81,541        0.38     
>   96.99
         40 |     28,921        0.14     
>   97.13
         41 |     36,246        0.17     
>   97.30
         42 |     76,201        0.36     
>   97.65
         44 |      6,551        0.03     
>   97.68
         45 |     33,552        0.16     
>   97.84
         46 |      6,067        0.03     
>   97.87
         47 |     48,061        0.22     
>   98.09
         48 |    197,912        0.92     
>   99.02
         49 |     25,798        0.12     
>   99.14
         50 |      4,106        0.02     
>   99.16
         51 |     64,560        0.30     
>   99.46
         53 |     64,790        0.30     
>   99.76
         54 |     10,532        0.05     
>   99.81
         55 |     35,653        0.17     
>   99.98
         56 |      5,023        0.02     
>  100.00
------------+----------------------------
> -------
      Total | 21,418,794      100.00

. rename migplac1 state_fips_o

. tab migcounty1

 migcounty1 |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 | 19,952,847       93.16     
>   93.16
          1 |     35,752        0.17     
>   93.32
          3 |     58,525        0.27     
>   93.60
          5 |     21,286        0.10     
>   93.70
          7 |     13,720        0.06     
>   93.76
          9 |     11,958        0.06     
>   93.82
         11 |     23,663        0.11     
>   93.93
         13 |     53,927        0.25     
>   94.18
         15 |      7,126        0.03     
>   94.21
         17 |     21,840        0.10     
>   94.31
         19 |     24,348        0.11     
>   94.43
         20 |      2,061        0.01     
>   94.44
         21 |     12,848        0.06     
>   94.50
         23 |      7,725        0.04     
>   94.53
         25 |     21,090        0.10     
>   94.63
         27 |     15,274        0.07     
>   94.70
         29 |     32,454        0.15     
>   94.85
         31 |     57,529        0.27     
>   95.12
         33 |     33,851        0.16     
>   95.28
         35 |     24,912        0.12     
>   95.40
         37 |     72,280        0.34     
>   95.73
         39 |     10,381        0.05     
>   95.78
         41 |      8,696        0.04     
>   95.82
         43 |      8,893        0.04     
>   95.86
         45 |      5,998        0.03     
>   95.89
         47 |     22,821        0.11     
>   96.00
         49 |     21,522        0.10     
>   96.10
         51 |     17,488        0.08     
>   96.18
         53 |     17,759        0.08     
>   96.26
         55 |     12,676        0.06     
>   96.32
         57 |     18,309        0.09     
>   96.41
         59 |     30,944        0.14     
>   96.55
         61 |     31,725        0.15     
>   96.70
         63 |     12,421        0.06     
>   96.76
         65 |     18,670        0.09     
>   96.85
         67 |     29,982        0.14     
>   96.99
         69 |      4,036        0.02     
>   97.01
         71 |     27,649        0.13     
>   97.13
         73 |     36,959        0.17     
>   97.31
         75 |     11,968        0.06     
>   97.36
         77 |      8,293        0.04     
>   97.40
         79 |      7,681        0.04     
>   97.44
         81 |     30,275        0.14     
>   97.58
         83 |      9,053        0.04     
>   97.62
         85 |     28,918        0.14     
>   97.76
         87 |      6,680        0.03     
>   97.79
         89 |     10,158        0.05     
>   97.83
         91 |     15,565        0.07     
>   97.91
         93 |      4,960        0.02     
>   97.93
         95 |     19,883        0.09     
>   98.02
         97 |     19,460        0.09     
>   98.11
         99 |     19,554        0.09     
>   98.21
        101 |     14,457        0.07     
>   98.27
        103 |     18,351        0.09     
>   98.36
        105 |      7,421        0.03     
>   98.39
        107 |      5,600        0.03     
>   98.42
        109 |     10,761        0.05     
>   98.47
        111 |     14,844        0.07     
>   98.54
        113 |     30,918        0.14     
>   98.68
        115 |      4,818        0.02     
>   98.71
        117 |      7,798        0.04     
>   98.74
        119 |     14,739        0.07     
>   98.81
        121 |     10,181        0.05     
>   98.86
        123 |      3,671        0.02     
>   98.88
        125 |      9,036        0.04     
>   98.92
        127 |      2,348        0.01     
>   98.93
        129 |      1,814        0.01     
>   98.94
        133 |      5,313        0.02     
>   98.96
        135 |      7,844        0.04     
>   99.00
        139 |      5,952        0.03     
>   99.03
        141 |      6,936        0.03     
>   99.06
        143 |      4,286        0.02     
>   99.08
        145 |      1,975        0.01     
>   99.09
        147 |      2,327        0.01     
>   99.10
        149 |      2,146        0.01     
>   99.11
        151 |      1,900        0.01     
>   99.12
        153 |      5,155        0.02     
>   99.14
        157 |     11,532        0.05     
>   99.20
        159 |        751        0.00     
>   99.20
        160 |        149        0.00     
>   99.20
        161 |      4,716        0.02     
>   99.22
        163 |     13,817        0.06     
>   99.29
        165 |      2,418        0.01     
>   99.30
        167 |      5,023        0.02     
>   99.32
        169 |        850        0.00     
>   99.33
        171 |        529        0.00     
>   99.33
        173 |        264        0.00     
>   99.33
        179 |      1,879        0.01     
>   99.34
        183 |     11,521        0.05     
>   99.39
        185 |        871        0.00     
>   99.40
        187 |      2,303        0.01     
>   99.41
        189 |      6,599        0.03     
>   99.44
        191 |        759        0.00     
>   99.44
        197 |      3,401        0.02     
>   99.46
        201 |     29,158        0.14     
>   99.59
        209 |      2,664        0.01     
>   99.60
        215 |      3,046        0.01     
>   99.62
        223 |        758        0.00     
>   99.62
        227 |        946        0.00     
>   99.63
        245 |      3,068        0.01     
>   99.64
        251 |      1,020        0.00     
>   99.65
        257 |        850        0.00     
>   99.65
        303 |      3,247        0.02     
>   99.67
        309 |      2,351        0.01     
>   99.68
        313 |        456        0.00     
>   99.68
        329 |      1,177        0.01     
>   99.68
        339 |      3,176        0.01     
>   99.70
        355 |      2,646        0.01     
>   99.71
        367 |        977        0.00     
>   99.72
        375 |      1,001        0.00     
>   99.72
        381 |      1,199        0.01     
>   99.73
        423 |      1,497        0.01     
>   99.73
        439 |     14,652        0.07     
>   99.80
        441 |      1,419        0.01     
>   99.81
        451 |        952        0.00     
>   99.81
        453 |     12,549        0.06     
>   99.87
        479 |      1,301        0.01     
>   99.88
        485 |      1,288        0.01     
>   99.88
        491 |      4,036        0.02     
>   99.90
        510 |     10,140        0.05     
>   99.95
        550 |      1,187        0.01     
>   99.95
        650 |      1,031        0.00     
>   99.96
        700 |      1,438        0.01     
>   99.97
        710 |        466        0.00     
>   99.97
        760 |      2,799        0.01     
>   99.98
        810 |      3,933        0.02     
>  100.00
------------+----------------------------
> -------
      Total | 21,418,794      100.00

. rename migcounty1 county_fips_o

. 
. ** Use migrate1 to update values 
. 
. ** Within same house 
. replace state_fips_o = state_fips_d if 
> migrate1 == 1
(19,172,129 real changes made)

. replace county_fips_o = county_fips_d i
> f migrate1 == 1 
(11,640,515 real changes made)

. 
. ** Within same state 
. replace state_fips_o = state_fips_d if 
> migrate1 == 2
(0 real changes made)

. 
. ** Generate county IDS 
. foreach x in "o" "d" {
  2.         
.         make_fips state_fips_`x' county
> _fips_`x', gen(fips_`x')
  3. 
. }

. 
. ** Check for within-state migration 
. gen same_county = fips_o == fips_d 

. tab year same_county

           | same_count
           |     y
      year |         0 |     Total
-----------+-----------+----------
      2015 |    89,492 | 2,334,973 
      2016 |    91,109 | 2,347,010 
      2017 |    93,553 | 2,371,901 
      2018 |    96,080 | 2,402,102 
      2019 |    96,088 | 2,440,259 
      2020 |    71,827 | 1,948,982 
      2021 |    97,600 | 2,459,118 
      2022 |   106,231 | 2,536,657 
      2023 |    98,226 | 2,577,792 
-----------+-----------+----------
     Total |   840,206 |21,418,794 


           | same_count
           |     y
      year |         1 |     Total
-----------+-----------+----------
      2015 | 2,245,481 | 2,334,973 
      2016 | 2,255,901 | 2,347,010 
      2017 | 2,278,348 | 2,371,901 
      2018 | 2,306,022 | 2,402,102 
      2019 | 2,344,171 | 2,440,259 
      2020 | 1,877,155 | 1,948,982 
      2021 | 2,361,518 | 2,459,118 
      2022 | 2,430,426 | 2,536,657 
      2023 | 2,479,566 | 2,577,792 
-----------+-----------+----------
     Total |20,578,588 |21,418,794 

. tab year same_county if migrate1 == 2

           | same_count
           |     y
      year |         0 |     Total
-----------+-----------+----------
      2015 |    42,597 |   215,553 
      2016 |    43,823 |   215,914 
      2017 |    45,058 |   219,444 
      2018 |    46,477 |   219,659 
      2019 |    46,329 |   214,430 
      2020 |    34,625 |   153,932 
      2021 |    46,470 |   195,395 
      2022 |    50,584 |   192,301 
      2023 |    47,498 |   183,292 
-----------+-----------+----------
     Total |   403,461 | 1,809,920 


           | same_count
           |     y
      year |         1 |     Total
-----------+-----------+----------
      2015 |   172,956 |   215,553 
      2016 |   172,091 |   215,914 
      2017 |   174,386 |   219,444 
      2018 |   173,182 |   219,659 
      2019 |   168,101 |   214,430 
      2020 |   119,307 |   153,932 
      2021 |   148,925 |   195,395 
      2022 |   141,717 |   192,301 
      2023 |   135,794 |   183,292 
-----------+-----------+----------
     Total | 1,406,459 | 1,809,920 

. 
. ** Tag HH head 
. gen byte hh_head = (relate == 1)

. 
. ** Compress file 
. compress 
  variable state_fips_o was int now byte
  variable hh_size was float now byte
  variable hh_adult_ct was float now byte
  variable hh_child_ct was float now byte
  variable same_county was float now byte
  (278,444,322 bytes saved)

. 
. ** Save 
. save "${data}working/acs_migration_file
> ", replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ac
    > s_migration_file.dta saved

. 
. // Keep only observations with valid or
> igin/destination counties and YEAR
. drop if missing(year) | missing(fips_o)
>  | missing(fips_d)
(0 observations deleted)

. 
. // Clean income (treat missing as 0; ke
> ep negative values as reported)
. replace inctot = 0 if missing(inctot)
(0 real changes made)

. gen double income_wt = inctot * perwt

. label var income_wt "Person income (INC
> TOT) weighted by PERWT"

. 
. // --- Persons + income totals by origi
> n/destination/year
. preserve

. keep year fips_o fips_d perwt income_wt

. collapse (sum) persons=perwt income_tot
> al=income_wt, by(year fips_o fips_d)

. tempfile acs_pi

. save `acs_pi'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000f.tmp saved as .dta
    format

. restore

. 
. // --- Households by origin/destination
> /year
. // Use HHWT among household heads (RELA
> TE==1) if available; else PERNUM==1 fal
> lback.
. 
. preserve

. keep if hh_head
(10,269,992 observations deleted)

. keep year fips_o fips_d hhwt

. collapse (sum) households=hhwt, by(year
>  fips_o fips_d)

. tempfile acs_hh

. save `acs_hh'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000h.tmp saved as .dta
    format

. restore

. 
. // --- Merge persons/income with househ
> olds
. use `acs_pi', clear

. merge 1:1 year fips_o fips_d using `acs
> _hh', nogen

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        45
> ,163
        from master                    45
> ,163  
        from using                       
>    0  

    Matched                           162
> ,899  
    -------------------------------------
> ----

. 
. label var persons "Estimated number of 
> persons (sum PERWT)"

. label var households "Estimated number 
> of households (sum HHWT among heads)"

. label var income_total "Estimated total
>  personal income (sum INCTOT*PERWT)"

. 
. // --- Derive state/county components f
> or merges with name crosswalk
. gen int state_fips_o  = floor(fips_o/10
> 00)

. gen int county_fips_o = mod(fips_o,1000
> )

. gen int state_fips_d  = floor(fips_d/10
> 00)

. gen int county_fips_d = mod(fips_d,1000
> )

. 
. label var state_fips_o "State FIPS (ori
> gin)"

. label var county_fips_o "County FIPS (o
> rigin)"

. label var state_fips_d "State FIPS (des
> tination)"

. label var county_fips_d "County FIPS (d
> estination)"

. 
. // --- Merge in names (from NHGIS IDs s
> napshot)
. preserve

. use "${data}working/ids", clear

. rename (state_fips county_fips state_na
> me county_name) (state_fips_o county_fi
> ps_o state_name_o county_name_o)

. tempfile ids_o

. save `ids_o'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000j.tmp saved as .dta
    format

. keep state_fips_o state_name_o 

. duplicates drop 

Duplicates in terms of all variables

(3,169 observations deleted)

. tempfile state_ids_o

. save `state_ids_o'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000k.tmp saved as .dta
    format

. restore

. merge m:1 state_fips_o county_fips_o us
> ing `ids_o', keep(master match) nogen

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        46
> ,997
        from master                    46
> ,997  
        from using                       
>    0  

    Matched                           161
> ,065  
    -------------------------------------
> ----

. drop state_name_o 

. merge m:1 state_fips_o using `state_ids
> _o', keep(master match) nogen

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                           208
> ,062  
    -------------------------------------
> ----

. 
. preserve

. use "${data}working/ids", clear

. rename (state_fips county_fips state_na
> me county_name) (state_fips_d county_fi
> ps_d state_name_d county_name_d)

. tempfile ids_d

. save `ids_d'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000m.tmp saved as .dta
    format

. keep state_fips_d state_name_d 

. duplicates drop 

Duplicates in terms of all variables

(3,169 observations deleted)

. tempfile state_ids_d

. save `state_ids_d'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000n.tmp saved as .dta
    format

. restore

. 
. merge m:1 state_fips_d county_fips_d us
> ing `ids_d', keep(master match) nogen

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        50
> ,197
        from master                    50
> ,197  
        from using                       
>    0  

    Matched                           157
> ,865  
    -------------------------------------
> ----

. drop state_name_d

. merge m:1 state_fips_d using `state_ids
> _d', keep(master match) nogen

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                           208
> ,062  
    -------------------------------------
> ----

. order year ///
>     state_fips_o county_fips_o state_na
> me_o county_name_o fips_o ///
>     state_fips_d county_fips_d state_na
> me_d county_name_d fips_d ///
>     persons households income_total

. 
. sort year state_fips_o county_fips_o st
> ate_fips_d county_fips_d

. 
. replace county_name_o = "Other" if coun
> ty_fips_o == 0 
(46,948 real changes made)

. replace county_name_d = "Other" if coun
> ty_fips_d == 0 
(49,676 real changes made)

. 
. save "${data}working/acs_county_flow", 
> replace
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ac
    > s_county_flow.dta saved

. 
. // Optional: Multnomah-focused flow ext
> ract (origin = Multnomah County, OR)
. // Multnomah County, OR = state 41, cou
> nty 051
. preserve

. keep if state_fips_o == 41 & county_fip
> s_o == 51
(207,316 observations deleted)

. save "${data}working/multnomah_acs_flow
> ", replace
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/mu
    > ltnomah_acs_flow.dta saved

. clear

. 
. ** Create gross-migration files for ACS
>  
. 
. ** All (18+)
. acs_make_gross_migration using "${data}
> working/acs_migration_file", ///
>     saving("${data}working/acs_county_g
> ross_18plus") replace 
(0 observations deleted)
(0 real changes made)
(10,269,992 missing values generated)
(10,269,992 real changes made)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000q.tmp not found)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000q.tmp saved as .dta
    format
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(203,730 missing values generated)
(168,672 missing values generated)
(43,722 missing values generated)
(file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000s.tmp not found)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000s.tmp saved as .dta
    format

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                             4
> ,332  
    -------------------------------------
> ----
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(variable fips was long, now double to
       accommodate using data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>  448
        from master                      
>  448  
        from using                       
>    0  

    Matched                             3
> ,884  
    -------------------------------------
> ----
  variable state_fips was int now byte
  variable fips was double now long
  variable persons_in_1 was double now lo
> ng
  variable persons_in_4 was double now lo
> ng
  variable persons_in_5 was double now lo
> ng
  variable households_in_1 was double now
>  long
  variable households_in_4 was double now
>  long
  variable households_in_5 was double now
>  long
  variable persons_in_2 was double now lo
> ng
  variable persons_in_3 was double now lo
> ng
  variable households_in_2 was double now
>  long
  variable households_in_3 was double now
>  long
  variable persons_out_1 was double now l
> ong
  variable persons_out_4 was double now l
> ong
  variable persons_out_5 was double now l
> ong
  variable households_out_1 was double no
> w long
  variable households_out_4 was double no
> w long
  variable households_out_5 was double no
> w long
  variable persons_out_2 was double now l
> ong
  variable persons_out_3 was double now l
> ong
  variable households_out_2 was double no
> w long
  variable households_out_3 was double no
> w long
  variable persons_net_2 was double now l
> ong
  variable persons_net_3 was double now l
> ong
  variable persons_net_4 was double now l
> ong
  variable persons_net_5 was double now l
> ong
  variable households_net_2 was double no
> w long
  variable households_net_3 was double no
> w long
  variable households_net_4 was double no
> w long
  variable households_net_5 was double no
> w long
  variable county_name was str46 now str2
> 3
  (606,480 bytes saved)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ac
    > s_county_gross_18plus.dta saved

.         
. 
. //-------------------------------------
> ---------------
. // STEP 4: Import and Clean IRS Migrati
> on Data 
. //-------------------------------------
> ---------------
. 
. ** Loop over years 
. forvalues y = 16(1)22 {
  2.         
.         local start = `y' - 1
  3.         local end = `y'  
  4.         
.         ** Import data (out)
.         import delimited "${data}irs/co
> untyoutflow`start'`end'.csv", clear 
  5.         
.         ** Describe data 
.         des 
  6.         
.         ** Generate year (end year)
.         gen year = 2000 + `y'
  7.         
.         ** Drop Regional Values 
.         drop if y2_state == "DS"
  8.         
.         ** Drop Foreign Migration 
.         drop if y2_state == "FR"
  9.         
.         ** Drop observations without a 
> county
.         drop if y1_countyfips == 0 
 10.         
.         ** Deal with suppressed values 
.         unsuppress n1 n2 agi
 11.         
.         ** Drop unnecc variables 
.         drop y2_state y2_countyname
 12.                 
.         ** Create two versions: gross a
> nd net 
.         tempfile tmp
 13.         save `tmp'
 14.         
.         ** Gross first 
.         
.         ** Keep gross categories 
.         keep if ///
>                 (y1_statefips == y2_sta
> tefips & y1_countyfips == y2_countyfips
> ) |       ///
>                 inlist(y2_statefips, 96
> , 97, 98)
 15. 
.         ** Clean up 
.         gen move_type = 0 
 16.         
.         ** Stayers 
.         replace move_type = 1 if       
>  (y1_statefips == y2_statefips) &      
>   ///
>                                        
>                          (y1_countyfips
>  == y2_countyfips) 
 17.         
.         ** Movers
.         replace move_type = 2 if       
>  y2_statefips == 96              // ALL
>  
 18.         replace move_type = 3 if    
>     y2_statefips == 97 &    ///
>                                        
>                          y2_countyfips 
> == 0              // Domestic Total
 19.         replace move_type = 4 if    
>     y2_statefips == 97 &    ///
>                                        
>                          y2_countyfips 
> == 1              // Within-state
 20.         replace move_type = 5 if    
>     y2_statefips == 97 &    ///
>                                        
>                          y2_countyfips 
> == 3              // Between-states 
 21.         replace move_type = 6 if    
>     y2_statefips == 98              // 
> Foreign 
 22.         
.         ** Label movers 
.         label values move_type lb_move_
> type 
 23.         
.         ** Generate total category 
.         foreach var of varlist n1 n2 ag
> i {
 24.                 
.                 gen tmp = `var' if inli
> st(move_type, 1, 2)
 25.                 bysort y1_statefips 
> y1_countyfips: egen `var'_total = total
> (tmp)
 26.                 drop tmp 
 27.                 
.         } // END VAR LOOP 
 28.         
.         ** Drop unnecc variables 
.         drop y2_* 
 29.         
.         ** Sort 
.         sort year y1_statefips y1_count
> yfips move_type 
 30. 
.         ** Order 
.         order year y1_statefips y1_coun
> tyfips move_type 
 31.         
.         ** Rename 
.         rename y1_countyfips county_fip
> s 
 32.         rename y1_statefips state_fi
> ps 
 33.         
.         ** Label variables 
.         label var year "Tax year (year 
> before move)"
 34.         label var state_fips "State 
> FIPS code (origin state)"
 35.         label var county_fips "Count
> y FIPS code (origin county)"
 36.         label var move_type "Mover c
> ategory"
 37.         label var n1 "Number of retu
> rns"
 38.         label var n2 "Number of exem
> ptions"
 39.         label var agi "Adjusted Gros
> s Income"
 40.         label var n1_total "Number o
> f returns, county total (origin)"
 41.         label var n2_total "Number o
> f exemptions, county total (origin)"
 42.         label var agi_total "Adjuste
> d Gross Income, county total (origin)"
 43.         
.         ** Save 
.         save "${data}working/irs_county
> _gross_out_`y'", replace 
 44.         
.         ** Create version for merge wit
> h net 
.         keep if move_type == 3 
 45.         
.         ** Rename variables 
.         rename n1 n1_mover
 46.         rename n2 n2_mover 
 47.         rename agi agi_mover 
 48.         
.         label var n1_mover "Number of d
> omestic mover returns"
 49.         label var n2_mover "Number o
> f domestic mover exemptions"
 50.         label var agi_mover "Adjuste
> d Gross Income, domestic movers"
 51.         
.         ** Save as temp file 
.         tempfile merge 
 52.         save `merge'
 53.         clear 
 54.         
.         ** Next, create flow file 
.         use `tmp', clear 
 55.         
.         ** Drop aggregate values 
.         drop if inlist(y2_statefips, 96
> , 97, 98)
 56.         drop if (y1_statefips == y2_
> statefips & y1_countyfips == y2_countyf
> ips) 
 57.         
.         ** Sort 
.         sort year y1_statefips y1_count
> yfips y2_statefips y2_countyfips 
 58. 
.         ** Order 
.         order year y1_statefips y1_coun
> tyfips y2_statefips y2_countyfips
 59. 
.         
.         ** Rename 
.         rename y1_countyfips county_fip
> s 
 60.         rename y1_statefips state_fi
> ps 
 61.         rename y2_countyfips y2_coun
> ty_fips 
 62.         rename y2_statefips y2_state
> _fips       
 63.         
.         ** Label variables 
.         label var year "Tax year (year 
> before move)"
 64.         label var state_fips "State 
> FIPS code (origin state)"
 65.         label var county_fips "Count
> y FIPS code (origin county)"
 66.         label var y2_state_fips "Sta
> te FIPS code (dest. state)"
 67.         label var y2_county_fips "Co
> unty FIPS code (dest. county)"      
 68.         label var n1 "Number of retu
> rns"
 69.         label var n2 "Number of exem
> ptions"
 70.         label var agi "Adjusted Gros
> s Income"
 71.         
.         ** Merge with county of origin 
> data 
.         merge m:1 state_fips county_fip
> s using `merge', nogen keep(master matc
> h)
 72.         
.         ** Rename 
.         rename state_fips state_fips_o
 73.         rename county_fips county_fi
> ps_o
 74.         rename y2_* *_d 
 75.         
.         ** Dropo unnecc variable 
.         drop move_type 
 76.         
.         ** Save 
.         save "${data}working/irs_county
> _flow_`y'", replace 
 77.         clear
 78.         
.         ** Import data (in)
.         import delimited "${data}irs/co
> untyinflow`start'`end'.csv", clear 
 79.         
.         ** Describe data 
.         des 
 80. 
.         ** Generate year 
.         gen year = 2000 + `y' 
 81.         
.         ** Drop Regional Values 
.         drop if y1_state == "DS"
 82.         
.         ** Drop Foreign Migration 
.         drop if y1_state == "FR"
 83.         
.         ** Drop observations with no co
> unty ID 
.         drop if y2_countyfips == 0 
 84.         
.         ** Keep gross categories 
.         keep if ///
>                 (y1_statefips == y2_sta
> tefips & y1_countyfips == y2_countyfips
> ) |       ///
>                 inlist(y1_statefips, 96
> , 97, 98)
 85. 
.         ** Clean up 
.         gen move_type = 0 
 86.         
.         ** Deal with suppressed values 
.         unsuppress n1 n2 agi
 87.         
.         ** Stayers 
.         replace move_type = 1 if       
>  (y1_statefips == y2_statefips) &      
>   ///
>                                        
>                          (y1_countyfips
>  == y2_countyfips) 
 88.         
.         ** Movers
.         replace move_type = 2 if       
>  y1_statefips == 96              // ALL
>  
 89.         replace move_type = 3 if    
>     y1_statefips == 97 &    ///
>                                        
>                          y1_countyfips 
> == 0              // Domestic Total
 90.         replace move_type = 4 if    
>     y1_statefips == 97 &    ///
>                                        
>                          y1_countyfips 
> == 1              // Within-state
 91.         replace move_type = 5 if    
>     y1_statefips == 97 &    ///
>                                        
>                          y1_countyfips 
> == 3              // Between-states 
 92.         replace move_type = 6 if    
>     y1_statefips == 98              // 
> Foreign 
 93.         
.         ** Label move variable  
.         label values move_type lb_move_
> type 
 94.         
.         ** Generate total category 
.         foreach var of varlist n1 n2 ag
> i {
 95.                 
.                 gen tmp = `var' if inli
> st(move_type, 1, 2)
 96.                 bysort y2_statefips 
> y2_countyfips: egen `var'_total = total
> (tmp)
 97.                 drop tmp 
 98.                 
.         } // END VAR LOOP 
 99.         
.         ** Drop unnecc variables 
.         drop y1_*
100.         
.         ** Sort 
.         sort year y2_statefips y2_count
> yfips move_type 
101. 
.         ** Order 
.         order year y2_statefips y2_coun
> tyfips move_type 
102.         
.         ** Rename 
.         rename y2_countyfips county_fip
> s 
103.         rename y2_statefips state_fi
> ps 
104.         
.         ** Label variables 
.         label var year "Tax year (year 
> before move)"
105.         label var state_fips "State 
> FIPS code (dest. state)"
106.         label var county_fips "Count
> y FIPS code (dest. county)"
107.         label var move_type "Mover c
> ategory"
108.         label var n1 "Number of retu
> rns"
109.         label var n2 "Number of exem
> ptions"
110.         label var agi "Adjusted Gros
> s Income"
111.         label var n1_total "Number o
> f returns, county total (dest.)"
112.         label var n2_total "Number o
> f exemptions, county total (dest.)"
113.         label var agi_total "Adjuste
> d Gross Income, county total (dest.)"
114.         
.         ** Save 
.         save "${data}working/irs_county
> _gross_in_`y'", replace 
115.         clear 
116.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 86,481 obs)

Contains data
 Observations:        86,481             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,289 observations deleted)
(2,937 observations deleted)
(254 observations deleted)
(2,056 real changes made)
(2,056 real changes made)
(2,056 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000p.tmp saved as .dta
    format
(50,007 observations deleted)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,291 real changes made)
(11,712 missing values generated)
(11,712 missing values generated)
(11,712 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_16.dta saved
(14,853 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000q.tmp saved as .dta
    format
(14,853 observations deleted)
(3,141 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                            50
> ,007  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_16.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 86,330 obs)

Contains data
 Observations:        86,330             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,315 observations deleted)
(2,814 observations deleted)
(254 observations deleted)
(50,005 observations deleted)
(2,041 real changes made)
(2,041 real changes made)
(2,041 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,239 real changes made)
(11,660 missing values generated)
(11,660 missing values generated)
(11,660 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_16.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 98,948 obs)

Contains data
 Observations:        98,948             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,372 observations deleted)
(2,360 observations deleted)
(254 observations deleted)
(1,877 real changes made)
(1,877 real changes made)
(1,877 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000r.tmp saved as .dta
    format
(63,249 observations deleted)
(3,140 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,141 real changes made)
(2,010 real changes made)
(11,432 missing values generated)
(11,432 missing values generated)
(11,432 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_17.dta saved
(14,572 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000s.tmp saved as .dta
    format
(14,573 observations deleted)
(3,140 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                            63
> ,249  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_17.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 98,874 obs)

Contains data
 Observations:        98,874             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,432 observations deleted)
(2,282 observations deleted)
(254 observations deleted)
(63,249 observations deleted)
(1,788 real changes made)
(1,788 real changes made)
(1,788 real changes made)
(3,140 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(1,955 real changes made)
(11,376 missing values generated)
(11,376 missing values generated)
(11,376 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_17.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 87,820 obs)

Contains data
 Observations:        87,820             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,300 observations deleted)
(2,364 observations deleted)
(254 observations deleted)
(1,942 real changes made)
(1,942 real changes made)
(1,942 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000t.tmp saved as .dta
    format
(52,173 observations deleted)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,026 real changes made)
(11,447 missing values generated)
(11,447 missing values generated)
(11,447 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_18.dta saved
(14,588 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000u.tmp saved as .dta
    format
(14,588 observations deleted)
(3,141 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                            52
> ,173  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_18.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 87,932 obs)

Contains data
 Observations:        87,932             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,368 observations deleted)
(2,403 observations deleted)
(254 observations deleted)
(52,174 observations deleted)
(1,919 real changes made)
(1,919 real changes made)
(1,919 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,141 real changes made)
(3,140 real changes made)
(3,140 real changes made)
(2,030 real changes made)
(11,451 missing values generated)
(11,451 missing values generated)
(11,451 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_18.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 83,878 obs)

Contains data
 Observations:        83,878             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(14,919 observations deleted)
(2,298 observations deleted)
(0 observations deleted)
(53 real changes made)
(53 real changes made)
(53 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000v.tmp saved as .dta
    format
(51,090 observations deleted)
(3,141 real changes made)
(3,107 real changes made)
(3,107 real changes made)
(3,103 real changes made)
(2,778 real changes made)
(335 real changes made)
(9,323 missing values generated)
(9,323 missing values generated)
(9,323 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_19.dta saved
(12,464 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000w.tmp saved as .dta
    format
(12,430 observations deleted)
(3,141 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   34
        from master                      
>   34  
        from using                       
>    0  

    Matched                            51
> ,056  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_19.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 83,762 obs)

Contains data
 Observations:        83,762             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(14,890 observations deleted)
(2,290 observations deleted)
(0 observations deleted)
(51,090 observations deleted)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3,141 real changes made)
(3,086 real changes made)
(3,086 real changes made)
(3,082 real changes made)
(2,729 real changes made)
(368 real changes made)
(9,265 missing values generated)
(9,265 missing values generated)
(9,265 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_19.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 87,325 obs)

Contains data
 Observations:        87,325             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(14,937 observations deleted)
(2,272 observations deleted)
(0 observations deleted)
(62 real changes made)
(62 real changes made)
(62 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_00000x.tmp saved as .dta
    format
(54,560 observations deleted)
(3,142 real changes made)
(3,104 real changes made)
(3,104 real changes made)
(3,101 real changes made)
(2,773 real changes made)
(332 real changes made)
(9,310 missing values generated)
(9,310 missing values generated)
(9,310 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_20.dta saved
(12,452 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000010.tmp saved as .dta
    format
(12,414 observations deleted)
(3,142 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   38
        from master                      
>   38  
        from using                       
>    0  

    Matched                            54
> ,522  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_20.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 87,552 obs)

Contains data
 Observations:        87,552             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,060 observations deleted)
(2,323 observations deleted)
(0 observations deleted)
(54,560 observations deleted)
(0 real changes made)
(0 real changes made)
(0 real changes made)
(3,142 real changes made)
(3,102 real changes made)
(3,102 real changes made)
(3,097 real changes made)
(2,805 real changes made)
(361 real changes made)
(9,365 missing values generated)
(9,365 missing values generated)
(9,365 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_20.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 89,511 obs)

Contains data
 Observations:        89,511             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(14,963 observations deleted)
(2,175 observations deleted)
(0 observations deleted)
(79 real changes made)
(79 real changes made)
(79 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000011.tmp saved as .dta
    format
(56,831 observations deleted)
(3,143 real changes made)
(3,097 real changes made)
(3,097 real changes made)
(3,094 real changes made)
(2,787 real changes made)
(324 real changes made)
(9,302 missing values generated)
(9,302 missing values generated)
(9,302 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_21.dta saved
(12,445 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000012.tmp saved as .dta
    format
(12,399 observations deleted)
(3,143 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   46
        from master                      
>   46  
        from using                       
>    0  

    Matched                            56
> ,785  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_21.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 89,850 obs)

Contains data
 Observations:        89,850             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,132 observations deleted)
(2,263 observations deleted)
(0 observations deleted)
(56,835 observations deleted)
(1 real change made)
(1 real change made)
(1 real change made)
(3,143 real changes made)
(3,101 real changes made)
(3,101 real changes made)
(3,098 real changes made)
(2,838 real changes made)
(339 real changes made)
(9,376 missing values generated)
(9,376 missing values generated)
(9,376 missing values generated)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_21.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 90,409 obs)

Contains data
 Observations:        90,409             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y2_state        str2    %9s              
                     >      
y2_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(14,962 observations deleted)
(2,223 observations deleted)
(0 observations deleted)
(64 real changes made)
(64 real changes made)
(64 real changes made)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000013.tmp saved as .dta
    format
(57,644 observations deleted)
(3,144 real changes made)
(3,107 real changes made)
(3,107 real changes made)
(3,103 real changes made)
(2,790 real changes made)
(329 real changes made)
(9,329 missing values generated)
(9,329 missing values generated)
(9,329 missing values generated)
(file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_22.dta not
    found)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out_22.dta saved
(12,473 observations deleted)
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000014.tmp saved as .dta
    format
(12,436 observations deleted)
(3,144 observations deleted)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   37
        from master                      
>   37  
        from using                       
>    0  

    Matched                            57
> ,607  
    -------------------------------------
> ----
(file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_22.dta not found)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow_22.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(9 vars, 90,498 obs)

Contains data
 Observations:        90,498             
>      
    Variables:             9             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
y2_statefips    byte    %8.0g            
                     >      
y2_countyfips   int     %8.0g            
                     >      
y1_statefips    byte    %8.0g            
                     >      
y1_countyfips   int     %8.0g            
                     >      
y1_state        str2    %9s              
                     >      
y1_countyname   str60   %60s             
                     >      
n1              long    %12.0g           
                     >      
n2              long    %12.0g           
                     >      
agi             long    %12.0g           
                     >      
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
(15,093 observations deleted)
(2,179 observations deleted)
(0 observations deleted)
(57,640 observations deleted)
(1 real change made)
(1 real change made)
(1 real change made)
(3,144 real changes made)
(3,098 real changes made)
(3,098 real changes made)
(3,094 real changes made)
(2,822 real changes made)
(330 real changes made)
(9,344 missing values generated)
(9,344 missing values generated)
(9,344 missing values generated)
(file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_22.dta not
    found)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in_22.dta saved

. 
. ** Append data 
. 
. ** Loop over datasets 
. foreach file in "irs_county_gross_in" "
> irs_county_gross_out" "irs_county_flow"
> {
  2.         
.                 
.         ** Loop over years 
.         forvalues y = 16(1)22 {
  3. 
.                 ** Append 
.                 append using "${data}wo
> rking/`file'_`y'"
  4.                 
.         } // END YEAR LOOP 
  5.         
.         
.         ** Order and sort flow file 
.         if "`file'" == "irs_county_flow
> " {
  6.                 
.                 ** Loop over orgin and 
> destination state 
.                 foreach x in "o" "d" {
  7.                         
.                         ** Rename 
.                         rename *_fips_`
> x' *_fips 
  8.                         
.                         ** Merge with c
> ounty and state names 
.                         merge m:1 state
> _fips county_fips using "${data}working
> /ids",    ///
>                                 keep(ma
> tch) nogen 
  9.                                 
.                         ** Rename 
.                         rename *_fips *
> _fips_`x' 
 10.                         rename *_nam
> e *_name_`x' 
 11.                         
.                         ** Generate cou
> nty IDS 
.                         make_fips state
> _fips_`x' county_fips_`x', gen(fips_`x'
> )
 12.                         
.                 } // END ORIGIN / DESTI
> NATION LOOP 
 13.                 
.                 ** Order file 
.                 order year state_*_o co
> unty_*_o state_*_d county_*_d  
 14.                 sort year state_*_o 
> county_*_o state_*_d county_*_d  
 15. 
.         } // END MIGRATION FLOW IF-STAT
> EMENT 
 16.         
.         else {
 17.                 
.                 ** Merge with county an
> d state names 
.                 merge m:1 state_fips co
> unty_fips using "${data}working/ids",  
>   ///
>                                 keep(ma
> tch) nogen 
 18.                                 
.                 ** Order 
.                 order year state_* coun
> ty* move_type
 19.                 
.         } 
 20.         
.         ** Save file 
.         save "${data}working/`file'", r
> eplace 
 21.         clear 
 22.         
. } // END FILE LOOP 

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                           115
> ,567  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_in.dta saved

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                           115
> ,611  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross_out.dta saved

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                           384
> ,896  
    -------------------------------------
> ----

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                           362
> ,678  
    -------------------------------------
> ----
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_flow.dta saved

. 
. ** Create gross file with in and out mi
> gration 
. use "${data}working/irs_county_gross_in
> ", clear 

. 
. ** Rename 
. rename n1 n1_in_

. rename n2 n2_in_

. rename agi agi_in_

. rename *_total *_total_in

. 
. ** Reshape 
. reshape wide n1_in_ n2_in_ agi_in_, i(y
> ear state_fips county_fips) j(move_type
> )
(j = 1 2 3 4 5 6)

Data                               Long  
>  ->                                    
>       Wide
-----------------------------------------
> ------------------------------------
Number of observations          115,567  
>  ->   21,980      
Number of variables                  13  
>  ->   27          
j variable (6 values)         move_type  
>  ->   (dropped)
xij variables:
                                 n1_in_  
>  ->   n1_in_1 n1_in_2 ... n1_in_6
                                 n2_in_  
>  ->   n2_in_1 n2_in_2 ... n2_in_6
                                agi_in_  
>  ->   agi_in_1 agi_in_2 ... agi_in_6
-----------------------------------------
> ------------------------------------

. 
. ** Define locals 
. local txt1 "Non-movers"

. local txt2 "All movers"                
>  

. local txt3 "Domestic movers"           
>  

. local txt4 "Within-state movers"       
>  

. local txt5 "Inter-state movers" 

. local txt6 "Foreign movers"

. 
. ** Label variables, in loop 
. foreach n of numlist 1(1)6 {
  2.         
.         label var n1_in_`n' "Returns, i
> n-migration, `txt`n''"
  3.         label var n2_in_`n' "Exempti
> ons, in-migration, `txt`n''"
  4.         label var agi_in_`n' "AGI, i
> n-migration, `txt`n''"
  5. 
. } // END NUMLIST LOOP 

. 
. ** Preserve 
. tempfile gross_in

. save `gross_in'
file
    C:\Users\ji252\AppData\Local\Temp\S
    > T_91a0_000015.tmp saved as .dta
    format

. clear

. 
. ** Create gross file with in and out mi
> gration 
. use "${data}working/irs_county_gross_ou
> t", clear 

. 
. ** Rename 
. rename n1 n1_out_

. rename n2 n2_out_

. rename agi agi_out_

. rename *_total *_total_out

. 
. ** Reshape 
. reshape wide n1_out_ n2_out_ agi_out_, 
> i(year state_fips county_fips) j(move_t
> ype)
(j = 1 2 3 4 5 6)

Data                               Long  
>  ->                                    
>       Wide
-----------------------------------------
> ------------------------------------
Number of observations          115,611  
>  ->   21,980      
Number of variables                  13  
>  ->   27          
j variable (6 values)         move_type  
>  ->   (dropped)
xij variables:
                                n1_out_  
>  ->   n1_out_1 n1_out_2 ... n1_out_6
                                n2_out_  
>  ->   n2_out_1 n2_out_2 ... n2_out_6
                               agi_out_  
>  ->   agi_out_1 agi_out_2 ... agi_out_6
-----------------------------------------
> ------------------------------------

. 
. ** Define locals 
. local txt1 "Non-movers"

. local txt2 "All movers"                
>  

. local txt3 "Domestic movers"           
>  

. local txt4 "Within-state movers"       
>  

. local txt5 "Inter-state movers" 

. local txt6 "Foreign movers"

. 
. ** Label variables, in loop 
. foreach n of numlist 1(1)6 {
  2.         
.         label var n1_out_`n' "Returns, 
> out-migration, `txt`n''"
  3.         label var n2_out_`n' "Exempt
> ions, out-migration, `txt`n''"
  4.         label var agi_out_`n' "AGI, 
> out-migration, `txt`n''"
  5. 
. } // END NUMLIST LOOP 

. 
. ** Merge data 
. merge 1:1 year state_fips county_fips u
> sing `gross_in', keep(match) nogen

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    0
    Matched                            21
> ,980  
    -------------------------------------
> ----

. 
. ** Text for correct matching (non-mover
> s should match perfectly)
. summ n*_*_1 agi_*_1

    Variable |        Obs        Mean    
> Std. dev.       Min        Max
-------------+---------------------------
> ------------------------------
    n1_out_1 |     21,979    37461.71    
> 123155.4          0    3944880
    n2_out_1 |     21,979    78000.79    
> 252081.2          0    7841705
     n1_in_1 |     21,979    37461.71    
> 123155.4          0    3944880
     n2_in_1 |     21,979    78000.79    
> 252081.2          0    7841705
   agi_out_1 |     21,979     3214755    
> 1.23e+07      -8051   4.30e+08
-------------+---------------------------
> ------------------------------
    agi_in_1 |     21,979     3214755    
> 1.23e+07      -8051   4.30e+08

. 
. ** Define net migration variables 
. 
. ** Loop over variable
. foreach a in "n1" "n2" "agi" {
  2. 
.         if "`a'" == "n1" local txt "Ret
> urns"
  3.         else if "`a'" == "n2" local 
> txt "Exemptions"
  4.         else if "`a'" == "agi" local
>  txt "AGI"
  5. 
.         ** Loop over type of movers 
.         forvalues n = 2/6 {
  6.                 
.                 ** Clean up missing val
> ues 
.                 replace `a'_in_`n' = 0 
> if missing(`a'_in_`n')
  7.                 replace `a'_out_`n' 
> = 0 if missing(`a'_out_`n')
  8. 
.                 ** Generate net 
.                 gen `a'_net_`n' = `a'_i
> n_`n' - `a'_out_`n'
  9.                 label var `a'_net_`n
> ' "`txt', net-migration, `txt`n''"
 10. 
.         } // END MOVER TYPE LOOP 
 11. 
. } // END VARIABLE LOOP 
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)
(183 real changes made)
(155 real changes made)
(183 real changes made)
(155 real changes made)
(202 real changes made)
(172 real changes made)
(1,379 real changes made)
(1,444 real changes made)
(14,365 real changes made)
(14,342 real changes made)

. 
. ** Generate fips variable
. *make_fips state_fips county_fips, gen(
> fips)
. 
. ** Save file 
. save "${data}working/irs_county_gross",
>  replace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_gross.dta saved

. clear

. 
. //-------------------------------------
> ----------------
. // STEP 4: Import and Clean IRS County-
> Level Aggr. Data 
. //-------------------------------------
> ----------------
. 
. ** Loop over years 
. forvalues y = 15(1)22 {
  2.         
.         
.         ** Import data (out)
.         import delimited "${data}irs/`y
> 'incyallagi.csv", clear 
  3. 
.         ** Describe data 
.         des 
  4.         
.         ** Generate year 
.         gen year = 2000 + `y' 
  5.         
.         ** Define AGI groups 
.         label var agi_stub "AGI Bracket
> s"
  6.         label values agi_stub lb_agi
>  
  7.         
.         ** Define set of variables to k
> eep 
.         keep state* county* agi_stub ye
> ar n1 mars1 mars2 mars4 n2 elderly     
>   ///
>                 a00100 n02650 a02650 n0
> 0200 a00200 
  8.                 
.         ** Rename variables 
.         rename a00100 agi 
  9.         rename n02650 n_total_inc
 10.         rename a02650 a_total_inc
 11.         rename n00200 n_wage
 12.         rename a00200 a_wage 
 13.         rename statefips state_fips
 14.         rename state state_abb 
 15.         rename countyfips county_fip
> s 
 16.         rename countyname county_nam
> e 
 17.         
.         ** Rescale 
.         replace agi = 1000 * agi 
 18.         replace a_total_inc = 1000 *
>  a_total_inc
 19.         replace a_wage = 1000 * a_wa
> ge 
 20.         
.         ** Label 
.         label var n1 "Number of returns
> "
 21.         label var mars1 "Number of s
> ingle returns"
 22.         label var mars1 "Number of M
> FJ returns"
 23.         label var mars1 "Number of H
> oH returns"
 24.         label var n2 "Number of indi
> viduals"
 25.         label var elderly "Number of
>  returns with one individual over 60"
 26.         label var agi "Adjusted Gros
> s Income (AGI)"
 27.         label var n_total_inc "Numbe
> r of returns with total income"
 28.         label var a_total_inc "Total
>  income amount"
 29.         label var n_wage "Number of 
> returns with wage income"
 30.         label var a_wage "Wage incom
> e amount"
 31.         
.         ** Sort 
.         sort year state_fips county_fip
> s agi_stub 
 32.         
.         ** Order 
.         order year state* county* agi_s
> tub 
 33.         
.         ** Save 
.         save "${data}working/irs_county
> _all_`y'", replace 
 34.         
.         clear 
 35.         
. } // END YEAR LOOP 
(encoding automatically selected: ISO-885
> 9-1)
(132 vars, 25,536 obs)

Contains data
 Observations:        25,536             
>      
    Variables:           132             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
prep            long    %12.0g           
                     >      PREP
n2              long    %12.0g           
                     >      N2
numdep          long    %12.0g           
                     >      NUMDEP
total_vita      long    %12.0g           
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             long    %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
ral             long    %8.0g            
                     >      RAL
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          long    %12.0g           
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %12.0g           
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            long    %8.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %12.0g           
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %12.0g           
                     >      N03210
a03210          long    %12.0g           
                     >      A03210
n03230          long    %8.0g            
                     >      N03230
a03230          long    %12.0g           
                     >      A03230
n03240          int     %8.0g            
                     >      N03240
a03240          long    %12.0g           
                     >      A03240
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %12.0g           
                     >      N18450
a18450          long    %12.0g           
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          long    %12.0g           
                     >      N09600
a09600          long    %12.0g           
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %12.0g           
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %12.0g           
                     >      N07180
a07180          long    %8.0g            
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %12.0g           
                     >      A07240
n07220          long    %12.0g           
                     >      N07220
a07220          long    %12.0g           
                     >      A07220
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n09750          long    %12.0g           
                     >      N09750
a09750          long    %8.0g            
                     >      A09750
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %12.0g           
                     >      N10960
a10960          long    %12.0g           
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,283 real changes made)
variable a_total_inc was long now double
(25,283 real changes made)
variable a_wage was long now double
(24,576 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_15.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(148 vars, 25,536 obs)

Contains data
 Observations:        25,536             
>      
    Variables:           148             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
prep            long    %12.0g           
                     >      PREP
n2              long    %12.0g           
                     >      N2
numdep          long    %12.0g           
                     >      NUMDEP
total_vita      long    %12.0g           
                     >      TOTAL_VITA
vita            long    %12.0g           
                     >      VITA
tce             long    %12.0g           
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
ral             long    %12.0g           
                     >      RAL
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          long    %12.0g           
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %12.0g           
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            long    %8.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %12.0g           
                     >      N03220
a03220          long    %12.0g           
                     >      A03220
n03300          long    %12.0g           
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %12.0g           
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %12.0g           
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %12.0g           
                     >      N03210
a03210          long    %12.0g           
                     >      A03210
n03230          long    %12.0g           
                     >      N03230
a03230          long    %12.0g           
                     >      A03230
n03240          int     %8.0g            
                     >      N03240
a03240          long    %12.0g           
                     >      A03240
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %12.0g           
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %12.0g           
                     >      N18450
a18450          long    %12.0g           
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %12.0g           
                     >      N18800
a18800          long    %12.0g           
                     >      A18800
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          long    %12.0g           
                     >      N19500
a19500          long    %12.0g           
                     >      A19500
n19530          long    %12.0g           
                     >      N19530
a19530          long    %12.0g           
                     >      A19530
n19550          long    %12.0g           
                     >      N19550
a19550          long    %12.0g           
                     >      A19550
n19570          long    %12.0g           
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20800          long    %12.0g           
                     >      N20800
a20800          long    %12.0g           
                     >      A20800
n21020          long    %12.0g           
                     >      N21020
a21020          long    %12.0g           
                     >      A21020
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          long    %12.0g           
                     >      N09600
a09600          long    %12.0g           
                     >      A09600
n05780          long    %12.0g           
                     >      N05780
a05780          long    %12.0g           
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %12.0g           
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %12.0g           
                     >      N07180
a07180          long    %12.0g           
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %12.0g           
                     >      A07240
n07220          long    %12.0g           
                     >      N07220
a07220          long    %12.0g           
                     >      A07220
n07260          long    %12.0g           
                     >      N07260
a07260          long    %12.0g           
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n09750          long    %12.0g           
                     >      N09750
a09750          long    %12.0g           
                     >      A09750
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %12.0g           
                     >      N10960
a10960          long    %12.0g           
                     >      A10960
n11560          long    %12.0g           
                     >      N11560
a11560          long    %12.0g           
                     >      A11560
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,267 real changes made)
variable a_total_inc was long now double
(25,267 real changes made)
variable a_wage was long now double
(24,662 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_16.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(154 vars, 25,536 obs)

Contains data
 Observations:        25,536             
>      
    Variables:           154             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
elf             long    %12.0g           
                     >      ELF
cprep           long    %12.0g           
                     >      CPREP
prep            long    %12.0g           
                     >      PREP
dir_dep         long    %12.0g           
                     >      DIR_DEP
n2              long    %12.0g           
                     >      N2
numdep          long    %12.0g           
                     >      NUMDEP
total_vita      long    %12.0g           
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             long    %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          long    %12.0g           
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %12.0g           
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            long    %8.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %12.0g           
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %12.0g           
                     >      N03210
a03210          long    %12.0g           
                     >      A03210
n03230          long    %8.0g            
                     >      N03230
a03230          long    %8.0g            
                     >      A03230
n03240          long    %8.0g            
                     >      N03240
a03240          long    %12.0g           
                     >      A03240
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %12.0g           
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %12.0g           
                     >      N18450
a18450          long    %12.0g           
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %12.0g           
                     >      N18800
a18800          long    %12.0g           
                     >      A18800
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          long    %8.0g            
                     >      N19500
a19500          long    %8.0g            
                     >      A19500
n19530          long    %8.0g            
                     >      N19530
a19530          long    %8.0g            
                     >      A19530
n19550          long    %8.0g            
                     >      N19550
a19550          long    %8.0g            
                     >      A19550
n19570          long    %8.0g            
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20800          long    %12.0g           
                     >      N20800
a20800          long    %12.0g           
                     >      A20800
n20950          long    %8.0g            
                     >      N20950
a20950          long    %12.0g           
                     >      A20950
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          long    %12.0g           
                     >      N09600
a09600          long    %12.0g           
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %12.0g           
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %12.0g           
                     >      N07180
a07180          long    %8.0g            
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %12.0g           
                     >      A07240
n07220          long    %12.0g           
                     >      N07220
a07220          long    %12.0g           
                     >      A07220
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n09750          long    %12.0g           
                     >      N09750
a09750          long    %12.0g           
                     >      A09750
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %12.0g           
                     >      N10960
a10960          long    %12.0g           
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11900          long    %12.0g           
                     >      N11900
a11900          long    %12.0g           
                     >      A11900
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
n12000          long    %12.0g           
                     >      N12000
a12000          long    %12.0g           
                     >      A12000
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,280 real changes made)
variable a_total_inc was long now double
(25,280 real changes made)
variable a_wage was long now double
(24,634 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_17.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(154 vars, 25,536 obs)

Contains data
 Observations:        25,536             
>      
    Variables:           154             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
elf             long    %12.0g           
                     >      ELF
cprep           long    %12.0g           
                     >      CPREP
prep            long    %12.0g           
                     >      PREP
dir_dep         long    %12.0g           
                     >      DIR_DEP
n2              long    %12.0g           
                     >      N2
numdep          long    %12.0g           
                     >      NUMDEP
total_vita      long    %12.0g           
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             long    %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          long    %12.0g           
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %12.0g           
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01750          long    %12.0g           
                     >      N01750
a01750          long    %12.0g           
                     >      A01750
schf            long    %8.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %12.0g           
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %12.0g           
                     >      N03210
a03210          long    %12.0g           
                     >      A03210
n04450          long    %12.0g           
                     >      N04450
a04450          long    %12.0g           
                     >      A04450
n04100          long    %12.0g           
                     >      N04100
a04100          long    %12.0g           
                     >      A04100
n04200          long    %12.0g           
                     >      N04200
a04200          long    %12.0g           
                     >      A04200
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %8.0g            
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %8.0g            
                     >      N18450
a18450          long    %8.0g            
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %12.0g           
                     >      N18800
a18800          long    %8.0g            
                     >      A18800
n18460          long    %12.0g           
                     >      N18460
a18460          long    %12.0g           
                     >      A18460
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          long    %8.0g            
                     >      N19500
a19500          long    %8.0g            
                     >      A19500
n19530          long    %8.0g            
                     >      N19530
a19530          long    %8.0g            
                     >      A19530
n19570          long    %8.0g            
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20950          long    %8.0g            
                     >      N20950
a20950          long    %12.0g           
                     >      A20950
n04475          long    %12.0g           
                     >      N04475
a04475          long    %12.0g           
                     >      A04475
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          long    %8.0g            
                     >      N09600
a09600          long    %12.0g           
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %12.0g           
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %12.0g           
                     >      N07180
a07180          long    %12.0g           
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %12.0g           
                     >      A07240
n07225          long    %12.0g           
                     >      N07225
a07225          long    %12.0g           
                     >      A07225
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n09750          long    %12.0g           
                     >      N09750
a09750          long    %8.0g            
                     >      A09750
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %12.0g           
                     >      N10960
a10960          long    %12.0g           
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11900          long    %12.0g           
                     >      N11900
a11900          long    %12.0g           
                     >      A11900
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
n12000          long    %12.0g           
                     >      N12000
a12000          long    %12.0g           
                     >      A12000
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,325 real changes made)
variable a_total_inc was long now double
(25,325 real changes made)
variable a_wage was long now double
(24,672 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_18.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(153 vars, 25,544 obs)

Contains data
 Observations:        25,544             
>      
    Variables:           153             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str24   %24s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
elf             long    %12.0g           
                     >      ELF
cprep           long    %12.0g           
                     >      CPREP
prep            long    %12.0g           
                     >      PREP
dir_dep         long    %12.0g           
                     >      DIR_DEP
n2              long    %12.0g           
                     >      N2
total_vita      long    %8.0g            
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             int     %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          float   %9.0g            
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %12.0g           
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            long    %8.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %12.0g           
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %12.0g           
                     >      N03210
a03210          long    %12.0g           
                     >      A03210
n04450          long    %12.0g           
                     >      N04450
a04450          long    %12.0g           
                     >      A04450
n04100          long    %12.0g           
                     >      N04100
a04100          long    %12.0g           
                     >      A04100
n04200          long    %12.0g           
                     >      N04200
a04200          long    %12.0g           
                     >      A04200
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %8.0g            
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %8.0g            
                     >      N18450
a18450          long    %8.0g            
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %12.0g           
                     >      N18800
a18800          long    %12.0g           
                     >      A18800
n18460          long    %12.0g           
                     >      N18460
a18460          long    %12.0g           
                     >      A18460
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          long    %8.0g            
                     >      N19500
a19500          long    %8.0g            
                     >      A19500
n19530          long    %8.0g            
                     >      N19530
a19530          long    %8.0g            
                     >      A19530
n19570          long    %8.0g            
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20950          long    %8.0g            
                     >      N20950
a20950          long    %12.0g           
                     >      A20950
n04475          long    %12.0g           
                     >      N04475
a04475          long    %12.0g           
                     >      A04475
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          int     %8.0g            
                     >      N09600
a09600          long    %8.0g            
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %12.0g           
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %12.0g           
                     >      N07180
a07180          long    %12.0g           
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %12.0g           
                     >      A07240
n07225          long    %12.0g           
                     >      N07225
a07225          long    %12.0g           
                     >      A07225
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %12.0g           
                     >      N10960
a10960          long    %12.0g           
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11900          long    %12.0g           
                     >      N11900
a11900          long    %12.0g           
                     >      A11900
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
n12000          long    %12.0g           
                     >      N12000
a12000          long    %12.0g           
                     >      A12000
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,363 real changes made)
(25,363 real changes made)
variable a_wage was long now double
(24,724 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_19.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(166 vars, 25,545 obs)

Contains data
 Observations:        25,545             
>      
    Variables:           166             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
elf             long    %12.0g           
                     >      ELF
cprep           long    %8.0g            
                     >      CPREP
prep            long    %12.0g           
                     >      PREP
dir_dep         long    %12.0g           
                     >      DIR_DEP
vrtcrind        long    %8.0g            
                     >      VRTCRIND
n2              long    %12.0g           
                     >      N2
total_vita      long    %8.0g            
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             int     %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          float   %9.0g            
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %8.0g            
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            float   %9.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %8.0g            
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %8.0g            
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %8.0g            
                     >      N03210
a03210          long    %8.0g            
                     >      A03210
n02910          long    %12.0g           
                     >      N02910
a02910          long    %12.0g           
                     >      A02910
n04450          long    %12.0g           
                     >      N04450
a04450          long    %12.0g           
                     >      A04450
n04100          long    %12.0g           
                     >      N04100
a04100          long    %12.0g           
                     >      A04100
n04200          long    %12.0g           
                     >      N04200
a04200          long    %12.0g           
                     >      A04200
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %8.0g            
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %8.0g            
                     >      N18450
a18450          long    %8.0g            
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %12.0g           
                     >      N18800
a18800          long    %8.0g            
                     >      A18800
n18460          long    %12.0g           
                     >      N18460
a18460          long    %12.0g           
                     >      A18460
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          int     %8.0g            
                     >      N19500
a19500          long    %8.0g            
                     >      A19500
n19530          long    %8.0g            
                     >      N19530
a19530          long    %8.0g            
                     >      A19530
n19550          long    %8.0g            
                     >      N19550
a19550          long    %8.0g            
                     >      A19550
n19570          long    %8.0g            
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20950          long    %8.0g            
                     >      N20950
a20950          long    %12.0g           
                     >      A20950
n04475          long    %12.0g           
                     >      N04475
a04475          long    %12.0g           
                     >      A04475
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          int     %8.0g            
                     >      N09600
a09600          long    %8.0g            
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %8.0g            
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %8.0g            
                     >      N07180
a07180          long    %8.0g            
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %8.0g            
                     >      A07240
n07225          long    %12.0g           
                     >      N07225
a07225          long    %12.0g           
                     >      A07225
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %8.0g            
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %8.0g            
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %8.0g            
                     >      N10960
a10960          long    %8.0g            
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n11450          long    %8.0g            
                     >      N11450
a11450          long    %8.0g            
                     >      A11450
n10970          long    %12.0g           
                     >      N10970
a10970          long    %12.0g           
                     >      A10970
n10971          long    %12.0g           
                     >      N10971
a10971          long    %12.0g           
                     >      A10971
n10973          long    %12.0g           
                     >      N10973
a10973          long    %12.0g           
                     >      A10973
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11900          long    %12.0g           
                     >      N11900
a11900          long    %12.0g           
                     >      A11900
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
n12000          long    %8.0g            
                     >      N12000
a12000          long    %12.0g           
                     >      A12000
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,410 real changes made)
(25,410 real changes made)
variable a_wage was long now double
(24,896 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_20.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(168 vars, 25,552 obs)

Contains data
 Observations:        25,552             
>      
    Variables:           168             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
elf             long    %12.0g           
                     >      ELF
cprep           long    %8.0g            
                     >      CPREP
prep            long    %12.0g           
                     >      PREP
dir_dep         long    %12.0g           
                     >      DIR_DEP
vrtcrind        long    %8.0g            
                     >      VRTCRIND
n2              long    %12.0g           
                     >      N2
total_vita      long    %8.0g            
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             int     %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          float   %9.0g            
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %8.0g            
                     >      N00700
a00700          long    %12.0g           
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            float   %9.0g            
                     >      SCHF
n02300          long    %12.0g           
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %8.0g            
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %8.0g            
                     >      N03210
a03210          long    %8.0g            
                     >      A03210
n02910          long    %12.0g           
                     >      N02910
a02910          long    %12.0g           
                     >      A02910
n04450          long    %12.0g           
                     >      N04450
a04450          long    %12.0g           
                     >      A04450
n04100          long    %12.0g           
                     >      N04100
a04100          long    %12.0g           
                     >      A04100
n04200          long    %12.0g           
                     >      N04200
a04200          long    %12.0g           
                     >      A04200
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %8.0g            
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %8.0g            
                     >      N18450
a18450          long    %8.0g            
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %8.0g            
                     >      N18800
a18800          long    %8.0g            
                     >      A18800
n18460          long    %12.0g           
                     >      N18460
a18460          long    %12.0g           
                     >      A18460
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          int     %8.0g            
                     >      N19500
a19500          long    %8.0g            
                     >      A19500
n19530          long    %8.0g            
                     >      N19530
a19530          long    %8.0g            
                     >      A19530
n19550          long    %8.0g            
                     >      N19550
a19550          long    %8.0g            
                     >      A19550
n19570          long    %8.0g            
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20950          long    %8.0g            
                     >      N20950
a20950          long    %12.0g           
                     >      A20950
n04475          long    %12.0g           
                     >      N04475
a04475          long    %12.0g           
                     >      A04475
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          long    %8.0g            
                     >      N09600
a09600          long    %8.0g            
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %8.0g            
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          int     %8.0g            
                     >      N07180
a07180          long    %8.0g            
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %8.0g            
                     >      A07240
n07225          long    %12.0g           
                     >      N07225
a07225          long    %8.0g            
                     >      A07225
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %8.0g            
                     >      N10960
a10960          long    %8.0g            
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n11450          long    %8.0g            
                     >      N11450
a11450          long    %12.0g           
                     >      A11450
n11520          long    %8.0g            
                     >      N11520
a11520          long    %12.0g           
                     >      A11520
n11530          long    %8.0g            
                     >      N11530
a11530          long    %12.0g           
                     >      A11530
n10970          long    %12.0g           
                     >      N10970
a10970          long    %12.0g           
                     >      A10970
n10971          long    %12.0g           
                     >      N10971
a10971          long    %12.0g           
                     >      A10971
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11900          long    %12.0g           
                     >      N11900
a11900          long    %12.0g           
                     >      A11900
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
n12000          long    %8.0g            
                     >      N12000
a12000          long    %12.0g           
                     >      A12000
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,456 real changes made)
(25,456 real changes made)
variable a_wage was long now double
(24,659 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_21.dta saved
(encoding automatically selected: ISO-885
> 9-1)
(166 vars, 25,552 obs)

Contains data
 Observations:        25,552             
>      
    Variables:           166             
>      
-----------------------------------------
Variable      Storage   Display    Value
    name         type    format    label 
>      Variable label
-----------------------------------------
statefips       byte    %8.0g            
                     >      STATEFIPS
state           str2    %9s              
                     >      STATE
countyfips      int     %8.0g            
                     >      COUNTYFIPS
countyname      str20   %20s             
                     >      COUNTYNAME
agi_stub        byte    %8.0g            
                     >      
n1              long    %12.0g           
                     >      N1
mars1           long    %12.0g           
                     >      
mars2           long    %12.0g           
                     >      MARS2
mars4           long    %12.0g           
                     >      MARS4
elf             long    %12.0g           
                     >      ELF
cprep           long    %8.0g            
                     >      CPREP
prep            long    %12.0g           
                     >      PREP
dir_dep         long    %12.0g           
                     >      DIR_DEP
vrtcrind        long    %8.0g            
                     >      VRTCRIND
n2              long    %12.0g           
                     >      N2
total_vita      long    %8.0g            
                     >      TOTAL_VITA
vita            long    %8.0g            
                     >      VITA
tce             int     %8.0g            
                     >      TCE
vita_eic        int     %8.0g            
                     >      VITA_EIC
rac             long    %12.0g           
                     >      RAC
elderly         long    %12.0g           
                     >      ELDERLY
a00100          long    %12.0g           
                     >      A00100
n02650          long    %12.0g           
                     >      N02650
a02650          long    %12.0g           
                     >      A02650
n00200          long    %12.0g           
                     >      N00200
a00200          long    %12.0g           
                     >      A00200
n00300          long    %12.0g           
                     >      N00300
a00300          long    %12.0g           
                     >      A00300
n00400          long    %8.0g            
                     >      N00400
a00400          long    %12.0g           
                     >      A00400
n00600          long    %12.0g           
                     >      N00600
a00600          long    %12.0g           
                     >      A00600
n00650          long    %12.0g           
                     >      N00650
a00650          long    %12.0g           
                     >      A00650
n00700          long    %8.0g            
                     >      N00700
a00700          long    %8.0g            
                     >      A00700
n00900          long    %12.0g           
                     >      N00900
a00900          long    %12.0g           
                     >      A00900
n01000          long    %12.0g           
                     >      N01000
a01000          long    %12.0g           
                     >      A01000
n01400          long    %12.0g           
                     >      N01400
a01400          long    %12.0g           
                     >      A01400
n01700          long    %12.0g           
                     >      N01700
a01700          long    %12.0g           
                     >      A01700
schf            long    %8.0g            
                     >      SCHF
n02300          long    %8.0g            
                     >      N02300
a02300          long    %12.0g           
                     >      A02300
n02500          long    %12.0g           
                     >      N02500
a02500          long    %12.0g           
                     >      A02500
n26270          long    %12.0g           
                     >      N26270
a26270          long    %12.0g           
                     >      A26270
n25870          long    %8.0g            
                     >      N25870
a25870          long    %12.0g           
                     >      A25870
n02900          long    %12.0g           
                     >      N02900
a02900          long    %12.0g           
                     >      A02900
n03220          long    %8.0g            
                     >      N03220
a03220          long    %8.0g            
                     >      A03220
n03300          long    %8.0g            
                     >      N03300
a03300          long    %12.0g           
                     >      A03300
n03270          long    %8.0g            
                     >      N03270
a03270          long    %12.0g           
                     >      A03270
n03150          long    %8.0g            
                     >      N03150
a03150          long    %12.0g           
                     >      A03150
n03210          long    %8.0g            
                     >      N03210
a03210          long    %8.0g            
                     >      A03210
n04450          long    %12.0g           
                     >      N04450
a04450          long    %12.0g           
                     >      A04450
n04100          long    %12.0g           
                     >      N04100
a04100          long    %12.0g           
                     >      A04100
n04200          long    %12.0g           
                     >      N04200
a04200          long    %12.0g           
                     >      A04200
n04470          long    %12.0g           
                     >      N04470
a04470          long    %12.0g           
                     >      A04470
a00101          long    %12.0g           
                     >      A00101
n17000          long    %8.0g            
                     >      N17000
a17000          long    %12.0g           
                     >      A17000
n18425          long    %12.0g           
                     >      N18425
a18425          long    %12.0g           
                     >      A18425
n18450          long    %8.0g            
                     >      N18450
a18450          long    %8.0g            
                     >      A18450
n18500          long    %12.0g           
                     >      N18500
a18500          long    %12.0g           
                     >      A18500
n18800          long    %12.0g           
                     >      N18800
a18800          long    %8.0g            
                     >      A18800
n18460          long    %12.0g           
                     >      N18460
a18460          long    %12.0g           
                     >      A18460
n18300          long    %12.0g           
                     >      N18300
a18300          long    %12.0g           
                     >      A18300
n19300          long    %12.0g           
                     >      N19300
a19300          long    %12.0g           
                     >      A19300
n19500          int     %8.0g            
                     >      N19500
a19500          long    %8.0g            
                     >      A19500
n19530          long    %8.0g            
                     >      N19530
a19530          long    %8.0g            
                     >      A19530
n19570          long    %8.0g            
                     >      N19570
a19570          long    %12.0g           
                     >      A19570
n19700          long    %12.0g           
                     >      N19700
a19700          long    %12.0g           
                     >      A19700
n20950          long    %8.0g            
                     >      N20950
a20950          long    %12.0g           
                     >      A20950
n04475          long    %12.0g           
                     >      N04475
a04475          long    %12.0g           
                     >      A04475
n04800          long    %12.0g           
                     >      N04800
a04800          long    %12.0g           
                     >      A04800
n05800          long    %12.0g           
                     >      N05800
a05800          long    %12.0g           
                     >      A05800
n09600          int     %8.0g            
                     >      N09600
a09600          long    %8.0g            
                     >      A09600
n05780          long    %8.0g            
                     >      N05780
a05780          long    %8.0g            
                     >      A05780
n07100          long    %12.0g           
                     >      N07100
a07100          long    %12.0g           
                     >      A07100
n07300          long    %8.0g            
                     >      N07300
a07300          long    %12.0g           
                     >      A07300
n07180          long    %8.0g            
                     >      N07180
a07180          long    %8.0g            
                     >      A07180
n07230          long    %12.0g           
                     >      N07230
a07230          long    %12.0g           
                     >      A07230
n07240          long    %12.0g           
                     >      N07240
a07240          long    %8.0g            
                     >      A07240
n07225          long    %12.0g           
                     >      N07225
a07225          long    %12.0g           
                     >      A07225
n07260          long    %8.0g            
                     >      N07260
a07260          long    %8.0g            
                     >      A07260
n09400          long    %12.0g           
                     >      N09400
a09400          long    %12.0g           
                     >      A09400
n85770          long    %12.0g           
                     >      N85770
a85770          long    %12.0g           
                     >      A85770
n85775          long    %12.0g           
                     >      N85775
a85775          long    %12.0g           
                     >      A85775
n10600          long    %12.0g           
                     >      N10600
a10600          long    %12.0g           
                     >      A10600
n59660          long    %12.0g           
                     >      N59660
a59660          long    %12.0g           
                     >      A59660
n59661          long    %12.0g           
                     >      N59661
a59661          long    %8.0g            
                     >      A59661
n59662          long    %12.0g           
                     >      N59662
a59662          long    %12.0g           
                     >      A59662
n59663          long    %12.0g           
                     >      N59663
a59663          long    %12.0g           
                     >      A59663
n59664          long    %8.0g            
                     >      N59664
a59664          long    %12.0g           
                     >      A59664
n59720          long    %12.0g           
                     >      N59720
a59720          long    %12.0g           
                     >      A59720
n11070          long    %12.0g           
                     >      N11070
a11070          long    %12.0g           
                     >      A11070
n10960          long    %8.0g            
                     >      N10960
a10960          long    %8.0g            
                     >      A10960
n11560          long    %8.0g            
                     >      N11560
a11560          long    %8.0g            
                     >      A11560
n06500          long    %12.0g           
                     >      N06500
a06500          long    %12.0g           
                     >      A06500
n10300          long    %12.0g           
                     >      N10300
a10300          long    %12.0g           
                     >      A10300
n85530          long    %12.0g           
                     >      N85530
a85530          long    %12.0g           
                     >      A85530
n85300          long    %12.0g           
                     >      N85300
a85300          long    %12.0g           
                     >      A85300
n11901          long    %12.0g           
                     >      N11901
a11901          long    %12.0g           
                     >      A11901
n11900          long    %12.0g           
                     >      N11900
a11900          long    %12.0g           
                     >      A11900
n11902          long    %12.0g           
                     >      N11902
a11902          long    %12.0g           
                     >      A11902
n12000          long    %8.0g            
                     >      N12000
a12000          long    %12.0g           
                     >      A12000
-----------------------------------------
Sorted by: 
     Note: Dataset has changed since last
>  saved.
variable agi was long now double
(25,400 real changes made)
variable a_total_inc was long now double
(25,400 real changes made)
variable a_wage was long now double
(24,693 real changes made)
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all_22.dta saved

. 
. ** Append data 
. 
. ** Loop over years 
. forvalues y = 15(1)22 {
  2. 
.         ** Append 
.         append using "${data}working/ir
> s_county_all_`y'"
  3.                 
.         } // END YEAR LOOP 
(variable county_name was str20, now
       str24 to accommodate using
       data's values)

.         
. ** Save file 
. save "${data}working/irs_county_all", r
> eplace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all.dta saved

.         
. ** Generate fips variable
. make_fips state_fips county_fips, gen(f
> ips)

. 
. ** Save file 
. save "${data}working/irs_county_all", r
> eplace 
file
    C:/Users/ji252/Documents/GitHub/mul
    > tnomah-county-tax/data/working/ir
    > s_county_all.dta saved

. 
. ** Close log
. log close log_01
      name:  log_01
       log:  C:/Users/ji252/Documents/Git
> Hub/multnomah-county-tax/code/logs/01_l
> og_data_clean_multnomah_2025-12-16.log
  log type:  text
 closed on:  18 Dec 2025, 19:28:38
-----------------------------------------

. 
end of do-file

. do "C:\Users\ji252\Documents\GitHub\mul
> tnomah-county-tax\code\02_sdid_analysis
> .do"

. /**************************************
> ***************************************
> **
> File Name:              02_sdid_analysi
> s.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-i
> n-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.isel
> in@yale.edu
> 
> ***************************************
> ***************************************
> */
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}",
>  replace text name(log_02)
-----------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/Git
> Hub/multnomah-county-tax/code/logs/02_l
> og_sdid_2025-12-16.log
  log type:  text
 opened on:  18 Dec 2025, 19:31:09

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", 
> replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}worki
> ng/acs_county_gross_18plus", gen(merge_
> acs)
(variable fips was float, now double to
       accommodate using data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        20
> ,278
        from master                    18
> ,963  (merge_acs==1)
        from using                      1
> ,315  (merge_acs==2)

    Matched                             3
> ,017  (merge_acs==3)
    -------------------------------------
> ----

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2016 |     2,710 |     3,140 
      2017 |     2,710 |     3,140 
      2018 |     2,710 |     3,140 
      2019 |     2,710 |     3,140 
      2020 |     2,712 |     3,142 
      2021 |     2,713 |     3,143 
      2022 |     2,698 |     3,135 
-----------+-----------+----------
     Total |    18,963 |    21,980 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2016 |       430 |     3,140 
      2017 |       430 |     3,140 
      2018 |       430 |     3,140 
      2019 |       430 |     3,140 
      2020 |       430 |     3,142 
      2021 |       430 |     3,143 
      2022 |       437 |     3,135 
-----------+-----------+----------
     Total |     3,017 |    21,980 

. tab state_name if merge_acs == 2 & year
>  == 2022
no observations

. tab state_name if merge_acs == 1 & year
>  == 2022

          State name |      Freq.     Per
> cent        Cum.
---------------------+-------------------
> ----------------
             Alabama |         62        
> 2.30        2.30
              Alaska |         29        
> 1.07        3.37
             Arizona |         11        
> 0.41        3.78
            Arkansas |         72        
> 2.67        6.45
          California |         24        
> 0.89        7.34
            Colorado |         62        
> 2.30        9.64
             Florida |         34        
> 1.26       10.90
             Georgia |        137        
> 5.08       15.97
              Hawaii |          3        
> 0.11       16.09
               Idaho |         43        
> 1.59       17.68
            Illinois |         89        
> 3.30       20.98
             Indiana |         76        
> 2.82       23.80
                Iowa |         94        
> 3.48       27.28
              Kansas |        102        
> 3.78       31.06
            Kentucky |        113        
> 4.19       35.25
           Louisiana |         57        
> 2.11       37.36
               Maine |         14        
> 0.52       37.88
            Maryland |         13        
> 0.48       38.36
       Massachusetts |          5        
> 0.19       38.55
            Michigan |         67        
> 2.48       41.03
           Minnesota |         79        
> 2.93       43.96
         Mississippi |         79        
> 2.93       46.89
            Missouri |        108        
> 4.00       50.89
             Montana |         55        
> 2.04       52.93
            Nebraska |         90        
> 3.34       56.26
              Nevada |         15        
> 0.56       56.82
       New Hampshire |         10        
> 0.37       57.19
          New Jersey |          4        
> 0.15       57.34
          New Mexico |         31        
> 1.15       58.49
            New York |         41        
> 1.52       60.01
      North Carolina |         82        
> 3.04       63.05
        North Dakota |         52        
> 1.93       64.97
                Ohio |         67        
> 2.48       67.46
            Oklahoma |         73        
> 2.71       70.16
              Oregon |         28        
> 1.04       71.20
        Pennsylvania |         47        
> 1.74       72.94
        Rhode Island |          2        
> 0.07       73.02
      South Carolina |         38        
> 1.41       74.43
        South Dakota |         66        
> 2.45       76.87
           Tennessee |         84        
> 3.11       79.99
               Texas |        216        
> 8.01       87.99
                Utah |         24        
> 0.89       88.88
             Vermont |         13        
> 0.48       89.36
            Virginia |        123        
> 4.56       93.92
          Washington |         29        
> 1.07       95.00
       West Virginia |         54        
> 2.00       97.00
           Wisconsin |         59        
> 2.19       99.18
             Wyoming |         22        
> 0.82      100.00
---------------------+-------------------
> ----------------
               Total |      2,698      10
> 0.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/de
> mographics_2020",        ///
>         gen(demo_merge) keep(master mat
> ch)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>    6
        from master                      
>    6  (demo_merge==1)
        from using                       
>    0  (demo_merge==2)

    Matched                            21
> ,974  (demo_merge==3)
    -------------------------------------
> ----

.         
. ** Show match 
. tab state_name demo_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |         0 |       
> 469 
              Alaska |         6 |       
> 202 
             Arizona |         0 |       
> 105 
            Arkansas |         0 |       
> 525 
          California |         0 |       
> 406 
            Colorado |         0 |       
> 448 
         Connecticut |         0 |       
>  48 
            Delaware |         0 |       
>  21 
District of Columbia |         0 |       
>   7 
             Florida |         0 |       
> 469 
             Georgia |         0 |     1,
> 113 
              Hawaii |         0 |       
>  30 
               Idaho |         0 |       
> 308 
            Illinois |         0 |       
> 714 
             Indiana |         0 |       
> 644 
                Iowa |         0 |       
> 693 
              Kansas |         0 |       
> 735 
            Kentucky |         0 |       
> 840 
           Louisiana |         0 |       
> 448 
               Maine |         0 |       
> 112 
            Maryland |         0 |       
> 168 
       Massachusetts |         0 |       
>  98 
            Michigan |         0 |       
> 581 
           Minnesota |         0 |       
> 609 
         Mississippi |         0 |       
> 574 
            Missouri |         0 |       
> 805 
             Montana |         0 |       
> 392 
            Nebraska |         0 |       
> 651 
              Nevada |         0 |       
> 119 
       New Hampshire |         0 |       
>  70 
          New Jersey |         0 |       
> 147 
          New Mexico |         0 |       
> 231 
            New York |         0 |       
> 434 
      North Carolina |         0 |       
> 700 
        North Dakota |         0 |       
> 371 
                Ohio |         0 |       
> 616 
            Oklahoma |         0 |       
> 539 
              Oregon |         0 |       
> 252 
        Pennsylvania |         0 |       
> 469 
        Rhode Island |         0 |       
>  35 
      South Carolina |         0 |       
> 322 
        South Dakota |         0 |       
> 462 
           Tennessee |         0 |       
> 665 
               Texas |         0 |     1,
> 778 
                Utah |         0 |       
> 203 
             Vermont |         0 |       
>  98 
            Virginia |         0 |       
> 931 
          Washington |         0 |       
> 273 
       West Virginia |         0 |       
> 385 
           Wisconsin |         0 |       
> 504 
             Wyoming |         0 |       
> 161 
---------------------+-----------+-------
> ---
               Total |         6 |    21,
> 980 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |       469 |       
> 469 
              Alaska |       196 |       
> 202 
             Arizona |       105 |       
> 105 
            Arkansas |       525 |       
> 525 
          California |       406 |       
> 406 
            Colorado |       448 |       
> 448 
         Connecticut |        48 |       
>  48 
            Delaware |        21 |       
>  21 
District of Columbia |         7 |       
>   7 
             Florida |       469 |       
> 469 
             Georgia |     1,113 |     1,
> 113 
              Hawaii |        30 |       
>  30 
               Idaho |       308 |       
> 308 
            Illinois |       714 |       
> 714 
             Indiana |       644 |       
> 644 
                Iowa |       693 |       
> 693 
              Kansas |       735 |       
> 735 
            Kentucky |       840 |       
> 840 
           Louisiana |       448 |       
> 448 
               Maine |       112 |       
> 112 
            Maryland |       168 |       
> 168 
       Massachusetts |        98 |       
>  98 
            Michigan |       581 |       
> 581 
           Minnesota |       609 |       
> 609 
         Mississippi |       574 |       
> 574 
            Missouri |       805 |       
> 805 
             Montana |       392 |       
> 392 
            Nebraska |       651 |       
> 651 
              Nevada |       119 |       
> 119 
       New Hampshire |        70 |       
>  70 
          New Jersey |       147 |       
> 147 
          New Mexico |       231 |       
> 231 
            New York |       434 |       
> 434 
      North Carolina |       700 |       
> 700 
        North Dakota |       371 |       
> 371 
                Ohio |       616 |       
> 616 
            Oklahoma |       539 |       
> 539 
              Oregon |       252 |       
> 252 
        Pennsylvania |       469 |       
> 469 
        Rhode Island |        35 |       
>  35 
      South Carolina |       322 |       
> 322 
        South Dakota |       462 |       
> 462 
           Tennessee |       665 |       
> 665 
               Texas |     1,778 |     1,
> 778 
                Utah |       203 |       
> 203 
             Vermont |        98 |       
>  98 
            Virginia |       931 |       
> 931 
          Washington |       273 |       
> 273 
       West Virginia |       385 |       
> 385 
           Wisconsin |       504 |       
> 504 
             Wyoming |       161 |       
> 161 
---------------------+-----------+-------
> ---
               Total |    21,974 |    21,
> 980 

. tab year demo_merge, m

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2016 |         0 |     3,140 
      2017 |         0 |     3,140 
      2018 |         0 |     3,140 
      2019 |         0 |     3,140 
      2020 |         2 |     3,142 
      2021 |         2 |     3,143 
      2022 |         2 |     3,135 
-----------+-----------+----------
     Total |         6 |    21,980 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2016 |     3,140 |     3,140 
      2017 |     3,140 |     3,140 
      2018 |     3,140 |     3,140 
      2019 |     3,140 |     3,140 
      2020 |     3,140 |     3,142 
      2021 |     3,141 |     3,143 
      2022 |     3,133 |     3,135 
-----------+-----------+----------
     Total |    21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}worki
> ng/bea_economics",       ///
>         gen(econ_merge) keep(master mat
> ch) 

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>  366
        from master                      
>  366  (econ_merge==1)
        from using                       
>    0  (econ_merge==2)

    Matched                            21
> ,608  (econ_merge==3)
    -------------------------------------
> ----

.         
. ** Show match 
. tab state_name econ_merge, m

                     |  Matching
                     |   result
                     | from merge
          State name | Master on |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |         0 |       
> 469 
              Alaska |         0 |       
> 196 
             Arizona |         0 |       
> 105 
            Arkansas |         0 |       
> 525 
          California |         0 |       
> 406 
            Colorado |         0 |       
> 448 
         Connecticut |         0 |       
>  48 
            Delaware |         0 |       
>  21 
District of Columbia |         0 |       
>   7 
             Florida |         0 |       
> 469 
             Georgia |         0 |     1,
> 113 
              Hawaii |         9 |       
>  30 
               Idaho |         0 |       
> 308 
            Illinois |         0 |       
> 714 
             Indiana |         0 |       
> 644 
                Iowa |         0 |       
> 693 
              Kansas |         0 |       
> 735 
            Kentucky |         0 |       
> 840 
           Louisiana |         0 |       
> 448 
               Maine |         0 |       
> 112 
            Maryland |         0 |       
> 168 
       Massachusetts |         0 |       
>  98 
            Michigan |         0 |       
> 581 
           Minnesota |         0 |       
> 609 
         Mississippi |         0 |       
> 574 
            Missouri |         0 |       
> 805 
             Montana |         0 |       
> 392 
            Nebraska |         0 |       
> 651 
              Nevada |         0 |       
> 119 
       New Hampshire |         0 |       
>  70 
          New Jersey |         0 |       
> 147 
          New Mexico |         0 |       
> 231 
            New York |         0 |       
> 434 
      North Carolina |         0 |       
> 700 
        North Dakota |         0 |       
> 371 
                Ohio |         0 |       
> 616 
            Oklahoma |         0 |       
> 539 
              Oregon |         0 |       
> 252 
        Pennsylvania |         0 |       
> 469 
        Rhode Island |         0 |       
>  35 
      South Carolina |         0 |       
> 322 
        South Dakota |         0 |       
> 462 
           Tennessee |         0 |       
> 665 
               Texas |         0 |     1,
> 778 
                Utah |         0 |       
> 203 
             Vermont |         0 |       
>  98 
            Virginia |       357 |       
> 931 
          Washington |         0 |       
> 273 
       West Virginia |         0 |       
> 385 
           Wisconsin |         0 |       
> 504 
             Wyoming |         0 |       
> 161 
---------------------+-----------+-------
> ---
               Total |       366 |    21,
> 974 


                     |  Matching
                     |   result
                     | from merge
          State name | Matched ( |     To
> tal
---------------------+-----------+-------
> ---
             Alabama |       469 |       
> 469 
              Alaska |       196 |       
> 196 
             Arizona |       105 |       
> 105 
            Arkansas |       525 |       
> 525 
          California |       406 |       
> 406 
            Colorado |       448 |       
> 448 
         Connecticut |        48 |       
>  48 
            Delaware |        21 |       
>  21 
District of Columbia |         7 |       
>   7 
             Florida |       469 |       
> 469 
             Georgia |     1,113 |     1,
> 113 
              Hawaii |        21 |       
>  30 
               Idaho |       308 |       
> 308 
            Illinois |       714 |       
> 714 
             Indiana |       644 |       
> 644 
                Iowa |       693 |       
> 693 
              Kansas |       735 |       
> 735 
            Kentucky |       840 |       
> 840 
           Louisiana |       448 |       
> 448 
               Maine |       112 |       
> 112 
            Maryland |       168 |       
> 168 
       Massachusetts |        98 |       
>  98 
            Michigan |       581 |       
> 581 
           Minnesota |       609 |       
> 609 
         Mississippi |       574 |       
> 574 
            Missouri |       805 |       
> 805 
             Montana |       392 |       
> 392 
            Nebraska |       651 |       
> 651 
              Nevada |       119 |       
> 119 
       New Hampshire |        70 |       
>  70 
          New Jersey |       147 |       
> 147 
          New Mexico |       231 |       
> 231 
            New York |       434 |       
> 434 
      North Carolina |       700 |       
> 700 
        North Dakota |       371 |       
> 371 
                Ohio |       616 |       
> 616 
            Oklahoma |       539 |       
> 539 
              Oregon |       252 |       
> 252 
        Pennsylvania |       469 |       
> 469 
        Rhode Island |        35 |       
>  35 
      South Carolina |       322 |       
> 322 
        South Dakota |       462 |       
> 462 
           Tennessee |       665 |       
> 665 
               Texas |     1,778 |     1,
> 778 
                Utah |       203 |       
> 203 
             Vermont |        98 |       
>  98 
            Virginia |       574 |       
> 931 
          Washington |       273 |       
> 273 
       West Virginia |       385 |       
> 385 
           Wisconsin |       504 |       
> 504 
             Wyoming |       161 |       
> 161 
---------------------+-----------+-------
> ---
               Total |    21,608 |    21,
> 974 

. tab year econ_merge, m

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2016 |        52 |     3,140 
      2017 |        52 |     3,140 
      2018 |        52 |     3,140 
      2019 |        52 |     3,140 
      2020 |        52 |     3,140 
      2021 |        53 |     3,141 
      2022 |        53 |     3,133 
-----------+-----------+----------
     Total |       366 |    21,974 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2016 |     3,088 |     3,140 
      2017 |     3,088 |     3,140 
      2018 |     3,088 |     3,140 
      2019 |     3,088 |     3,140 
      2020 |     3,088 |     3,140 
      2021 |     3,088 |     3,141 
      2022 |     3,080 |     3,133 
-----------+-----------+----------
     Total |    21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/cov
> id_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master ma
> tch )
(variable state_name was str20, now
       str24 to accommodate using
       data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                          
>   63
        from master                      
>   63  (covid_merge==1)
        from using                       
>    0  (covid_merge==2)

    Matched                            21
> ,545  (covid_merge==3)
    -------------------------------------
> ----

. 
. ** Show match 
. tab state_name covid_merge, m

                      |  Matching
                      |   result
                      | from merge
           State name | Master on |     T
> otal
----------------------+-----------+------
> ----
              Alabama |         0 |      
>  469 
               Alaska |        28 |      
>  196 
              Arizona |         0 |      
>  105 
             Arkansas |         0 |      
>  525 
           California |         0 |      
>  406 
             Colorado |         0 |      
>  448 
          Connecticut |         0 |      
>   48 
             Delaware |         0 |      
>   21 
 District of Columbia |         0 |      
>    7 
              Florida |         0 |      
>  469 
              Georgia |         0 |     1
> ,113 
               Hawaii |         0 |      
>   21 
                Idaho |         0 |      
>  308 
             Illinois |         0 |      
>  714 
              Indiana |         0 |      
>  644 
                 Iowa |         0 |      
>  693 
               Kansas |         0 |      
>  735 
             Kentucky |         0 |      
>  840 
            Louisiana |         0 |      
>  448 
                Maine |         0 |      
>  112 
             Maryland |         0 |      
>  168 
        Massachusetts |         0 |      
>   98 
             Michigan |         0 |      
>  581 
            Minnesota |         0 |      
>  609 
          Mississippi |         0 |      
>  574 
             Missouri |         0 |      
>  805 
              Montana |         0 |      
>  392 
             Nebraska |         0 |      
>  651 
               Nevada |         0 |      
>  119 
        New Hampshire |         0 |      
>   70 
           New Jersey |         0 |      
>  147 
           New Mexico |         0 |      
>  231 
             New York |        35 |      
>  434 
       North Carolina |         0 |      
>  700 
         North Dakota |         0 |      
>  371 
                 Ohio |         0 |      
>  616 
             Oklahoma |         0 |      
>  539 
               Oregon |         0 |      
>  252 
         Pennsylvania |         0 |      
>  469 
         Rhode Island |         0 |      
>   35 
       South Carolina |         0 |      
>  322 
         South Dakota |         0 |      
>  462 
            Tennessee |         0 |      
>  665 
                Texas |         0 |     1
> ,778 
                 Utah |         0 |      
>  203 
              Vermont |         0 |      
>   98 
             Virginia |         0 |      
>  574 
           Washington |         0 |      
>  273 
        West Virginia |         0 |      
>  385 
            Wisconsin |         0 |      
>  504 
              Wyoming |         0 |      
>  161 
----------------------+-----------+------
> ----
                Total |        63 |    21
> ,608 


                      |  Matching
                      |   result
                      | from merge
           State name | Matched ( |     T
> otal
----------------------+-----------+------
> ----
              Alabama |       469 |      
>  469 
               Alaska |       168 |      
>  196 
              Arizona |       105 |      
>  105 
             Arkansas |       525 |      
>  525 
           California |       406 |      
>  406 
             Colorado |       448 |      
>  448 
          Connecticut |        48 |      
>   48 
             Delaware |        21 |      
>   21 
 District of Columbia |         7 |      
>    7 
              Florida |       469 |      
>  469 
              Georgia |     1,113 |     1
> ,113 
               Hawaii |        21 |      
>   21 
                Idaho |       308 |      
>  308 
             Illinois |       714 |      
>  714 
              Indiana |       644 |      
>  644 
                 Iowa |       693 |      
>  693 
               Kansas |       735 |      
>  735 
             Kentucky |       840 |      
>  840 
            Louisiana |       448 |      
>  448 
                Maine |       112 |      
>  112 
             Maryland |       168 |      
>  168 
        Massachusetts |        98 |      
>   98 
             Michigan |       581 |      
>  581 
            Minnesota |       609 |      
>  609 
          Mississippi |       574 |      
>  574 
             Missouri |       805 |      
>  805 
              Montana |       392 |      
>  392 
             Nebraska |       651 |      
>  651 
               Nevada |       119 |      
>  119 
        New Hampshire |        70 |      
>   70 
           New Jersey |       147 |      
>  147 
           New Mexico |       231 |      
>  231 
             New York |       399 |      
>  434 
       North Carolina |       700 |      
>  700 
         North Dakota |       371 |      
>  371 
                 Ohio |       616 |      
>  616 
             Oklahoma |       539 |      
>  539 
               Oregon |       252 |      
>  252 
         Pennsylvania |       469 |      
>  469 
         Rhode Island |        35 |      
>   35 
       South Carolina |       322 |      
>  322 
         South Dakota |       462 |      
>  462 
            Tennessee |       665 |      
>  665 
                Texas |     1,778 |     1
> ,778 
                 Utah |       203 |      
>  203 
              Vermont |        98 |      
>   98 
             Virginia |       574 |      
>  574 
           Washington |       273 |      
>  273 
        West Virginia |       385 |      
>  385 
            Wisconsin |       504 |      
>  504 
              Wyoming |       161 |      
>  161 
----------------------+-----------+------
> ----
                Total |    21,545 |    21
> ,608 

. tab year covid_merge, m

  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Master on |     Total
-----------+-----------+----------
      2016 |         9 |     3,088 
      2017 |         9 |     3,088 
      2018 |         9 |     3,088 
      2019 |         9 |     3,088 
      2020 |         9 |     3,088 
      2021 |         9 |     3,088 
      2022 |         9 |     3,080 
-----------+-----------+----------
     Total |        63 |    21,608 


  Tax year |  Matching
     (year |   result
    before | from merge
     move) | Matched ( |     Total
-----------+-----------+----------
      2016 |     3,079 |     3,088 
      2017 |     3,079 |     3,088 
      2018 |     3,079 |     3,088 
      2019 |     3,079 |     3,088 
      2020 |     3,079 |     3,088 
      2021 |     3,079 |     3,088 
      2022 |     3,071 |     3,080 
-----------+-----------+----------
     Total |    21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing ba
> se populations
. tab county_name year if (missing(n1_in_
> 1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2017 |     T
> otal
----------------------+-----------+------
> ----
        Loving County |         1 |      
>    1 
----------------------+-----------+------
> ----
                Total |         1 |      
>    1 

. drop if (missing(n1_in_1 ) | n1_in_1 ==
>  0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations i
> n each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      | State name
          County name | Connect.. |     T
> otal
----------------------+-----------+------
> ----
     Fairfield County |         6 |      
>    6 
      Hartford County |         6 |      
>    6 
    Litchfield County |         6 |      
>    6 
        Loving County |         0 |      
>    6 
     Middlesex County |         6 |      
>    6 
     New Haven County |         6 |      
>    6 
    New London County |         6 |      
>    6 
       Tolland County |         6 |      
>    6 
       Windham County |         6 |      
>    6 
----------------------+-----------+------
> ----
                Total |        48 |      
>   54 


                      | State name
          County name |     Texas |     T
> otal
----------------------+-----------+------
> ----
     Fairfield County |         0 |      
>    6 
      Hartford County |         0 |      
>    6 
    Litchfield County |         0 |      
>    6 
        Loving County |         6 |      
>    6 
     Middlesex County |         0 |      
>    6 
     New Haven County |         0 |      
>    6 
    New London County |         0 |      
>    6 
       Tolland County |         0 |      
>    6 
       Windham County |         0 |      
>    6 
----------------------+-----------+------
> ----
                Total |         6 |      
>   54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & coun
> ty_fips == 51

. label var multnomah "Indicator for Mult
> nomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 
> 2020

. label var Treated "Treatment indicator 
> for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (exc
> luding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 
> percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urba
> n areas
-----------------------------------------
> --------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs
>                3,079
25%            0              0       Sum
>  of wgt.       3,079

50%     .3256337                      Mea
> n           .3521437
                        Largest       Std
> . dev.       .332065
75%     .6326353              1
90%      .847923              1       Var
> iance       .1102672
95%     .9372299              1       Ske
> wness       .3661052
99%     .9972304              1       Kur
> tosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urb
> an >= `cutoff' & year == 2020

                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         0 |     T
> otal
----------------------+-----------+------
> ----
               Alaska |         1 |      
>    1 
              Arizona |         1 |      
>    1 
           California |        15 |      
>   15 
             Colorado |         4 |      
>    4 
             Delaware |         1 |      
>    1 
 District of Columbia |         1 |      
>    1 
              Florida |        13 |      
>   13 
              Georgia |         8 |      
>    8 
               Hawaii |         1 |      
>    1 
                Idaho |         1 |      
>    1 
             Illinois |         5 |      
>    5 
              Indiana |         3 |      
>    3 
                 Iowa |         1 |      
>    1 
               Kansas |         2 |      
>    2 
             Kentucky |         2 |      
>    2 
            Louisiana |         3 |      
>    3 
             Maryland |         3 |      
>    3 
        Massachusetts |         5 |      
>    5 
             Michigan |         3 |      
>    3 
            Minnesota |         3 |      
>    3 
             Missouri |         4 |      
>    4 
             Nebraska |         2 |      
>    2 
               Nevada |         3 |      
>    3 
           New Jersey |        10 |      
>   10 
           New Mexico |         2 |      
>    2 
             New York |         9 |      
>    9 
       North Carolina |         4 |      
>    4 
                 Ohio |         6 |      
>    6 
             Oklahoma |         1 |      
>    1 
               Oregon |         1 |      
>    2 
         Pennsylvania |         4 |      
>    4 
         Rhode Island |         2 |      
>    2 
            Tennessee |         2 |      
>    2 
                Texas |        11 |      
>   11 
                 Utah |         4 |      
>    4 
             Virginia |        10 |      
>   10 
           Washington |         1 |      
>    1 
            Wisconsin |         1 |      
>    1 
----------------------+-----------+------
> ----
                Total |       153 |      
>  154 


                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         1 |     T
> otal
----------------------+-----------+------
> ----
               Alaska |         0 |      
>    1 
              Arizona |         0 |      
>    1 
           California |         0 |      
>   15 
             Colorado |         0 |      
>    4 
             Delaware |         0 |      
>    1 
 District of Columbia |         0 |      
>    1 
              Florida |         0 |      
>   13 
              Georgia |         0 |      
>    8 
               Hawaii |         0 |      
>    1 
                Idaho |         0 |      
>    1 
             Illinois |         0 |      
>    5 
              Indiana |         0 |      
>    3 
                 Iowa |         0 |      
>    1 
               Kansas |         0 |      
>    2 
             Kentucky |         0 |      
>    2 
            Louisiana |         0 |      
>    3 
             Maryland |         0 |      
>    3 
        Massachusetts |         0 |      
>    5 
             Michigan |         0 |      
>    3 
            Minnesota |         0 |      
>    3 
             Missouri |         0 |      
>    4 
             Nebraska |         0 |      
>    2 
               Nevada |         0 |      
>    3 
           New Jersey |         0 |      
>   10 
           New Mexico |         0 |      
>    2 
             New York |         0 |      
>    9 
       North Carolina |         0 |      
>    4 
                 Ohio |         0 |      
>    6 
             Oklahoma |         0 |      
>    1 
               Oregon |         1 |      
>    2 
         Pennsylvania |         0 |      
>    4 
         Rhode Island |         0 |      
>    2 
            Tennessee |         0 |      
>    2 
                Texas |         0 |      
>   11 
                 Utah |         0 |      
>    4 
             Virginia |         0 |      
>   10 
           Washington |         0 |      
>    1 
            Wisconsin |         0 |      
>    1 
----------------------+-----------+------
> ----
                Total |         1 |      
>  154 

. gen sample_urban95 = percent_urban >= `
> cutoff' // All counties 

. label var sample_urban95 "Urban countie
> s (top 5%) (excluding AK, CA, HI OR, WA
> )"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 |      2,925       95.00     
>   95.00
          1 |        154        5.00     
>  100.00
------------+----------------------------
> -------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 
> percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urb
> an >= `cutoff' & year == 2020

                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         0 |     T
> otal
----------------------+-----------+------
> ----
           California |         6 |      
>    6 
             Colorado |         2 |      
>    2 
 District of Columbia |         1 |      
>    1 
              Florida |         4 |      
>    4 
              Georgia |         5 |      
>    5 
             Illinois |         2 |      
>    2 
              Indiana |         1 |      
>    1 
            Louisiana |         1 |      
>    1 
             Maryland |         1 |      
>    1 
        Massachusetts |         1 |      
>    1 
             Michigan |         1 |      
>    1 
            Minnesota |         1 |      
>    1 
             Missouri |         1 |      
>    1 
               Nevada |         1 |      
>    1 
           New Jersey |         6 |      
>    6 
             New York |         7 |      
>    7 
       North Carolina |         1 |      
>    1 
                 Ohio |         1 |      
>    1 
               Oregon |         0 |      
>    1 
         Pennsylvania |         2 |      
>    2 
         Rhode Island |         1 |      
>    1 
                Texas |         3 |      
>    3 
                 Utah |         2 |      
>    2 
             Virginia |         8 |      
>    8 
            Wisconsin |         1 |      
>    1 
----------------------+-----------+------
> ----
                Total |        60 |      
>   61 


                      | Indicator
                      |    for
                      | Multnomah
                      |  County,
                      |   Oregon
           State name |         1 |     T
> otal
----------------------+-----------+------
> ----
           California |         0 |      
>    6 
             Colorado |         0 |      
>    2 
 District of Columbia |         0 |      
>    1 
              Florida |         0 |      
>    4 
              Georgia |         0 |      
>    5 
             Illinois |         0 |      
>    2 
              Indiana |         0 |      
>    1 
            Louisiana |         0 |      
>    1 
             Maryland |         0 |      
>    1 
        Massachusetts |         0 |      
>    1 
             Michigan |         0 |      
>    1 
            Minnesota |         0 |      
>    1 
             Missouri |         0 |      
>    1 
               Nevada |         0 |      
>    1 
           New Jersey |         0 |      
>    6 
             New York |         0 |      
>    7 
       North Carolina |         0 |      
>    1 
                 Ohio |         0 |      
>    1 
               Oregon |         1 |      
>    1 
         Pennsylvania |         0 |      
>    2 
         Rhode Island |         0 |      
>    1 
                Texas |         0 |      
>    3 
                 Utah |         0 |      
>    2 
             Virginia |         0 |      
>    8 
            Wisconsin |         0 |      
>    1 
----------------------+-----------+------
> ----
                Total |         1 |      
>   61 

. gen sample_urban98 = percent_urban >= `
> cutoff' // All counties 

. label var sample_urban98 "Urban countie
> s (top 1%) (excluding AK, CA, HI OR, WA
> )"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 |      3,018       98.02     
>   98.02
          1 |         61        1.98     
>  100.00
------------+----------------------------
> -------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multno
> mah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 
> + covid 
. cluster kmeans cases_cum* deaths_cum* i
> f        ///
>         sample_urban95 == 1 & year == 2
> 020 & covid_merge == 3 , k(5) gen(kmean
> )
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(km
> ean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnom
> a
. gen tmp1 = kmean if sample_urban95 == 1
>  & year == 2020 & covid_merge == 3 & mu
> ltnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban
> 95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban c
> ounties (top 5%) w. Kmean Covid Match  
> (excluding AK, CA, HI OR, WA)"

. tab sample_urban95_covid if year == 202
> 0

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent     
>    Cum.
------------+----------------------------
> -------
          0 |      2,879       98.73     
>   98.73
          1 |         37        1.27     
>  100.00
------------+----------------------------
> -------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2
> 020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* popul
> ation

. collapse (mean) cases_cum* deaths_cum* 
> [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(km
> ean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
> 16 17 18 19 20 21 22 23 24 25 26 27 28 
> 29)

Data                               Wide  
>  ->                                    
>       Long
-----------------------------------------
> ------------------------------------
Number of observations                5  
>  ->   145         
Number of variables                  59  
>  ->   4           
j variable (29 values)                   
>  ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29  
>  ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29 
>  ->   deaths_cum
-----------------------------------------
> ------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg"
> , as(jpg) name("Graph") quality(100) re
> place             
file C:/Users/ji252/Documents/GitHub/mult
> nomah-county-tax/results/fig_kmeans.jpg
>  written in JPEG format

. clear  

. 
. ** Restore      
. restore 

. 
. ** Define covariates 
. local covariates "population per_capita
> _income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now d
> ouble
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x
> '_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net
> _3 / (households_out_1 + households_out
> _2))
(17,815 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 
> / (persons_out_1 + persons_out_2))
(17,815 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3
>  / (dollars_out_1 + dollars_out_2))
(17,815 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic m
> igration rate, returns (%)"

. label var n2_rate_irs   "Net domestic m
> igration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic m
> igration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic m
> igration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic m
> igration rate, persons (%)"

. label var agi_rate_acs  "Net domestic m
> igration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2016 to 2022
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before | tag(fips)
     move) |         0 |     Total
-----------+-----------+----------
      2016 |         0 |     2,916 
      2017 |     2,916 |     2,916 
      2018 |     2,916 |     2,916 
      2019 |     2,916 |     2,916 
      2020 |     2,916 |     2,916 
      2021 |     2,916 |     2,916 
      2022 |     2,916 |     2,916 
-----------+-----------+----------
     Total |    17,496 |    20,412 


  Tax year |
     (year |
    before | tag(fips)
     move) |         1 |     Total
-----------+-----------+----------
      2016 |     2,916 |     2,916 
      2017 |         0 |     2,916 
      2018 |         0 |     2,916 
      2019 |         0 |     2,916 
      2020 |         0 |     2,916 
      2021 |         0 |     2,916 
      2022 |         0 |     2,916 
-----------+-----------+----------
     Total |     2,916 |    20,412 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_
> all sample_urban95 sample_urban95_covid
>  sample_urban98 { 
  3.                         
.                 gen sample = `samp' == 
> 1        
  4.                 if "`data'" == "acs"
>  replace sample = 0 if merge_acs != 3  
>      
  5.                         
.                 ** Clear stored values 
.                 eststo clear           
>  
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist 
> n1_rate_`data' n2_rate_`data' agi_rate_
> `data' {
  7.                         
.                         ** Store label 
.                         local label : v
> ariable label `out'
  8.                                 
.                         ** Loop over in
> clusion of covariates
.                         forvalues c = 0
> /1 {
  9.                                 
.                                 if `c' 
> == 0 local covars ""
 10.                                 else
>  if `c' == 1 local covars "covariates(`
> covariates', projected)"
 11.                                 dis 
> "`covars'"
 12.                                 
.                                 ** Run 
> SDID
.                                 eststo 
> sdid_`out'_`c': sdid `out' fips year Tr
> eated     ///
>                                        
>  if sample == 1,                       
>   ///
>                                        
>  vce(placebo)                          
>   ///
>                                        
>  `covar'                               
>           ///
>                                        
>  reps(`reps')                          
>   ///
>                                        
>  graph graph_export("${results}fig_`out
> '_`c'_`samp'_", .pdf) 
 13.                                     
>     
.                                 ** Esta
> dd counties  
.                                 qui sum
> m `out' if year == 2020 & sample == 1
 14.                                 esta
> dd scalar count = r(N)      
 15.                                     
>     
.                                 ** Esta
> dd mean 
.                                 qui sum
> m `out' if multnomah == 1 & Treated == 
> 0 
 16.                                 esta
> dd scalar mean = r(mean)
 17. 
.                                 ** Run 
> event-study 
.                                 sdid_ev
> ent `out' fips year Treated            
>           ///
>                                        
>  if sample == 1,                       
>                   ///
>                                        
>  `covar'                               
>                           ///
>                                        
>  vce(placebo)                          
>                   ///
>                                        
>  brep(`reps')                          
>                   ///
>                                        
>  placebo(all)
 18.                                 
.                                 ** Crea
> te Figure 
.                                 
.                                 ** Move
>  results from matrix to data 
.                                 matrix 
> list e(H)
 19.                                 mat 
> res_att_`ct' = e(H)[1,1..4]
 20.                                 mat 
> res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move
>  Matrix results to data 
.                                 svmat r
> es
 22.                                 
.                                 ** Gene
> rate ID variable
.                                 gen id 
> = 2021 - _n + 1 if !missing(res1)
 23.                                 labe
> l var id "Tax year (origin)"
 24.                                 
.                                 ** Sort
>  
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway 
>  (rcap res3 res4 id, lc(gs10) fc(gs11%5
> 0))       ///
>                                        
>          (scatter res1 id, mc(black)), 
>                           ///          
>    
>                                        
>  legend(off) ytitle("`label'")         
>                           ///
>                                        
>  yline(0, lc(red) lp(-))               
>                                   ///
>                                        
>  xline(2019.5, lc(black) lp(solid))    
>                           ///
>                                        
>  ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph e
> xport "${results}fig_`out'_`c'_sample_e
> ventstudy.jpg",   ///
>                                        
>  as(jpg) name("Graph") quality(100) rep
> lace              
 27. 
.                                 ** Clea
> n up 
.                                 drop re
> s1 res2 res3 res4 res5 id 
 28. 
.                                 ** Upda
> te Count
.                                 local c
> t = `ct' + 1 
 29.                                     
>                             
.                         } // END COVAR 
> LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_`d
> ata'_0 sdid_n1_rate_`data'_1           
>           ///
>                                 sdid_n2
> _rate_`data'_0 sdid_n2_rate_`data'_1   
>                   ///
>                                 sdid_ag
> i_rate_`data'_0 sdid_agi_rate_`data'_1 
> using     ///
>                 "${results}tab_sdid_`da
> ta'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**"
>  0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) re
> place                                  
>   ///
>                 mgroups("Returns" "Exem
> ptions" "AGI",                   ///
>                         pattern(1 0 1 0
>  1 0) )                                
>           ///
>                 mtitle( "No Covariates"
>  "Covariates"                    ///
>                                 "No Cov
> ariates" "Covariates"                  
>   ///
>                                 "No Cov
> ariates" "Covariates")                 
>   ///
>                 stats(count mean,      
>                                        
>                   ///
>                         fmt(%9.0fc %9.3
> fc)                                    
>                   ///
>                         labels("Number 
> of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,815 real changes made)

Panel is unbalanced.
r(451);

end of do-file

r(451);

. do "C:\Users\ji252\AppData\Local\Temp\S
> TD91a0_00004k.tmp"

. ** Load data 
. use "${data}working/irs_county_gross", 
> replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}worki
> ng/acs_county_gross_18plus", gen(merge_
> acs)
(variable fips was float, now double to
       accommodate using data's values)

    Result                      Number of
>  obs
    -------------------------------------
> ----
    Not matched                        20
> ,278
        from master                    18
> ,963  (merge_acs==1)
        from using                      1
> ,315  (merge_acs==2)

    Matched                             3
> ,017  (merge_acs==3)
    -------------------------------------
> ----

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004l.tmp"

. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,278
        from master                    18,963  (merge_acs==1)
        from using                      1,315  (merge_acs==2)

    Matched                             3,017  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
end of do-file

. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004m.tmp"

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. tab state_name if merge_acs == 2 & year == 2022
no observations

. tab state_name if merge_acs == 1 & year == 2022

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         62        2.30        2.30
              Alaska |         29        1.07        3.37
             Arizona |         11        0.41        3.78
            Arkansas |         72        2.67        6.45
          California |         24        0.89        7.34
            Colorado |         62        2.30        9.64
             Florida |         34        1.26       10.90
             Georgia |        137        5.08       15.97
              Hawaii |          3        0.11       16.09
               Idaho |         43        1.59       17.68
            Illinois |         89        3.30       20.98
             Indiana |         76        2.82       23.80
                Iowa |         94        3.48       27.28
              Kansas |        102        3.78       31.06
            Kentucky |        113        4.19       35.25
           Louisiana |         57        2.11       37.36
               Maine |         14        0.52       37.88
            Maryland |         13        0.48       38.36
       Massachusetts |          5        0.19       38.55
            Michigan |         67        2.48       41.03
           Minnesota |         79        2.93       43.96
         Mississippi |         79        2.93       46.89
            Missouri |        108        4.00       50.89
             Montana |         55        2.04       52.93
            Nebraska |         90        3.34       56.26
              Nevada |         15        0.56       56.82
       New Hampshire |         10        0.37       57.19
          New Jersey |          4        0.15       57.34
          New Mexico |         31        1.15       58.49
            New York |         41        1.52       60.01
      North Carolina |         82        3.04       63.05
        North Dakota |         52        1.93       64.97
                Ohio |         67        2.48       67.46
            Oklahoma |         73        2.71       70.16
              Oregon |         28        1.04       71.20
        Pennsylvania |         47        1.74       72.94
        Rhode Island |          2        0.07       73.02
      South Carolina |         38        1.41       74.43
        South Dakota |         66        2.45       76.87
           Tennessee |         84        3.11       79.99
               Texas |        216        8.01       87.99
                Utah |         24        0.89       88.88
             Vermont |         13        0.48       89.36
            Virginia |        123        4.56       93.92
          Washington |         29        1.07       95.00
       West Virginia |         54        2.00       97.00
           Wisconsin |         59        2.19       99.18
             Wyoming |         22        0.82      100.00
---------------------+-----------------------------------
               Total |      2,698      100.00

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004n.tmp"

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         0      3,140 |     3,140 
      2020 |         2      3,140 |     3,142 
      2021 |         2      3,141 |     3,143 
      2022 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004o.tmp"

. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,278
        from master                    18,963  (merge_acs==1)
        from using                      1,315  (merge_acs==2)

    Matched                             3,017  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. tab state_name if merge_acs == 2 & year == 2022
no observations

. tab state_name if merge_acs == 1 & year == 2022

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         62        2.30        2.30
              Alaska |         29        1.07        3.37
             Arizona |         11        0.41        3.78
            Arkansas |         72        2.67        6.45
          California |         24        0.89        7.34
            Colorado |         62        2.30        9.64
             Florida |         34        1.26       10.90
             Georgia |        137        5.08       15.97
              Hawaii |          3        0.11       16.09
               Idaho |         43        1.59       17.68
            Illinois |         89        3.30       20.98
             Indiana |         76        2.82       23.80
                Iowa |         94        3.48       27.28
              Kansas |        102        3.78       31.06
            Kentucky |        113        4.19       35.25
           Louisiana |         57        2.11       37.36
               Maine |         14        0.52       37.88
            Maryland |         13        0.48       38.36
       Massachusetts |          5        0.19       38.55
            Michigan |         67        2.48       41.03
           Minnesota |         79        2.93       43.96
         Mississippi |         79        2.93       46.89
            Missouri |        108        4.00       50.89
             Montana |         55        2.04       52.93
            Nebraska |         90        3.34       56.26
              Nevada |         15        0.56       56.82
       New Hampshire |         10        0.37       57.19
          New Jersey |          4        0.15       57.34
          New Mexico |         31        1.15       58.49
            New York |         41        1.52       60.01
      North Carolina |         82        3.04       63.05
        North Dakota |         52        1.93       64.97
                Ohio |         67        2.48       67.46
            Oklahoma |         73        2.71       70.16
              Oregon |         28        1.04       71.20
        Pennsylvania |         47        1.74       72.94
        Rhode Island |          2        0.07       73.02
      South Carolina |         38        1.41       74.43
        South Dakota |         66        2.45       76.87
           Tennessee |         84        3.11       79.99
               Texas |        216        8.01       87.99
                Utah |         24        0.89       88.88
             Vermont |         13        0.48       89.36
            Virginia |        123        4.56       93.92
          Washington |         29        1.07       95.00
       West Virginia |         54        2.00       97.00
           Wisconsin |         59        2.19       99.18
             Wyoming |         22        0.82      100.00
---------------------+-----------------------------------
               Total |      2,698      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         0      3,140 |     3,140 
      2020 |         2      3,140 |     3,142 
      2021 |         2      3,141 |     3,143 
      2022 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004p.tmp"

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        52      3,088 |     3,140 
      2021 |        53      3,088 |     3,141 
      2022 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,079 |     3,088 
      2022 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2017 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

.         
. 
end of do-file

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004q.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16
> .log
  log type:  text
 opened on:  19 Dec 2025, 10:17:05

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,278
        from master                    18,963  (merge_acs==1)
        from using                      1,315  (merge_acs==2)

    Matched                             3,017  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. tab state_name if merge_acs == 2 & year == 2022
no observations

. tab state_name if merge_acs == 1 & year == 2022

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         62        2.30        2.30
              Alaska |         29        1.07        3.37
             Arizona |         11        0.41        3.78
            Arkansas |         72        2.67        6.45
          California |         24        0.89        7.34
            Colorado |         62        2.30        9.64
             Florida |         34        1.26       10.90
             Georgia |        137        5.08       15.97
              Hawaii |          3        0.11       16.09
               Idaho |         43        1.59       17.68
            Illinois |         89        3.30       20.98
             Indiana |         76        2.82       23.80
                Iowa |         94        3.48       27.28
              Kansas |        102        3.78       31.06
            Kentucky |        113        4.19       35.25
           Louisiana |         57        2.11       37.36
               Maine |         14        0.52       37.88
            Maryland |         13        0.48       38.36
       Massachusetts |          5        0.19       38.55
            Michigan |         67        2.48       41.03
           Minnesota |         79        2.93       43.96
         Mississippi |         79        2.93       46.89
            Missouri |        108        4.00       50.89
             Montana |         55        2.04       52.93
            Nebraska |         90        3.34       56.26
              Nevada |         15        0.56       56.82
       New Hampshire |         10        0.37       57.19
          New Jersey |          4        0.15       57.34
          New Mexico |         31        1.15       58.49
            New York |         41        1.52       60.01
      North Carolina |         82        3.04       63.05
        North Dakota |         52        1.93       64.97
                Ohio |         67        2.48       67.46
            Oklahoma |         73        2.71       70.16
              Oregon |         28        1.04       71.20
        Pennsylvania |         47        1.74       72.94
        Rhode Island |          2        0.07       73.02
      South Carolina |         38        1.41       74.43
        South Dakota |         66        2.45       76.87
           Tennessee |         84        3.11       79.99
               Texas |        216        8.01       87.99
                Utah |         24        0.89       88.88
             Vermont |         13        0.48       89.36
            Virginia |        123        4.56       93.92
          Washington |         29        1.07       95.00
       West Virginia |         54        2.00       97.00
           Wisconsin |         59        2.19       99.18
             Wyoming |         22        0.82      100.00
---------------------+-----------------------------------
               Total |      2,698      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         0      3,140 |     3,140 
      2020 |         2      3,140 |     3,142 
      2021 |         2      3,141 |     3,143 
      2022 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        52      3,088 |     3,140 
      2021 |        53      3,088 |     3,141 
      2022 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,079 |     3,088 
      2022 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2017 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA,
>  HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG f
> ormat

. clear  

. 
. ** Restore      
. restore 

. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,815 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,815 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,815 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2016 to 2022
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2016 |         0      2,916 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
      2022 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if merge_acs != 3       
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate_`data' n2_rate_`data' agi_rate_`data' {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', proje
> cted)"
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`out'_`c'_`samp'_", .p
> df) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out' fips year Treated                      ///
>                                         if sample == 1,                                         
> ///
>                                         `covar'                                                 
>         ///
>                                         vce(placebo)                                            
> ///
>                                         brep(`reps')                                            
> ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                   
>         ///             
>                                         legend(off) ytitle("`label'")                           
>         ///
>                                         yline(0, lc(red) lp(-))                                 
>                 ///
>                                         xline(2019.5, lc(black) lp(solid))                      
>         ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`out'_`c'_sample_eventstudy.jpg",   
> ///
>                                         as(jpg) name("Graph") quality(100) replace              
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_`data'_0 sdid_n1_rate_`data'_1                     ///
>                                 sdid_n2_rate_`data'_0 sdid_n2_rate_`data'_1                     
> ///
>                                 sdid_agi_rate_`data'_0 sdid_agi_rate_`data'_1 using     ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                               
> ///
>                         fmt(%9.0fc %9.3fc)                                                      
> ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(17,815 real changes made)

Panel is unbalanced.
r(451);

end of do-file

r(451);

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004r.tmp"

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,278
        from master                    18,963  (merge_acs==1)
        from using                      1,315  (merge_acs==2)

    Matched                             3,017  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. tab state_name if merge_acs == 2 & year == 2022
no observations

. tab state_name if merge_acs == 1 & year == 2022

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         62        2.30        2.30
              Alaska |         29        1.07        3.37
             Arizona |         11        0.41        3.78
            Arkansas |         72        2.67        6.45
          California |         24        0.89        7.34
            Colorado |         62        2.30        9.64
             Florida |         34        1.26       10.90
             Georgia |        137        5.08       15.97
              Hawaii |          3        0.11       16.09
               Idaho |         43        1.59       17.68
            Illinois |         89        3.30       20.98
             Indiana |         76        2.82       23.80
                Iowa |         94        3.48       27.28
              Kansas |        102        3.78       31.06
            Kentucky |        113        4.19       35.25
           Louisiana |         57        2.11       37.36
               Maine |         14        0.52       37.88
            Maryland |         13        0.48       38.36
       Massachusetts |          5        0.19       38.55
            Michigan |         67        2.48       41.03
           Minnesota |         79        2.93       43.96
         Mississippi |         79        2.93       46.89
            Missouri |        108        4.00       50.89
             Montana |         55        2.04       52.93
            Nebraska |         90        3.34       56.26
              Nevada |         15        0.56       56.82
       New Hampshire |         10        0.37       57.19
          New Jersey |          4        0.15       57.34
          New Mexico |         31        1.15       58.49
            New York |         41        1.52       60.01
      North Carolina |         82        3.04       63.05
        North Dakota |         52        1.93       64.97
                Ohio |         67        2.48       67.46
            Oklahoma |         73        2.71       70.16
              Oregon |         28        1.04       71.20
        Pennsylvania |         47        1.74       72.94
        Rhode Island |          2        0.07       73.02
      South Carolina |         38        1.41       74.43
        South Dakota |         66        2.45       76.87
           Tennessee |         84        3.11       79.99
               Texas |        216        8.01       87.99
                Utah |         24        0.89       88.88
             Vermont |         13        0.48       89.36
            Virginia |        123        4.56       93.92
          Washington |         29        1.07       95.00
       West Virginia |         54        2.00       97.00
           Wisconsin |         59        2.19       99.18
             Wyoming |         22        0.82      100.00
---------------------+-----------------------------------
               Total |      2,698      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         0      3,140 |     3,140 
      2020 |         2      3,140 |     3,142 
      2021 |         2      3,141 |     3,143 
      2022 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        52      3,088 |     3,140 
      2021 |        53      3,088 |     3,141 
      2022 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,079 |     3,088 
      2022 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2017 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA,
>  HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG f
> ormat

. clear  

. 
. ** Restore      
. restore 

. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,815 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,815 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,815 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2016 to 2022
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2016 |         0      2,916 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
      2022 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
end of do-file

. tab merge_acs

   Matching result from |
                  merge |      Freq.     Percent        Cum.
------------------------+-----------------------------------
        Master only (1) |     17,815       87.28       87.28
            Matched (3) |      2,597       12.72      100.00
------------------------+-----------------------------------
                  Total |     20,412      100.00

. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,547        369 |     2,916 
      2017 |     2,547        369 |     2,916 
      2018 |     2,547        369 |     2,916 
      2019 |     2,547        369 |     2,916 
      2020 |     2,547        369 |     2,916 
      2021 |     2,547        369 |     2,916 
      2022 |     2,533        383 |     2,916 
-----------+----------------------+----------
     Total |    17,815      2,597 |    20,412 

. tab year merge_acs if sample_all

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,547        369 |     2,916 
      2017 |     2,547        369 |     2,916 
      2018 |     2,547        369 |     2,916 
      2019 |     2,547        369 |     2,916 
      2020 |     2,547        369 |     2,916 
      2021 |     2,547        369 |     2,916 
      2022 |     2,533        383 |     2,916 
-----------+----------------------+----------
     Total |    17,815      2,597 |    20,412 

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004s.tmp"

. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,278
        from master                    18,963  (merge_acs==1)
        from using                      1,315  (merge_acs==2)

    Matched                             3,017  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. tab state_name if merge_acs == 2 & year == 2022
no observations

. tab state_name if merge_acs == 1 & year == 2022

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         62        2.30        2.30
              Alaska |         29        1.07        3.37
             Arizona |         11        0.41        3.78
            Arkansas |         72        2.67        6.45
          California |         24        0.89        7.34
            Colorado |         62        2.30        9.64
             Florida |         34        1.26       10.90
             Georgia |        137        5.08       15.97
              Hawaii |          3        0.11       16.09
               Idaho |         43        1.59       17.68
            Illinois |         89        3.30       20.98
             Indiana |         76        2.82       23.80
                Iowa |         94        3.48       27.28
              Kansas |        102        3.78       31.06
            Kentucky |        113        4.19       35.25
           Louisiana |         57        2.11       37.36
               Maine |         14        0.52       37.88
            Maryland |         13        0.48       38.36
       Massachusetts |          5        0.19       38.55
            Michigan |         67        2.48       41.03
           Minnesota |         79        2.93       43.96
         Mississippi |         79        2.93       46.89
            Missouri |        108        4.00       50.89
             Montana |         55        2.04       52.93
            Nebraska |         90        3.34       56.26
              Nevada |         15        0.56       56.82
       New Hampshire |         10        0.37       57.19
          New Jersey |          4        0.15       57.34
          New Mexico |         31        1.15       58.49
            New York |         41        1.52       60.01
      North Carolina |         82        3.04       63.05
        North Dakota |         52        1.93       64.97
                Ohio |         67        2.48       67.46
            Oklahoma |         73        2.71       70.16
              Oregon |         28        1.04       71.20
        Pennsylvania |         47        1.74       72.94
        Rhode Island |          2        0.07       73.02
      South Carolina |         38        1.41       74.43
        South Dakota |         66        2.45       76.87
           Tennessee |         84        3.11       79.99
               Texas |        216        8.01       87.99
                Utah |         24        0.89       88.88
             Vermont |         13        0.48       89.36
            Virginia |        123        4.56       93.92
          Washington |         29        1.07       95.00
       West Virginia |         54        2.00       97.00
           Wisconsin |         59        2.19       99.18
             Wyoming |         22        0.82      100.00
---------------------+-----------------------------------
               Total |      2,698      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         0      3,140 |     3,140 
      2020 |         2      3,140 |     3,142 
      2021 |         2      3,141 |     3,143 
      2022 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        52      3,088 |     3,140 
      2021 |        53      3,088 |     3,141 
      2022 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,079 |     3,088 
      2022 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2017 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

.         
. 
end of do-file

. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,657        422 |     3,079 
      2017 |     2,657        422 |     3,079 
      2018 |     2,657        422 |     3,079 
      2019 |     2,657        422 |     3,079 
      2020 |     2,657        422 |     3,079 
      2021 |     2,657        422 |     3,079 
      2022 |     2,642        437 |     3,079 
-----------+----------------------+----------
     Total |    18,584      2,969 |    21,553 

. bysort fips : gen ct = _N

. tab ct

         ct |      Freq.     Percent        Cum.
------------+-----------------------------------
          7 |     21,553      100.00      100.00
------------+-----------------------------------
      Total |     21,553      100.00

. tab year merge_acs, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,657        422 |     3,079 
      2017 |     2,657        422 |     3,079 
      2018 |     2,657        422 |     3,079 
      2019 |     2,657        422 |     3,079 
      2020 |     2,657        422 |     3,079 
      2021 |     2,657        422 |     3,079 
      2022 |     2,642        437 |     3,079 
-----------+----------------------+----------
     Total |    18,584      2,969 |    21,553 

. gen tmp = merge_acs == 3

. bysort fips: egen ct_acs = total(tmp)

. tab ct_acs

     ct_acs |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |     18,263       84.74       84.74
          1 |        336        1.56       86.29
          6 |        231        1.07       87.37
          7 |      2,723       12.63      100.00
------------+-----------------------------------
      Total |     21,553      100.00

. tab state_fips if ct_acs == 1

 State FIPS |
       code |
    (origin |
     state) |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |         14        4.17        4.17
          4 |          7        2.08        6.25
          8 |          7        2.08        8.33
         12 |         35       10.42       18.75
         13 |         14        4.17       22.92
         17 |          7        2.08       25.00
         19 |          7        2.08       27.08
         21 |         14        4.17       31.25
         25 |         49       14.58       45.83
         27 |         14        4.17       50.00
         29 |         14        4.17       54.17
         30 |          7        2.08       56.25
         36 |          7        2.08       58.33
         39 |         14        4.17       62.50
         40 |          7        2.08       64.58
         41 |          7        2.08       66.67
         45 |         49       14.58       81.25
         47 |         28        8.33       89.58
         50 |          7        2.08       91.67
         51 |          7        2.08       93.75
         53 |          7        2.08       95.83
         54 |          7        2.08       97.92
         56 |          7        2.08      100.00
------------+-----------------------------------
      Total |        336      100.00

. tab state_name  if ct_acs == 1

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         14        4.17        4.17
                 Arizona |          7        2.08        6.25
                Colorado |          7        2.08        8.33
                 Florida |         35       10.42       18.75
                 Georgia |         14        4.17       22.92
                Illinois |          7        2.08       25.00
                    Iowa |          7        2.08       27.08
                Kentucky |         14        4.17       31.25
           Massachusetts |         49       14.58       45.83
               Minnesota |         14        4.17       50.00
                Missouri |         14        4.17       54.17
                 Montana |          7        2.08       56.25
                New York |          7        2.08       58.33
                    Ohio |         14        4.17       62.50
                Oklahoma |          7        2.08       64.58
                  Oregon |          7        2.08       66.67
          South Carolina |         49       14.58       81.25
               Tennessee |         28        8.33       89.58
                 Vermont |          7        2.08       91.67
                Virginia |          7        2.08       93.75
              Washington |          7        2.08       95.83
           West Virginia |          7        2.08       97.92
                 Wyoming |          7        2.08      100.00
-------------------------+-----------------------------------
                   Total |        336      100.00

. tab state_name if ct_acs == 6

              State name |      Freq.     Percent        Cum.
-------------------------+-----------------------------------
                 Alabama |         28       12.12       12.12
                 Arizona |         14        6.06       18.18
                Arkansas |          7        3.03       21.21
                Illinois |         42       18.18       39.39
               Louisiana |          7        3.03       42.42
                   Maine |          7        3.03       45.45
                Maryland |          7        3.03       48.48
               Minnesota |         14        6.06       54.55
                Missouri |         14        6.06       60.61
              New Mexico |          7        3.03       63.64
                New York |          7        3.03       66.67
          North Carolina |         14        6.06       72.73
                    Ohio |         14        6.06       78.79
                  Oregon |          7        3.03       81.82
          South Carolina |         21        9.09       90.91
               Tennessee |         14        6.06       96.97
                Virginia |          7        3.03      100.00
-------------------------+-----------------------------------
                   Total |        231      100.00

. do "C:\Users\ji252\AppData\Local\Temp\STD91a0_00004t.tmp"

. /*******************************************************************************
> File Name:              02_sdid_analysis.do
> Creator:                John Iselin
> Date Update:    November 26, 2025
> 
> Called by: 00_multnomah.do
> 
> Purpose: Preform synthetic difference-in-difference estiamtion. 
> 
> Authors: John Iselin 
> 
> For more information, contact john.iselin@yale.edu
> 
> *******************************************************************************/
. 
. 
. ** Start log file 
. capture log close log_02

. log using "${logs}02_log_sdid_${date}", replace text name(log_02)
--------------------------------------------------------------------------------------------------
      name:  log_02
       log:  C:/Users/ji252/Documents/GitHub/multnomah-county-tax/code/logs/02_log_sdid_2025-12-16
> .log
  log type:  text
 opened on:  19 Dec 2025, 10:22:49

. 
. ** Parameters 
. local reps = 100

. 
. ** Load data 
. use "${data}working/irs_county_gross", replace 

. 
. ** Merge with ACS Data 
. merge 1:1 year fips using "${data}working/acs_county_gross_18plus", gen(merge_acs)
(variable fips was float, now double to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                        20,278
        from master                    18,963  (merge_acs==1)
        from using                      1,315  (merge_acs==2)

    Matched                             3,017  (merge_acs==3)
    -----------------------------------------

. 
. ** Drop "other counties"
. drop if county_fips == 0
(434 observations deleted)

. drop if year >= 2023
(444 observations deleted)

. drop if merge_acs == 2
(437 observations deleted)

. 
. ** Tabulation of merge 
. tab year merge_acs

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |     2,710        430 |     3,140 
      2017 |     2,710        430 |     3,140 
      2018 |     2,710        430 |     3,140 
      2019 |     2,710        430 |     3,140 
      2020 |     2,712        430 |     3,142 
      2021 |     2,713        430 |     3,143 
      2022 |     2,698        437 |     3,135 
-----------+----------------------+----------
     Total |    18,963      3,017 |    21,980 

. tab state_name if merge_acs == 2 & year == 2022
no observations

. tab state_name if merge_acs == 1 & year == 2022

          State name |      Freq.     Percent        Cum.
---------------------+-----------------------------------
             Alabama |         62        2.30        2.30
              Alaska |         29        1.07        3.37
             Arizona |         11        0.41        3.78
            Arkansas |         72        2.67        6.45
          California |         24        0.89        7.34
            Colorado |         62        2.30        9.64
             Florida |         34        1.26       10.90
             Georgia |        137        5.08       15.97
              Hawaii |          3        0.11       16.09
               Idaho |         43        1.59       17.68
            Illinois |         89        3.30       20.98
             Indiana |         76        2.82       23.80
                Iowa |         94        3.48       27.28
              Kansas |        102        3.78       31.06
            Kentucky |        113        4.19       35.25
           Louisiana |         57        2.11       37.36
               Maine |         14        0.52       37.88
            Maryland |         13        0.48       38.36
       Massachusetts |          5        0.19       38.55
            Michigan |         67        2.48       41.03
           Minnesota |         79        2.93       43.96
         Mississippi |         79        2.93       46.89
            Missouri |        108        4.00       50.89
             Montana |         55        2.04       52.93
            Nebraska |         90        3.34       56.26
              Nevada |         15        0.56       56.82
       New Hampshire |         10        0.37       57.19
          New Jersey |          4        0.15       57.34
          New Mexico |         31        1.15       58.49
            New York |         41        1.52       60.01
      North Carolina |         82        3.04       63.05
        North Dakota |         52        1.93       64.97
                Ohio |         67        2.48       67.46
            Oklahoma |         73        2.71       70.16
              Oregon |         28        1.04       71.20
        Pennsylvania |         47        1.74       72.94
        Rhode Island |          2        0.07       73.02
      South Carolina |         38        1.41       74.43
        South Dakota |         66        2.45       76.87
           Tennessee |         84        3.11       79.99
               Texas |        216        8.01       87.99
                Utah |         24        0.89       88.88
             Vermont |         13        0.48       89.36
            Virginia |        123        4.56       93.92
          Washington |         29        1.07       95.00
       West Virginia |         54        2.00       97.00
           Wisconsin |         59        2.19       99.18
             Wyoming |         22        0.82      100.00
---------------------+-----------------------------------
               Total |      2,698      100.00

. 
. ** Merge with Demographic data 
. merge m:1 fips using "${data}working/demographics_2020",        ///
>         gen(demo_merge) keep(master match)

    Result                      Number of obs
    -----------------------------------------
    Not matched                             6
        from master                         6  (demo_merge==1)
        from using                          0  (demo_merge==2)

    Matched                            21,974  (demo_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name demo_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         6        196 |       202 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         0         30 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |         0        931 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |         6     21,974 |    21,980 

. tab year demo_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         0      3,140 |     3,140 
      2017 |         0      3,140 |     3,140 
      2018 |         0      3,140 |     3,140 
      2019 |         0      3,140 |     3,140 
      2020 |         2      3,140 |     3,142 
      2021 |         2      3,141 |     3,143 
      2022 |         2      3,133 |     3,135 
-----------+----------------------+----------
     Total |         6     21,974 |    21,980 

. 
. ** Keep if matched 
. keep if demo_merge == 3
(6 observations deleted)

. drop demo_merge

. 
. ** Rename 
. rename population pop_census

.         
. ** Merge with Demographic data 
. merge m:1 year fips using "${data}working/bea_economics",       ///
>         gen(econ_merge) keep(master match) 

    Result                      Number of obs
    -----------------------------------------
    Not matched                           366
        from master                       366  (econ_merge==1)
        from using                          0  (econ_merge==2)

    Matched                            21,608  (econ_merge==3)
    -----------------------------------------

.         
. ** Show match 
. tab state_name econ_merge, m

                     | Matching result from
                     |         merge
          State name | Master on  Matched ( |     Total
---------------------+----------------------+----------
             Alabama |         0        469 |       469 
              Alaska |         0        196 |       196 
             Arizona |         0        105 |       105 
            Arkansas |         0        525 |       525 
          California |         0        406 |       406 
            Colorado |         0        448 |       448 
         Connecticut |         0         48 |        48 
            Delaware |         0         21 |        21 
District of Columbia |         0          7 |         7 
             Florida |         0        469 |       469 
             Georgia |         0      1,113 |     1,113 
              Hawaii |         9         21 |        30 
               Idaho |         0        308 |       308 
            Illinois |         0        714 |       714 
             Indiana |         0        644 |       644 
                Iowa |         0        693 |       693 
              Kansas |         0        735 |       735 
            Kentucky |         0        840 |       840 
           Louisiana |         0        448 |       448 
               Maine |         0        112 |       112 
            Maryland |         0        168 |       168 
       Massachusetts |         0         98 |        98 
            Michigan |         0        581 |       581 
           Minnesota |         0        609 |       609 
         Mississippi |         0        574 |       574 
            Missouri |         0        805 |       805 
             Montana |         0        392 |       392 
            Nebraska |         0        651 |       651 
              Nevada |         0        119 |       119 
       New Hampshire |         0         70 |        70 
          New Jersey |         0        147 |       147 
          New Mexico |         0        231 |       231 
            New York |         0        434 |       434 
      North Carolina |         0        700 |       700 
        North Dakota |         0        371 |       371 
                Ohio |         0        616 |       616 
            Oklahoma |         0        539 |       539 
              Oregon |         0        252 |       252 
        Pennsylvania |         0        469 |       469 
        Rhode Island |         0         35 |        35 
      South Carolina |         0        322 |       322 
        South Dakota |         0        462 |       462 
           Tennessee |         0        665 |       665 
               Texas |         0      1,778 |     1,778 
                Utah |         0        203 |       203 
             Vermont |         0         98 |        98 
            Virginia |       357        574 |       931 
          Washington |         0        273 |       273 
       West Virginia |         0        385 |       385 
           Wisconsin |         0        504 |       504 
             Wyoming |         0        161 |       161 
---------------------+----------------------+----------
               Total |       366     21,608 |    21,974 

. tab year econ_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |        52      3,088 |     3,140 
      2017 |        52      3,088 |     3,140 
      2018 |        52      3,088 |     3,140 
      2019 |        52      3,088 |     3,140 
      2020 |        52      3,088 |     3,140 
      2021 |        53      3,088 |     3,141 
      2022 |        53      3,080 |     3,133 
-----------+----------------------+----------
     Total |       366     21,608 |    21,974 

. 
. ** Keep if matched 
. keep if econ_merge == 3
(366 observations deleted)

. drop econ_merge

. 
. ** Merge with COVID-19 Data
. merge m:1 fips using ${data}working/covid_cleaned_wide.dta,     ///
>         gen(covid_merge) keep(master match )
(variable state_name was str20, now str24 to accommodate using data's values)

    Result                      Number of obs
    -----------------------------------------
    Not matched                            63
        from master                        63  (covid_merge==1)
        from using                          0  (covid_merge==2)

    Matched                            21,545  (covid_merge==3)
    -----------------------------------------

. 
. ** Show match 
. tab state_name covid_merge, m

                      | Matching result from
                      |         merge
           State name | Master on  Matched ( |     Total
----------------------+----------------------+----------
              Alabama |         0        469 |       469 
               Alaska |        28        168 |       196 
              Arizona |         0        105 |       105 
             Arkansas |         0        525 |       525 
           California |         0        406 |       406 
             Colorado |         0        448 |       448 
          Connecticut |         0         48 |        48 
             Delaware |         0         21 |        21 
 District of Columbia |         0          7 |         7 
              Florida |         0        469 |       469 
              Georgia |         0      1,113 |     1,113 
               Hawaii |         0         21 |        21 
                Idaho |         0        308 |       308 
             Illinois |         0        714 |       714 
              Indiana |         0        644 |       644 
                 Iowa |         0        693 |       693 
               Kansas |         0        735 |       735 
             Kentucky |         0        840 |       840 
            Louisiana |         0        448 |       448 
                Maine |         0        112 |       112 
             Maryland |         0        168 |       168 
        Massachusetts |         0         98 |        98 
             Michigan |         0        581 |       581 
            Minnesota |         0        609 |       609 
          Mississippi |         0        574 |       574 
             Missouri |         0        805 |       805 
              Montana |         0        392 |       392 
             Nebraska |         0        651 |       651 
               Nevada |         0        119 |       119 
        New Hampshire |         0         70 |        70 
           New Jersey |         0        147 |       147 
           New Mexico |         0        231 |       231 
             New York |        35        399 |       434 
       North Carolina |         0        700 |       700 
         North Dakota |         0        371 |       371 
                 Ohio |         0        616 |       616 
             Oklahoma |         0        539 |       539 
               Oregon |         0        252 |       252 
         Pennsylvania |         0        469 |       469 
         Rhode Island |         0         35 |        35 
       South Carolina |         0        322 |       322 
         South Dakota |         0        462 |       462 
            Tennessee |         0        665 |       665 
                Texas |         0      1,778 |     1,778 
                 Utah |         0        203 |       203 
              Vermont |         0         98 |        98 
             Virginia |         0        574 |       574 
           Washington |         0        273 |       273 
        West Virginia |         0        385 |       385 
            Wisconsin |         0        504 |       504 
              Wyoming |         0        161 |       161 
----------------------+----------------------+----------
                Total |        63     21,545 |    21,608 

. tab year covid_merge, m

  Tax year |
     (year | Matching result from
    before |         merge
     move) | Master on  Matched ( |     Total
-----------+----------------------+----------
      2016 |         9      3,079 |     3,088 
      2017 |         9      3,079 |     3,088 
      2018 |         9      3,079 |     3,088 
      2019 |         9      3,079 |     3,088 
      2020 |         9      3,079 |     3,088 
      2021 |         9      3,079 |     3,088 
      2022 |         9      3,071 |     3,080 
-----------+----------------------+----------
     Total |        63     21,545 |    21,608 

. 
. ** Organize data 
. order year fips state_* county_* 

. sort fips year  

. isid fips year 

. 
. ** Keep only sample with non-missing base populations
. tab county_name year if (missing(n1_in_1 ) | n1_in_1 == 0 ) 

                      |  Tax year
                      |   (year
                      |   before
                      |   move)
          County name |      2017 |     Total
----------------------+-----------+----------
        Loving County |         1 |         1 
----------------------+-----------+----------
                Total |         1 |         1 

. drop if (missing(n1_in_1 ) | n1_in_1 == 0 ) 
(1 observation deleted)

. 
. ** Keep only sample with observations in each year 
. bysort fips: gen ct = _N

. tab county_name state_name  if ct != 7 

                      |      State name
          County name | Connect..      Texas |     Total
----------------------+----------------------+----------
     Fairfield County |         6          0 |         6 
      Hartford County |         6          0 |         6 
    Litchfield County |         6          0 |         6 
        Loving County |         0          6 |         6 
     Middlesex County |         6          0 |         6 
     New Haven County |         6          0 |         6 
    New London County |         6          0 |         6 
       Tolland County |         6          0 |         6 
       Windham County |         6          0 |         6 
----------------------+----------------------+----------
                Total |        48          6 |        54 

. drop if ct != 7 
(54 observations deleted)

. drop ct 

. 
. ** Tag ACS sample 
. gen tmp = merge_acs == 3 

. bysort fips: egen ct_tmp = total(tmp)

. gen sample_acs = ct_tmp == 7

. drop tmp ct_tmp

. 
. tab year sample_acs 

  Tax year |
     (year |
    before |      sample_acs
     move) |         0          1 |     Total
-----------+----------------------+----------
      2016 |     2,690        389 |     3,079 
      2017 |     2,690        389 |     3,079 
      2018 |     2,690        389 |     3,079 
      2019 |     2,690        389 |     3,079 
      2020 |     2,690        389 |     3,079 
      2021 |     2,690        389 |     3,079 
      2022 |     2,690        389 |     3,079 
-----------+----------------------+----------
     Total |    18,830      2,723 |    21,553 

. tab merge_acs sample_acs        

 Matching result from |      sample_acs
                merge |         0          1 |     Total
----------------------+----------------------+----------
      Master only (1) |    18,584          0 |    18,584 
          Matched (3) |       246      2,723 |     2,969 
----------------------+----------------------+----------
                Total |    18,830      2,723 |    21,553 

.         
. ** Define treated state 
. gen multnomah = state_fips == 41 & county_fips == 51

. label var multnomah "Indicator for Multnomah County, Oregon"    

. 
. ** Define treatment indicator 
. gen Treated = multnomah == 1 & year >= 2020

. label var Treated "Treatment indicator for Multnomah County, Oregon"    

. 
. ** Define sample 1: All counties 
. gen sample_all = 1 

. label var sample_all "All counties (excluding AK, CA, HI OR, WA)"

. 
. ** Define sample 2: Counties in top 95 percent 
. summ percent_urban if year == 2020, de 

            Percent of population in urban areas
-------------------------------------------------------------
      Percentiles      Smallest
 1%            0              0
 5%            0              0
10%            0              0       Obs               3,079
25%            0              0       Sum of wgt.       3,079

50%     .3256337                      Mean           .3521437
                        Largest       Std. dev.       .332065
75%     .6326353              1
90%      .847923              1       Variance       .1102672
95%     .9372299              1       Skewness       .3661052
99%     .9972304              1       Kurtosis       1.763629

. local cutoff = r(p95) 

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
               Alaska |         1          0 |         1 
              Arizona |         1          0 |         1 
           California |        15          0 |        15 
             Colorado |         4          0 |         4 
             Delaware |         1          0 |         1 
 District of Columbia |         1          0 |         1 
              Florida |        13          0 |        13 
              Georgia |         8          0 |         8 
               Hawaii |         1          0 |         1 
                Idaho |         1          0 |         1 
             Illinois |         5          0 |         5 
              Indiana |         3          0 |         3 
                 Iowa |         1          0 |         1 
               Kansas |         2          0 |         2 
             Kentucky |         2          0 |         2 
            Louisiana |         3          0 |         3 
             Maryland |         3          0 |         3 
        Massachusetts |         5          0 |         5 
             Michigan |         3          0 |         3 
            Minnesota |         3          0 |         3 
             Missouri |         4          0 |         4 
             Nebraska |         2          0 |         2 
               Nevada |         3          0 |         3 
           New Jersey |        10          0 |        10 
           New Mexico |         2          0 |         2 
             New York |         9          0 |         9 
       North Carolina |         4          0 |         4 
                 Ohio |         6          0 |         6 
             Oklahoma |         1          0 |         1 
               Oregon |         1          1 |         2 
         Pennsylvania |         4          0 |         4 
         Rhode Island |         2          0 |         2 
            Tennessee |         2          0 |         2 
                Texas |        11          0 |        11 
                 Utah |         4          0 |         4 
             Virginia |        10          0 |        10 
           Washington |         1          0 |         1 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |       153          1 |       154 

. gen sample_urban95 = percent_urban >= `cutoff' // All counties 

. label var sample_urban95 "Urban counties (top 5%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban95 if year == 2020

      Urban |
   counties |
   (top 5%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,925       95.00       95.00
          1 |        154        5.00      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define sample 3: Counties in top 98 percent 
. local cutoff = .9864539 //

. tab state_name multnomah if percent_urban >= `cutoff' & year == 2020

                      |     Indicator for
                      |   Multnomah County,
                      |        Oregon
           State name |         0          1 |     Total
----------------------+----------------------+----------
           California |         6          0 |         6 
             Colorado |         2          0 |         2 
 District of Columbia |         1          0 |         1 
              Florida |         4          0 |         4 
              Georgia |         5          0 |         5 
             Illinois |         2          0 |         2 
              Indiana |         1          0 |         1 
            Louisiana |         1          0 |         1 
             Maryland |         1          0 |         1 
        Massachusetts |         1          0 |         1 
             Michigan |         1          0 |         1 
            Minnesota |         1          0 |         1 
             Missouri |         1          0 |         1 
               Nevada |         1          0 |         1 
           New Jersey |         6          0 |         6 
             New York |         7          0 |         7 
       North Carolina |         1          0 |         1 
                 Ohio |         1          0 |         1 
               Oregon |         0          1 |         1 
         Pennsylvania |         2          0 |         2 
         Rhode Island |         1          0 |         1 
                Texas |         3          0 |         3 
                 Utah |         2          0 |         2 
             Virginia |         8          0 |         8 
            Wisconsin |         1          0 |         1 
----------------------+----------------------+----------
                Total |        60          1 |        61 

. gen sample_urban98 = percent_urban >= `cutoff' // All counties 

. label var sample_urban98 "Urban counties (top 1%) (excluding AK, CA, HI OR, WA)"

. tab sample_urban98 if year == 2020

      Urban |
   counties |
   (top 1%) |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      3,018       98.02       98.02
          1 |         61        1.98      100.00
------------+-----------------------------------
      Total |      3,079      100.00

. 
. ** Define Sample of States      
. drop if state_name == "Alaska"
(196 observations deleted)

. drop if state_name == "Hawaii"
(21 observations deleted)

. drop if state_name == "California"
(406 observations deleted)

. drop if state_name == "Washington"
(273 observations deleted)

. drop if state_name == "Oregon" & multnomah == 0
(245 observations deleted)

. 
. ** Define sample 4: Counties in top 95 + covid 
. cluster kmeans cases_cum* deaths_cum* if        ///
>         sample_urban95 == 1 & year == 2020 & covid_merge == 3 , k(5) gen(kmean)
cluster name: _clus_1

. bysort fips: egen kmean_group = mean(kmean)
(19,502 missing values generated)

. 
. ** Pull out kmeans cluster with Multnoma
. gen tmp1 = kmean if sample_urban95 == 1 & year == 2020 & covid_merge == 3 & multnomah == 1 
(20,411 missing values generated)

. egen tmp2 = mean(tmp1)

. gen sample_urban95_covid = sample_urban95 == 1 & kmean_group == tmp2

. drop tmp1 tmp2 

. label var sample_urban95_covid "Urban counties (top 5%) w. Kmean Covid Match  (excluding AK, CA,
>  HI OR, WA)"

. tab sample_urban95_covid if year == 2020

      Urban |
   counties |
(top 5%) w. |
Kmean Covid |
      Match |
 (excluding |
 AK, CA, HI |
    OR, WA) |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |      2,879       98.73       98.73
          1 |         37        1.27      100.00
------------+-----------------------------------
      Total |      2,916      100.00

. 
. ** Show results across clusters 
. preserve 

. 
. ** Keep required variables 
. keep if sample_urban95 == 1 & year == 2020 & covid_merge == 3
(20,282 observations deleted)

. keep kmean cases_cum* deaths_cum* population

. collapse (mean) cases_cum* deaths_cum* [fw = population], by(kmean)

. reshape long cases_cum deaths_cum, i(kmean) j(time)
(j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29)

Data                               Wide   ->   Long
-----------------------------------------------------------------------------
Number of observations                5   ->   145         
Number of variables                  59   ->   4           
j variable (29 values)                    ->   time
xij variables:
  cases_cum1 cases_cum2 ... cases_cum29   ->   cases_cum
deaths_cum1 deaths_cum2 ... deaths_cum29  ->   deaths_cum
-----------------------------------------------------------------------------

. xtset kmean time 

Panel variable: kmean (strongly balanced)
 Time variable: time, 1 to 29
         Delta: 1 unit

. xtline cases_cum 

. graph export "${results}fig_kmeans.jpg", as(jpg) name("Graph") quality(100) replace             
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_kmeans.jpg written in JPEG f
> ormat

. clear  

. 
. ** Restore      
. restore 

. 
. ** Define covariates 
. local covariates "population per_capita_income"

. 
. ** Standardize covariates 
. foreach v of local covariates {
  2.         egen tmp_v = std(`v') 
  3.         replace `v' = tmp_v
  4.         drop tmp_v
  5. } // END COVAR LOOP 
variable population was long now double
(20,412 real changes made)
variable per_capita_income was long now double
(20,412 real changes made)

. 
. ** Define outcome variables (IRS)
. foreach x in "n1" "n2" "agi" {
  2.         gen `x'_rate_irs = 100 * (`x'_net_3 / (`x'_out_1 + `x'_out_2))
  3. } // END OUTCOME TYPE LOOP 

. 
. ** Define outcome variables (ACS)
. gen n1_rate_acs = 100 * (households_net_3 / (households_out_1 + households_out_2))
(17,815 missing values generated)

. gen n2_rate_acs = 100 * (persons_net_3 / (persons_out_1 + persons_out_2))
(17,815 missing values generated)

. gen agi_rate_acs = 100 * (dollars_net_3 / (dollars_out_1 + dollars_out_2))
(17,815 missing values generated)

. 
. ** Label var 
. label var n1_rate_irs   "Net domestic migration rate, returns (%)"

. label var n2_rate_irs   "Net domestic migration rate, exemptions (%)"

. label var agi_rate_irs  "Net domestic migration rate, AGI (%)"

. label var n1_rate_acs   "Net domestic migration rate, HHs (%)"

. label var n2_rate_acs   "Net domestic migration rate, persons (%)"

. label var agi_rate_acs  "Net domestic migration rate, total income (%)"

. 
. ** Declare panel
. xtset fips year 

Panel variable: fips (strongly balanced)
 Time variable: year, 2016 to 2022
         Delta: 1 unit

. 
. ** Tag unique fips 
. egen unique = tag(fips)

. tab year unique

  Tax year |
     (year |
    before |       tag(fips)
     move) |         0          1 |     Total
-----------+----------------------+----------
      2016 |         0      2,916 |     2,916 
      2017 |     2,916          0 |     2,916 
      2018 |     2,916          0 |     2,916 
      2019 |     2,916          0 |     2,916 
      2020 |     2,916          0 |     2,916 
      2021 |     2,916          0 |     2,916 
      2022 |     2,916          0 |     2,916 
-----------+----------------------+----------
     Total |    17,496      2,916 |    20,412 

. 
. ** Loop over datasets 
. foreach data in "acs" "irs"  {
  2. 
.         ** Loop over samples 
.         foreach samp of varlist sample_all sample_urban95 sample_urban95_covid sample_urban98 { 
  3.                         
.                 gen sample = `samp' == 1        
  4.                 if "`data'" == "acs" replace sample = 0 if sample_acs == 0      
  5.                         
.                 ** Clear stored values 
.                 eststo clear            
  6.                         
.                 ** Loop over outcomes 
.                 foreach out of varlist n1_rate_`data' n2_rate_`data' agi_rate_`data' {
  7.                         
.                         ** Store label 
.                         local label : variable label `out'
  8.                                 
.                         ** Loop over inclusion of covariates
.                         forvalues c = 0/1 {
  9.                                 
.                                 if `c' == 0 local covars ""
 10.                                 else if `c' == 1 local covars "covariates(`covariates', proje
> cted)"
 11.                                 dis "`covars'"
 12.                                 
.                                 ** Run SDID
.                                 eststo sdid_`out'_`c': sdid `out' fips year Treated     ///
>                                         if sample == 1,                         ///
>                                         vce(placebo)                            ///
>                                         `covar'                                         ///
>                                         reps(`reps')                            ///
>                                         graph graph_export("${results}fig_`out'_`c'_`samp'_", .p
> df) 
 13.                                         
.                                 ** Estadd counties  
.                                 qui summ `out' if year == 2020 & sample == 1
 14.                                 estadd scalar count = r(N)      
 15.                                         
.                                 ** Estadd mean 
.                                 qui summ `out' if multnomah == 1 & Treated == 0 
 16.                                 estadd scalar mean = r(mean)
 17. 
.                                 ** Run event-study 
.                                 sdid_event `out' fips year Treated                      ///
>                                         if sample == 1,                                         
> ///
>                                         `covar'                                                 
>         ///
>                                         vce(placebo)                                            
> ///
>                                         brep(`reps')                                            
> ///
>                                         placebo(all)
 18.                                 
.                                 ** Create Figure 
.                                 
.                                 ** Move results from matrix to data 
.                                 matrix list e(H)
 19.                                 mat res_att_`ct' = e(H)[1,1..4]
 20.                                 mat res = e(H)[2..8,1..5]
 21.                                 
.                                 ** Move Matrix results to data 
.                                 svmat res
 22.                                 
.                                 ** Generate ID variable
.                                 gen id = 2021 - _n + 1 if !missing(res1)
 23.                                 label var id "Tax year (origin)"
 24.                                 
.                                 ** Sort 
.                                 sort id
 25.                                 
.                                 ** Plot
.                                 twoway  (rcap res3 res4 id, lc(gs10) fc(gs11%50))       ///
>                                                 (scatter res1 id, mc(black)),                   
>         ///             
>                                         legend(off) ytitle("`label'")                           
>         ///
>                                         yline(0, lc(red) lp(-))                                 
>                 ///
>                                         xline(2019.5, lc(black) lp(solid))                      
>         ///
>                                         ylabel(-10(2.5)10, format(%9.1f))
 26. 
.                                 graph export "${results}fig_`out'_`c'_sample_eventstudy.jpg",   
> ///
>                                         as(jpg) name("Graph") quality(100) replace              
 27. 
.                                 ** Clean up 
.                                 drop res1 res2 res3 res4 res5 id 
 28. 
.                                 ** Update Count
.                                 local ct = `ct' + 1 
 29.                                                                 
.                         } // END COVAR LOOP 
 30.                 
.                 } // END OUTCOME LOOP 
 31.                 
.                 
.                 ** Table of results 
.                 esttab  sdid_n1_rate_`data'_0 sdid_n1_rate_`data'_1                     ///
>                                 sdid_n2_rate_`data'_0 sdid_n2_rate_`data'_1                     
> ///
>                                 sdid_agi_rate_`data'_0 sdid_agi_rate_`data'_1 using     ///
>                 "${results}tab_sdid_`data'_`samp'.tex",                 ///
>                 starlevel("*" 0.10 "**" 0.05 "***" 0.01)                ///
>                 b(%-9.3f) se(%-9.3f) replace                                    ///
>                 mgroups("Returns" "Exemptions" "AGI",                   ///
>                         pattern(1 0 1 0 1 0) )                                          ///
>                 mtitle( "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates"                    ///
>                                 "No Covariates" "Covariates")                   ///
>                 stats(count mean,                                                               
> ///
>                         fmt(%9.0fc %9.3fc)                                                      
> ///
>                         labels("Number of Counties" "Pre-treatment mean"))
 32.                 
.                 ** Drop sample var 
.                 drop sample 
 33.                         
.         } // END SAMPLE LOOP 
 34.         
. } // END DATA LOOP 
(18,053 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.19289    1.49005    -0.80    0.423    -4.11332     1.72755
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  337

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.192887   1.315476   -3.77122   1.385446          1 
    Effect_1 |  .5124846   1.816328  -3.047518   4.072488          1 
    Effect_2 | -.8867554   1.918061  -4.646156   2.872645          1 
    Effect_3 | -3.204389   1.991957  -7.108625   .6998464          1 
   Placebo_1 |  .0287314   .4167861  -.7881695   .8456322          1 
   Placebo_2 |  -.022701   .5339654  -1.069273   1.023871          1 
   Placebo_3 |    .02122   .4861061  -.9315479    .973988          1 
   Placebo_4 | -.0253545   .3256162  -.6635623   .6128532          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.1928867   1.3154761  -3.7712198   1.3854464           1
 Effect_1   .51248457   1.8163281  -3.0475184   4.0724876           1
 Effect_2  -.88675541   1.9180613  -4.6461556   2.8726448           1
 Effect_3  -3.2043893    1.991957  -7.1086251   .69984645           1
Placebo_1   .02873137   .41678614  -.78816946    .8456322           1
Placebo_2  -.02270098   .53396539  -1.0692731   1.0238712           1
Placebo_3   .02122004   .48610608  -.93154788   .97398797           1
Placebo_4  -.02535451    .3256162  -.66356226   .61285324           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.19289    1.49426    -0.80    0.425    -4.12159     1.73582
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  337

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.192887   1.309951  -3.760392   1.374618          1 
    Effect_1 |  .5124846   2.234267   -3.86668   4.891649          1 
    Effect_2 | -.8867554   1.852237   -4.51714   2.743629          1 
    Effect_3 | -3.204389   1.700344  -6.537063   .1282844          1 
   Placebo_1 |  .0287314   .1437093  -.2529389   .3104016          1 
   Placebo_2 |  -.022701   .1998575  -.4144216   .3690196          1 
   Placebo_3 |    .02122   .2567235   -.481958   .5243981          1 
   Placebo_4 | -.0253545     .18829   -.394403    .343694          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.1928867   1.3099515  -3.7603916   1.3746182           1
 Effect_1   .51248457   2.2342675  -3.8666796   4.8916488           1
 Effect_2  -.88675541   1.8522372  -4.5171403   2.7436295           1
 Effect_3  -3.2043893   1.7003437   -6.537063   .12828441           1
Placebo_1   .02873137   .14370932  -.25293889   .31040163           1
Placebo_2  -.02270098   .19985746   -.4144216   .36901964           1
Placebo_3   .02122004   .25672349    -.481958   .52439808           1
Placebo_4  -.02535451   .18829003  -.39440298   .34369396           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.01403    1.35455    -1.49    0.137    -4.66891     0.64085
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  337

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  -2.01403   1.380348  -4.719512   .6914514          1 
    Effect_1 |  -.892453   2.140379  -5.087595   3.302689          1 
    Effect_2 | -1.586061   1.798877   -5.11186   1.939737          1 
    Effect_3 | -3.563576   2.114698  -7.708384   .5812322          1 
   Placebo_1 |  .0245928   .2509401  -.4672498   .5164353          1 
   Placebo_2 | -.0090829   .3288298  -.6535893   .6354235          1 
   Placebo_3 |  .0276807   .2825266  -.5260713   .5814328          1 
   Placebo_4 |  -.040506   .3248015   -.677117    .596105          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.0140301   1.3803477  -4.7195115   .69145136           1
 Effect_1  -.89245304   2.1403788  -5.0875955   3.3026894           1
 Effect_2  -1.5860611   1.7988767  -5.1118595   1.9397373           1
 Effect_3  -3.5635761   2.1146981  -7.7083844   .58123217           1
Placebo_1   .02459276   .25094009  -.46724982   .51643535           1
Placebo_2   -.0090829   .32882982  -.65358934   .63542354           1
Placebo_3   .02768072   .28252655  -.52607133   .58143276           1
Placebo_4  -.04050598   .32480152  -.67711696     .596105           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.01403    1.17906    -1.71    0.088    -4.32495     0.29689
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  337

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT |  -2.01403   1.358127   -4.67596   .6478995          1 
    Effect_1 |  -.892453   1.703892   -4.23208   2.447174          1 
    Effect_2 | -1.586061   1.779681  -5.074235   1.902113          1 
    Effect_3 | -3.563576   2.401316  -8.270155   1.143003          1 
   Placebo_1 |  .0245928   .2076241  -.3823504   .4315359          1 
   Placebo_2 | -.0090829   .2233103   -.446771   .4286052          1 
   Placebo_3 |  .0276807   .3088585  -.5776819   .6330434          1 
   Placebo_4 |  -.040506   .2501215  -.5307441   .4497321          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.0140301   1.3581273  -4.6759596   .64789946           1
 Effect_1  -.89245304   1.7038915  -4.2320804   2.4471743           1
 Effect_2  -1.5860611   1.7796807  -5.0742353   1.9021131           1
 Effect_3  -3.5635761   2.4013157   -8.270155   1.1430028           1
Placebo_1   .02459276   .20762407  -.38235041   .43153593           1
Placebo_2   -.0090829   .22331026  -.44677101   .42860521           1
Placebo_3   .02768072    .3088585  -.57768194   .63304337           1
Placebo_4  -.04050598   .25012149   -.5307441   .44973214           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.44821    1.62369    -1.51    0.132    -5.63058     0.73416
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  337

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.448207   1.277913  -4.952916   .0565023          1 
    Effect_1 | -.4933153   2.103649  -4.616468   3.629837          1 
    Effect_2 | -1.275496   1.990563     -5.177   2.626008          1 
    Effect_3 |  -5.57581    1.83682  -9.175977  -1.975642          1 
   Placebo_1 |  .0387621   .3417114  -.6309921   .7085164          1 
   Placebo_2 | -.0683879   .6843722  -1.409757   1.272982          1 
   Placebo_3 | -.0120022   .3143137   -.628057   .6040527          1 
   Placebo_4 |   .015419   .5654459  -1.092855   1.123693          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.4482071   1.2779129  -4.9529164   .05650228           1
 Effect_1  -.49331535   2.1036494  -4.6164681   3.6298374           1
 Effect_2  -1.2754961    1.990563  -5.1769996   2.6260075           1
 Effect_3  -5.5758098   1.8368201  -9.1759772  -1.9756424           1
Placebo_1   .03876215   .34171137  -.63099214   .70851644           1
Placebo_2  -.06838794   .68437218  -1.4097574   1.2729815           1
Placebo_3  -.01200217   .31431371  -.62805704   .60405269           1
Placebo_4     .015419    .5654459   -1.092855    1.123693           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.44821    2.31902    -1.06    0.291    -6.99341     2.09700
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_all_t
    > rends2020.pdf saved as PDF format

added scalar:
              e(count) =  337

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.448207   1.708349  -5.796571    .900157          1 
    Effect_1 | -.4933153   2.937085  -6.250002   5.263371          1 
    Effect_2 | -1.275496   2.046216  -5.286079   2.735087          1 
    Effect_3 |  -5.57581   2.186906  -9.862146  -1.289473          1 
   Placebo_1 |  .0387621   .2815387  -.5130536   .5905779          1 
   Placebo_2 | -.0683879   .2935201  -.6436874   .5069115          1 
   Placebo_3 | -.0120022   .2856626  -.5719009   .5478966          1 
   Placebo_4 |   .015419   .2928378  -.5585431   .5893812          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.4482071    1.708349  -5.7965712   .90015703           1
 Effect_1  -.49331535   2.9370849  -6.2500018   5.2633711           1
 Effect_2  -1.2754961   2.0462157  -5.2860788   2.7350866           1
 Effect_3  -5.5758098   2.1869064  -9.8621463  -1.2894733           1
Placebo_1   .03876215   .28153866  -.51305363   .59057793           1
Placebo_2  -.06838794   .29352013  -.64368739   .50691151           1
Placebo_3  -.01200217   .28566262   -.5719009   .54789655           1
Placebo_4     .015419   .29283783  -.55854314   .58938115           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_events
> tudy.jpg written in JPEG format
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sampl
> e_all.tex)
(196 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.10966    1.12844    -0.98    0.325    -3.32136     1.10203
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_urban9
    > 5_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.109663   1.074197   -3.21509   .9957643          1 
    Effect_1 |  .1205593   1.568674  -2.954042   3.195161          1 
    Effect_2 | -.5731527    1.45198  -3.419034   2.272729          1 
    Effect_3 | -2.876395   1.674636  -6.158682   .4058927          1 
   Placebo_1 |  .1937537   .3459121   -.484234   .8717414          1 
   Placebo_2 | -.0963831   .3405142  -.7637908   .5710247          1 
   Placebo_3 |  .1387681    .195827  -.2450528   .5225891          1 
   Placebo_4 | -.1219794   .2327771  -.5782225   .3342637          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.1096627   1.0741975  -3.2150897   .99576433           1
 Effect_1   .12055926   1.5686743  -2.9540423   3.1951608           1
 Effect_2  -.57315266   1.4519803   -3.419034   2.2727287           1
 Effect_3  -2.8763947   1.6746364  -6.1586821   .40589268           1
Placebo_1   .19375371   .34591208  -.48423396   .87174137           1
Placebo_2  -.09638305   .34051417  -.76379083   .57102472           1
Placebo_3   .13876814   .19582703  -.24505285   .52258912           1
Placebo_4  -.12197938   .23277709  -.57822248   .33426371           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.10966    1.33605    -0.83    0.406    -3.72828     1.50895
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_urban9
    > 5_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.109663   1.252304  -3.564178   1.344852          1 
    Effect_1 |  .1205593   1.805116  -3.417469   3.658587          1 
    Effect_2 | -.5731527   1.516531  -3.545553   2.399247          1 
    Effect_3 | -2.876395   1.647837  -6.106155   .3533652          1 
   Placebo_1 |  .1937537   .4616248  -.7110309   1.098538          1 
   Placebo_2 | -.0963831   .3719398  -.8253851    .632619          1 
   Placebo_3 |  .1387681   .2464968  -.3443657    .621902          1 
   Placebo_4 | -.1219794   .2331406   -.578935   .3349762          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.1096627   1.2523036  -3.5641777   1.3448523           1
 Effect_1   .12055926   1.8051163  -3.4174687   3.6585872           1
 Effect_2  -.57315266   1.5165306  -3.5455526   2.3992472           1
 Effect_3  -2.8763947   1.6478367  -6.1061546   .35336519           1
Placebo_1   .19375371   .46162478  -.71103087   1.0985383           1
Placebo_2  -.09638305   .37193982   -.8253851     .632619           1
Placebo_3   .13876814   .24649684  -.34436568   .62190195           1
Placebo_4  -.12197938   .23314061  -.57893498   .33497622           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.05758    1.19559    -1.72    0.085    -4.40090     0.28574
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_urban9
    > 5_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.057583   .9077365  -3.836747  -.2784198          1 
    Effect_1 | -1.430925   1.309465  -3.997476   1.135626          1 
    Effect_2 | -1.466611   1.240745  -3.898472   .9652495          1 
    Effect_3 | -3.275214   1.351385  -5.923928  -.6265002          1 
   Placebo_1 |   .074305   .4347673  -.7778388   .9264488          1 
   Placebo_2 | -.0380536   .3848964  -.7924505   .7163433          1 
   Placebo_3 |  .1251348   .2992299  -.4613558   .7116255          1 
   Placebo_4 | -.2045464   .3045046  -.8013755   .3922826          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.0575835   .90773654  -3.8367471  -.27841985           1
 Effect_1   -1.430925   1.3094646  -3.9974757   1.1356257           1
 Effect_2  -1.4666111   1.2407452  -3.8984717   .96524955           1
 Effect_3  -3.2752143   1.3513848  -5.9239284  -.62650018           1
Placebo_1   .07430499   .43476726  -.77783883   .92644881           1
Placebo_2  -.03805357   .38489637  -.79245046   .71634331           1
Placebo_3   .12513483   .29922992  -.46135581   .71162547           1
Placebo_4  -.20454644    .3045046  -.80137546   .39228258           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.05758    1.09817    -1.87    0.061    -4.20996     0.09479
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_urban9
    > 5_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.057583   1.099323  -4.212257     .09709          1 
    Effect_1 | -1.430925   1.441955  -4.257158   1.395308          1 
    Effect_2 | -1.466611   1.389788  -4.190595   1.257373          1 
    Effect_3 | -3.275214   1.362061  -5.944854  -.6055749          1 
   Placebo_1 |   .074305   .2441341  -.4041978   .5528078          1 
   Placebo_2 | -.0380536   .3175076  -.6603684   .5842613          1 
   Placebo_3 |  .1251348   .2701313  -.4043225   .6545922          1 
   Placebo_4 | -.2045464   .3110451  -.8141948   .4051019          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.0575835   1.0993232  -4.2122569   .09708996           1
 Effect_1   -1.430925   1.4419555  -4.2571578   1.3953077           1
 Effect_2  -1.4666111   1.3897878  -4.1905951   1.2573729           1
 Effect_3  -3.2752143   1.3620609  -5.9448537  -.60557488           1
Placebo_1   .07430499   .24413407  -.40419779   .55280776           1
Placebo_2  -.03805357   .31750759  -.66036845    .5842613           1
Placebo_3   .12513483    .2701313  -.40432252   .65459218           1
Placebo_4  -.20454644   .31104508   -.8141948   .40510192           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.35879    1.38717    -1.70    0.089    -5.07759     0.36001
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_urban
    > 95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.358787   1.217754  -4.745584   .0280106          1 
    Effect_1 | -.8738965   1.841835  -4.483894   2.736101          1 
    Effect_2 |  -.913085    1.62899  -4.105906   2.279736          1 
    Effect_3 | -5.289379   1.746466  -8.712453  -1.866305          1 
   Placebo_1 |  .1189997   .2650976  -.4005916   .6385911          1 
   Placebo_2 |  -.205184   .3439805  -.8793858   .4690178          1 
   Placebo_3 | -.0150767   .3644261   -.729352   .6991985          1 
   Placebo_4 | -.0359091   .2736601  -.5722828   .5004647          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.3587867   1.2177537   -4.745584   .02801058           1
 Effect_1   -.8738965   1.8418354  -4.4838938   2.7361008           1
 Effect_2  -.91308496   1.6289901  -4.1059055   2.2797356           1
 Effect_3  -5.2893786   1.7464664  -8.7124527  -1.8663046           1
Placebo_1   .11899974   .26509761  -.40059159   .63859106           1
Placebo_2  -.20518398   .34398051  -.87938577   .46901781           1
Placebo_3  -.01507674   .36442614  -.72935198   .69919849           1
Placebo_4  -.03590908   .27366008  -.57228283   .50046468           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.35879    1.42312    -1.66    0.097    -5.14805     0.43047
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_urban
    > 95_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  107

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.358787   1.322068   -4.95004   .2324663          1 
    Effect_1 | -.8738965   1.776109   -4.35507   2.607277          1 
    Effect_2 |  -.913085   1.534237   -3.92019    2.09402          1 
    Effect_3 | -5.289379   1.938438  -9.088718   -1.49004          1 
   Placebo_1 |  .1189997   .3173017  -.5029115    .740911          1 
   Placebo_2 |  -.205184    .391416  -.9723593   .5619913          1 
   Placebo_3 | -.0150767   .4024958  -.8039686   .7738151          1 
   Placebo_4 | -.0359091    .376182  -.7732258   .7014076          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.3587867   1.3220678  -4.9500397   .23246629           1
 Effect_1   -.8738965   1.7761091  -4.3550702   2.6072772           1
 Effect_2  -.91308496   1.5342371  -3.9201898   2.0940198           1
 Effect_3  -5.2893786   1.9384382  -9.0887175  -1.4900397           1
Placebo_1   .11899974   .31730167  -.50291153     .740911           1
Placebo_2  -.20518398   .39141598   -.9723593   .56199134           1
Placebo_3  -.01507674   .40249583  -.80396857   .77381509           1
Placebo_4  -.03590908   .37618199  -.77322578   .70140762           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_events
> tudy.jpg written in JPEG format
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sampl
> e_urban95.tex)
(91 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.63967    2.03404    -0.81    0.420    -5.62633     2.34698
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_urban9
    > 5_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  24

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.639674   1.763286  -5.095715   1.816367          1 
    Effect_1 |  .0420994   2.675017  -5.200934   5.285133          1 
    Effect_2 |  -1.07892   2.166293  -5.324854   3.167014          1 
    Effect_3 | -3.882201   2.851857   -9.47184   1.707438          1 
   Placebo_1 |  .2852485   .9909002  -1.656916   2.227413          1 
   Placebo_2 | -.5476622   .9807177  -2.469869   1.374544          1 
   Placebo_3 |  .5143623   .6148692  -.6907813   1.719506          1 
   Placebo_4 | -.7653938   .6499405  -2.039277   .5084897          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.6396739   1.7632864  -5.0957152   1.8163675           1
 Effect_1   .04209943   2.6750172  -5.2009342   5.2851331           1
 Effect_2  -1.0789201   2.1662929  -5.3248541   3.1670139           1
 Effect_3  -3.8822009   2.8518568  -9.4718403   1.7074384           1
Placebo_1   .28524852   .99090022  -1.6569159    2.227413           1
Placebo_2   -.5476622   .98071768  -2.4698689   1.3745444           1
Placebo_3   .51436231   .61486918  -.69078128   1.7195059           1
Placebo_4  -.76539376   .64994053  -2.0392772   .50848968           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.63967    1.89111    -0.87    0.386    -5.34618     2.06683
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_urban9
    > 5_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  24

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.639674   1.669096  -4.911102   1.631755          1 
    Effect_1 |  .0420994    2.75021  -5.348312   5.432511          1 
    Effect_2 |  -1.07892   1.916532  -4.835323   2.677482          1 
    Effect_3 | -3.882201   2.600678  -8.979529   1.215127          1 
   Placebo_1 |  .2852485   .9254236  -1.528582   2.099079          1 
   Placebo_2 | -.5476622   .9005509  -2.312742   1.217418          1 
   Placebo_3 |  .5143623   .4836636  -.4336184   1.462343          1 
   Placebo_4 | -.7653938   .7346365  -2.205281   .6744938          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.6396739   1.6690962  -4.9111024   1.6317546           1
 Effect_1   .04209943     2.75021  -5.3483122    5.432511           1
 Effect_2  -1.0789201   1.9165319  -4.8353226   2.6774823           1
 Effect_3  -3.8822009   2.6006776  -8.9795289   1.2151271           1
Placebo_1   .28524852   .92542356  -1.5285817   2.0990787           1
Placebo_2   -.5476622   .90055089  -2.3127419   1.2174175           1
Placebo_3   .51436231   .48366363   -.4336184    1.462343           1
Placebo_4  -.76539376   .73463649  -2.2052813   .67449376           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.61452    1.97287    -1.33    0.185    -6.48128     1.25223
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_urban9
    > 5_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  24

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.614524   1.455868  -5.468025   .2389769          1 
    Effect_1 | -1.710573   1.889243  -5.413488   1.992342          1 
    Effect_2 | -2.125057    1.86638  -5.783163   1.533048          1 
    Effect_3 | -4.007942    2.22953   -8.37782   .3619365          1 
   Placebo_1 | -.0528947   .7625629  -1.547518   1.441729          1 
   Placebo_2 | -.5063483   .9956441  -2.457811   1.445114          1 
   Placebo_3 |  .2959235   .4868073  -.6582188   1.250066          1 
   Placebo_4 | -.9099476   .8442841  -2.564744   .7448493          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.6145241   1.4558678   -5.468025   .23897687           1
 Effect_1  -1.7105729   1.8892425  -5.4134882   1.9923425           1
 Effect_2  -2.1250575   1.8663801  -5.7831626   1.5330476           1
 Effect_3  -4.0079419   2.2295298  -8.3778203   .36193647           1
Placebo_1  -.05289467   .76256292   -1.547518   1.4417287           1
Placebo_2  -.50634825   .99564415  -2.4578108   1.4451143           1
Placebo_3   .29592354   .48680731  -.65821878   1.2500659           1
Placebo_4  -.90994758   .84428412  -2.5647445    .7448493           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.61452    1.56634    -1.67    0.095    -5.68450     0.45545
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_urban9
    > 5_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  24

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.614524   1.347094  -5.254828   .0257795          1 
    Effect_1 | -1.710573   2.006838  -5.643975   2.222829          1 
    Effect_2 | -2.125057    1.97179  -5.989766   1.739651          1 
    Effect_3 | -4.007942   2.089846  -8.104041    .088157          1 
   Placebo_1 | -.0528947   .8683567  -1.754874   1.649085          1 
   Placebo_2 | -.5063483   .9339052  -2.336802   1.324106          1 
   Placebo_3 |  .2959235   .5418383  -.7660796   1.357927          1 
   Placebo_4 | -.9099476   1.038127  -2.944677   1.124782          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.6145241   1.3470937  -5.2548277   .02577951           1
 Effect_1  -1.7105729   2.0068379  -5.6439751   2.2228293           1
 Effect_2  -2.1250575   1.9717902  -5.9897663   1.7396514           1
 Effect_3  -4.0079419   2.0898464  -8.1040408   .08815701           1
Placebo_1  -.05289467   .86835673  -1.7548739   1.6490845           1
Placebo_2  -.50634825   .93390519  -2.3368024   1.3241059           1
Placebo_3   .29592354   .54183833  -.76607959   1.3579267           1
Placebo_4  -.90994758   1.0381274  -2.9446772    1.124782           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.78844    1.72776    -1.61    0.107    -6.17479     0.59791
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_urban
    > 95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  24

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.788442   2.082237  -6.869625   1.292742          1 
    Effect_1 | -1.374166   3.159136  -7.566072    4.81774          1 
    Effect_2 | -1.553075   2.282667  -6.027103   2.920953          1 
    Effect_3 | -5.438084   2.485753  -10.31016  -.5660079          1 
   Placebo_1 |  .0303133   .6425305  -1.229046   1.289673          1 
   Placebo_2 | -.6170217   .9095026  -2.399647   1.165603          1 
   Placebo_3 |  .0776746   .7524819   -1.39719   1.552539          1 
   Placebo_4 | -.3383124   .8452703  -1.995042   1.318417          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.7884415   2.0822366  -6.8696252   1.2927422           1
 Effect_1  -1.3741658   3.1591356  -7.5660717     4.81774           1
 Effect_2  -1.5530752   2.2826673   -6.027103   2.9209526           1
 Effect_3  -5.4380835   2.4857529  -10.310159  -.56600792           1
Placebo_1   .03031332   .64253048  -1.2290464   1.2896731           1
Placebo_2  -.61702171   .90950257  -2.3996468   1.1656033           1
Placebo_3   .07767458   .75248193    -1.39719   1.5525392           1
Placebo_4  -.33831239    .8452703  -1.9950422   1.3184174           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -2.78844    2.00443    -1.39    0.164    -6.71706     1.14017
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_urban
    > 95_covid_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  24

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -2.788442   2.053639  -6.813574   1.236691          1 
    Effect_1 | -1.374166   3.198719  -7.643654   4.895323          1 
    Effect_2 | -1.553075   2.411851  -6.280302   3.174152          1 
    Effect_3 | -5.438084   2.586611  -10.50784  -.3683253          1 
   Placebo_1 |  .0303133   .6822935  -1.306982   1.367609          1 
   Placebo_2 | -.6170217   1.112963  -2.798429   1.564385          1 
   Placebo_3 |  .0776746   .7223838  -1.338198   1.493547          1 
   Placebo_4 | -.3383124   1.080944  -2.456963   1.780339          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -2.7884415   2.0536388  -6.8135736   1.2366906           1
 Effect_1  -1.3741658   3.1987187  -7.6436544   4.8953228           1
 Effect_2  -1.5530752   2.4118506  -6.2803024    3.174152           1
 Effect_3  -5.4380835   2.5866113  -10.507842  -.36832531           1
Placebo_1   .03031332   .68229347  -1.3069819   1.3676085           1
Placebo_2  -.61702171   1.1129628  -2.7984289   1.5643854           1
Placebo_3   .07767458   .72238375  -1.3381976   1.4935467           1
Placebo_4  -.33831239   1.0809444  -2.4569634   1.7803387           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_events
> tudy.jpg written in JPEG format
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sampl
> e_urban95_covid.tex)
(63 real changes made)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.07501    1.08946    -0.99    0.324    -3.21031     1.06028
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_urban9
    > 8_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.075013   1.008829  -3.052318   .9022923          1 
    Effect_1 |  .0762716   2.019601  -3.882147    4.03469          1 
    Effect_2 | -.3714576   1.204766  -2.732799   1.989883          1 
    Effect_3 | -2.929853   1.713575   -6.28846   .4287534          1 
   Placebo_1 |  .4491481   .5932438  -.7136097   1.611906          1 
   Placebo_2 | -.1362187   .5643365  -1.242318   .9698808          1 
   Placebo_3 |   .382183   .4234936  -.4478644    1.21223          1 
   Placebo_4 | -.3115747   .4340727  -1.162357   .5392079          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   -1.075013   1.0088292  -3.0523183   .90229226           1
 Effect_1   .07627162   2.0196014  -3.8821471   4.0346903           1
 Effect_2  -.37145757   1.2047658  -2.7327985   1.9898834           1
 Effect_3  -2.9298531   1.7135747  -6.2884596   .42875338           1
Placebo_1   .44914808   .59324378  -.71360973   1.6119059           1
Placebo_2  -.13621866   .56433646  -1.2423181    .9698808           1
Placebo_3   .38218303   .42349359   -.4478644   1.2122305           1
Placebo_4  -.31157467   .43407272  -1.1623572   .53920787           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.07501    1.00504    -1.07    0.285    -3.04487     0.89484
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_urban9
    > 8_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .72324176
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.075013   1.066915  -3.166167   1.016141          1 
    Effect_1 |  .0762716   2.224823  -4.284381   4.436925          1 
    Effect_2 | -.3714576   1.457256  -3.227679   2.484763          1 
    Effect_3 | -2.929853   1.895203  -6.644451   .7847445          1 
   Placebo_1 |  .4491481   .5016331  -.5340528   1.432349          1 
   Placebo_2 | -.1362187    .545833  -1.206051   .9336141          1 
   Placebo_3 |   .382183   .4696692  -.5383686   1.302735          1 
   Placebo_4 | -.3115747   .3926935  -1.081254   .4581046          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT   -1.075013   1.0669152  -3.1661667   1.0161407           1
 Effect_1   .07627162   2.2248229  -4.2843813   4.4369246           1
 Effect_2  -.37145757   1.4572556  -3.2276785   2.4847634           1
 Effect_3  -2.9298531   1.8952029  -6.6444507    .7847445           1
Placebo_1   .44914808    .5016331  -.53405279    1.432349           1
Placebo_2  -.13621866   .54583303  -1.2060514   .93361408           1
Placebo_3   .38218303    .4696692  -.53836861   1.3027347           1
Placebo_4  -.31157467   .39269353   -1.081254   .45810464           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.83595    1.40457    -1.31    0.191    -4.58886     0.91696
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_urban9
    > 8_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.835949   1.335752  -4.454024   .7821252          1 
    Effect_1 | -1.304581   1.940664  -5.108282    2.49912          1 
    Effect_2 | -.9905932   1.650477  -4.225528   2.244342          1 
    Effect_3 | -3.212673   1.464509  -6.083111  -.3422351          1 
   Placebo_1 |  .2667897   .6621847  -1.031092   1.564672          1 
   Placebo_2 |  .1326575   .4311388  -.7123747   .9776896          1 
   Placebo_3 |  .3494536   .4706812  -.5730816   1.271989          1 
   Placebo_4 | -.5220927   .6784189  -1.851794   .8076083          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.8359492   1.3357523  -4.4540237   .78212523           1
 Effect_1  -1.3045813   1.9406637  -5.1082822   2.4991197           1
 Effect_2  -.99059317   1.6504769   -4.225528   2.2443416           1
 Effect_3  -3.2126732   1.4645092  -6.0831112  -.34223514           1
Placebo_1   .26678974   .66218473  -1.0310923   1.5646718           1
Placebo_2   .13265746   .43113883  -.71237465   .97768957           1
Placebo_3   .34945361   .47068121  -.57308156   1.2719888           1
Placebo_4  -.52209271    .6784189  -1.8517938   .80760833           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.83595    1.15261    -1.59    0.111    -4.09502     0.42313
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_urban9
    > 8_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .59115162
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.835949     1.0026  -3.801045   .1291468          1 
    Effect_1 | -1.304581   1.639823  -4.518635   1.909473          1 
    Effect_2 | -.9905932   1.495208    -3.9212   1.940014          1 
    Effect_3 | -3.212673   1.243271  -5.649485  -.7758613          1 
   Placebo_1 |  .2667897   .6291858  -.9664145   1.499994          1 
   Placebo_2 |  .1326575   .4121324  -.6751221    .940437          1 
   Placebo_3 |  .3494536   .3510781  -.3386595   1.037567          1 
   Placebo_4 | -.5220927   .3720427  -1.251296    .207111          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.8359492      1.0026  -3.8010452   .12914682           1
 Effect_1  -1.3045813   1.6398234  -4.5186351   1.9094726           1
 Effect_2  -.99059317   1.4952078  -3.9212005   1.9400141           1
 Effect_3  -3.2126732   1.2432714  -5.6494851  -.77586133           1
Placebo_1   .26678974   .62918582  -.96641447   1.4999939           1
Placebo_2   .13265746   .41213244  -.67512213   .94043705           1
Placebo_3   .34945361   .35107813  -.33865953   1.0375668           1
Placebo_4  -.52209271   .37204271  -1.2512964     .207111           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_acs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.83566    1.30541    -1.41    0.160    -4.39422     0.72290
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_urban
    > 98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.835661    1.27846  -4.341444   .6701208          1 
    Effect_1 | -.1301878   1.332699  -2.742278   2.481902          1 
    Effect_2 | -.3412946   2.022684  -4.305755   3.623166          1 
    Effect_3 | -5.035502   2.100522  -9.152525  -.9184787          1 
   Placebo_1 |  .2107732   .5920279  -.9496014   1.371148          1 
   Placebo_2 | -.2938899   .4800761  -1.234839   .6470592          1 
   Placebo_3 |  .0740187    .654717  -1.209227   1.357264          1 
   Placebo_4 |   -.00069   .6063604  -1.189156   1.187776          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.8356615   1.2784604  -4.3414438   .67012084           1
 Effect_1  -.13018776   1.3326991  -2.7422779   2.4819024           1
 Effect_2  -.34129462   2.0226838  -4.3057548   3.6231656           1
 Effect_3   -5.035502   2.1005221  -9.1525253  -.91847868           1
Placebo_1   .21077321   .59202787  -.94960141   1.3711478           1
Placebo_2  -.29388994   .48007611  -1.2348391   .64705923           1
Placebo_3   .07401873   .65471701  -1.2092266   1.3572641           1
Placebo_4  -.00069005   .60636042  -1.1891565   1.1877764           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_0_sample_events
> tudy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
agi_rate_acs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.83566    1.48197    -1.24    0.215    -4.74026     1.06894
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_urban
    > 98_trends2020.pdf saved as PDF format

added scalar:
              e(count) =  46

added scalar:
               e(mean) =  .65277338
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.835661   1.187033  -4.162247   .4909238          1 
    Effect_1 | -.1301878   1.534742  -3.138281   2.877906          1 
    Effect_2 | -.3412946     1.9844  -4.230719   3.548129          1 
    Effect_3 | -5.035502   1.454625  -7.886567  -2.184437          1 
   Placebo_1 |  .2107732   .4300805  -.6321845   1.053731          1 
   Placebo_2 | -.2938899   .4099059  -1.097306   .5095257          1 
   Placebo_3 |  .0740187   .3651602  -.6416953   .7897328          1 
   Placebo_4 |   -.00069   .4836459  -.9486361    .947256          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.8356615   1.1870333  -4.1622467   .49092375           1
 Effect_1  -.13018776   1.5347415  -3.1382811   2.8779056           1
 Effect_2  -.34129462      1.9844  -4.2307186   3.5481294           1
 Effect_3   -5.035502    1.454625  -7.8865671  -2.1844369           1
Placebo_1   .21077321   .43008048  -.63218453    1.053731           1
Placebo_2  -.29388994   .40990594  -1.0973056   .50952571           1
Placebo_3   .07401873   .36516024  -.64169535   .78973281           1
Placebo_4  -.00069005   .48364594   -.9486361     .947256           1
(20,405 missing values generated)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_agi_rate_acs_1_sample_events
> tudy.jpg written in JPEG format
(output written to C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/tab_sdid_acs_sampl
> e_urban98.tex)

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_irs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.71155    0.80613    -2.12    0.034    -3.29154    -0.13155
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_irs_0_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  .32251353
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.711545   .7654723  -3.211871  -.2112194          1 
    Effect_1 | -1.284474   1.440701  -4.108248   1.539299          1 
    Effect_2 | -2.431631   1.297322  -4.974383   .1111214          1 
    Effect_3 |  -1.41853   1.089897  -3.554729   .7176685          1 
   Placebo_1 |  .0021324   .0652191  -.1256971   .1299619          1 
   Placebo_2 |  -.002089   .0346917  -.0700846   .0659067          1 
   Placebo_3 | -.0073683   .0698444  -.1442634   .1295268          1 
   Placebo_4 |  .0108111   .0278234  -.0437227   .0653449          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.7115451   .76547233  -3.2118709  -.21121937           1
 Effect_1  -1.2844743   1.4407009  -4.1082481   1.5392995           1
 Effect_2  -2.4316306   1.2973224  -4.9743826   .11112138           1
 Effect_3  -1.4185304   1.0898974  -3.5547294   .71766847           1
Placebo_1   .00213237   .06521913  -.12569712   .12996186           1
Placebo_2  -.00208895   .03469165  -.07008459   .06590669           1
Placebo_3  -.00736829   .06984442  -.14426335   .12952678           1
Placebo_4   .01081112   .02782335  -.04372266   .06534489           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_irs_0_sample_events
> tudy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_irs_0_sample_eventst
> udy.jpg written in JPEG format
covariates(population per_capita_income, projected)
Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n1_rate_irs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.71155    1.08646    -1.58    0.115    -3.84097     0.41788
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_irs_1_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  .32251353
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
|.................................................|


             |  Estimate         SE      LB CI      UB CI  Switchers 
-------------+------------------------------------------------------
         ATT | -1.711545    .973616  -3.619832   .1967421          1 
    Effect_1 | -1.284474    .945851  -3.138342   .5693936          1 
    Effect_2 | -2.431631   1.532232  -5.434805   .5715434          1 
    Effect_3 |  -1.41853   1.064971  -3.505874   .6688135          1 
   Placebo_1 |  .0021324    .097156  -.1882934   .1925581          1 
   Placebo_2 |  -.002089   .0699965  -.1392821   .1351042          1 
   Placebo_3 | -.0073683   .1085448  -.2201162   .2053796          1 
   Placebo_4 |  .0108111   .0769616  -.1400336   .1616559          1 

e(H)[8,5]
             Estimate          SE       LB CI       UB CI   Switchers
      ATT  -1.7115451   .97361596  -3.6198324   .19674215           1
 Effect_1  -1.2844743   .94585096  -3.1383422   .56939357           1
 Effect_2  -2.4316306   1.5322316  -5.4348046    .5715434           1
 Effect_3  -1.4185304   1.0649714  -3.5058744   .66881349           1
Placebo_1   .00213237     .097156  -.18829339   .19255813           1
Placebo_2  -.00208895   .06999651  -.13928212   .13510422           1
Placebo_3  -.00736829   .10854485  -.22011619   .20537961           1
Placebo_4   .01081112   .07696161  -.14003363   .16165587           1
(20,405 missing values generated)
(file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_irs_1_sample_events
> tudy.jpg not found)
file C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n1_rate_irs_1_sample_eventst
> udy.jpg written in JPEG format

Placebo replications (100). This may take some time.
----+--- 1 ---+--- 2 ---+--- 3 ---+--- 4 ---+--- 5
..................................................     50
..................................................     100


Synthetic Difference-in-Differences Estimator

-----------------------------------------------------------------------------
 n2_rate_irs |     ATT     Std. Err.     t      P>|t|    [95% Conf. Interval]
-------------+---------------------------------------------------------------
     Treated |  -1.61577    0.90191    -1.79    0.073    -3.38348     0.15194
-----------------------------------------------------------------------------
95% CIs and p-values are based on large-sample approximations.
Refer to Arkhangelsky et al., (2021) for theoretical derivations.
file
    C:/Users/ji252/Documents/GitHub/multnomah-county-tax/results/fig_n2_rate_irs_0_sample_all_tr
    > ends2020.pdf saved as PDF format

added scalar:
              e(count) =  2916

added scalar:
               e(mean) =  -.59132469
Synthetic Difference-in-differences

Boostrap replications (100), placebo mode.
|0% ----------------------------------------- 100%|
